{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0gwipggnJnk"
      },
      "source": [
        "# 10-714 Homework 4\n",
        "\n",
        "In this homework, you will leverage all of the components built in the last three homeworks to solve some modern problems with high performing network structures. We will start by adding a few new ops leveraging our new CPU/CUDA backends. Then, you will implement convolution, and a convolutional neural network to train a classifier on the CIFAR-10 image classification dataset. Then, you will implement recurrent and long-short term memory (LSTM) neural networks, and do word-level prediction language modeling on the Penn Treebank dataset.\n",
        "\n",
        "As always, we will start by copying this notebook and getting the starting code.\n",
        "Reminder: __you must save a copy in drive__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "mC-UJquQnJnl",
        "outputId": "8902af02-d881-4d54-8394-d0c4487b0c76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/10714\n",
            "fatal: destination path 'hw4' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/10714/hw4\n",
            "Collecting git+https://github.com/dlsys10714/mugrade.git\n",
            "  Cloning https://github.com/dlsys10714/mugrade.git to /tmp/pip-req-build-zrtfjc6u\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dlsys10714/mugrade.git /tmp/pip-req-build-zrtfjc6u\n",
            "  Resolved https://github.com/dlsys10714/mugrade.git to commit ac73f725eb2ce0e2c6a38fa540035ee970b8b873\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir -p 10714\n",
        "%cd /content/drive/MyDrive/10714\n",
        "!git clone https://github.com/dlsys10714/hw4.git\n",
        "%cd /content/drive/MyDrive/10714/hw4\n",
        "\n",
        "!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
        "!pip3 install pybind11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "4CjhlxGvnJnl"
      },
      "outputs": [],
      "source": [
        "# REQUIRED FOR MUGRADE\n",
        "MY_API_KEY = \"Ppy4ROJ4cS9i0cIXvmUM\"\n",
        "HW4_NAME = \"hw4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "pGvPluKenJnl",
        "outputId": "646e525e-fddd-4b05-90bb-94f146821126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- Found pybind11: /usr/local/lib/python3.12/dist-packages/pybind11/include (found version \"3.0.1\")\n",
            "-- Found cuda, building cuda backend\n",
            "Sun Nov 16 03:04:18 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Configuring done (0.4s)\n",
            "-- Generating done (0.2s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/hw4/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n"
          ]
        }
      ],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Hwo-sH3RnJnl",
        "outputId": "7140e0cf-71b8-402f-d256-bc34c59a18ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n"
          ]
        }
      ],
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "dDx4zzP5nJnl"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "pBhi2DD0nJnl"
      },
      "outputs": [],
      "source": [
        "# Download the datasets you will be using for this assignment\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "!mkdir -p './data/ptb'\n",
        "# Download Penn Treebank dataset\n",
        "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
        "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
        "    if not os.path.exists(os.path.join('./data/ptb', f)):\n",
        "        urllib.request.urlretrieve(ptb_data + f, os.path.join('./data/ptb', f))\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "if not os.path.isdir(\"./data/cifar-10-batches-py\"):\n",
        "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"./data/cifar-10-python.tar.gz\")\n",
        "    !tar -xvzf './data/cifar-10-python.tar.gz' -C './data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiiJj4tenJnl"
      },
      "source": [
        "To finish setting up the assignment, go ahead and fill in all the code in `python/needle/autograd.py` using your solution code from the previous homework. Also copy the solutions in `src/ndarray_backend_cpu.cc` and `src/ndarray_backend_cuda.cu` from homework 3.\n",
        "\n",
        "**Note**: Be careful not to accidentally delete or modify any new imports and function declarations when copying over code from previous assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjNdDiLCnJnl"
      },
      "source": [
        "## Part 1: ND Backend [10 pts]\n",
        "\n",
        "Recall that in homework 2, the `array_api` was imported as `numpy`. In this part, the goal is to write the necessary operations with `array_api` imported from the needle backend `NDArray` in `python/needle/backend_ndarray/ndarray.py`. Make sure to copy the solutions for `reshape`, `permute`, `broadcast_to` and `__getitem__` from homework 3.\n",
        "\n",
        "Fill in the following classes in `python/needle/ops/ops_logarithmic.py` and `python/needle/ops/ops_mathematic.py`:\n",
        "\n",
        "- `PowerScalar`\n",
        "- `EWiseDiv`\n",
        "- `DivScalar`\n",
        "- `Transpose`\n",
        "- `Reshape`\n",
        "- `BroadcastTo`\n",
        "- `Summation`\n",
        "- `MatMul`\n",
        "- `Negate`\n",
        "- `Log`\n",
        "- `Exp`\n",
        "- `ReLU`\n",
        "- `LogSumExp`\n",
        "- `Tanh` (new)\n",
        "- `Stack` (new)\n",
        "- `Split` (new)\n",
        "\n",
        "Note that for most of these, you already wrote the solutions in the previous homework and you should not change most part of your previous solution, if issues arise, please check if the `array_api` function used is supported in the needle backend.\n",
        "\n",
        "The `Tanh`, `Stack`, and `Split` operators are newly added. `Stack` concatenates same-sized tensors along a new axis, and `Split` undoes this operation. The gradients of the two operations can be written in terms of each other. We do not directly test `Split`, and only test the backward pass of `Stack` (for which we assume you used `Split`).\n",
        "\n",
        "**Note:** You may want to make your Summation op support sums over multiple axes; you will likely need it for the backward pass of the BroadcastTo op if yours supports broadcasting over multiple axes at a time. However, this is more about ease of use than necessity, and we leave this decision up to you (there are no corresponding tests).\n",
        "\n",
        "**Note:** Depending on your implementations, you may want to ensure that you call `.compact()` before reshaping arrays. (If this is necessary, you will run into corresponding error messages later in the assignment.)\n",
        "\n",
        "**Note**: Be careful not to accidentally delete or modify any new imports and function declarations when copying over code from previous assignments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "KM2G1WvBnJnl",
        "outputId": "36163365-2bb3-4ddb-f765-a8b7fb8d3e19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1685 deselected / 118 selected                          \u001b[0m\n",
            "\n",
            "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m    [  0%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m  [  1%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m    [  2%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m  [  3%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m   [  4%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m   [  5%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m   [  7%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m   [  9%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 11%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 12%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-16-16-16] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 14%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-8-8-8] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 15%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-1-2-3] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 16%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-3-4-5] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 16%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-5-4-3] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 17%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-16-16-32] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 18%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-64-64-64] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 19%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-72-72-72] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 20%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-72-73-74] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 21%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-74-73-72] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 22%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cpu-128-128-128] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 22%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-16-16-16] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 23%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-8-8-8] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 24%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-1-2-3] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 25%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-3-4-5] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 26%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-5-4-3] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 27%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-16-16-32] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 27%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-64-64-64] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 28%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-72-72-72] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 29%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-72-73-74] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 30%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-74-73-72] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 31%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_matmul[cuda-128-128-128] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 32%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_power[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 33%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_power[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 33%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_power[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 34%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_power[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 35%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_log[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 36%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_log[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 37%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_log[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 38%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_log[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 38%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_exp[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 39%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_exp[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 40%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_exp[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 41%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_exp[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 42%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_relu[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 43%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_relu[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 44%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_relu[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 44%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_relu[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 45%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_tanh[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 46%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_tanh[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 47%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_tanh[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 48%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_tanh[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 49%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_tanh_backward[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_tanh_backward[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_tanh_backward[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 51%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_tanh_backward[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 52%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack[cpu-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 53%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack[cpu-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 54%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack[cpu-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 55%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack[cuda-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 55%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack[cuda-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 56%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack[cuda-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 57%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack_backward[cpu-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack_backward[cpu-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack_backward[cpu-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack_backward[cuda-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack_backward[cuda-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_stack_backward[cuda-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 63%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 64%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 65%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 66%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation[cuda-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 66%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation[cuda-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 67%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation[cuda-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 68%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation[cuda-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 69%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_broadcast_to[cpu-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_broadcast_to[cpu-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_broadcast_to[cuda-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_broadcast_to[cuda-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_reshape[cpu-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 80%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_reshape[cpu-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 81%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_reshape[cuda-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_reshape[cuda-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes0-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 83%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes0-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 84%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes1-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 85%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes1-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 86%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cpu-None-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 87%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cpu-None-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 88%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes0-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 88%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes0-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 89%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes1-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 90%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes1-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 91%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cuda-None-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 92%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_transpose[cuda-None-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 93%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 94%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 94%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 95%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 96%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 97%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 98%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 99%]\u001b[0m\n",
            "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m===================== \u001b[32m\u001b[1m118 passed\u001b[0m, \u001b[33m1685 deselected\u001b[0m\u001b[32m in 2.64s\u001b[0m\u001b[32m =====================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"nd_backend\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCo3b3vxnJnm"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"new_nd_backend\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AkkB2wknJnm"
      },
      "source": [
        "## Part 2: CIFAR-10 dataset [10 points]\n",
        "\n",
        "Next, you will write support for the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) image classification dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50k training images and 10k test images.\n",
        "\n",
        "Start by implementing the `__init__` function in the `CIFAR10Dataset` class in `python/needle/data/datasets/cifar10_dataset.py`. You can read in the link above how to properly read the CIFAR-10 dataset files you downloaded at the beginning of the homework. Also fill in `__getitem__` and `__len__`. Note that the return shape of the data from `__getitem__` should be in order (3, 32, 32).\n",
        "\n",
        "Copy `python/needle/data/data_transforms.py` and `python/needle/data/data_basic.py` from previous homeworks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "NyG4YmejnJnm",
        "outputId": "f1db001c-f50f-4dd5-9442-c7b41580ab63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1793 deselected / 10 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[True] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 10%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[False] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 20%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m===================== \u001b[32m\u001b[1m10 passed\u001b[0m, \u001b[33m1793 deselected\u001b[0m\u001b[32m in 9.27s\u001b[0m\u001b[32m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"test_cifar10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "XK0Ns8kOnJnm",
        "outputId": "cf3331eb-bbdd-4753-dba6-5dafee3557ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_cifar_ptb_data.py \n",
            "Submitting cifar10...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 passed\n",
            "Grader test 5 passed\n",
            "Grader test 6 passed\n",
            "Grader test 7 passed\n",
            "Grader test 8 passed\n",
            "Grader test 9 passed\n",
            "Grader test 10 passed\n",
            "Grader test 11 passed\n",
            "Grader test 12 passed\n",
            "Grader test 13 passed\n",
            "Grader test 14 passed\n",
            "Grader test 15 passed\n",
            "Grader test 16 passed\n",
            "Grader test 17 passed\n",
            "Grader test 18 passed\n",
            "\u001b[32m.\u001b[0m\n",
            "\n",
            "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 22.92s\u001b[0m\u001b[32m =======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"cifar10\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "tQ_uN6zBnJnm"
      },
      "source": [
        "## Part 3: Convolutional neural network [40 points]\n",
        "\n",
        "Here's an outline of what you will do in this task.\n",
        "\n",
        "In `python/needle/backend_ndarray/ndarray.py`, implement:\n",
        "- `flip`\n",
        "- `pad`\n",
        "\n",
        "In `python/needle/ops/ops_mathematic.py`, implement (forward and backward):\n",
        "- `Flip`\n",
        "- `Dilate`\n",
        "- `UnDilate`\n",
        "- `Conv`\n",
        "\n",
        "In `python/needle/nn/nn_conv.py`, implement:\n",
        "- `Conv`\n",
        "\n",
        "In `apps/models.py`, fill in the `ResNet9` class.  \n",
        "\n",
        "In `apps/simple_ml.py`, fill in:\n",
        "- `epoch_general_cifar10`,\n",
        "- `train_cifar10`\n",
        "- `evaluate_cifar10`\n",
        "\n",
        "We have provided a `BatchNorm2d` implementation in `python/needle/nn/nn_basic.py` for you as a wrapper around your previous `BatchNorm1d` implementation.\n",
        "\n",
        "**Note**: Remember to copy the solution of `nn_basic.py` from previous homework, make sure to not overwrite the `BatchNorm2d` module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMcJB9x6nJnm"
      },
      "source": [
        "### Padding ndarrays\n",
        "\n",
        "Convolution as typically implemented in deep learning libraries cuts down the size of inputs;\n",
        "e.g., a (1, 32, 32, 3) image convolved with a 3x3 filter would give a (1, 30, 30, c) output.\n",
        "A way around this is to pad the input ndarray before performing convolution, e.g., pad with zeros to get a (1, 34, 34, 3) ndarray so that the result is (1, 32, 32, 3).\n",
        "\n",
        "Padding is also required for the backward pass of convolution.\n",
        "\n",
        "You should implement `pad` in `ndarray.py` to closely reflect the behavior of `np.pad`.\n",
        "That is, `pad` should take a tuple of 2-tuples with length equal to the number of dimensions of the array,\n",
        "where each element in the 2-tuple corresponds to \"left padding\" and \"right padding\", respectively.\n",
        "\n",
        "For example, if `A` is a (10, 32, 32, 8) ndarray (think NHWC), then `A.pad( (0, 0), (2, 2), (2, 2), (0, 0) )` would be a (10, 36, 36, 8) ndarray where the \"spatial\" dimension has been padded by two zeros on all sides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "nePH0OuanJnm",
        "outputId": "e75730bb-0e7c-4d8d-f175-854ae1ffc50e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_pad_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_pad_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m====================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 2.06s\u001b[0m\u001b[32m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"pad_forward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmzPp7KsnJnm"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4cAoDiAnJnm"
      },
      "source": [
        "### Flipping ndarrays & FlipOp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "s5xpq-7ZnJnm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import ctypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2tYQ9n8nJnm"
      },
      "source": [
        "Some utility code for a demonstration below which you can probably ignore. It might be instructive to check out the `offset` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "joQYpwOLnJnm"
      },
      "outputs": [],
      "source": [
        "# reads off the underlying data array in order (i.e., offset 0, offset 1, ..., offset n)\n",
        "# i.e., ignoring strides\n",
        "def raw_data(X):\n",
        "    X = np.array(X) # copy, thus compact X\n",
        "    return np.frombuffer(ctypes.string_at(X.ctypes.data, X.nbytes), dtype=X.dtype, count=X.size)\n",
        "\n",
        "# Xold and Xnew should reference the same underlying data\n",
        "def offset(Xold, Xnew):\n",
        "    assert Xold.itemsize == Xnew.itemsize\n",
        "    # compare addresses to the beginning of the arrays\n",
        "    return (Xnew.ctypes.data - Xold.ctypes.data)//Xnew.itemsize\n",
        "\n",
        "def strides(X):\n",
        "    return ', '.join([str(x//X.itemsize) for x in X.strides])\n",
        "\n",
        "def format_array(X, shape):\n",
        "    assert len(shape) == 3, \"I only made this formatting work for ndims = 3\"\n",
        "    def chunks(l, n):\n",
        "        n = max(1, n)\n",
        "        return (l[i:i+n] for i in range(0, len(l), n))\n",
        "    a = [str(x) if x >= 10 else ' ' + str(x) for x in X]\n",
        "    a = ['(' + ' '.join(y) + ')' for y in [x for x in chunks(a, shape[-1])]]\n",
        "    a = ['|' + ' '.join(y) + '|' for y in [x for x in chunks(a, shape[-2])]]\n",
        "    return '  '.join(a)\n",
        "\n",
        "def inspect_array(X, *, is_a_copy_of):\n",
        "    # compacts X, then reads it off in order\n",
        "    print('Data: %s' % format_array(raw_data(X), X.shape))\n",
        "    # compares address of X to copy_of, thus finding X's offset\n",
        "    print('Offset: %s' % offset(is_a_copy_of, X))\n",
        "    print('Strides: %s' % strides(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "zLOz6vVZnJnm"
      },
      "source": [
        "In order to implement the backwards pass of 2D convolution, we will (probably) need a function which _flips_\n",
        "axes of ndarrays. We say \"probably\" because you could probably cleverly implement your convolution forward\n",
        "function to avoid this. However, we think it is easiest to think about this if you have the ability to \"flip\" the kernel along its vertical and horizontal dimensions.\n",
        "\n",
        "We will try to build up your intuition for the \"flip\" operation below in order to help you figure out how to implement it in `ndarray.py`. To do that, we explore numpy's `np.flip` function below. One thing to note is that\n",
        "`flip` is typically implemented by using negative strides and changing the _offset_ of the underlying array.\n",
        "\n",
        "For example, flipping an array on _all_ of its axes is equivalent to reversing the array. In this case, you can imagine that we would want all the strides to be negative, and the offset to be the length of the array (to start at the end of the array and \"stride\" backwards).\n",
        "\n",
        "Since we did not explicitly support negative strides in our implementation for the last homework, we will merely call `NDArray.make` with them to make our \"flipped\" array and then immediately call `.compact()`. Other than changing unsigned ints to signed ints in a few places, we suspect your existing `compact` function should not have to change at all to accomodate negative strides. In the .cc and .cu files we distributed, we have already changed the function signatures to reflect this.\n",
        "\n",
        "Alternatively, you could simply implement `flip` in the CPU backend by copying memory, which you _may_ find more intuitive. We suggest following our mini tutorial below to keep your implementation Python-focused, since we believe it is involves approximately the same amount of effort to implement it slightly more naively in C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhmGfrrWnJnm"
      },
      "source": [
        "Use this array as reference for the other examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "1Had7J0tnJnm",
        "outputId": "aeb48629-a115-4993-d401-890f34084551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |( 1  2  3  4) ( 5  6  7  8)|  |( 9 10 11 12) (13 14 15 16)|  |(17 18 19 20) (21 22 23 24)|\n",
            "Offset: 0\n",
            "Strides: 8, 4, 1\n"
          ]
        }
      ],
      "source": [
        "A = np.arange(1, 25).reshape(3, 2, 4)\n",
        "inspect_array(A, is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIihPuURnJnm"
      },
      "source": [
        "We have put brackets around each axis of the array. Notice that for this array, the offset is 0 and the strides are all positive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9L5oPMTnJnm"
      },
      "source": [
        "----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiwyFlfVnJnm"
      },
      "source": [
        "See what happens when you flip the array along the last axis below.\n",
        "Note that the `inspect_array` function compacts the array after flipping it so you can see the\n",
        "\"logical\" order of the data, and the offset is calculated by comparing the address of the **non**-compacted\n",
        "flipped array with that of `is_copy_of`, i.e., the array `A` we looked at above.\n",
        "\n",
        "That is, we are looking at how numpy calculates the strides and offset for flipped arrays in order\n",
        "to copy this behavior in our own implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "kmR77SstnJnm",
        "outputId": "5a8061f1-8599-4869-deb0-ef432850da9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |( 4  3  2  1) ( 8  7  6  5)|  |(12 11 10  9) (16 15 14 13)|  |(20 19 18 17) (24 23 22 21)|\n",
            "Offset: 3\n",
            "Strides: 8, 4, -1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (2,)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TFBzDKVnJnm"
      },
      "source": [
        "So flipping the last axis reverses the order of the elements within each 4-dimensional \"cell\", as you can see above. The stride corresponding to the axis we flipped has been negated. And the offset is 3 -- this makes sense, e.g., because we want the new \"first\" element of the array to be 4, which was at index 3 in `A`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "bu7pMz0mnJnm",
        "outputId": "45fd8b73-267b-4740-8e91-d284d3b2cc85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |( 5  6  7  8) ( 1  2  3  4)|  |(13 14 15 16) ( 9 10 11 12)|  |(21 22 23 24) (17 18 19 20)|\n",
            "Offset: 4\n",
            "Strides: 8, -4, 1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (1,)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eErbOA0nJnm"
      },
      "source": [
        "Again for the middle axis: we negate the middle stride, and the offset is 4, which seems reasonable since we now want the first element to be 5, which was at index 4 in the original array `A`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "-ac9Uq_XnJnm",
        "outputId": "c7382aeb-c78f-4086-8df1-ec3a70036823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |(17 18 19 20) (21 22 23 24)|  |( 9 10 11 12) (13 14 15 16)|  |( 1  2  3  4) ( 5  6  7  8)|\n",
            "Offset: 16\n",
            "Strides: -8, 4, 1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (0,)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76e_n_wTnJnm"
      },
      "source": [
        "Try to infer the more general algorithm for computing the offset given the axis to flip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux4KCZbUnJnm"
      },
      "source": [
        "----------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKbmpc_SnJnn"
      },
      "source": [
        "Observe what happens when we flip _all_ axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "z1K2Uc75nJnn",
        "outputId": "4c99b1ee-5e92-4a56-fcdd-95f38e5a95c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |(24 23 22 21) (20 19 18 17)|  |(16 15 14 13) (12 11 10  9)|  |( 8  7  6  5) ( 4  3  2  1)|\n",
            "Offset: 23\n",
            "Strides: -8, -4, -1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (0, 1, 2)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEoChF-FnJnn"
      },
      "source": [
        "As mentioned earlier, the offset is then sufficient to point to the last element of the array, and this is just the \"reverse order\" version of `A`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCf0CQ63nJnn"
      },
      "source": [
        "When we flip just axes 1 and 0..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "HCAnvBIUnJnp",
        "outputId": "80f54967-319e-490e-ac11-79f31f194a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |(21 22 23 24) (17 18 19 20)|  |(13 14 15 16) ( 9 10 11 12)|  |( 5  6  7  8) ( 1  2  3  4)|\n",
            "Offset: 20\n",
            "Strides: -8, -4, 1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (0, 1)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDz0G0vCnJnp"
      },
      "source": [
        "The offset is 20. Looking back on our previous offset computations, do you notice something?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elLZss2VnJnp"
      },
      "source": [
        "-------------------\n",
        "\n",
        "With this exploration of numpy's ndarray flipping functionality, which uses negative strides and a custom offset,\n",
        "try to implement `flip` in `ndarray.py`. You also must implement \"flip\" forward and backward functions in `ops_mathematic.py`; note that these should be extremely short.\n",
        "\n",
        "**Important:** You should call NDArray.make with the new strides and offset, and then immediately `.compact()` this array. The resulting array is then copied and has positive strides. We want this (less-than-optimal) behavior because we did not account for negative strides in our previous implementation. _Aside:_ If you want, consider where/if negative strides break your implementation. `__getitem__` definitely doesn't work due to how we processed slices; is there anything else? (_Note_: this isn't graded.)\n",
        "\n",
        "Also, if you want to add a `flip` operator implementation on the CPU/CUDA backends instead, that's also okay.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "3nY9XLbLnJnp",
        "outputId": "cb5d6e48-8389-4c17-f8da-b91ef0ec5e6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1763 deselected / 40 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m===================== \u001b[32m\u001b[1m40 passed\u001b[0m, \u001b[33m1763 deselected\u001b[0m\u001b[32m in 2.82s\u001b[0m\u001b[32m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"flip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9EM01uZnJnp"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3EUD-6PnJnp"
      },
      "source": [
        "### Dilation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92tTXFetnJnp"
      },
      "source": [
        "The dilation operator puts zeros between elements of an ndarray. We will need it for computing the backward pass of convolution when the stride of the convolution is greater than 1. As an example, dilation should do the following to a 2x2 matrix when dilated by 1 on both axes:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "\\Longrightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 2 & 0 \\\\\n",
        "0 & 0 & 0 & 0 \\\\\n",
        "3 & 0 & 4 & 0 \\\\\n",
        "0 & 0 & 0 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "To get some intuition for why we need dilation for the backward pass of strided convolution, consider a  `stride=2`, `padding=\"same\"`, `input_channels=output_channels=8` convolution applied to an input of size (10, 32, 32, 8). The resulting output will be of size (10, 16, 16, 8) due to the stride, and thus `out_grad` will have shape (10, 16, 16, 8). Yet, the gradient of the input needs to, of course, have shape (10, 32, 32, 8) -- so we must need to increase the size of `out_grad` in some way. Consider also that you could implement strided convolution as `Conv(x)[:, ::2, ::2, :]`, i.e., only keeping every other pixel in the spatial dimension.\n",
        "\n",
        "\n",
        "Implement `Dilate` and `UnDilate` in `ops_mathematic.py`. Each operator takes two additional parameters (in attrs): the `dilation` amount and the `axes` to dilate. You must also implement the corresponding op `UnDilate`, whose forward pass will be used to implement the gradient of `Dilate`. (This is so we do not have to implement `GetItem` and `SetItem` ops, which can be highly inefficient to backprop through without additional optimizations.)\n",
        "\n",
        "**Note**: The dilation amount is additive, not multiplicative. In the example above, a dilation of `1` implies adding one row/column of zeros between each element along each dilated axis (and one removed row/column for each undilated axis). A dilation of `0` means no change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "TJp_st3DnJnp",
        "outputId": "1992a3e1-76d8-467e-bf77-c2fafd6588b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1777 deselected / 26 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_dilate_forward[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_forward[needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params10-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params10-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params11-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params11-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (0,), 'd': 1, 'shape': (2, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0,)\n",
            "d          = 1\n",
            "device     = cuda()\n",
            "params     = {'axes': (0,), 'd': 1, 'shape': (2, 5)}\n",
            "shape      = (2, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[ 1.7640525   0.40015718  0.978738    2.240893    1.8675581 ]\n",
            " [-0.9772779   0.95008844 -0.1513572  -0.10321885  0.4105985 ]]),)\n",
            "kwargs = {'axes': (0,), 'dilation': 1}, eps = 0.001\n",
            "out = needle.Tensor([[ 1.7640524   0.978738    1.867558    0.95008844 -0.10321885]\n",
            " [ 0.          0.          0.          0....1572   2.2408931  -0.9772779  -0.1513572   0.41059852]\n",
            " [ 0.          0.          0.          0.          0.        ]])\n",
            "c = array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323],\n",
            "       [ 0.33367433,  1.49407907, -0.2051582...86 ,  0.8644362 , -0.74216502,  2.26975462],\n",
            "       [-1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 9\n",
            "f1 = np.float64(3.813379646916299), f2 = np.float64(3.8088401284687454)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(5.733398933267279) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[ 1.7640525   0.40015718  0.978738    2.240893    1.8675581 ]\n",
            " [-0.9772779   0.95008844 -0.1513572  -0.10321885  0.4105985 ]]),)\n",
            "backward_grad = (needle.Tensor([[ 0.14404356  1.4542735   0.7610377   0.12167501  0.44386324]\n",
            " [-2.5529897   0.6536186   0.8644362  -0.742165    2.2697546 ]]),)\n",
            "c          = array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323],\n",
            "       [ 0.33367433,  1.49407907, -0.2051582...86 ,  0.8644362 , -0.74216502,  2.26975462],\n",
            "       [-1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(5.733398933267279)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(3.813379646916299)\n",
            "f2         = np.float64(3.8088401284687454)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 9\n",
            "kwargs     = {'axes': (0,), 'dilation': 1}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[ 0.14404172, -2.55299499,  1.45425478,  0.65364914,  0.76102793],\n",
            "       [ 0.86442507,  0.12167345, -0.74216652,  0.44386248,  2.26975922]])]\n",
            "out        = needle.Tensor([[ 1.7640524   0.978738    1.867558    0.95008844 -0.10321885]\n",
            " [ 0.          0.          0.          0....1572   2.2408931  -0.9772779  -0.1513572   0.41059852]\n",
            " [ 0.          0.          0.          0.          0.        ]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params1-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (1,), 'd': 2, 'shape': (2, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (1,)\n",
            "d          = 2\n",
            "device     = cuda()\n",
            "params     = {'axes': (1,), 'd': 2, 'shape': (2, 5)}\n",
            "shape      = (2, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[ 1.7640525   0.40015718  0.978738    2.240893    1.8675581 ]\n",
            " [-0.9772779   0.95008844 -0.1513572  -0.10321885  0.4105985 ]]),)\n",
            "kwargs = {'axes': (1,), 'dilation': 2}, eps = 0.001\n",
            "out = needle.Tensor([[ 1.7640524   0.          0.          0.978738    0.          0.\n",
            "   1.867558    0.          0.         ...          0.\n",
            "  -0.9772779   0.          0.         -0.1513572   0.          0.\n",
            "   0.41059852  0.          0.        ]])\n",
            "c = array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,\n",
            "         0.33367433,  1.49407907, -0.20515826...6252, -0.88778575, -1.98079647, -0.34791215,\n",
            "         0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 9\n",
            "f1 = np.float64(5.293581357668904), f2 = np.float64(5.29117659309795)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(4.638273686060527) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[ 1.7640525   0.40015718  0.978738    2.240893    1.8675581 ]\n",
            " [-0.9772779   0.95008844 -0.1513572  -0.10321885  0.4105985 ]]),)\n",
            "backward_grad = (needle.Tensor([[ 0.14404356  0.12167501  1.4940791  -0.85409576  0.8644362 ]\n",
            " [-1.4543657   1.5327792   0.37816253 -0.34791216  1.2023798 ]]),)\n",
            "c          = array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,\n",
            "         0.33367433,  1.49407907, -0.20515826...6252, -0.88778575, -1.98079647, -0.34791215,\n",
            "         0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(4.638273686060527)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(5.293581357668904)\n",
            "f2         = np.float64(5.29117659309795)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 9\n",
            "kwargs     = {'axes': (1,), 'dilation': 2}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[ 0.14404172, -1.45436862,  0.12167345,  1.53285084,  1.49405984],\n",
            "       [ 0.37815765, -0.85408474, -0.34791285,  0.86443473,  1.20238229]])]\n",
            "out        = needle.Tensor([[ 1.7640524   0.          0.          0.978738    0.          0.\n",
            "   1.867558    0.          0.         ...          0.\n",
            "  -0.9772779   0.          0.         -0.1513572   0.          0.\n",
            "   0.41059852  0.          0.        ]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params2-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'd': 1, 'shape': (2, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0, 1)\n",
            "d          = 1\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'd': 1, 'shape': (2, 5)}\n",
            "shape      = (2, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[ 1.7640525   0.40015718  0.978738    2.240893    1.8675581 ]\n",
            " [-0.9772779   0.95008844 -0.1513572  -0.10321885  0.4105985 ]]),)\n",
            "kwargs = {'axes': (0, 1), 'dilation': 1}, eps = 0.001\n",
            "out = needle.Tensor([[ 1.7640524   0.          0.978738    0.          1.867558    0.\n",
            "   0.95008844  0.         -0.10321885 ...\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]])\n",
            "c = array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,\n",
            "         0.33367433,  1.49407907, -0.20515826...1794, -1.70627019,  1.9507754 , -0.50965218,\n",
            "        -0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 9\n",
            "f1 = np.float64(1.2820310367383771), f2 = np.float64(1.2828056919430735)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(3.9263984614144847) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[ 1.7640525   0.40015718  0.978738    2.240893    1.8675581 ]\n",
            " [-0.9772779   0.95008844 -0.1513572  -0.10321885  0.4105985 ]]),)\n",
            "backward_grad = (needle.Tensor([[ 0.14404356  0.7610377   0.44386324  1.4940791   0.3130677 ]\n",
            " [ 0.15494743 -0.88778573 -0.34791216  1.2302907  -0.3873268 ]]),)\n",
            "c          = array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,\n",
            "         0.33367433,  1.49407907, -0.20515826...1794, -1.70627019,  1.9507754 , -0.50965218,\n",
            "        -0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(3.9263984614144847)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(1.2820310367383771)\n",
            "f2         = np.float64(1.2828056919430735)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 9\n",
            "kwargs     = {'axes': (0, 1), 'dilation': 1}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[ 0.14404172,  0.15494774,  0.76102793, -0.88782723,  0.44385752],\n",
            "       [-0.34790767,  1.49405984,  1.23029317,  0.31306717, -0.3873276 ]])]\n",
            "out        = needle.Tensor([[ 1.7640524   0.          0.978738    0.          1.867558    0.\n",
            "   0.95008844  0.         -0.10321885 ...\n",
            " [ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.        ]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params3-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'd': 0, 'shape': (2, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0, 1)\n",
            "d          = 0\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'd': 0, 'shape': (2, 5)}\n",
            "shape      = (2, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[ 1.7640525   0.40015718  0.978738    2.240893    1.8675581 ]\n",
            " [-0.9772779   0.95008844 -0.1513572  -0.10321885  0.4105985 ]]),)\n",
            "kwargs = {'axes': (0, 1), 'dilation': 0}, eps = 0.001\n",
            "out = needle.Tensor([[ 1.7640524   0.978738    1.867558    0.95008844 -0.10321885]\n",
            " [ 0.4001572   2.2408931  -0.9772779  -0.1513572   0.41059852]])\n",
            "c = array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323],\n",
            "       [ 0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 9\n",
            "f1 = np.float64(6.451682740762536), f2 = np.float64(6.453390935702888)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(2.4859746410943573) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[ 1.7640525   0.40015718  0.978738    2.240893    1.8675581 ]\n",
            " [-0.9772779   0.95008844 -0.1513572  -0.10321885  0.4105985 ]]),)\n",
            "backward_grad = (needle.Tensor([[ 0.14404356  1.4542735   0.7610377   0.12167501  0.44386324]\n",
            " [ 0.33367434  1.4940791  -0.20515826  0.3130677  -0.85409576]]),)\n",
            "c          = array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323],\n",
            "       [ 0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(2.4859746410943573)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(6.451682740762536)\n",
            "f2         = np.float64(6.453390935702888)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 9\n",
            "kwargs     = {'axes': (0, 1), 'dilation': 0}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[ 0.14404172,  0.333675  ,  1.45425478,  1.49414889,  0.76102793],\n",
            "       [-0.20515562,  0.12167345,  0.31306834,  0.44386248, -0.85409747]])]\n",
            "out        = needle.Tensor([[ 1.7640524   0.978738    1.867558    0.95008844 -0.10321885]\n",
            " [ 0.4001572   2.2408931  -0.9772779  -0.1513572   0.41059852]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params4-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'd': 2, 'shape': (2, 3, 3, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0, 1)\n",
            "d          = 2\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'd': 2, 'shape': (2, 3, 3, 4)}\n",
            "shape      = (2, 3, 3, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "kwargs = {'axes': (0, 1), 'dilation': 2}, eps = 0.001\n",
            "out = needle.Tensor([[[[ 1.7640524   0.3130677   1.2302907  -0.02818223]\n",
            "   [ 0.95008844  2.2697546  -1.7062702  -0.67246044...        ]\n",
            "   [ 0.          0.          0.          0.        ]\n",
            "   [ 0.          0.          0.          0.        ]]]])\n",
            "c = array([[[[ 1.13940068e+00, -1.23482582e+00,  4.02341641e-01,\n",
            "          -6.84810091e-01],\n",
            "         [-8.70797149e-01, -5...          -1.01281486e-01],\n",
            "         [-8.03141387e-01, -4.64337691e-01,  1.02179059e+00,\n",
            "          -5.52540673e-01]]]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 71\n",
            "f1 = np.float64(13.318270179684738), f2 = np.float64(13.317278175781702)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(11.95571362856236) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "backward_grad = (needle.Tensor([[[[ 1.1394007  -1.2348258   0.40234163 -0.6848101 ]\n",
            "   [-0.87079716 -0.5788497  -0.31155252  0.0561653...945464]\n",
            "   [-0.27567053 -0.70972794  1.7388726   0.99439436]\n",
            "   [ 1.3191369  -0.8824188   1.128594    0.49600095]]]]),)\n",
            "c          = array([[[[ 1.13940068e+00, -1.23482582e+00,  4.02341641e-01,\n",
            "          -6.84810091e-01],\n",
            "         [-8.70797149e-01, -5...          -1.01281486e-01],\n",
            "         [-8.03141387e-01, -4.64337691e-01,  1.02179059e+00,\n",
            "          -5.52540673e-01]]]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(11.95571362856236)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(13.318270179684738)\n",
            "f2         = np.float64(13.317278175781702)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 71\n",
            "kwargs     = {'axes': (0, 1), 'dilation': 2}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[[[ 1.13938602,  0.85792566,  1.92291727,  0.86900409],\n",
            "         [ 2.38311409, -2.28859057, -0.87078594, -0.59... 1.71334619,  0.99439641, -1.53622391,  0.05892571],\n",
            "         [ 0.9221948 ,  0.19429297, -0.66346974,  0.49600195]]]])]\n",
            "out        = needle.Tensor([[[[ 1.7640524   0.3130677   1.2302907  -0.02818223]\n",
            "   [ 0.95008844  2.2697546  -1.7062702  -0.67246044...        ]\n",
            "   [ 0.          0.          0.          0.        ]\n",
            "   [ 0.          0.          0.          0.        ]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params5-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'd': 3, 'shape': (3, 3, 6, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0, 1)\n",
            "d          = 3\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'd': 3, 'shape': (3, 3, 6, 4)}\n",
            "shape      = (3, 3, 6, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...80309 ]\n",
            "   [ 0.27992457 -0.09815038  0.9101789   0.31721818]\n",
            "   [ 0.78632796 -0.46641913 -0.94444627 -0.41004974]]]]),)\n",
            "kwargs = {'axes': (0, 1), 'dilation': 3}, eps = 0.001\n",
            "out = needle.Tensor([[[[ 1.7640524  -0.02818223  1.922942    0.9494208 ]\n",
            "   [ 0.41059852 -1.7262826  -0.15501009  0.31872764...        ]\n",
            "   [ 0.          0.          0.          0.        ]\n",
            "   [ 0.          0.          0.          0.        ]]]])\n",
            "c = array([[[[-1.70204139e-02,  3.79151736e-01,  2.25930895e+00,\n",
            "          -4.22571517e-02],\n",
            "         [-9.55945000e-01, -3...          -6.30225748e-01],\n",
            "         [-1.34319254e+00,  7.58038051e-01, -5.83840844e-01,\n",
            "          -1.02370145e+00]]]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 215\n",
            "f1 = np.float64(-8.504169963537874), f2 = np.float64(-8.507375697293222)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(18.851855029280763) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...80309 ]\n",
            "   [ 0.27992457 -0.09815038  0.9101789   0.31721818]\n",
            "   [ 0.78632796 -0.46641913 -0.94444627 -0.41004974]]]]),)\n",
            "backward_grad = (needle.Tensor([[[[-1.7020414e-02  3.7915173e-01  2.2593091e+00 -4.2257152e-02]\n",
            "   [-9.5594501e-01 -3.4598178e-01 -4.6...01  2.2542837e+00  6.7263675e-01  2.5983250e-01]\n",
            "   [-7.3718518e-01 -6.7832983e-01 -8.3288394e-02  1.6028637e+00]]]]),)\n",
            "c          = array([[[[-1.70204139e-02,  3.79151736e-01,  2.25930895e+00,\n",
            "          -4.22571517e-02],\n",
            "         [-9.55945000e-01, -3...          -6.30225748e-01],\n",
            "         [-1.34319254e+00,  7.58038051e-01, -5.83840844e-01,\n",
            "          -1.02370145e+00]]]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(18.851855029280763)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(-8.504169963537874)\n",
            "f2         = np.float64(-8.507375697293222)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 215\n",
            "kwargs     = {'axes': (0, 1), 'dilation': 3}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[[[-1.70201947e-02,  4.57310573e-01,  1.02177011e-01,\n",
            "          -1.12687847e+00],\n",
            "         [ 1.12556082e-01, -...          9.07700637e-01],\n",
            "         [-1.66182697e+00, -1.41690898e+00, -2.54120609e+00,\n",
            "           1.60286688e+00]]]])]\n",
            "out        = needle.Tensor([[[[ 1.7640524  -0.02818223  1.922942    0.9494208 ]\n",
            "   [ 0.41059852 -1.7262826  -0.15501009  0.31872764...        ]\n",
            "   [ 0.          0.          0.          0.        ]\n",
            "   [ 0.          0.          0.          0.        ]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params6-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (1, 2), 'd': 0, 'shape': (2, 3, 3, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (1, 2)\n",
            "d          = 0\n",
            "device     = cuda()\n",
            "params     = {'axes': (1, 2), 'd': 0, 'shape': (2, 3, 3, 4)}\n",
            "shape      = (2, 3, 3, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "kwargs = {'axes': (1, 2), 'dilation': 0}, eps = 0.001\n",
            "out = needle.Tensor([[[[ 1.7640524   0.3130677   1.2302907  -0.02818223]\n",
            "   [ 0.95008844  2.2697546  -1.7062702  -0.67246044...36274117]\n",
            "   [ 1.4542735   1.4693588   0.7774904  -0.40178093]\n",
            "   [-0.20515826  0.15634897 -1.1806322   0.12898292]]]])\n",
            "c = array([[[[ 1.13940068, -1.23482582,  0.40234164, -0.68481009],\n",
            "         [-0.87079715, -0.57884966, -0.31155253,  0.056...[ 0.57659082, -0.20829876,  0.39600671, -1.09306151],\n",
            "         [-1.49125759,  0.4393917 ,  0.1666735 ,  0.63503144]]]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 71\n",
            "f1 = np.float64(-8.149152619547696), f2 = np.float64(-8.150422684995336)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(11.506137577176508) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "backward_grad = (needle.Tensor([[[[ 1.1394007  -1.2348258   0.40234163 -0.6848101 ]\n",
            "   [-0.87079716 -0.5788497  -0.31155252  0.0561653...643327]\n",
            "   [ 0.57659084 -0.20829876  0.3960067  -1.0930616 ]\n",
            "   [-1.4912575   0.4393917   0.1666735   0.63503146]]]]),)\n",
            "c          = array([[[[ 1.13940068, -1.23482582,  0.40234164, -0.68481009],\n",
            "         [-0.87079715, -0.57884966, -0.31155253,  0.056...[ 0.57659082, -0.20829876,  0.39600671, -1.09306151],\n",
            "         [-1.49125759,  0.4393917 ,  0.1666735 ,  0.63503144]]]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(11.506137577176508)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(-8.149152619547696)\n",
            "f2         = np.float64(-8.150422684995336)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 71\n",
            "kwargs     = {'axes': (1, 2), 'dilation': 0}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[[[ 1.13938602,  1.92294592,  1.48823303,  0.37644312],\n",
            "         [ 0.01049989, -0.67432398, -0.87078594, -0.86... 0.96939867, -1.09306372, -1.53622391,  0.92220854],\n",
            "         [ 0.70656407,  0.53924928, -0.74744519,  0.63503272]]]])]\n",
            "out        = needle.Tensor([[[[ 1.7640524   0.3130677   1.2302907  -0.02818223]\n",
            "   [ 0.95008844  2.2697546  -1.7062702  -0.67246044...36274117]\n",
            "   [ 1.4542735   1.4693588   0.7774904  -0.40178093]\n",
            "   [-0.20515826  0.15634897 -1.1806322   0.12898292]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params7-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (1, 2), 'd': 1, 'shape': (2, 3, 3, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (1, 2)\n",
            "d          = 1\n",
            "device     = cuda()\n",
            "params     = {'axes': (1, 2), 'd': 1, 'shape': (2, 3, 3, 4)}\n",
            "shape      = (2, 3, 3, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "kwargs = {'axes': (1, 2), 'dilation': 1}, eps = 0.001\n",
            "out = needle.Tensor([[[[ 1.7640524   0.3130677   1.2302907  -0.02818223]\n",
            "   [ 0.          0.          0.          0.        ...        ]\n",
            "   [ 0.          0.          0.          0.        ]\n",
            "   [ 0.          0.          0.          0.        ]]]])\n",
            "c = array([[[[ 1.13940068, -1.23482582,  0.40234164, -0.68481009],\n",
            "         [-0.87079715, -0.57884966, -0.31155253,  0.056...[ 1.36453185, -0.68944918, -0.6522936 , -0.52118931],\n",
            "         [-1.84306955, -0.477974  , -0.47965581,  0.6203583 ]]]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 71\n",
            "f1 = np.float64(6.538034623457447), f2 = np.float64(6.540412518186787)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(9.369915933145588) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "backward_grad = (needle.Tensor([[[[ 1.1394007  -1.2348258   0.40234163 -0.6848101 ]\n",
            "   [-1.1651498   0.9008265   0.46566245 -1.5362437...435159]\n",
            "   [-0.7196044  -0.812993    0.27451634 -0.8909151 ]\n",
            "   [-0.7047003   0.9432607   0.7471883  -1.1889449 ]]]]),)\n",
            "c          = array([[[[ 1.13940068, -1.23482582,  0.40234164, -0.68481009],\n",
            "         [-0.87079715, -0.57884966, -0.31155253,  0.056...[ 1.36453185, -0.68944918, -0.6522936 , -0.52118931],\n",
            "         [-1.84306955, -0.477974  , -0.47965581,  0.6203583 ]]]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(9.369915933145588)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(6.538034623457447)\n",
            "f2         = np.float64(6.540412518186787)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 71\n",
            "kwargs     = {'axes': (1, 2), 'dilation': 1}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[[[ 1.13938602, -0.01702045,  0.37642068, -1.93637029],\n",
            "         [ 1.1880145 , -1.1268113 , -1.16513484, -1.54... 0.01747919, -0.89091689,  1.22242933,  0.78119968],\n",
            "         [-1.09304744,  1.53637731,  0.05216441, -1.18894736]]]])]\n",
            "out        = needle.Tensor([[[[ 1.7640524   0.3130677   1.2302907  -0.02818223]\n",
            "   [ 0.          0.          0.          0.        ...        ]\n",
            "   [ 0.          0.          0.          0.        ]\n",
            "   [ 0.          0.          0.          0.        ]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params8-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (1, 2), 'd': 1, 'shape': (3, 3, 6, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (1, 2)\n",
            "d          = 1\n",
            "device     = cuda()\n",
            "params     = {'axes': (1, 2), 'd': 1, 'shape': (3, 3, 6, 4)}\n",
            "shape      = (3, 3, 6, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...80309 ]\n",
            "   [ 0.27992457 -0.09815038  0.9101789   0.31721818]\n",
            "   [ 0.78632796 -0.46641913 -0.94444627 -0.41004974]]]]),)\n",
            "kwargs = {'axes': (1, 2), 'dilation': 1}, eps = 0.001\n",
            "out = needle.Tensor([[[[ 1.7640524  -0.02818223  1.922942    0.9494208 ]\n",
            "   [ 0.          0.          0.          0.        ...        ]\n",
            "   [ 0.          0.          0.          0.        ]\n",
            "   [ 0.          0.          0.          0.        ]]]])\n",
            "c = array([[[[-1.70204139e-02,  3.79151736e-01,  2.25930895e+00,\n",
            "          -4.22571517e-02],\n",
            "         [-9.55945000e-01, -3...           9.38746876e-01],\n",
            "         [ 6.07111672e-01, -1.04817041e+00, -8.60262452e-01,\n",
            "           3.28301295e-01]]]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 215\n",
            "f1 = np.float64(-12.254145233333935), f2 = np.float64(-12.251975516817964)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(20.140864061063038) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...80309 ]\n",
            "   [ 0.27992457 -0.09815038  0.9101789   0.31721818]\n",
            "   [ 0.78632796 -0.46641913 -0.94444627 -0.41004974]]]]),)\n",
            "backward_grad = (needle.Tensor([[[[-0.01702041  0.37915173  2.259309   -0.04225715]\n",
            "   [-1.540797    0.06326199  0.15650654  0.2321810...39857 ]\n",
            "   [ 0.22425222 -1.6786884   0.2149656   0.09721923]\n",
            "   [ 1.7123052  -0.79211503 -1.0455246  -1.084856  ]]]]),)\n",
            "c          = array([[[[-1.70204139e-02,  3.79151736e-01,  2.25930895e+00,\n",
            "          -4.22571517e-02],\n",
            "         [-9.55945000e-01, -3...           9.38746876e-01],\n",
            "         [ 6.07111672e-01, -1.04817041e+00, -8.60262452e-01,\n",
            "           3.28301295e-01]]]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(20.140864061063038)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(-12.254145233333935)\n",
            "f2         = np.float64(-12.251975516817964)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 215\n",
            "kwargs     = {'axes': (1, 2), 'dilation': 1}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[[[-0.01702019, -0.34745136, -0.89738937, -1.12687847],\n",
            "         [-1.55040938,  0.27116669, -0.18505129, -0.34...-2.55918985,  0.86727516, -0.5211826 , -0.99621466],\n",
            "         [-0.2585693 ,  0.8202495 , -0.98798922, -1.08485826]]]])]\n",
            "out        = needle.Tensor([[[[ 1.7640524  -0.02818223  1.922942    0.9494208 ]\n",
            "   [ 0.          0.          0.          0.        ...        ]\n",
            "   [ 0.          0.          0.          0.        ]\n",
            "   [ 0.          0.          0.          0.        ]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params9-needle.backend_ndarray.ndarray_backend_cuda] ___\u001b[0m\n",
            "\n",
            "params = {'axes': (2, 3), 'd': 1, 'shape': (2, 3, 3, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (2, 3)\n",
            "d          = 1\n",
            "device     = cuda()\n",
            "params     = {'axes': (2, 3), 'd': 1, 'shape': (2, 3, 3, 4)}\n",
            "shape      = (2, 3, 3, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "kwargs = {'axes': (2, 3), 'dilation': 1}, eps = 0.001\n",
            "out = needle.Tensor([[[[ 1.7640524   0.          0.3130677   0.          1.2302907\n",
            "     0.         -0.02818223  0.        ]\n",
            "...98292  0.        ]\n",
            "   [ 0.          0.          0.          0.          0.\n",
            "     0.          0.          0.        ]]]])\n",
            "c = array([[[[ 1.13940068, -1.23482582,  0.40234164, -0.68481009,\n",
            "          -0.87079715, -0.57884966, -0.31155253,  0.0561... [ 1.36453185, -0.68944918, -0.6522936 , -0.52118931,\n",
            "          -1.84306955, -0.477974  , -0.47965581,  0.6203583 ]]]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 71\n",
            "f1 = np.float64(-5.366166421555186), f2 = np.float64(-5.36463813061021)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(11.429023353574536) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "backward_grad = (needle.Tensor([[[[ 1.1394007   0.40234163 -0.87079716 -0.31155252]\n",
            "   [-1.0707526  -0.40317693  0.20827498  0.3563664...16264 ]\n",
            "   [-0.7047003   0.7471883   0.77325296 -2.6591723 ]\n",
            "   [-0.44092262 -0.36469355  0.5785215  -0.76414394]]]]),)\n",
            "c          = array([[[[ 1.13940068, -1.23482582,  0.40234164, -0.68481009,\n",
            "          -0.87079715, -0.57884966, -0.31155253,  0.0561... [ 1.36453185, -0.68944918, -0.6522936 , -0.52118931,\n",
            "          -1.84306955, -0.477974  , -0.47965581,  0.6203583 ]]]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(11.429023353574536)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(-5.366166421555186)\n",
            "f2         = np.float64(-5.36463813061021)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 71\n",
            "kwargs     = {'axes': (2, 3), 'dilation': 1}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[[[ 1.13938602, -0.01702045,  0.37642068, -1.93637029],\n",
            "         [ 1.1880145 , -1.1268113 , -1.07073884, -0.54...-1.29285953, -2.65917763,  1.86753492,  0.69154015],\n",
            "         [-1.14745388, -0.11816406, -0.02432581, -0.76414547]]]])]\n",
            "out        = needle.Tensor([[[[ 1.7640524   0.          0.3130677   0.          1.2302907\n",
            "     0.         -0.02818223  0.        ]\n",
            "...98292  0.        ]\n",
            "   [ 0.          0.          0.          0.          0.\n",
            "     0.          0.          0.        ]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params10-needle.backend_ndarray.ndarray_backend_cuda] __\u001b[0m\n",
            "\n",
            "params = {'axes': (2, 3), 'd': 1, 'shape': (3, 3, 6, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (2, 3)\n",
            "d          = 1\n",
            "device     = cuda()\n",
            "params     = {'axes': (2, 3), 'd': 1, 'shape': (3, 3, 6, 4)}\n",
            "shape      = (3, 3, 6, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...80309 ]\n",
            "   [ 0.27992457 -0.09815038  0.9101789   0.31721818]\n",
            "   [ 0.78632796 -0.46641913 -0.94444627 -0.41004974]]]]),)\n",
            "kwargs = {'axes': (2, 3), 'dilation': 1}, eps = 0.001\n",
            "out = needle.Tensor([[[[ 1.7640524   0.         -0.02818223  0.          1.922942\n",
            "     0.          0.9494208   0.        ]\n",
            " ...0497   0.        ]\n",
            "   [ 0.          0.          0.          0.          0.\n",
            "     0.          0.          0.        ]]]])\n",
            "c = array([[[[-1.70204139e-02,  3.79151736e-01,  2.25930895e+00,\n",
            "          -4.22571517e-02, -9.55945000e-01, -3.45981776e-...14709e-02,\n",
            "           9.38746876e-01,  6.07111672e-01, -1.04817041e+00,\n",
            "          -8.60262452e-01,  3.28301295e-01]]]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 215\n",
            "f1 = np.float64(17.58554096851964), f2 = np.float64(17.58760393762099)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(18.305306630466177) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...80309 ]\n",
            "   [ 0.27992457 -0.09815038  0.9101789   0.31721818]\n",
            "   [ 0.78632796 -0.46641913 -0.94444627 -0.41004974]]]]),)\n",
            "backward_grad = (needle.Tensor([[[[-0.01702041  2.259309   -0.955945   -0.463596  ]\n",
            "   [-0.54286146 -1.1561824   1.4944845   0.4262587...262553]\n",
            "   [ 0.03308975 -0.71994054 -0.15602389  3.1709747 ]\n",
            "   [ 0.09837791  0.06749225  0.2843145  -1.0314825 ]]]]),)\n",
            "c          = array([[[[-1.70204139e-02,  3.79151736e-01,  2.25930895e+00,\n",
            "          -4.22571517e-02, -9.55945000e-01, -3.45981776e-...14709e-02,\n",
            "           9.38746876e-01,  6.07111672e-01, -1.04817041e+00,\n",
            "          -8.60262452e-01,  3.28301295e-01]]]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(18.305306630466177)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(17.58554096851964)\n",
            "f2         = np.float64(17.58760393762099)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 215\n",
            "kwargs     = {'axes': (2, 3), 'dilation': 1}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[[[-0.01702019, -0.34745136, -0.89738937, -1.12687847],\n",
            "         [-1.55040938,  0.27116669, -0.18505129, -0.34... 0.54331299,  0.05095419,  1.46655983,  2.11679531],\n",
            "         [ 2.01403422,  2.69622952,  0.61191931, -1.03148455]]]])]\n",
            "out        = needle.Tensor([[[[ 1.7640524   0.         -0.02818223  0.          1.922942\n",
            "     0.          0.9494208   0.        ]\n",
            " ...0497   0.        ]\n",
            "   [ 0.          0.          0.          0.          0.\n",
            "     0.          0.          0.        ]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[31m\u001b[1m__ test_dilate_backward[params11-needle.backend_ndarray.ndarray_backend_cuda] __\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1, 2, 3), 'd': 1, 'shape': (2, 3, 3, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, dilate_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dilate_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, d, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.dilate, ndl.Tensor(np.random.randn(*shape), device=device), dilation=d, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0, 1, 2, 3)\n",
            "d          = 1\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1, 2, 3), 'd': 1, 'shape': (2, 3, 3, 4)}\n",
            "shape      = (2, 3, 3, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:296: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "f = <function dilate at 0x7cc387fc0860>\n",
            "args = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "kwargs = {'axes': (0, 1, 2, 3), 'dilation': 1}, eps = 0.001\n",
            "out = needle.Tensor([[[[ 1.7640524   0.          0.3130677  ...  0.         -0.02818223\n",
            "     0.        ]\n",
            "   [ 0.          0....  ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]]]])\n",
            "c = array([[[[ 1.13940068e+00, -1.23482582e+00,  4.02341641e-01, ...,\n",
            "          -5.78849665e-01, -3.11552532e-01,  5.61653...7.51946588e-01,  5.62989719e-01, -1.19498681e+00, ...,\n",
            "          -4.08014709e-01,  1.77465856e+00, -3.93153195e-01]]]])\n",
            "is_stacked = False, num_args = 1, i = 0, j = 71\n",
            "f1 = np.float64(-17.885390484415126), f2 = np.float64(-17.88549239317567)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mbackward_check\u001b[39;49;00m(f, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        eps = \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = f(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        c = np.random.randn(*out.shape)\u001b[90m\u001b[39;49;00m\n",
            "        is_stacked = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(args[\u001b[94m0\u001b[39;49;00m], \u001b[96mlist\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            args = args[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "            is_stacked = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        numerical_grad = [np.zeros(a.shape) \u001b[94mfor\u001b[39;49;00m a \u001b[95min\u001b[39;49;00m args]\u001b[90m\u001b[39;49;00m\n",
            "        num_args = \u001b[96mlen\u001b[39;49;00m(args)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_args):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m j \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(args[i].realize_cached_data().size):\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f1 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] -= \u001b[94m2\u001b[39;49;00m * eps\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m is_stacked:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    f2 = (f(*args, **kwargs).numpy() * c).sum()\u001b[90m\u001b[39;49;00m\n",
            "                args[i].realize_cached_data().flat[j] += eps\u001b[90m\u001b[39;49;00m\n",
            "                numerical_grad[i].flat[j] = (f1 - f2) / (\u001b[94m2\u001b[39;49;00m * eps)\u001b[90m\u001b[39;49;00m\n",
            "        backward_grad = out.op.gradient_as_tuple(ndl.Tensor(c, device=args[\u001b[94m0\u001b[39;49;00m].device), out)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(backward_grad[\u001b[94m0\u001b[39;49;00m], ndl.TensorTuple): \u001b[90m# TODO keep this?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            backward_grad = backward_grad[\u001b[94m0\u001b[39;49;00m].tuple()\u001b[90m\u001b[39;49;00m\n",
            "        error = \u001b[96msum\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            np.linalg.norm(backward_grad[i].numpy() - numerical_grad[i])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[96mlen\u001b[39;49;00m(args))\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m error < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.float64(10.45429236243762) < 0.01\u001b[0m\n",
            "\n",
            "args       = (needle.Tensor([[[[ 1.7640525   0.40015718  0.978738    2.240893  ]\n",
            "   [ 1.8675581  -0.9772779   0.95008844 -0.1513572...62825 ]\n",
            "   [ 0.17742614 -0.40178096 -1.6301982   0.46278223]\n",
            "   [-0.9072984   0.05194539  0.7290906   0.12898292]]]]),)\n",
            "backward_grad = (needle.Tensor([[[[ 1.1394007   0.40234163 -0.87079716 -0.31155252]\n",
            "   [-1.0707526  -0.40317693  0.20827498  0.3563664...57403 ]\n",
            "   [-1.6429653  -0.53527015  1.154184    0.02106202]\n",
            "   [-0.24133779  0.69938046 -0.222477    0.05095428]]]]),)\n",
            "c          = array([[[[ 1.13940068e+00, -1.23482582e+00,  4.02341641e-01, ...,\n",
            "          -5.78849665e-01, -3.11552532e-01,  5.61653...7.51946588e-01,  5.62989719e-01, -1.19498681e+00, ...,\n",
            "          -4.08014709e-01,  1.77465856e+00, -3.93153195e-01]]]])\n",
            "eps        = 0.001\n",
            "error      = np.float64(10.45429236243762)\n",
            "f          = <function dilate at 0x7cc387fc0860>\n",
            "f1         = np.float64(-17.885390484415126)\n",
            "f2         = np.float64(-17.88549239317567)\n",
            "i          = 0\n",
            "is_stacked = False\n",
            "j          = 71\n",
            "kwargs     = {'axes': (0, 1, 2, 3), 'dilation': 1}\n",
            "num_args   = 1\n",
            "numerical_grad = [array([[[[ 1.13938602, -0.60065877,  1.1880145 , -0.76573798],\n",
            "         [-1.93625488,  0.23957968, -1.07073884, -0.44...-1.04525548,  0.02106206,  1.86753492,  2.11679531],\n",
            "         [-0.02432581,  0.61192729, -0.11816252,  0.05095438]]]])]\n",
            "out        = needle.Tensor([[[[ 1.7640524   0.          0.3130677  ...  0.         -0.02818223\n",
            "     0.        ]\n",
            "   [ 0.          0....  ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:45: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(5.733398933267279) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params1-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(4.638273686060527) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params2-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(3.9263984614144847) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params3-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(2.4859746410943573) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params4-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(11.95571362856236) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params5-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(18.851855029280763) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params6-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(11.506137577176508) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params7-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(9.369915933145588) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params8-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(20.140864061063038) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params9-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(11.429023353574536) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params10-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(18.305306630466177) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_dilate_backward[params11-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.float64(10.45429236243762) < 0.01\n",
            "\u001b[31m================ \u001b[31m\u001b[1m12 failed\u001b[0m, \u001b[32m14 passed\u001b[0m, \u001b[33m1777 deselected\u001b[0m\u001b[31m in 3.37s\u001b[0m\u001b[31m ================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"dilate\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRWbYsFynJnp"
      },
      "source": [
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVgHLjLenJnp"
      },
      "source": [
        "### Submit new ops (flip/dilation) to mugrade [10 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "f5RCgIlrnJnp",
        "outputId": "06c32560-899a-4c9f-d255-a6eb8ca3f3cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py \n",
            "Submitting new_ops...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 passed\n",
            "Grader test 5 passed\n",
            "Grader test 6 passed\n",
            "Grader test 7 passed\n",
            "Grader test 8 passed\n",
            "Grader test 9 passed\n",
            "Grader test 10 passed\n",
            "Grader test 11 passed\n",
            "\u001b[32m.\u001b[0m\n",
            "\n",
            "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 7.23s\u001b[0m\u001b[32m ========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"new_ops\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3MM34kjnJnp"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m33BxHJxnJnq"
      },
      "source": [
        "### Convolution forward\n",
        "\n",
        "Implement the forward pass of 2D multi-channel convolution in `ops_mathematic.py`. You should probably refer to [this notebook](https://github.com/dlsyscourse/public_notebooks/blob/main/convolution_implementation.ipynb) from lecture, which implements 2D multi-channel convolution using im2col in numpy.\n",
        "\n",
        "**Note:** Your convolution op should accept tensors in the NHWC format, as in the example above, and weights in the format (kernel_size, kernel_size, input_channels, output_channels).\n",
        "\n",
        "However, you will need to add two additional features. Your convolution function should accept arguments for `padding` (default 0) and `stride` (default 1). For `padding`, you should simply apply your padding function to the spatial dimensions (i.e., axes 1 and 2).\n",
        "\n",
        "Implementing strided convolution should consist of a relatively small set of changes to your plain convolution implementation.\n",
        "\n",
        "We recommend working your way up through the full feature set: Implement convolution without stride first, ensuring you pass some of the tests below, and then add in support for stride."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "roz-YYwjnJnq",
        "outputId": "9a208730-7944-4560-a9eb-6ed261956732",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 1\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m err3 < \u001b[94m1e-1\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33moutputs match \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (y2, out2)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: outputs match [-18337.072], tensor(-12155.8203, grad_fn=<SumBackward0>)\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(6181.252) < 0.1\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
            "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
            "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
            "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "err3       = np.float32(6181.252)\n",
            "out        = tensor([[[[ 107.2545, -109.1249,   -9.3744,  ...,  118.7832,  127.2525,\n",
            "           -146.6358],\n",
            "          [-296.2552,  ...[-107.9026,   -8.9582,  137.1271,  ..., -355.2759,  128.8402,\n",
            "             28.4111]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-12155.8203, grad_fn=<SumBackward0>)\n",
            "padding    = 1\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ 1.90032745e+02  1.88493179e+02  1.65462341e+02 ... -1.67105198e+01\n",
            "    -9.37990856e+00  9.17474289e...6e+01]\n",
            "   [-2.78323029e+02 -2.50287933e+02 -7.06390381e+00 ...  4.79975891e+01\n",
            "    -9.97107849e+01 -1.52627945e+02]]]])\n",
            "y2         = needle.Tensor([-18337.072])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:448: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 2\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m err3 < \u001b[94m1e-1\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33moutputs match \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (y2, out2)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: outputs match [-25527.768], tensor(23346.6914, grad_fn=<SumBackward0>)\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(48874.46) < 0.1\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  0.4091,  -0.6498,  11.3203,  ...,  -0.1208,   1.4287,  -5.5845],\n",
            "          [ -6.8918,  -9.3836,  10.6335,... -10.1363],\n",
            "          [  1.1511,   0.7441,  16.4635,  ...,  -6.8931,  -0.5833,  -2.5046]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
            "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "err3       = np.float32(48874.46)\n",
            "out        = tensor([[[[-6.3835e+01, -7.3393e+01,  7.0442e+01,  ..., -8.6601e+01,\n",
            "            2.9473e+01,  3.8723e+01],\n",
            "          [...,  8.9989e+01,  2.4763e+01,  ..., -2.3400e+02,\n",
            "            1.3548e+02, -2.8245e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(23346.6914, grad_fn=<SumBackward0>)\n",
            "padding    = 2\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[-1.26214775e+02 -1.58737457e+02 -1.04328835e+02 ...  1.03407967e+02\n",
            "    -9.62943115e+01 -7.89211731e...2e+01]\n",
            "   [ 9.80739441e+01  1.16876907e+02  1.00872055e+02 ... -1.42234207e+02\n",
            "     3.60289879e+01 -7.11440229e+00]]]])\n",
            "y2         = needle.Tensor([-25527.768])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:448: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 1\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m err3 < \u001b[94m1e-1\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33moutputs match \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (y2, out2)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: outputs match [-13179.184], tensor(4313.9385, grad_fn=<SumBackward0>)\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(17493.121) < 0.1\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
            "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
            "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
            "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "err3       = np.float32(17493.121)\n",
            "out        = tensor([[[[ 1.0725e+02, -9.3744e+00,  2.7834e+02,  ..., -9.7155e+01,\n",
            "            1.3371e+02,  1.2725e+02],\n",
            "          [...,  5.7277e+02,  2.3476e+01,  ..., -2.1788e+02,\n",
            "           -1.8747e+02,  2.0660e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(4313.9385, grad_fn=<SumBackward0>)\n",
            "padding    = 1\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ 1.90032745e+02  1.88493179e+02  1.65462341e+02 ... -1.67105198e+01\n",
            "    -9.37990856e+00  9.17474289e...7e+02]\n",
            "   [-8.11057053e+01 -1.00296509e+02  1.24597679e+02 ...  2.19077393e+02\n",
            "    -1.98630432e+02 -9.00562286e+01]]]])\n",
            "y2         = needle.Tensor([-13179.184])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:448: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 2\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m err3 < \u001b[94m1e-1\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33moutputs match \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (y2, out2)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: outputs match [-850.24097], tensor(-8988.4932, grad_fn=<SumBackward0>)\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(8138.252) < 0.1\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  0.4091,  -0.6498,  11.3203,  ...,  -0.1208,   1.4287,  -5.5845],\n",
            "          [ -6.8918,  -9.3836,  10.6335,... -10.1363],\n",
            "          [  1.1511,   0.7441,  16.4635,  ...,  -6.8931,  -0.5833,  -2.5046]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
            "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "err3       = np.float32(8138.252)\n",
            "out        = tensor([[[[-6.3835e+01,  7.0442e+01, -1.5787e+02,  ..., -1.1571e+02,\n",
            "            2.7167e+02,  2.9473e+01],\n",
            "          [...,  1.5725e+02, -4.1424e+01,  ...,  1.6422e+02,\n",
            "            1.0298e+02,  8.0763e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-8988.4932, grad_fn=<SumBackward0>)\n",
            "padding    = 2\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[-1.26214775e+02 -1.58737457e+02 -1.04328835e+02 ...  1.03407967e+02\n",
            "    -9.62943115e+01 -7.89211731e...1e+01]\n",
            "   [-2.26657852e+02  1.48191986e+02  2.87746246e+02 ...  1.39716034e+02\n",
            "     1.51161957e+02 -8.67736816e+01]]]])\n",
            "y2         = needle.Tensor([-850.24097])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:448: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1]\u001b[0m - AssertionError: outputs match [-18337.072], tensor(-12155.8203, grad_fn=<Su...\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2]\u001b[0m - AssertionError: outputs match [-25527.768], tensor(23346.6914, grad_fn=<Sum...\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1]\u001b[0m - AssertionError: outputs match [-13179.184], tensor(4313.9385, grad_fn=<SumB...\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2]\u001b[0m - AssertionError: outputs match [-850.24097], tensor(-8988.4932, grad_fn=<Sum...\n",
            "\u001b[31m================ \u001b[31m\u001b[1m4 failed\u001b[0m, \u001b[32m30 passed\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[31m in 2.48s\u001b[0m\u001b[31m =================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"op_conv and forward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpa-TEpEnJnq"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c0Mm5xYnJnq"
      },
      "source": [
        "### Convolution backward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcL6Dw42nJnq"
      },
      "source": [
        "Finding the gradients of 2D multi-channel convolution can be technically quite challenging (especially \"rigorously\"). We will try to provide some useful hints here. Basically, we encourage you to make use of the surprising fact that _whatever makes the dimensions work out is typically right_.\n",
        "\n",
        "Ultimately, the backward pass of convolution can be done in terms of the convolution operator itself, with some clever manipulations using `flip`, `dilate`, and multiple applications of `transpose` to both the arguments and the results.\n",
        "\n",
        "In the last section, we essentially implemented convolution as a matrix product: ignoring the various restride and reshape operations, we basically have something like `X @ W`, where `X` is the input and `W` is the weight. We also have `out_grad`, which is the same shape as `X @ W`. Now, you have already implemented the backward pass of matrix multiplication in a previous assignment, and we can use this knowledge to get some insight into the backward pass of convolution. In particular, referencing your matmul backward implementation, you may notice (heuristically speaking here):\n",
        "\n",
        "`X.grad = out_grad @ W.transpose` \\\n",
        "`W.grad = X.transpose @ out_grad`\n",
        "\n",
        "Surprisingly enough, things work out if we just assume that these are also convolutions (and now assuming that `out_grad`, `W`, and `X` are tensors amenable to 2D multi-channel convolution instead of matrices):\n",
        "\n",
        "`X.grad = conv(out_grad, W)` \\\n",
        "`W.grad = conv(X, out_grad)`\n",
        "\n",
        "In which the \"\" indicates that you need to apply some additional operators to these terms in order to get the dimensions to work out, such as permuting/transposing axes, dilating, changing the `padding=` argument to the convolution function, or permuting/transposing axes of the resulting convolution.\n",
        "\n",
        "As we saw on the [last few slides here](https://dlsyscourse.org/slides/conv_nets.pdf) in class, the transpose of a convolution can be found by simply flipping the kernel. Since we're working in 2D instead of 1D, this means flipping the kernel both vertically and horizontally (thus why we implemented `flip`).\n",
        "\n",
        "Summarizing some hints for both `X.grad` and `W.grad`:\n",
        "\n",
        "`X.grad`\n",
        "- The convolution of `out_grad` and `W`, with some operations applied to those\n",
        "- `W` should be flipped over both the kernel dimensions\n",
        "- If the convolution is strided, increase the size of `out_grad` with a corresponding dilation\n",
        "- Do an example to analyze dimensions: note the shape you want for `X.grad`, and think about how you must permute/transpose the arguments and add padding to the convolution to achieve this shape\n",
        "    - This padding depends on both the kernel size and the `padding` argument to the convolution\n",
        "\n",
        "`W.grad`\n",
        "- The convolution of `X` and `out_grad`, with some operations applied to those\n",
        "- The gradients of `W` must be accumulated over the batches; how can you make the conv operator itself do this accumulation?\n",
        "    - Consider turning batches into channels via transpose/permute\n",
        "- Analyze dimensions: how can you modify `X` and `out_grad` so that the shape of their convolution matches the shape of `W`? You may need to transpose/permute the result.\n",
        "    - Remember to account for the `padding` argument passed to convolution\n",
        "\n",
        "General tips\n",
        "- Deal with strided convolutions last (you should be able to just drop in `dilate` when you've passed most of the tests)\n",
        "- Start with the case where `padding=0`, then consider changing `padding` arguments\n",
        "- You can \"permute\" axes with multiple calls to `transpose`\n",
        "\n",
        "It might also be useful to skip ahead to nn.Conv, pass the forward tests, and then use both the tests below and the nn.Conv backward tests to debug your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "QYFeNjIDnJnq",
        "outputId": "a1258555-084d-4b6f-9920-6c6808be50b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(3969.2078) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
            "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
            "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
            "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(0.00073335366)\n",
            "err2       = np.float32(3969.2078)\n",
            "err3       = np.float32(0.0034179688)\n",
            "out        = tensor([[[[-2.1851e+01, -1.8266e+02, -2.9496e+02,  ...,  9.3036e+01,\n",
            "           -1.0480e+02,  1.1030e+02],\n",
            "          [...,  5.7277e+02, -9.0837e+01,  ..., -1.8747e+02,\n",
            "           -1.1281e+02,  2.0660e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-6614.2402, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[-2.18507862e+01  7.10567322e+01 -2.19253067e+02 ...  1.22643860e+02\n",
            "     1.09581779e+02  5.29599533e...5e+02]\n",
            "   [ 1.20957283e+02 -4.53491516e+02  7.81254578e+01 ...  1.71220749e+02\n",
            "    -1.71809418e+02  2.06600098e+02]]]])\n",
            "y2         = needle.Tensor([-6614.237])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 1\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(4185.233) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
            "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
            "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
            "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(0.0)\n",
            "err2       = np.float32(4185.233)\n",
            "err3       = np.float32(6181.252)\n",
            "out        = tensor([[[[ 107.2545, -109.1249,   -9.3744,  ...,  118.7832,  127.2525,\n",
            "           -146.6358],\n",
            "          [-296.2552,  ...[-107.9026,   -8.9582,  137.1271,  ..., -355.2759,  128.8402,\n",
            "             28.4111]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-12155.8203, grad_fn=<SumBackward0>)\n",
            "padding    = 1\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ 1.90032745e+02  1.88493179e+02  1.65462341e+02 ... -1.67105198e+01\n",
            "    -9.37990856e+00  9.17474289e...6e+01]\n",
            "   [-2.78323029e+02 -2.50287933e+02 -7.06390381e+00 ...  4.79975891e+01\n",
            "    -9.97107849e+01 -1.52627945e+02]]]])\n",
            "y2         = needle.Tensor([-18337.072])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 2\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(6275.465) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  0.4091,  -0.6498,  11.3203,  ...,  -0.1208,   1.4287,  -5.5845],\n",
            "          [ -6.8918,  -9.3836,  10.6335,... -10.1363],\n",
            "          [  1.1511,   0.7441,  16.4635,  ...,  -6.8931,  -0.5833,  -2.5046]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
            "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(0.0)\n",
            "err2       = np.float32(6275.465)\n",
            "err3       = np.float32(48874.46)\n",
            "out        = tensor([[[[-6.3835e+01, -7.3393e+01,  7.0442e+01,  ..., -8.6601e+01,\n",
            "            2.9473e+01,  3.8723e+01],\n",
            "          [...,  8.9989e+01,  2.4763e+01,  ..., -2.3400e+02,\n",
            "            1.3548e+02, -2.8245e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(23346.6914, grad_fn=<SumBackward0>)\n",
            "padding    = 2\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[-1.26214775e+02 -1.58737457e+02 -1.04328835e+02 ...  1.03407967e+02\n",
            "    -9.62943115e+01 -7.89211731e...2e+01]\n",
            "   [ 9.80739441e+01  1.16876907e+02  1.00872055e+02 ... -1.42234207e+02\n",
            "     3.60289879e+01 -7.11440229e+00]]]])\n",
            "y2         = needle.Tensor([-25527.768])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(6274.5596) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Wtch       = tensor([[[[ 4.0910e-01, -6.4983e-01,  1.1320e+01,  ..., -5.5609e+00,\n",
            "           -4.8439e+00, -1.2078e-01],\n",
            "          [...[-1.1071e+00,  2.5445e+00, -7.7387e+00,  ..., -1.1334e+00,\n",
            "           -1.2166e+00, -4.7933e+00]]]], requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
            "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(0.0008252314)\n",
            "err2       = np.float32(6274.5596)\n",
            "err3       = np.float32(0.049804688)\n",
            "out        = tensor([[[[ 5.7346e+00, -2.1858e+02, -5.5911e+01,  ..., -8.9695e+01,\n",
            "            2.2620e+02,  3.4342e+02],\n",
            "          [...,  2.3405e+01, -2.1477e+01,  ...,  1.2947e+02,\n",
            "            1.2442e+02, -4.6003e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(16161.7031, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ 5.73456383e+00 -2.22225971e+01  2.64719360e+02 ... -6.97373962e+01\n",
            "    -3.79622650e+02  9.98186493e...8e+02]\n",
            "   [ 3.72021103e+01  8.33753281e+01 -4.17866564e+00 ... -1.67722427e+02\n",
            "    -1.28576309e+02 -4.60030090e+02]]]])\n",
            "y2         = needle.Tensor([16161.753])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(809.0367) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Wtch       = tensor([[[[ -8.0968,  -2.5552,   8.7031,  -1.4674,   4.5861,  -0.2852,   4.3836,\n",
            "            -9.1346,  -2.0159,   4.74...0.2258,\n",
            "             9.2967,  -8.1316,  -0.6741,  -2.9205,   1.6755, -12.1878,   5.5746]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "Ztch       = tensor([[[[  8.8203,   2.0008],\n",
            "          [  4.8937,  11.2045],\n",
            "          [  9.3378,  -4.8864],\n",
            "          ...,\n",
            "       ...\n",
            "          [ -7.9224,   4.2223],\n",
            "          [ -6.0643,   1.4188],\n",
            "          [ -1.4110,  -5.7910]]]], requires_grad=True)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(0.0002241043)\n",
            "err2       = np.float32(809.0367)\n",
            "err3       = np.float32(0.0014648438)\n",
            "out        = tensor([[[[-346.0716,  -28.1759,   63.5063,  ..., -158.1952,  -57.8746,\n",
            "             63.6776],\n",
            "          [  73.3426,  ...[  58.9731,    3.5575, -155.4996,  ...,  123.7366,   54.5836,\n",
            "             92.4735]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-6321.1787, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[-346.07162     -1.1081867  420.15115   ...  -58.583153\n",
            "     -66.19938     33.158627 ]\n",
            "   [ -28.17595... -8.201235    54.58357  ]\n",
            "   [ -17.069721  -119.112015    24.423635  ...   47.367493\n",
            "     -38.16554     92.47348  ]]]])\n",
            "y2         = needle.Tensor([-6321.18])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: input grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(2294.0593) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
            "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
            "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
            "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(2294.0593)\n",
            "err2       = np.float32(2683.5474)\n",
            "err3       = np.float32(0.0029296875)\n",
            "out        = tensor([[[[ -21.8508, -294.9621, -318.0497,   -4.7934,   59.4825, -104.8043],\n",
            "          [  14.3621,  303.2643, -221.53...          [ 183.8510, -115.7199,  115.7395, -105.5507,   75.9456, -171.5427]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-4902.2178, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ -21.850786    71.05673   -219.25307   ...  122.64386\n",
            "     109.58178     52.959953 ]\n",
            "   [-294.9621  ...-120.10991     75.945595 ]\n",
            "   [ 372.3654    -347.1187     253.12747   ...  220.83806\n",
            "     113.929146  -171.54272  ]]]])\n",
            "y2         = needle.Tensor([-4902.2207])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:446: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 1\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: input grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(2476.6155) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
            "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
            "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
            "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(2476.6155)\n",
            "err2       = np.float32(2894.6785)\n",
            "err3       = np.float32(17493.121)\n",
            "out        = tensor([[[[ 1.0725e+02, -9.3744e+00,  2.7834e+02,  ..., -9.7155e+01,\n",
            "            1.3371e+02,  1.2725e+02],\n",
            "          [...,  5.7277e+02,  2.3476e+01,  ..., -2.1788e+02,\n",
            "           -1.8747e+02,  2.0660e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(4313.9385, grad_fn=<SumBackward0>)\n",
            "padding    = 1\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ 1.90032745e+02  1.88493179e+02  1.65462341e+02 ... -1.67105198e+01\n",
            "    -9.37990856e+00  9.17474289e...7e+02]\n",
            "   [-8.11057053e+01 -1.00296509e+02  1.24597679e+02 ...  2.19077393e+02\n",
            "    -1.98630432e+02 -9.00562286e+01]]]])\n",
            "y2         = needle.Tensor([-13179.184])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:446: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 2\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(3880.5847) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Wtch       = tensor([[[[  0.4091,  -0.6498,  11.3203,  ...,  -0.1208,   1.4287,  -5.5845],\n",
            "          [ -6.8918,  -9.3836,  10.6335,... -10.1363],\n",
            "          [  1.1511,   0.7441,  16.4635,  ...,  -6.8931,  -0.5833,  -2.5046]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
            "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(0.00040186255)\n",
            "err2       = np.float32(3880.5847)\n",
            "err3       = np.float32(8138.252)\n",
            "out        = tensor([[[[-6.3835e+01,  7.0442e+01, -1.5787e+02,  ..., -1.1571e+02,\n",
            "            2.7167e+02,  2.9473e+01],\n",
            "          [...,  1.5725e+02, -4.1424e+01,  ...,  1.6422e+02,\n",
            "            1.0298e+02,  8.0763e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-8988.4932, grad_fn=<SumBackward0>)\n",
            "padding    = 2\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[-1.26214775e+02 -1.58737457e+02 -1.04328835e+02 ...  1.03407967e+02\n",
            "    -9.62943115e+01 -7.89211731e...1e+01]\n",
            "   [-2.26657852e+02  1.48191986e+02  2.87746246e+02 ...  1.39716034e+02\n",
            "     1.51161957e+02 -8.67736816e+01]]]])\n",
            "y2         = needle.Tensor([-850.24097])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 2, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: input grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(2715.8862) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Wtch       = tensor([[[[ 4.0910e-01, -6.4983e-01,  1.1320e+01,  ..., -5.5609e+00,\n",
            "           -4.8439e+00, -1.2078e-01],\n",
            "          [...[-1.1071e+00,  2.5445e+00, -7.7387e+00,  ..., -1.1334e+00,\n",
            "           -1.2166e+00, -4.7933e+00]]]], requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
            "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(2715.8862)\n",
            "err2       = np.float32(2905.258)\n",
            "err3       = np.float32(0.00390625)\n",
            "out        = tensor([[[[   5.7346,  -55.9106,  320.3619,  ..., -472.6719,  -63.6798,\n",
            "            226.2005],\n",
            "          [ -39.7949, -...[ -34.6254, -262.0989, -192.8079,  ..., -480.3307,  172.4242,\n",
            "            163.7107]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(10302.4697, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[   5.734564   -22.222597   264.71936   ...  -69.7374\n",
            "    -379.62265     99.81865  ]\n",
            "   [ -55.910625 ... 143.49785    172.42424  ]\n",
            "   [ 140.06458    -33.92796    128.48518   ...  228.07355\n",
            "     153.4408     163.71072  ]]]])\n",
            "y2         = needle.Tensor([10302.474])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:446: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 2, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: input grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(971.5993) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Wtch       = tensor([[[[ -8.0968,  -2.5552,   8.7031,  -1.4674,   4.5861,  -0.2852,   4.3836,\n",
            "            -9.1346,  -2.0159,   4.74...0.2258,\n",
            "             9.2967,  -8.1316,  -0.6741,  -2.9205,   1.6755, -12.1878,   5.5746]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "Ztch       = tensor([[[[  8.8203,   2.0008],\n",
            "          [  4.8937,  11.2045],\n",
            "          [  9.3378,  -4.8864],\n",
            "          ...,\n",
            "       ...\n",
            "          [ -7.9224,   4.2223],\n",
            "          [ -6.0643,   1.4188],\n",
            "          [ -1.4110,  -5.7910]]]], requires_grad=True)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(971.5993)\n",
            "err2       = np.float32(677.2478)\n",
            "err3       = np.float32(0.005126953)\n",
            "out        = tensor([[[[-3.4607e+02,  6.3506e+01, -3.3188e+01,  ...,  1.9525e+02,\n",
            "            1.2715e+02, -5.7875e+01],\n",
            "          [..., -1.1399e+02, -6.9067e+01,  ..., -1.4515e+02,\n",
            "            5.3236e+01,  3.2069e+00]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-2297.1741, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[-3.46071625e+02 -1.10818672e+00  4.20151154e+02 ... -5.85831528e+01\n",
            "    -6.61993790e+01  3.31586266e...3e+01]\n",
            "   [-9.30875702e+01 -4.32016563e+01  1.87175808e+01 ... -3.38230171e+01\n",
            "    -5.38563805e+01  3.20688462e+00]]]])\n",
            "y2         = needle.Tensor([-2297.1792])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:446: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 24), W_shape = (3, 3, 24, 14), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(7170.4985) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
            "     -0.36175704   4.6234684 ]\n",
            "   [  5.279258... -4.82095      4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]])\n",
            "W_shape    = (3, 3, 24, 14)\n",
            "Wtch       = tensor([[[[ -1.3246,   1.0111,  -1.9237,  ...,  -2.5907,  -0.3618,   4.6235],\n",
            "          [  5.2793,  -1.3090,   0.0500,...   4.9852],\n",
            "          [  3.2300,  -2.4162,  -3.4208,  ...,  -9.4447,   8.5378,   2.3818]]]],\n",
            "       requires_grad=True)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773...4.207389     8.935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]])\n",
            "Z_shape    = (3, 16, 16, 24)\n",
            "Ztch       = tensor([[[[  8.8203,   2.0008,   4.8937,  ...,   3.2681,   4.3222,  -3.7108],\n",
            "          [ 11.3488,  -7.2718,   0.2288,...   8.9354],\n",
            "          [  2.5084,   3.1399,  -0.1296,  ...,   0.1374,  -1.4009,   0.0748]]]],\n",
            "       requires_grad=True)\n",
            "_W         = array([[[[ -1.3245817 ,   1.0111231 ,  -1.9236585 , ...,  -2.5907016 ,\n",
            "           -0.36175704,   4.6234684 ],\n",
            "        ... [  3.2300415 ,  -2.4161792 ,  -3.420825  , ...,  -9.444658  ,\n",
            "            8.537833  ,   2.3818388 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(0.001412236)\n",
            "err2       = np.float32(7170.4985)\n",
            "err3       = np.float32(0.032226562)\n",
            "out        = tensor([[[[ 5.9644e+02,  1.7622e+01, -3.8665e+02,  ..., -5.6437e+02,\n",
            "           -1.4383e+02, -1.2310e+02],\n",
            "          [..., -6.6977e+02,  7.6359e+00,  ...,  3.7344e+02,\n",
            "           -8.9822e+01,  1.5355e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-5941.3750, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ 5.96437805e+02 -2.17912796e+02 -2.09804783e+01 ... -4.44460907e+02\n",
            "    -2.74169159e+02 -6.12073181e...4e+01]\n",
            "   [-5.03057983e+02 -1.26949539e+02 -1.28574600e+01 ...  4.08393738e+02\n",
            "    -1.71167480e+02  1.53551315e+02]]]])\n",
            "y2         = needle.Tensor([-5941.407])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(5732.7817) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
            "     2.17041516e+00 -3.88039827e...7e+00]\n",
            "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]])\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Wtch       = tensor([[[[ 4.2827e+00,  8.1336e+00, -4.6223e+00,  ...,  2.0798e+00,\n",
            "            2.1704e+00, -3.8804e-01],\n",
            "          [...[-7.8603e-01,  4.3095e+00, -4.9780e+00,  ..., -5.6943e-01,\n",
            "            4.2778e-01, -3.8444e+00]]]], requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
            "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[ 4.28266907e+00,  8.13360405e+00, -4.62234831e+00, ...,\n",
            "           2.07981968e+00,  2.17041516e+00, -3.88039...947495e+00, -4.97804356e+00, ...,\n",
            "          -5.69430470e-01,  4.27775383e-01, -3.84437203e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(0.0018357928)\n",
            "err2       = np.float32(5732.7817)\n",
            "err3       = np.float32(0.0068359375)\n",
            "out        = tensor([[[[ 1.7557e+02,  1.3950e+02,  4.5144e+02,  ...,  1.9506e+01,\n",
            "           -5.7378e+01, -2.2967e+02],\n",
            "          [...,  3.1106e+02,  4.1425e+02,  ...,  3.3462e+02,\n",
            "           -1.0345e+02,  2.4403e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(-10705.7383, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ 1.75570267e+02  2.39688141e+02  5.25702209e+02 ...  4.85040955e+02\n",
            "    -2.37886475e+02 -2.36008549e...4e+02]\n",
            "   [-4.85305603e+02 -1.46666489e+02 -3.62995392e+02 ...  1.50065781e+02\n",
            "    -5.45707825e+02  2.44026398e+02]]]])\n",
            "y2         = needle.Tensor([-10705.731])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(7245.236) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
            "     6.47611380e+00 -3.38525438e...7e+00]\n",
            "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]])\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Wtch       = tensor([[[[ 5.9312e+00, -4.6160e+00, -7.4341e+00,  ...,  9.4905e+00,\n",
            "            6.4761e+00, -3.3853e+00],\n",
            "          [...[-3.9358e+00, -6.9861e+00,  1.6366e+00,  ...,  8.2247e+00,\n",
            "            2.5656e+00,  1.6300e+00]]]], requires_grad=True)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...8e+00]\n",
            "   [ 2.80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]])\n",
            "Z_shape    = (3, 17, 17, 8)\n",
            "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
            "            4.7504e+00, -7.5679e-01],\n",
            "          [...[ 2.8016e+00,  3.1130e+00, -3.2476e+00,  ..., -7.9623e-01,\n",
            "            4.7264e+00, -5.7547e+00]]]], requires_grad=True)\n",
            "_W         = array([[[[ 5.93117094e+00, -4.61600447e+00, -7.43411541e+00, ...,\n",
            "           9.49053860e+00,  6.47611380e+00, -3.38525...609781e+00,  1.63659811e+00, ...,\n",
            "           8.22474575e+00,  2.56555057e+00,  1.63004756e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(0.0016586707)\n",
            "err2       = np.float32(7245.236)\n",
            "err3       = np.float32(0.0703125)\n",
            "out        = tensor([[[[ 5.8605e+02,  6.5851e+02,  3.1471e+01,  ..., -2.0572e+02,\n",
            "           -5.6982e+02, -7.7784e+02],\n",
            "          [...,  1.3106e+02, -3.2224e+02,  ...,  7.1755e+01,\n",
            "           -5.2006e+02, -6.5310e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(50567.7344, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ 5.86050903e+02 -5.11887695e+02  5.65467911e+01 ...  7.48446426e+01\n",
            "    -3.56891510e+02 -3.76215637e...2e+02]\n",
            "   [-6.95190125e+02 -8.10500183e+01  2.38304077e+02 ... -1.27415886e+02\n",
            "     8.60565063e+02 -6.53100510e+01]]]])\n",
            "y2         = needle.Tensor([50567.664])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (1, 14, 14, 2), W_shape = (3, 3, 2, 2), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
            "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
            "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m err1 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minput grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94massert\u001b[39;49;00m err2 < \u001b[94m1e-2\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight grads match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: weight grads match\u001b[0m\n",
            "\u001b[1m\u001b[31mE           assert np.float32(455.3955) < 0.01\u001b[0m\n",
            "\n",
            "W          = needle.Tensor([[[[ -1.7671587   -8.082371  ]\n",
            "   [ -1.4591868   -3.807461  ]]\n",
            "\n",
            "  [[  4.2896194    5.705509  ]\n",
            "   [  7.3...7526     2.911123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]])\n",
            "W_shape    = (3, 3, 2, 2)\n",
            "Wtch       = tensor([[[[ -1.7672,  -8.0824],\n",
            "          [ -1.4592,  -3.8075]],\n",
            "\n",
            "         [[  4.2896,   5.7055],\n",
            "          [  7.3329,...         [-10.4730,   0.6186]],\n",
            "\n",
            "         [[ -0.6505,   0.4698],\n",
            "          [  4.7152, -13.6984]]]], requires_grad=True)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750...19315276  -8.283575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]])\n",
            "Z_shape    = (1, 14, 14, 2)\n",
            "Ztch       = tensor([[[[  8.8203,   2.0008],\n",
            "          [  4.8937,  11.2045],\n",
            "          [  9.3378,  -4.8864],\n",
            "          [  4.7504,  ...\n",
            "          [ -4.9276,  -7.3592],\n",
            "          [  8.2407,   0.8211],\n",
            "          [  2.8365,  -1.1134]]]], requires_grad=True)\n",
            "_W         = array([[[[ -1.7671587 ,  -8.082371  ],\n",
            "         [ -1.4591868 ,  -3.807461  ]],\n",
            "\n",
            "        [[  4.2896194 ,   5.705509  ],...016  ,   0.61860955]],\n",
            "\n",
            "        [[ -0.65053475,   0.46976614],\n",
            "         [  4.7152305 , -13.698386  ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "err1       = np.float32(1.2557781e-05)\n",
            "err2       = np.float32(455.3955)\n",
            "err3       = np.float32(0.0017089844)\n",
            "out        = tensor([[[[ -83.1438,   -6.3602,   93.8760,  -41.2035,  -96.8909,  152.8543,\n",
            "           -101.4654,  259.1811,    7.015...            -60.5771,   13.6480,  228.9975,    8.4413, -121.9792,   26.1601]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "out2       = tensor(2243.9304, grad_fn=<SumBackward0>)\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "y          = needle.Tensor([[[[ -83.14382     -46.58788   ]\n",
            "   [  -6.3601565    -5.1046524 ]\n",
            "   [  93.87601     -20.797268  ]\n",
            "   [ ...   228.99751   ]\n",
            "   [  41.437016      8.441346  ]\n",
            "   [ -26.093277   -121.97922   ]\n",
            "   [  22.205511     26.16009   ]]]])\n",
            "y2         = needle.Tensor([2243.9321])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:447: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0]\u001b[0m - AssertionError: input grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1]\u001b[0m - AssertionError: input grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0]\u001b[0m - AssertionError: input grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0]\u001b[0m - AssertionError: input grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0]\u001b[0m - AssertionError: weight grads match\n",
            "\u001b[31m================ \u001b[31m\u001b[1m14 failed\u001b[0m, \u001b[32m20 passed\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[31m in 3.48s\u001b[0m\u001b[31m ================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"op_conv and backward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m9_MBqunJnq"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNuRsc_NnJnq"
      },
      "source": [
        "### nn.Conv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "PCjAJRe1nJnq"
      },
      "source": [
        "#### Fixing init._calculate_fans for convolution\n",
        "Previously, we have implemented Kaiming uniform/normal initializations, where we essentially assigned `fan_in = input_size` and `fan_out = output_size`.\n",
        "For convolution, this becomes somewhat more detailed, in that you should multiply both of these by the \"receptive field size\", which is in this case just the product of the kernel sizes -- which in our case are always going to be the same, i.e., $k\\times k$ kernels.\n",
        "\n",
        "**You will need to edit your `kaiming_uniform` in `python/needle/init/init_initializers.py`, etc. init functions to support multidimensional arrays.** In particular, it should support a new `shape` argument which is then passed to, e.g., the underlying `rand` function. Specifically, if the argument `shape` is not `None`, then ignore `fan_in` and `fan_out`, and use the value of `shape` for initializations instead.\n",
        "\n",
        "You can test this below; though it is not _directly_ graded, it must match ours to pass the nn.Conv mugrade tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "lP58Da3PnJnq",
        "outputId": "7c3b177e-00a1-4821-8c5e-cc1f571863a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m====================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 2.12s\u001b[0m\u001b[32m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"kaiming_uniform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwOpKu1wnJnq"
      },
      "source": [
        "#### Implementing nn.Conv\n",
        "\n",
        "Essentially, nn.Conv is just a wrapper of the convolution operator we previously implemented\n",
        "which adds a bias term, initializes the weight and bias, and ensures that the padding is set so that the input and output dimensions are the same (in the `stride=1` case, anyways).\n",
        "\n",
        "Importantly, nn.Conv should support NCHW format instead of NHWC format. In particular, we think this makes more sense given our current BatchNorm implementation. You can implement this by applying `transpose` twice to both the input and output.  \n",
        "\n",
        "- Ensure nn.Conv works for `(N, C, H, W)` tensors even though we implemented the conv op for `(N, H, W, C)` tensors\n",
        "- Initialize the `(k, k, i, o)` weight tensor using Kaiming uniform initialization with default settings\n",
        "- Initialize the `(o,)` bias tensor using uniform initialization on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|in_channels| \\times \\verb|kernel_size|^2}}$\n",
        "- Calculate the appropriate padding to ensure input and output dimensions are the same\n",
        "- Calculate the convolution, then add the properly-broadcasted bias term if present\n",
        "\n",
        "You can now test your nn.Conv against PyTorch's nn.Conv2d with the two PyTest calls below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "bNVOH4ounJnq",
        "outputId": "2a242454-b04b-46c5-f9ce-7e368a51f421",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1793 deselected / 10 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-4-8-16-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-16-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-4-8-16-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-16-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-4-8-16-3-1] _\u001b[0m\n",
            "\n",
            "s = 4, cin = 8, cout = 16, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert np.float32(24.799076) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(24.799076) = <function norm at 0x78de681e28f0>((array([[[[ 0.9614984 ,  0.18507531,  0.45108768, -0.15583369],\\n         [ 0.6721291 ,  0.43875065, -0.40976214, -0.05421432],\\n         [ 0.09986708,  0.59877616,  0.41438234, -0.34444872],\\n         [ 0.7685642 , -0.13823068,  0.04601748,  0.03305402]],\\n\\n        [[-0.45584416,  0.65168923, -0.37744236,  0.01817221],\\n         [ 0.56739455,  1.253125  ,  0.38783577,  0.34113753],\\n         [ 0.11224493,  0.29147422,  0.6227909 ,  0.66942763],\\n         [ 0.0535505 , -0.53826624,  0.5199805 ,  0.48923674]],\\n\\n        [[ 0.34109256, -0.07847372,  0.18477465,  0.10322276],\\n         [ 0.19868082,  0.8802005 ,  0.255134  ,  0.92093706],\\n         [ 0.65564984,  0.65205157,  0.23196039,  0.5609234 ],\\n         [ 0.4508136 , -0.6336484 ,  0.14944857,  0.66682065]],\\n\\n        ...,\\n\\n        [[-0.27894512, -0.40351155,  0.18792397,  0.05672256],\\n         [ 0.20382637, -0.8051432 , -0.2684171 ,  0.188351  ],\\n         [-0.25474146, -0.18283749, -0.11097631, -0.14275688],\\n         [-0.09754519, -0.16104588, -0.16492458, -0.49893668]],\\n\\n        [[ 0.47263396,  0.6951636 ,  0.17216495,  0.6512528 ],\\n         [ 1.4676476 , -0.6478419 , -0.11291147,  0.48149496],\\n         [ 0.75447595,  0.72579676, -0.734...8524,  0.23522797],\\n         [ 0.9648773 ,  1.1387159 ,  0.10492196,  0.5536462 ],\\n         [ 0.0537894 , -0.02059563, -0.30552495,  0.07707847]],\\n\\n        [[ 0.32607388,  0.37076294,  0.5689548 ,  0.30110627],\\n         [ 0.6903826 ,  0.9133538 ,  0.48307303,  0.43004555],\\n         [-0.06159865,  0.8618226 ,  0.30547938,  1.0129852 ],\\n         [ 0.3798752 ,  0.09115952,  0.49076867,  0.27220723]],\\n\\n        ...,\\n\\n        [[-0.61040914,  0.0085753 , -0.3121436 ,  0.1356031 ],\\n         [-0.19638494,  0.51091224,  0.096462  , -0.06863552],\\n         [-0.10546575, -0.44456747,  0.51925534, -0.44515204],\\n         [ 0.07901487,  0.00578388,  0.12137435, -0.40837017]],\\n\\n        [[ 0.9916986 , -0.19406009, -0.08435839, -0.1180807 ],\\n         [ 0.9097904 , -0.16026178,  1.453805  , -0.4069232 ],\\n         [ 0.58931273,  0.01552818,  0.633066  , -0.7997602 ],\\n         [ 1.0826112 , -0.08126947,  0.43451095, -0.24741772]],\\n\\n        [[ 0.3273959 ,  0.48057655,  0.70053846, -0.23785356],\\n         [ 0.23586112, -0.4185446 , -0.51092875, -0.17806727],\\n         [ 0.17894682, -0.19772175, -0.50655043, -0.85206884],\\n         [ 0.2155672 , -0.14814061, -0.36385733,  0.11623047]]]],\\n      dtype=float32) - array([[[[ 1.13283944e+00,  2.11146444e-01,  3.28146428e-01,\\n          -2.94300765e-01],\\n         [ 8.64967048e-01,  8.48758459e-01, -1.34139165e-01,\\n          -1.81775212e-01],\\n         [ 7.18198478e-01,  1.78922057e-01,  5.13797998e-01,\\n           5.03971756e-01],\\n         [ 3.48404586e-01, -2.31752962e-01,  9.52353403e-02,\\n          -2.37080604e-02]],\\n\\n        [[-1.03525221e-01, -2.80523151e-01, -1.06877041e+00,\\n          -6.20132029e-01],\\n         [ 2.59960532e-01,  4.49261278e-01,  5.80089092e-01,\\n           4.76463825e-01],\\n         [ 7.56408215e-01,  1.01847851e+00,  7.63063312e-01,\\n           5.78593254e-01],\\n         [ 7.72867024e-01,  1.46085322e-01,  6.38055980e-01,\\n           2.69220144e-01]],\\n\\n        [[ 7.37306952e-01,  6.37956738e-01,  4.85839009e-01,\\n           1.44786656e-01],\\n         [ 9.83604193e-01,  6.77989662e-01,  5.66651464e-01,\\n           6.74410760e-01],\\n         [ 6.20535553e-01,  5.66158414e-01,  5.55725813e-01,\\n           2.70422101e-01],\\n         [ 3.90210062e-01,  2.15183832e-02, -3.00094336e-02,\\n           6.24719322e-01]],\\n\\n        ...,\\n\\n        [[-1.82251573e-01, -4.19065773e-01, -6.97782576e-01,\\n          -3.53183836e-01],\\n         [ 1.31522790...01],\\n         [-1.81403816e-01,  4.79588121e-01,  4.74800527e-01,\\n           2.30098337e-01]],\\n\\n        ...,\\n\\n        [[-7.28121758e-01,  9.56341848e-02,  2.07222670e-01,\\n           1.16611645e-02],\\n         [-2.37867087e-01,  3.96258950e-01, -4.22562182e-01,\\n           2.75304735e-01],\\n         [ 3.43546063e-01, -3.55143934e-01, -4.67006594e-01,\\n          -2.13369593e-01],\\n         [-3.97753537e-01, -2.79079795e-01, -2.84636021e-02,\\n          -3.21933061e-01]],\\n\\n        [[-2.12227494e-01, -2.61999965e-01,  7.61673331e-01,\\n           2.23954409e-01],\\n         [ 8.53516519e-01,  1.12631567e-01,  9.63037014e-01,\\n          -1.63880736e-01],\\n         [ 4.88140374e-01, -2.78400600e-01,  3.52733374e-01,\\n           4.58401173e-01],\\n         [ 7.73353875e-01,  8.45712364e-01,  5.57578743e-01,\\n          -6.83829725e-01]],\\n\\n        [[ 7.93174207e-01, -4.68334705e-01,  7.92165473e-02,\\n           2.03460865e-02],\\n         [-3.41133237e-01, -3.85057814e-02,  2.12926656e-01,\\n          -2.78965592e-01],\\n         [-6.48336485e-02,  1.23881690e-01, -9.45147753e-01,\\n          -2.59960413e-01],\\n         [-1.74283534e-01, -6.06331468e-01,  2.69641787e-01,\\n          -5.90705514e-01]]]], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78de681e28f0> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 0.9614984 ,  0.18507531,  0.45108768, -0.15583369],\\n         [ 0.6721291 ,  0.43875065, -0.40976214, -0.05421432],\\n         [ 0.09986708,  0.59877616,  0.41438234, -0.34444872],\\n         [ 0.7685642 , -0.13823068,  0.04601748,  0.03305402]],\\n\\n        [[-0.45584416,  0.65168923, -0.37744236,  0.01817221],\\n         [ 0.56739455,  1.253125  ,  0.38783577,  0.34113753],\\n         [ 0.11224493,  0.29147422,  0.6227909 ,  0.66942763],\\n         [ 0.0535505 , -0.53826624,  0.5199805 ,  0.48923674]],\\n\\n        [[ 0.34109256, -0.07847372,  0.18477465,  0.10322276],\\n         [ 0.19868082,  0.8802005 ,  0.255134  ,  0.92093706],\\n         [ 0.65564984,  0.65205157,  0.23196039,  0.5609234 ],\\n         [ 0.4508136 , -0.6336484 ,  0.14944857,  0.66682065]],\\n\\n        ...,\\n\\n        [[-0.27894512, -0.40351155,  0.18792397,  0.05672256],\\n         [ 0.20382637, -0.8051432 , -0.2684171 ,  0.188351  ],\\n         [-0.25474146, -0.18283749, -0.11097631, -0.14275688],\\n         [-0.09754519, -0.16104588, -0.16492458, -0.49893668]],\\n\\n        [[ 0.47263396,  0.6951636 ,  0.17216495,  0.6512528 ],\\n         [ 1.4676476 , -0.6478419 , -0.11291147,  0.48149496],\\n         [ 0.75447595,  0.72579676, -0.734...8524,  0.23522797],\\n         [ 0.9648773 ,  1.1387159 ,  0.10492196,  0.5536462 ],\\n         [ 0.0537894 , -0.02059563, -0.30552495,  0.07707847]],\\n\\n        [[ 0.32607388,  0.37076294,  0.5689548 ,  0.30110627],\\n         [ 0.6903826 ,  0.9133538 ,  0.48307303,  0.43004555],\\n         [-0.06159865,  0.8618226 ,  0.30547938,  1.0129852 ],\\n         [ 0.3798752 ,  0.09115952,  0.49076867,  0.27220723]],\\n\\n        ...,\\n\\n        [[-0.61040914,  0.0085753 , -0.3121436 ,  0.1356031 ],\\n         [-0.19638494,  0.51091224,  0.096462  , -0.06863552],\\n         [-0.10546575, -0.44456747,  0.51925534, -0.44515204],\\n         [ 0.07901487,  0.00578388,  0.12137435, -0.40837017]],\\n\\n        [[ 0.9916986 , -0.19406009, -0.08435839, -0.1180807 ],\\n         [ 0.9097904 , -0.16026178,  1.453805  , -0.4069232 ],\\n         [ 0.58931273,  0.01552818,  0.633066  , -0.7997602 ],\\n         [ 1.0826112 , -0.08126947,  0.43451095, -0.24741772]],\\n\\n        [[ 0.3273959 ,  0.48057655,  0.70053846, -0.23785356],\\n         [ 0.23586112, -0.4185446 , -0.51092875, -0.17806727],\\n         [ 0.17894682, -0.19772175, -0.50655043, -0.85206884],\\n         [ 0.2155672 , -0.14814061, -0.36385733,  0.11623047]]]],\\n      dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where numpy = NDArray([[[[ 0.9614984   0.18507531  0.45108768 -0.15583369]\\n   [ 0.6721291   0.43875065 -0.40976214 -0.05421432]\\n   [ 0.09986708  0.59877616  0.41438234 -0.34444872]\\n   [ 0.7685642  -0.13823068  0.04601748  0.03305402]]\\n\\n  [[-0.45584416  0.65168923 -0.37744236  0.01817221]\\n   [ 0.56739455  1.253125    0.38783577  0.34113753]\\n   [ 0.11224493  0.29147422  0.6227909   0.66942763]\\n   [ 0.0535505  -0.53826624  0.5199805   0.48923674]]\\n\\n  [[ 0.34109256 -0.07847372  0.18477465  0.10322276]\\n   [ 0.19868082  0.8802005   0.255134    0.92093706]\\n   [ 0.65564984  0.65205157  0.23196039  0.5609234 ]\\n   [ 0.4508136  -0.6336484   0.14944857  0.66682065]]\\n\\n  ...\\n\\n  [[-0.27894512 -0.40351155  0.18792397  0.05672256]\\n   [ 0.20382637 -0.8051432  -0.2684171   0.188351  ]\\n   [-0.25474146 -0.18283749 -0.11097631 -0.14275688]\\n   [-0.09754519 -0.16104588 -0.16492458 -0.49893668]]\\n\\n  [[ 0.47263396  0.6951636   0.17216495  0.6512528 ]\\n   [ 1.4676476  -0.6478419  -0.11291147  0.48149496]\\n   [ 0.75447595  0.72579676 -0.7341296   0.32234484]\\n   [ 0.9251521   0.9411834   0.5674993  -0.44224086]]\\n\\n  [[ 0.23617071  0.21687105  0.35276994  0.02636582]\\n   [ 0.28259185 -0.58970535 -0.39982095 -0.94399536]\\n   [ 0.... [ 0.16398796  0.11440317  0.04611299 -0.3077623 ]\\n   [ 0.5308357   0.17526034  0.16854498 -0.6977975 ]]\\n\\n  [[ 0.4906796   0.25973114  0.81172925 -0.147687  ]\\n   [ 1.2011157   0.20299038 -0.10878524  0.23522797]\\n   [ 0.9648773   1.1387159   0.10492196  0.5536462 ]\\n   [ 0.0537894  -0.02059563 -0.30552495  0.07707847]]\\n\\n  [[ 0.32607388  0.37076294  0.5689548   0.30110627]\\n   [ 0.6903826   0.9133538   0.48307303  0.43004555]\\n   [-0.06159865  0.8618226   0.30547938  1.0129852 ]\\n   [ 0.3798752   0.09115952  0.49076867  0.27220723]]\\n\\n  ...\\n\\n  [[-0.61040914  0.0085753  -0.3121436   0.1356031 ]\\n   [-0.19638494  0.51091224  0.096462   -0.06863552]\\n   [-0.10546575 -0.44456747  0.51925534 -0.44515204]\\n   [ 0.07901487  0.00578388  0.12137435 -0.40837017]]\\n\\n  [[ 0.9916986  -0.19406009 -0.08435839 -0.1180807 ]\\n   [ 0.9097904  -0.16026178  1.453805   -0.4069232 ]\\n   [ 0.58931273  0.01552818  0.633066   -0.7997602 ]\\n   [ 1.0826112  -0.08126947  0.43451095 -0.24741772]]\\n\\n  [[ 0.3273959   0.48057655  0.70053846 -0.23785356]\\n   [ 0.23586112 -0.4185446  -0.51092875 -0.17806727]\\n   [ 0.17894682 -0.19772175 -0.50655043 -0.85206884]\\n   [ 0.2155672  -0.14814061 -0.36385733  0.11623047]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where NDArray([[[[ 0.9614984   0.18507531  0.45108768 -0.15583369]\\n   [ 0.6721291   0.43875065 -0.40976214 -0.05421432]\\n   [ 0.09986708  0.59877616  0.41438234 -0.34444872]\\n   [ 0.7685642  -0.13823068  0.04601748  0.03305402]]\\n\\n  [[-0.45584416  0.65168923 -0.37744236  0.01817221]\\n   [ 0.56739455  1.253125    0.38783577  0.34113753]\\n   [ 0.11224493  0.29147422  0.6227909   0.66942763]\\n   [ 0.0535505  -0.53826624  0.5199805   0.48923674]]\\n\\n  [[ 0.34109256 -0.07847372  0.18477465  0.10322276]\\n   [ 0.19868082  0.8802005   0.255134    0.92093706]\\n   [ 0.65564984  0.65205157  0.23196039  0.5609234 ]\\n   [ 0.4508136  -0.6336484   0.14944857  0.66682065]]\\n\\n  ...\\n\\n  [[-0.27894512 -0.40351155  0.18792397  0.05672256]\\n   [ 0.20382637 -0.8051432  -0.2684171   0.188351  ]\\n   [-0.25474146 -0.18283749 -0.11097631 -0.14275688]\\n   [-0.09754519 -0.16104588 -0.16492458 -0.49893668]]\\n\\n  [[ 0.47263396  0.6951636   0.17216495  0.6512528 ]\\n   [ 1.4676476  -0.6478419  -0.11291147  0.48149496]\\n   [ 0.75447595  0.72579676 -0.7341296   0.32234484]\\n   [ 0.9251521   0.9411834   0.5674993  -0.44224086]]\\n\\n  [[ 0.23617071  0.21687105  0.35276994  0.02636582]\\n   [ 0.28259185 -0.58970535 -0.39982095 -0.94399536]\\n   [ 0.... [ 0.16398796  0.11440317  0.04611299 -0.3077623 ]\\n   [ 0.5308357   0.17526034  0.16854498 -0.6977975 ]]\\n\\n  [[ 0.4906796   0.25973114  0.81172925 -0.147687  ]\\n   [ 1.2011157   0.20299038 -0.10878524  0.23522797]\\n   [ 0.9648773   1.1387159   0.10492196  0.5536462 ]\\n   [ 0.0537894  -0.02059563 -0.30552495  0.07707847]]\\n\\n  [[ 0.32607388  0.37076294  0.5689548   0.30110627]\\n   [ 0.6903826   0.9133538   0.48307303  0.43004555]\\n   [-0.06159865  0.8618226   0.30547938  1.0129852 ]\\n   [ 0.3798752   0.09115952  0.49076867  0.27220723]]\\n\\n  ...\\n\\n  [[-0.61040914  0.0085753  -0.3121436   0.1356031 ]\\n   [-0.19638494  0.51091224  0.096462   -0.06863552]\\n   [-0.10546575 -0.44456747  0.51925534 -0.44515204]\\n   [ 0.07901487  0.00578388  0.12137435 -0.40837017]]\\n\\n  [[ 0.9916986  -0.19406009 -0.08435839 -0.1180807 ]\\n   [ 0.9097904  -0.16026178  1.453805   -0.4069232 ]\\n   [ 0.58931273  0.01552818  0.633066   -0.7997602 ]\\n   [ 1.0826112  -0.08126947  0.43451095 -0.24741772]]\\n\\n  [[ 0.3273959   0.48057655  0.70053846 -0.23785356]\\n   [ 0.23586112 -0.4185446  -0.51092875 -0.17806727]\\n   [ 0.17894682 -0.19772175 -0.50655043 -0.85206884]\\n   [ 0.2155672  -0.14814061 -0.36385733  0.11623047]]]], device=cuda()) = needle.Tensor([[[[ 0.9614984   0.18507531  0.45108768 -0.15583369]\\n   [ 0.6721291   0.43875065 -0.40976214 -0.05421432]\\n   [ 0.09986708  0.59877616  0.41438234 -0.34444872]\\n   [ 0.7685642  -0.13823068  0.04601748  0.03305402]]\\n\\n  [[-0.45584416  0.65168923 -0.37744236  0.01817221]\\n   [ 0.56739455  1.253125    0.38783577  0.34113753]\\n   [ 0.11224493  0.29147422  0.6227909   0.66942763]\\n   [ 0.0535505  -0.53826624  0.5199805   0.48923674]]\\n\\n  [[ 0.34109256 -0.07847372  0.18477465  0.10322276]\\n   [ 0.19868082  0.8802005   0.255134    0.92093706]\\n   [ 0.65564984  0.65205157  0.23196039  0.5609234 ]\\n   [ 0.4508136  -0.6336484   0.14944857  0.66682065]]\\n\\n  ...\\n\\n  [[-0.27894512 -0.40351155  0.18792397  0.05672256]\\n   [ 0.20382637 -0.8051432  -0.2684171   0.188351  ]\\n   [-0.25474146 -0.18283749 -0.11097631 -0.14275688]\\n   [-0.09754519 -0.16104588 -0.16492458 -0.49893668]]\\n\\n  [[ 0.47263396  0.6951636   0.17216495  0.6512528 ]\\n   [ 1.4676476  -0.6478419  -0.11291147  0.48149496]\\n   [ 0.75447595  0.72579676 -0.7341296   0.32234484]\\n   [ 0.9251521   0.9411834   0.5674993  -0.44224086]]\\n\\n  [[ 0.23617071  0.21687105  0.35276994  0.02636582]\\n   [ 0.28259185 -0.58970535 -0.39982095 -0.94399536]\\n ... 0.21089122]\\n   [ 0.16398796  0.11440317  0.04611299 -0.3077623 ]\\n   [ 0.5308357   0.17526034  0.16854498 -0.6977975 ]]\\n\\n  [[ 0.4906796   0.25973114  0.81172925 -0.147687  ]\\n   [ 1.2011157   0.20299038 -0.10878524  0.23522797]\\n   [ 0.9648773   1.1387159   0.10492196  0.5536462 ]\\n   [ 0.0537894  -0.02059563 -0.30552495  0.07707847]]\\n\\n  [[ 0.32607388  0.37076294  0.5689548   0.30110627]\\n   [ 0.6903826   0.9133538   0.48307303  0.43004555]\\n   [-0.06159865  0.8618226   0.30547938  1.0129852 ]\\n   [ 0.3798752   0.09115952  0.49076867  0.27220723]]\\n\\n  ...\\n\\n  [[-0.61040914  0.0085753  -0.3121436   0.1356031 ]\\n   [-0.19638494  0.51091224  0.096462   -0.06863552]\\n   [-0.10546575 -0.44456747  0.51925534 -0.44515204]\\n   [ 0.07901487  0.00578388  0.12137435 -0.40837017]]\\n\\n  [[ 0.9916986  -0.19406009 -0.08435839 -0.1180807 ]\\n   [ 0.9097904  -0.16026178  1.453805   -0.4069232 ]\\n   [ 0.58931273  0.01552818  0.633066   -0.7997602 ]\\n   [ 1.0826112  -0.08126947  0.43451095 -0.24741772]]\\n\\n  [[ 0.3273959   0.48057655  0.70053846 -0.23785356]\\n   [ 0.23586112 -0.4185446  -0.51092875 -0.17806727]\\n   [ 0.17894682 -0.19772175 -0.50655043 -0.85206884]\\n   [ 0.2155672  -0.14814061 -0.36385733  0.11623047]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where needle.Tensor([[[[ 0.9614984   0.18507531  0.45108768 -0.15583369]\\n   [ 0.6721291   0.43875065 -0.40976214 -0.05421432]\\n   [ 0.09986708  0.59877616  0.41438234 -0.34444872]\\n   [ 0.7685642  -0.13823068  0.04601748  0.03305402]]\\n\\n  [[-0.45584416  0.65168923 -0.37744236  0.01817221]\\n   [ 0.56739455  1.253125    0.38783577  0.34113753]\\n   [ 0.11224493  0.29147422  0.6227909   0.66942763]\\n   [ 0.0535505  -0.53826624  0.5199805   0.48923674]]\\n\\n  [[ 0.34109256 -0.07847372  0.18477465  0.10322276]\\n   [ 0.19868082  0.8802005   0.255134    0.92093706]\\n   [ 0.65564984  0.65205157  0.23196039  0.5609234 ]\\n   [ 0.4508136  -0.6336484   0.14944857  0.66682065]]\\n\\n  ...\\n\\n  [[-0.27894512 -0.40351155  0.18792397  0.05672256]\\n   [ 0.20382637 -0.8051432  -0.2684171   0.188351  ]\\n   [-0.25474146 -0.18283749 -0.11097631 -0.14275688]\\n   [-0.09754519 -0.16104588 -0.16492458 -0.49893668]]\\n\\n  [[ 0.47263396  0.6951636   0.17216495  0.6512528 ]\\n   [ 1.4676476  -0.6478419  -0.11291147  0.48149496]\\n   [ 0.75447595  0.72579676 -0.7341296   0.32234484]\\n   [ 0.9251521   0.9411834   0.5674993  -0.44224086]]\\n\\n  [[ 0.23617071  0.21687105  0.35276994  0.02636582]\\n   [ 0.28259185 -0.58970535 -0.39982095 -0.94399536]\\n ... 0.21089122]\\n   [ 0.16398796  0.11440317  0.04611299 -0.3077623 ]\\n   [ 0.5308357   0.17526034  0.16854498 -0.6977975 ]]\\n\\n  [[ 0.4906796   0.25973114  0.81172925 -0.147687  ]\\n   [ 1.2011157   0.20299038 -0.10878524  0.23522797]\\n   [ 0.9648773   1.1387159   0.10492196  0.5536462 ]\\n   [ 0.0537894  -0.02059563 -0.30552495  0.07707847]]\\n\\n  [[ 0.32607388  0.37076294  0.5689548   0.30110627]\\n   [ 0.6903826   0.9133538   0.48307303  0.43004555]\\n   [-0.06159865  0.8618226   0.30547938  1.0129852 ]\\n   [ 0.3798752   0.09115952  0.49076867  0.27220723]]\\n\\n  ...\\n\\n  [[-0.61040914  0.0085753  -0.3121436   0.1356031 ]\\n   [-0.19638494  0.51091224  0.096462   -0.06863552]\\n   [-0.10546575 -0.44456747  0.51925534 -0.44515204]\\n   [ 0.07901487  0.00578388  0.12137435 -0.40837017]]\\n\\n  [[ 0.9916986  -0.19406009 -0.08435839 -0.1180807 ]\\n   [ 0.9097904  -0.16026178  1.453805   -0.4069232 ]\\n   [ 0.58931273  0.01552818  0.633066   -0.7997602 ]\\n   [ 1.0826112  -0.08126947  0.43451095 -0.24741772]]\\n\\n  [[ 0.3273959   0.48057655  0.70053846 -0.23785356]\\n   [ 0.23586112 -0.4185446  -0.51092875 -0.17806727]\\n   [ 0.17894682 -0.19772175 -0.50655043 -0.85206884]\\n   [ 0.2155672  -0.14814061 -0.36385733  0.11623047]]]]) = <needle.nn.nn_conv.Conv object at 0x78dd762f54c0>(needle.Tensor([[[[7.98689246e-01 9.23455536e-01 2.99153656e-01 3.88404131e-01]\\n   [4.86272097e-01 5.88151455e-01 9.83853817e-01 6.97330236e-01]\\n   [3.89548510e-01 2.63767689e-01 9.44625735e-01 1.35548428e-01]\\n   [7.20265865e-01 9.25395012e-01 6.64665580e-01 4.23054427e-01]]\\n\\n  [[1.98990941e-01 3.67475331e-01 7.06871808e-01 6.49534225e-01]\\n   [9.27976191e-01 8.66860926e-01 8.16150725e-01 9.11450863e-01]\\n   [2.76337147e-01 3.69523555e-01 3.79893899e-01 5.60450613e-01]\\n   [6.68218255e-01 2.86716670e-01 1.94624681e-02 3.99222374e-01]]\\n\\n  [[3.08527946e-01 9.42184746e-01 8.88265014e-01 8.60310674e-01]\\n   [6.52999759e-01 3.44289154e-01 5.48849285e-01 8.15225065e-01]\\n   [9.86103714e-02 8.01074862e-01 4.11797911e-02 8.16421032e-01]\\n   [8.07563782e-01 5.10073081e-02 6.27160728e-01 5.02453089e-01]]\\n\\n  ...\\n\\n  [[9.71763074e-01 3.63844782e-01 7.87915766e-01 5.55294096e-01]\\n   [3.95633668e-01 9.55465913e-01 5.98315954e-01 1.18916944e-01]\\n   [4.17539209e-01 7.81581700e-01 6.93747044e-01 9.16340351e-01]\\n   [2.59377390e-01 7.58193731e-01 4.59875196e-01 5.73609769e-01]]\\n\\n  [[9.55046654e-01 9.79286313e-01 8.61590981e-01 3.59097093e-01]\\n   [8.87700856e-01 6.38609171e-01 4.29996789e-01 3.57426815e-02]...88966e-01]\\n   [8.38227034e-01 9.35492754e-01 1.41986474e-01 2.59373814e-01]\\n   [4.27461416e-01 9.03285516e-04 6.98143020e-02 2.26491272e-01]]\\n\\n  [[4.81101960e-01 2.51522750e-01 8.76681864e-01 3.24272871e-01]\\n   [9.24622834e-01 9.74787235e-01 4.49861526e-01 2.27128819e-01]\\n   [2.91666120e-01 7.76333690e-01 2.73349702e-01 3.80582869e-01]\\n   [4.78575855e-01 5.75111091e-01 9.96100426e-01 2.32209757e-01]]\\n\\n  ...\\n\\n  [[8.86683226e-01 8.30908775e-01 3.16054411e-02 5.68419039e-01]\\n   [6.09161258e-01 9.61575150e-01 2.32366268e-02 5.31103790e-01]\\n   [2.04781368e-01 5.36629073e-02 5.87488532e-01 7.72604167e-01]\\n   [7.74865448e-01 3.02884094e-02 4.06946391e-01 4.45096269e-02]]\\n\\n  [[2.47838646e-01 1.92880705e-01 2.15182573e-01 3.39118421e-01]\\n   [2.77418047e-01 9.62279916e-01 3.52407128e-01 8.94172490e-01]\\n   [1.81041673e-01 7.63746858e-01 6.13455363e-02 4.62761223e-01]\\n   [5.51044010e-03 8.10290754e-01 9.50486064e-01 3.51073705e-02]]\\n\\n  [[9.33846354e-01 7.73853898e-01 3.58861566e-01 9.08876538e-01]\\n   [2.96257257e-01 4.09295321e-01 9.67112631e-02 6.56938970e-01]\\n   [2.96008289e-02 4.84905273e-01 6.83191836e-01 8.21237624e-01]\\n   [1.49941385e-01 7.54090369e-01 7.19077051e-01 5.59570551e-01]]]]))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 1.13283944e+00,  2.11146444e-01,  3.28146428e-01,\\n          -2.94300765e-01],\\n         [ 8.64967048e-01,  8.48758459e-01, -1.34139165e-01,\\n          -1.81775212e-01],\\n         [ 7.18198478e-01,  1.78922057e-01,  5.13797998e-01,\\n           5.03971756e-01],\\n         [ 3.48404586e-01, -2.31752962e-01,  9.52353403e-02,\\n          -2.37080604e-02]],\\n\\n        [[-1.03525221e-01, -2.80523151e-01, -1.06877041e+00,\\n          -6.20132029e-01],\\n         [ 2.59960532e-01,  4.49261278e-01,  5.80089092e-01,\\n           4.76463825e-01],\\n         [ 7.56408215e-01,  1.01847851e+00,  7.63063312e-01,\\n           5.78593254e-01],\\n         [ 7.72867024e-01,  1.46085322e-01,  6.38055980e-01,\\n           2.69220144e-01]],\\n\\n        [[ 7.37306952e-01,  6.37956738e-01,  4.85839009e-01,\\n           1.44786656e-01],\\n         [ 9.83604193e-01,  6.77989662e-01,  5.66651464e-01,\\n           6.74410760e-01],\\n         [ 6.20535553e-01,  5.66158414e-01,  5.55725813e-01,\\n           2.70422101e-01],\\n         [ 3.90210062e-01,  2.15183832e-02, -3.00094336e-02,\\n           6.24719322e-01]],\\n\\n        ...,\\n\\n        [[-1.82251573e-01, -4.19065773e-01, -6.97782576e-01,\\n          -3.53183836e-01],\\n         [ 1.31522790...01],\\n         [-1.81403816e-01,  4.79588121e-01,  4.74800527e-01,\\n           2.30098337e-01]],\\n\\n        ...,\\n\\n        [[-7.28121758e-01,  9.56341848e-02,  2.07222670e-01,\\n           1.16611645e-02],\\n         [-2.37867087e-01,  3.96258950e-01, -4.22562182e-01,\\n           2.75304735e-01],\\n         [ 3.43546063e-01, -3.55143934e-01, -4.67006594e-01,\\n          -2.13369593e-01],\\n         [-3.97753537e-01, -2.79079795e-01, -2.84636021e-02,\\n          -3.21933061e-01]],\\n\\n        [[-2.12227494e-01, -2.61999965e-01,  7.61673331e-01,\\n           2.23954409e-01],\\n         [ 8.53516519e-01,  1.12631567e-01,  9.63037014e-01,\\n          -1.63880736e-01],\\n         [ 4.88140374e-01, -2.78400600e-01,  3.52733374e-01,\\n           4.58401173e-01],\\n         [ 7.73353875e-01,  8.45712364e-01,  5.57578743e-01,\\n          -6.83829725e-01]],\\n\\n        [[ 7.93174207e-01, -4.68334705e-01,  7.92165473e-02,\\n           2.03460865e-02],\\n         [-3.41133237e-01, -3.85057814e-02,  2.12926656e-01,\\n          -2.78965592e-01],\\n         [-6.48336485e-02,  1.23881690e-01, -9.45147753e-01,\\n          -2.59960413e-01],\\n         [-1.74283534e-01, -6.06331468e-01,  2.69641787e-01,\\n          -5.90705514e-01]]]], dtype=float32) = <built-in method numpy of Tensor object at 0x78dd9adaed50>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x78dd9adaed50> = tensor([[[[ 1.1328e+00,  2.1115e-01,  3.2815e-01, -2.9430e-01],\\n          [ 8.6497e-01,  8.4876e-01, -1.3414e-01, -1.8178e-01],\\n          [ 7.1820e-01,  1.7892e-01,  5.1380e-01,  5.0397e-01],\\n          [ 3.4840e-01, -2.3175e-01,  9.5235e-02, -2.3708e-02]],\\n\\n         [[-1.0353e-01, -2.8052e-01, -1.0688e+00, -6.2013e-01],\\n          [ 2.5996e-01,  4.4926e-01,  5.8009e-01,  4.7646e-01],\\n          [ 7.5641e-01,  1.0185e+00,  7.6306e-01,  5.7859e-01],\\n          [ 7.7287e-01,  1.4609e-01,  6.3806e-01,  2.6922e-01]],\\n\\n         [[ 7.3731e-01,  6.3796e-01,  4.8584e-01,  1.4479e-01],\\n          [ 9.8360e-01,  6.7799e-01,  5.6665e-01,  6.7441e-01],\\n          [ 6.2054e-01,  5.6616e-01,  5.5573e-01,  2.7042e-01],\\n          [ 3.9021e-01,  2.1518e-02, -3.0009e-02,  6.2472e-01]],\\n\\n         ...,\\n\\n         [[-1.8225e-01, -4.1907e-01, -6.9778e-01, -3.5318e-01],\\n          [ 1.3152e-02, -4.7525e-01,  3.4559e-01,  5.7020e-02],\\n          [-3.0725e-01, -2.6807e-01,  7.5777e-03,  5.2009e-02],\\n          [-1.7795e-01, -4.1597e-01,  4.5274e-01, -6.1822e-02]],\\n\\n         [[ 4.1379e-01,  1.3513e-01, -1.2919e-01,  5.3184e-01],\\n          [ 1.2155e+00,  9.5675e-02,  1.0671e-01, -6.6989e-03],\\n          [ 1.4876e+00,...50e-01,  6.7576e-01],\\n          [-4.3260e-01,  1.5645e+00,  5.8104e-01,  1.0303e+00],\\n          [ 3.1491e-01,  2.0707e-01, -1.4859e-01,  2.8729e-01]],\\n\\n         [[ 4.0328e-01,  7.6685e-01,  3.8708e-01, -7.6053e-02],\\n          [ 9.3904e-01,  1.2781e+00, -5.1079e-01,  5.2053e-01],\\n          [ 7.5930e-01,  7.4942e-01, -4.3756e-01,  8.0201e-01],\\n          [-1.8140e-01,  4.7959e-01,  4.7480e-01,  2.3010e-01]],\\n\\n         ...,\\n\\n         [[-7.2812e-01,  9.5634e-02,  2.0722e-01,  1.1661e-02],\\n          [-2.3787e-01,  3.9626e-01, -4.2256e-01,  2.7530e-01],\\n          [ 3.4355e-01, -3.5514e-01, -4.6701e-01, -2.1337e-01],\\n          [-3.9775e-01, -2.7908e-01, -2.8464e-02, -3.2193e-01]],\\n\\n         [[-2.1223e-01, -2.6200e-01,  7.6167e-01,  2.2395e-01],\\n          [ 8.5352e-01,  1.1263e-01,  9.6304e-01, -1.6388e-01],\\n          [ 4.8814e-01, -2.7840e-01,  3.5273e-01,  4.5840e-01],\\n          [ 7.7335e-01,  8.4571e-01,  5.5758e-01, -6.8383e-01]],\\n\\n         [[ 7.9317e-01, -4.6833e-01,  7.9217e-02,  2.0346e-02],\\n          [-3.4113e-01, -3.8506e-02,  2.1293e-01, -2.7897e-01],\\n          [-6.4834e-02,  1.2388e-01, -9.4515e-01, -2.5996e-01],\\n          [-1.7428e-01, -6.0633e-01,  2.6964e-01, -5.9071e-01]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[ 1.1328e+00,  2.1115e-01,  3.2815e-01, -2.9430e-01],\\n          [ 8.6497e-01,  8.4876e-01, -1.3414e-01, -1.8178e-01],\\n          [ 7.1820e-01,  1.7892e-01,  5.1380e-01,  5.0397e-01],\\n          [ 3.4840e-01, -2.3175e-01,  9.5235e-02, -2.3708e-02]],\\n\\n         [[-1.0353e-01, -2.8052e-01, -1.0688e+00, -6.2013e-01],\\n          [ 2.5996e-01,  4.4926e-01,  5.8009e-01,  4.7646e-01],\\n          [ 7.5641e-01,  1.0185e+00,  7.6306e-01,  5.7859e-01],\\n          [ 7.7287e-01,  1.4609e-01,  6.3806e-01,  2.6922e-01]],\\n\\n         [[ 7.3731e-01,  6.3796e-01,  4.8584e-01,  1.4479e-01],\\n          [ 9.8360e-01,  6.7799e-01,  5.6665e-01,  6.7441e-01],\\n          [ 6.2054e-01,  5.6616e-01,  5.5573e-01,  2.7042e-01],\\n          [ 3.9021e-01,  2.1518e-02, -3.0009e-02,  6.2472e-01]],\\n\\n         ...,\\n\\n         [[-1.8225e-01, -4.1907e-01, -6.9778e-01, -3.5318e-01],\\n          [ 1.3152e-02, -4.7525e-01,  3.4559e-01,  5.7020e-02],\\n          [-3.0725e-01, -2.6807e-01,  7.5777e-03,  5.2009e-02],\\n          [-1.7795e-01, -4.1597e-01,  4.5274e-01, -6.1822e-02]],\\n\\n         [[ 4.1379e-01,  1.3513e-01, -1.2919e-01,  5.3184e-01],\\n          [ 1.2155e+00,  9.5675e-02,  1.0671e-01, -6.6989e-03],\\n          [ 1.4876e+00,...50e-01,  6.7576e-01],\\n          [-4.3260e-01,  1.5645e+00,  5.8104e-01,  1.0303e+00],\\n          [ 3.1491e-01,  2.0707e-01, -1.4859e-01,  2.8729e-01]],\\n\\n         [[ 4.0328e-01,  7.6685e-01,  3.8708e-01, -7.6053e-02],\\n          [ 9.3904e-01,  1.2781e+00, -5.1079e-01,  5.2053e-01],\\n          [ 7.5930e-01,  7.4942e-01, -4.3756e-01,  8.0201e-01],\\n          [-1.8140e-01,  4.7959e-01,  4.7480e-01,  2.3010e-01]],\\n\\n         ...,\\n\\n         [[-7.2812e-01,  9.5634e-02,  2.0722e-01,  1.1661e-02],\\n          [-2.3787e-01,  3.9626e-01, -4.2256e-01,  2.7530e-01],\\n          [ 3.4355e-01, -3.5514e-01, -4.6701e-01, -2.1337e-01],\\n          [-3.9775e-01, -2.7908e-01, -2.8464e-02, -3.2193e-01]],\\n\\n         [[-2.1223e-01, -2.6200e-01,  7.6167e-01,  2.2395e-01],\\n          [ 8.5352e-01,  1.1263e-01,  9.6304e-01, -1.6388e-01],\\n          [ 4.8814e-01, -2.7840e-01,  3.5273e-01,  4.5840e-01],\\n          [ 7.7335e-01,  8.4571e-01,  5.5758e-01, -6.8383e-01]],\\n\\n         [[ 7.9317e-01, -4.6833e-01,  7.9217e-02,  2.0346e-02],\\n          [-3.4113e-01, -3.8506e-02,  2.1293e-01, -2.7897e-01],\\n          [-6.4834e-02,  1.2388e-01, -9.4515e-01, -2.5996e-01],\\n          [-1.7428e-01, -6.0633e-01,  2.6964e-01, -5.9071e-01]]]]) = tensor([[[[ 1.1328e+00,  2.1115e-01,  3.2815e-01, -2.9430e-01],\\n          [ 8.6497e-01,  8.4876e-01, -1.3414e-01, -1.8178e-01],\\n          [ 7.1820e-01,  1.7892e-01,  5.1380e-01,  5.0397e-01],\\n          [ 3.4840e-01, -2.3175e-01,  9.5235e-02, -2.3708e-02]],\\n\\n         [[-1.0353e-01, -2.8052e-01, -1.0688e+00, -6.2013e-01],\\n          [ 2.5996e-01,  4.4926e-01,  5.8009e-01,  4.7646e-01],\\n          [ 7.5641e-01,  1.0185e+00,  7.6306e-01,  5.7859e-01],\\n          [ 7.7287e-01,  1.4609e-01,  6.3806e-01,  2.6922e-01]],\\n\\n         [[ 7.3731e-01,  6.3796e-01,  4.8584e-01,  1.4479e-01],\\n          [ 9.8360e-01,  6.7799e-01,  5.6665e-01,  6.7441e-01],\\n          [ 6.2054e-01,  5.6616e-01,  5.5573e-01,  2.7042e-01],\\n          [ 3.9021e-01,  2.1518e-02, -3.0009e-02,  6.2472e-01]],\\n\\n         ...,\\n\\n         [[-1.8225e-01, -4.1907e-01, -6.9778e-01, -3.5318e-01],\\n          [ 1.3152e-02, -4.7525e-01,  3.4559e-01,  5.7020e-02],\\n          [-3.0725e-01, -2.6807e-01,  7.5777e-03,  5.2009e-02],\\n          [-1.7795e-01, -4.1597e-01,  4.5274e-01, -6.1822e-02]],\\n\\n         [[ 4.1379e-01,  1.3513e-01, -1.2919e-01,  5.3184e-01],\\n          [ 1.2155e+00,  9.5675e-02,  1.0671e-01, -6.6989e-03],\\n          [ 1.4876e+00,...0e-01,  1.5645e+00,  5.8104e-01,  1.0303e+00],\\n          [ 3.1491e-01,  2.0707e-01, -1.4859e-01,  2.8729e-01]],\\n\\n         [[ 4.0328e-01,  7.6685e-01,  3.8708e-01, -7.6053e-02],\\n          [ 9.3904e-01,  1.2781e+00, -5.1079e-01,  5.2053e-01],\\n          [ 7.5930e-01,  7.4942e-01, -4.3756e-01,  8.0201e-01],\\n          [-1.8140e-01,  4.7959e-01,  4.7480e-01,  2.3010e-01]],\\n\\n         ...,\\n\\n         [[-7.2812e-01,  9.5634e-02,  2.0722e-01,  1.1661e-02],\\n          [-2.3787e-01,  3.9626e-01, -4.2256e-01,  2.7530e-01],\\n          [ 3.4355e-01, -3.5514e-01, -4.6701e-01, -2.1337e-01],\\n          [-3.9775e-01, -2.7908e-01, -2.8464e-02, -3.2193e-01]],\\n\\n         [[-2.1223e-01, -2.6200e-01,  7.6167e-01,  2.2395e-01],\\n          [ 8.5352e-01,  1.1263e-01,  9.6304e-01, -1.6388e-01],\\n          [ 4.8814e-01, -2.7840e-01,  3.5273e-01,  4.5840e-01],\\n          [ 7.7335e-01,  8.4571e-01,  5.5758e-01, -6.8383e-01]],\\n\\n         [[ 7.9317e-01, -4.6833e-01,  7.9217e-02,  2.0346e-02],\\n          [-3.4113e-01, -3.8506e-02,  2.1293e-01, -2.7897e-01],\\n          [-6.4834e-02,  1.2388e-01, -9.4515e-01, -2.5996e-01],\\n          [-1.7428e-01, -6.0633e-01,  2.6964e-01, -5.9071e-01]]]],\\n       grad_fn=<ConvolutionBackward0>).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[ 1.1328e+00,  2.1115e-01,  3.2815e-01, -2.9430e-01],\\n          [ 8.6497e-01,  8.4876e-01, -1.3414e-01, -1.8178e-01],\\n          [ 7.1820e-01,  1.7892e-01,  5.1380e-01,  5.0397e-01],\\n          [ 3.4840e-01, -2.3175e-01,  9.5235e-02, -2.3708e-02]],\\n\\n         [[-1.0353e-01, -2.8052e-01, -1.0688e+00, -6.2013e-01],\\n          [ 2.5996e-01,  4.4926e-01,  5.8009e-01,  4.7646e-01],\\n          [ 7.5641e-01,  1.0185e+00,  7.6306e-01,  5.7859e-01],\\n          [ 7.7287e-01,  1.4609e-01,  6.3806e-01,  2.6922e-01]],\\n\\n         [[ 7.3731e-01,  6.3796e-01,  4.8584e-01,  1.4479e-01],\\n          [ 9.8360e-01,  6.7799e-01,  5.6665e-01,  6.7441e-01],\\n          [ 6.2054e-01,  5.6616e-01,  5.5573e-01,  2.7042e-01],\\n          [ 3.9021e-01,  2.1518e-02, -3.0009e-02,  6.2472e-01]],\\n\\n         ...,\\n\\n         [[-1.8225e-01, -4.1907e-01, -6.9778e-01, -3.5318e-01],\\n          [ 1.3152e-02, -4.7525e-01,  3.4559e-01,  5.7020e-02],\\n          [-3.0725e-01, -2.6807e-01,  7.5777e-03,  5.2009e-02],\\n          [-1.7795e-01, -4.1597e-01,  4.5274e-01, -6.1822e-02]],\\n\\n         [[ 4.1379e-01,  1.3513e-01, -1.2919e-01,  5.3184e-01],\\n          [ 1.2155e+00,  9.5675e-02,  1.0671e-01, -6.6989e-03],\\n          [ 1.4876e+00,...0e-01,  1.5645e+00,  5.8104e-01,  1.0303e+00],\\n          [ 3.1491e-01,  2.0707e-01, -1.4859e-01,  2.8729e-01]],\\n\\n         [[ 4.0328e-01,  7.6685e-01,  3.8708e-01, -7.6053e-02],\\n          [ 9.3904e-01,  1.2781e+00, -5.1079e-01,  5.2053e-01],\\n          [ 7.5930e-01,  7.4942e-01, -4.3756e-01,  8.0201e-01],\\n          [-1.8140e-01,  4.7959e-01,  4.7480e-01,  2.3010e-01]],\\n\\n         ...,\\n\\n         [[-7.2812e-01,  9.5634e-02,  2.0722e-01,  1.1661e-02],\\n          [-2.3787e-01,  3.9626e-01, -4.2256e-01,  2.7530e-01],\\n          [ 3.4355e-01, -3.5514e-01, -4.6701e-01, -2.1337e-01],\\n          [-3.9775e-01, -2.7908e-01, -2.8464e-02, -3.2193e-01]],\\n\\n         [[-2.1223e-01, -2.6200e-01,  7.6167e-01,  2.2395e-01],\\n          [ 8.5352e-01,  1.1263e-01,  9.6304e-01, -1.6388e-01],\\n          [ 4.8814e-01, -2.7840e-01,  3.5273e-01,  4.5840e-01],\\n          [ 7.7335e-01,  8.4571e-01,  5.5758e-01, -6.8383e-01]],\\n\\n         [[ 7.9317e-01, -4.6833e-01,  7.9217e-02,  2.0346e-02],\\n          [-3.4113e-01, -3.8506e-02,  2.1293e-01, -2.7897e-01],\\n          [-6.4834e-02,  1.2388e-01, -9.4515e-01, -2.5996e-01],\\n          [-1.7428e-01, -6.0633e-01,  2.6964e-01, -5.9071e-01]]]],\\n       grad_fn=<ConvolutionBackward0>) = Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(tensor([[[[7.9869e-01, 9.2346e-01, 2.9915e-01, 3.8840e-01],\\n          [4.8627e-01, 5.8815e-01, 9.8385e-01, 6.9733e-01],\\n          [3.8955e-01, 2.6377e-01, 9.4463e-01, 1.3555e-01],\\n          [7.2027e-01, 9.2540e-01, 6.6467e-01, 4.2305e-01]],\\n\\n         [[1.9899e-01, 3.6748e-01, 7.0687e-01, 6.4953e-01],\\n          [9.2798e-01, 8.6686e-01, 8.1615e-01, 9.1145e-01],\\n          [2.7634e-01, 3.6952e-01, 3.7989e-01, 5.6045e-01],\\n          [6.6822e-01, 2.8672e-01, 1.9462e-02, 3.9922e-01]],\\n\\n         [[3.0853e-01, 9.4218e-01, 8.8827e-01, 8.6031e-01],\\n          [6.5300e-01, 3.4429e-01, 5.4885e-01, 8.1523e-01],\\n          [9.8610e-02, 8.0107e-01, 4.1180e-02, 8.1642e-01],\\n          [8.0756e-01, 5.1007e-02, 6.2716e-01, 5.0245e-01]],\\n\\n         ...,\\n\\n         [[9.7176e-01, 3.6384e-01, 7.8792e-01, 5.5529e-01],\\n          [3.9563e-01, 9.5547e-01, 5.9832e-01, 1.1892e-01],\\n          [4.1754e-01, 7.8158e-01, 6.9375e-01, 9.1634e-01],\\n          [2.5938e-01, 7.5819e-01, 4.5988e-01, 5.7361e-01]],\\n\\n         [[9.5505e-01, 9.7929e-01, 8.6159e-01, 3.5910e-01],\\n          [8.8770e-01, 6.3861e-01, 4.3000e-01, 3.5743e-02],\\n          [7.7013e-01, 5.0211e-01, 7.8619e-01, 7.4802e-01],\\n          [7.9357e-01, 3.0065e-01, ...250e-02, 3.6612e-01, 8.9264e-01],\\n          [8.4438e-02, 1.6548e-01, 6.2542e-01, 6.2279e-01],\\n          [8.3823e-01, 9.3549e-01, 1.4199e-01, 2.5937e-01],\\n          [4.2746e-01, 9.0329e-04, 6.9814e-02, 2.2649e-01]],\\n\\n         [[4.8110e-01, 2.5152e-01, 8.7668e-01, 3.2427e-01],\\n          [9.2462e-01, 9.7479e-01, 4.4986e-01, 2.2713e-01],\\n          [2.9167e-01, 7.7633e-01, 2.7335e-01, 3.8058e-01],\\n          [4.7858e-01, 5.7511e-01, 9.9610e-01, 2.3221e-01]],\\n\\n         ...,\\n\\n         [[8.8668e-01, 8.3091e-01, 3.1605e-02, 5.6842e-01],\\n          [6.0916e-01, 9.6158e-01, 2.3237e-02, 5.3110e-01],\\n          [2.0478e-01, 5.3663e-02, 5.8749e-01, 7.7260e-01],\\n          [7.7487e-01, 3.0288e-02, 4.0695e-01, 4.4510e-02]],\\n\\n         [[2.4784e-01, 1.9288e-01, 2.1518e-01, 3.3912e-01],\\n          [2.7742e-01, 9.6228e-01, 3.5241e-01, 8.9417e-01],\\n          [1.8104e-01, 7.6375e-01, 6.1346e-02, 4.6276e-01],\\n          [5.5104e-03, 8.1029e-01, 9.5049e-01, 3.5107e-02]],\\n\\n         [[9.3385e-01, 7.7385e-01, 3.5886e-01, 9.0888e-01],\\n          [2.9626e-01, 4.0930e-01, 9.6711e-02, 6.5694e-01],\\n          [2.9601e-02, 4.8491e-01, 6.8319e-01, 8.2124e-01],\\n          [1.4994e-01, 7.5409e-01, 7.1908e-01, 5.5957e-01]]]]))\u001b[0m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78dd762f54c0>\n",
            "g          = Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 4\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[7.98689246e-01 9.23455536e-01 2.99153656e-01 3.88404131e-01]\n",
            "   [4.86272097e-01 5.88151455e-01 9.838...e-02 4.84905273e-01 6.83191836e-01 8.21237624e-01]\n",
            "   [1.49941385e-01 7.54090369e-01 7.19077051e-01 5.59570551e-01]]]])\n",
            "z          = tensor([[[[7.9869e-01, 9.2346e-01, 2.9915e-01, 3.8840e-01],\n",
            "          [4.8627e-01, 5.8815e-01, 9.8385e-01, 6.9733e-01]...       [2.9601e-02, 4.8491e-01, 6.8319e-01, 8.2124e-01],\n",
            "          [1.4994e-01, 7.5409e-01, 7.1908e-01, 5.5957e-01]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-16-3-2] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 8, cout = 16, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert np.float32(116.216415) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(116.216415) = <function norm at 0x78de681e28f0>((array([[[[ 9.50395107e-01,  3.21526706e-01,  1.63950473e-01, ...,\\n           5.05320251e-01,  1.34905100e-01,  3.84345680e-01],\\n         [ 6.13426208e-01,  1.68655366e-01,  4.52038616e-01, ...,\\n           1.14690971e+00,  3.88191551e-01,  7.21741199e-01],\\n         [ 1.19367230e+00,  1.25065315e+00,  5.98395824e-01, ...,\\n           3.59696448e-01,  5.48729420e-01,  4.41675156e-01],\\n         ...,\\n         [ 1.28314316e+00,  9.73905444e-01,  2.57270396e-01, ...,\\n           3.70159060e-01, -1.23191074e-01,  3.93700421e-01],\\n         [ 7.89439142e-01,  2.82939762e-01,  1.67972654e-01, ...,\\n          -9.02334228e-02,  2.07455784e-01, -5.99997282e-01],\\n         [ 5.98105490e-01,  2.36299396e-01,  2.44247615e-01, ...,\\n           1.42445803e-01, -1.59476861e-01, -2.63356447e-01]],\\n\\n        [[-6.10701323e-01, -6.14604473e-01,  2.05927879e-01, ...,\\n           1.83845937e-01, -9.11953032e-01,  4.73720044e-01],\\n         [-1.10629126e-01,  4.44203138e-01,  7.91594744e-01, ...,\\n           3.40120047e-01,  6.55336440e-01,  6.95094764e-01],\\n         [ 5.34845173e-01,  3.94934684e-01, -4.08148438e-01, ...,\\n           9.55740437e-02, -4.10786606e-02,  1.64239645e-01],\\n         ...,\\n         [ 2.110...   ...,\\n         [ 9.38201249e-01,  2.89379880e-02, -4.50358212e-01, ...,\\n          -5.45014888e-02,  1.38011658e+00,  1.34637177e+00],\\n         [ 6.89967155e-01, -6.53528988e-01,  1.28930604e+00, ...,\\n           5.32465816e-01, -7.93475360e-02,  4.61623162e-01],\\n         [ 7.92554259e-01,  2.99716681e-01,  2.02750921e-01, ...,\\n           6.43168271e-01,  2.23002881e-01,  1.06033117e-01]],\\n\\n        [[ 3.27151150e-01,  3.47317010e-02,  5.17835140e-01, ...,\\n           4.26491141e-01, -2.05965221e-01,  6.18042111e-01],\\n         [ 1.14071198e-01, -5.94645590e-02, -7.46991217e-01, ...,\\n          -1.30947936e+00, -3.16619992e-01, -1.06311285e+00],\\n         [ 3.78764898e-01,  4.13930006e-02, -5.37174821e-01, ...,\\n           2.72973269e-01, -4.19536203e-01, -7.99152255e-02],\\n         ...,\\n         [-5.57190835e-01, -4.72976506e-01, -5.51198602e-01, ...,\\n          -1.53226149e+00, -3.23101997e-01, -6.69011831e-01],\\n         [ 3.28084826e-01, -9.52885449e-01, -8.02080452e-01, ...,\\n          -4.01418582e-02, -8.54934454e-01, -1.50654107e-01],\\n         [ 3.39581043e-01, -8.95585895e-01, -3.51220369e-01, ...,\\n          -1.84171915e-01, -2.05860622e-02, -2.81132698e-01]]]],\\n      dtype=float32) - array([[[[ 1.25517499e+00,  1.23805308e+00,  5.06362855e-01, ...,\\n           3.76563638e-01,  1.92835450e-01,  4.68248636e-01],\\n         [ 6.87683582e-01, -9.25929770e-02,  8.39353919e-01, ...,\\n           6.96082592e-01,  1.18835187e+00, -3.01308870e-01],\\n         [ 7.39141524e-01,  3.88867825e-01,  4.94218498e-01, ...,\\n           4.01363045e-01,  7.63477802e-01,  7.20197916e-01],\\n         ...,\\n         [ 4.52959210e-01,  4.24301773e-01,  7.03548864e-02, ...,\\n          -2.59804912e-02, -1.27740011e-01,  3.21708381e-01],\\n         [ 7.04538345e-01,  4.93652672e-02,  5.52885652e-01, ...,\\n          -8.52732956e-02,  1.01796591e+00, -1.58051938e-01],\\n         [ 9.65068221e-01,  2.02497691e-01,  2.69775808e-01, ...,\\n           1.53577477e-01,  1.72773600e-02,  2.94009775e-01]],\\n\\n        [[-1.17994428e-01,  8.70674372e-01, -3.34805667e-01, ...,\\n          -4.80107933e-01,  3.73688996e-01,  6.93071932e-02],\\n         [ 5.98219991e-01,  7.39419237e-02,  5.07466793e-01, ...,\\n           1.39197969e+00,  4.62339550e-01,  6.54042065e-01],\\n         [ 5.23016095e-01, -3.37546796e-01,  3.69948447e-01, ...,\\n           1.00172080e-01,  6.31091356e-01,  4.25991982e-01],\\n         ...,\\n         [-1.743...   ...,\\n         [ 8.86188686e-01,  5.88466585e-01, -4.42435801e-01, ...,\\n           5.20224988e-01,  6.71351492e-01,  4.22686487e-01],\\n         [ 6.32111132e-01,  4.58991557e-01,  1.77357495e-01, ...,\\n          -4.59594101e-01,  5.48739314e-01,  4.59446669e-01],\\n         [ 1.87763977e+00, -1.69312418e-01,  9.62234974e-01, ...,\\n          -1.87873214e-01, -2.08155155e-01,  3.72916669e-01]],\\n\\n        [[ 1.49956733e-01,  2.92518139e-01, -1.99758917e-01, ...,\\n          -2.80823916e-01, -1.99688263e-02, -2.60857552e-01],\\n         [-2.82422990e-01, -5.30835986e-01, -9.93221998e-01, ...,\\n          -6.44835830e-01, -5.30486763e-01, -5.19809306e-01],\\n         [-2.64891349e-02,  4.13195670e-01, -6.94190264e-01, ...,\\n          -4.13916022e-01, -1.42627567e-01, -2.81290799e-01],\\n         ...,\\n         [ 2.59776384e-01, -4.74356860e-01, -1.39674291e-01, ...,\\n          -8.22058916e-01, -3.14598009e-02, -7.50814676e-01],\\n         [ 3.83682728e-01, -7.49206722e-01,  3.03213410e-02, ...,\\n          -3.31378341e-01, -3.83156687e-01, -3.59465331e-01],\\n         [-1.41593695e-01, -4.57422912e-01, -2.30891585e-01, ...,\\n           9.08953547e-02, -4.65405762e-01, -6.65843785e-01]]]],\\n      dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78de681e28f0> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 9.50395107e-01,  3.21526706e-01,  1.63950473e-01, ...,\\n           5.05320251e-01,  1.34905100e-01,  3.84345680e-01],\\n         [ 6.13426208e-01,  1.68655366e-01,  4.52038616e-01, ...,\\n           1.14690971e+00,  3.88191551e-01,  7.21741199e-01],\\n         [ 1.19367230e+00,  1.25065315e+00,  5.98395824e-01, ...,\\n           3.59696448e-01,  5.48729420e-01,  4.41675156e-01],\\n         ...,\\n         [ 1.28314316e+00,  9.73905444e-01,  2.57270396e-01, ...,\\n           3.70159060e-01, -1.23191074e-01,  3.93700421e-01],\\n         [ 7.89439142e-01,  2.82939762e-01,  1.67972654e-01, ...,\\n          -9.02334228e-02,  2.07455784e-01, -5.99997282e-01],\\n         [ 5.98105490e-01,  2.36299396e-01,  2.44247615e-01, ...,\\n           1.42445803e-01, -1.59476861e-01, -2.63356447e-01]],\\n\\n        [[-6.10701323e-01, -6.14604473e-01,  2.05927879e-01, ...,\\n           1.83845937e-01, -9.11953032e-01,  4.73720044e-01],\\n         [-1.10629126e-01,  4.44203138e-01,  7.91594744e-01, ...,\\n           3.40120047e-01,  6.55336440e-01,  6.95094764e-01],\\n         [ 5.34845173e-01,  3.94934684e-01, -4.08148438e-01, ...,\\n           9.55740437e-02, -4.10786606e-02,  1.64239645e-01],\\n         ...,\\n         [ 2.110...   ...,\\n         [ 9.38201249e-01,  2.89379880e-02, -4.50358212e-01, ...,\\n          -5.45014888e-02,  1.38011658e+00,  1.34637177e+00],\\n         [ 6.89967155e-01, -6.53528988e-01,  1.28930604e+00, ...,\\n           5.32465816e-01, -7.93475360e-02,  4.61623162e-01],\\n         [ 7.92554259e-01,  2.99716681e-01,  2.02750921e-01, ...,\\n           6.43168271e-01,  2.23002881e-01,  1.06033117e-01]],\\n\\n        [[ 3.27151150e-01,  3.47317010e-02,  5.17835140e-01, ...,\\n           4.26491141e-01, -2.05965221e-01,  6.18042111e-01],\\n         [ 1.14071198e-01, -5.94645590e-02, -7.46991217e-01, ...,\\n          -1.30947936e+00, -3.16619992e-01, -1.06311285e+00],\\n         [ 3.78764898e-01,  4.13930006e-02, -5.37174821e-01, ...,\\n           2.72973269e-01, -4.19536203e-01, -7.99152255e-02],\\n         ...,\\n         [-5.57190835e-01, -4.72976506e-01, -5.51198602e-01, ...,\\n          -1.53226149e+00, -3.23101997e-01, -6.69011831e-01],\\n         [ 3.28084826e-01, -9.52885449e-01, -8.02080452e-01, ...,\\n          -4.01418582e-02, -8.54934454e-01, -1.50654107e-01],\\n         [ 3.39581043e-01, -8.95585895e-01, -3.51220369e-01, ...,\\n          -1.84171915e-01, -2.05860622e-02, -2.81132698e-01]]]],\\n      dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where numpy = NDArray([[[[ 9.50395107e-01  3.21526706e-01  1.63950473e-01 ...  5.05320251e-01\\n     1.34905100e-01  3.84345680e-01]\\n   [ 6.13426208e-01  1.68655366e-01  4.52038616e-01 ...  1.14690971e+00\\n     3.88191551e-01  7.21741199e-01]\\n   [ 1.19367230e+00  1.25065315e+00  5.98395824e-01 ...  3.59696448e-01\\n     5.48729420e-01  4.41675156e-01]\\n   ...\\n   [ 1.28314316e+00  9.73905444e-01  2.57270396e-01 ...  3.70159060e-01\\n    -1.23191074e-01  3.93700421e-01]\\n   [ 7.89439142e-01  2.82939762e-01  1.67972654e-01 ... -9.02334228e-02\\n     2.07455784e-01 -5.99997282e-01]\\n   [ 5.98105490e-01  2.36299396e-01  2.44247615e-01 ...  1.42445803e-01\\n    -1.59476861e-01 -2.63356447e-01]]\\n\\n  [[-6.10701323e-01 -6.14604473e-01  2.05927879e-01 ...  1.83845937e-01\\n    -9.11953032e-01  4.73720044e-01]\\n   [-1.10629126e-01  4.44203138e-01  7.91594744e-01 ...  3.40120047e-01\\n     6.55336440e-01  6.95094764e-01]\\n   [ 5.34845173e-01  3.94934684e-01 -4.08148438e-01 ...  9.55740437e-02\\n    -4.10786606e-02  1.64239645e-01]\\n   ...\\n   [ 2.11003363e-01  8.82716894e-01  1.31874293e-01 ...  8.71454835e-01\\n     2.42752314e-01  3.73536050e-01]\\n   [ 4.91608948e-01 -1.55880004e-01  8.40625390e-02 ...  2.14333653e-01\\n     1.67362...2  2.81505972e-01 ...  4.30270821e-01\\n     6.34850096e-03 -3.69563103e-01]\\n   [ 8.15983832e-01  7.27352083e-01 -1.27897769e-01 ... -5.57616279e-02\\n     7.79671431e-01  9.00181174e-01]\\n   ...\\n   [ 9.38201249e-01  2.89379880e-02 -4.50358212e-01 ... -5.45014888e-02\\n     1.38011658e+00  1.34637177e+00]\\n   [ 6.89967155e-01 -6.53528988e-01  1.28930604e+00 ...  5.32465816e-01\\n    -7.93475360e-02  4.61623162e-01]\\n   [ 7.92554259e-01  2.99716681e-01  2.02750921e-01 ...  6.43168271e-01\\n     2.23002881e-01  1.06033117e-01]]\\n\\n  [[ 3.27151150e-01  3.47317010e-02  5.17835140e-01 ...  4.26491141e-01\\n    -2.05965221e-01  6.18042111e-01]\\n   [ 1.14071198e-01 -5.94645590e-02 -7.46991217e-01 ... -1.30947936e+00\\n    -3.16619992e-01 -1.06311285e+00]\\n   [ 3.78764898e-01  4.13930006e-02 -5.37174821e-01 ...  2.72973269e-01\\n    -4.19536203e-01 -7.99152255e-02]\\n   ...\\n   [-5.57190835e-01 -4.72976506e-01 -5.51198602e-01 ... -1.53226149e+00\\n    -3.23101997e-01 -6.69011831e-01]\\n   [ 3.28084826e-01 -9.52885449e-01 -8.02080452e-01 ... -4.01418582e-02\\n    -8.54934454e-01 -1.50654107e-01]\\n   [ 3.39581043e-01 -8.95585895e-01 -3.51220369e-01 ... -1.84171915e-01\\n    -2.05860622e-02 -2.81132698e-01]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where NDArray([[[[ 9.50395107e-01  3.21526706e-01  1.63950473e-01 ...  5.05320251e-01\\n     1.34905100e-01  3.84345680e-01]\\n   [ 6.13426208e-01  1.68655366e-01  4.52038616e-01 ...  1.14690971e+00\\n     3.88191551e-01  7.21741199e-01]\\n   [ 1.19367230e+00  1.25065315e+00  5.98395824e-01 ...  3.59696448e-01\\n     5.48729420e-01  4.41675156e-01]\\n   ...\\n   [ 1.28314316e+00  9.73905444e-01  2.57270396e-01 ...  3.70159060e-01\\n    -1.23191074e-01  3.93700421e-01]\\n   [ 7.89439142e-01  2.82939762e-01  1.67972654e-01 ... -9.02334228e-02\\n     2.07455784e-01 -5.99997282e-01]\\n   [ 5.98105490e-01  2.36299396e-01  2.44247615e-01 ...  1.42445803e-01\\n    -1.59476861e-01 -2.63356447e-01]]\\n\\n  [[-6.10701323e-01 -6.14604473e-01  2.05927879e-01 ...  1.83845937e-01\\n    -9.11953032e-01  4.73720044e-01]\\n   [-1.10629126e-01  4.44203138e-01  7.91594744e-01 ...  3.40120047e-01\\n     6.55336440e-01  6.95094764e-01]\\n   [ 5.34845173e-01  3.94934684e-01 -4.08148438e-01 ...  9.55740437e-02\\n    -4.10786606e-02  1.64239645e-01]\\n   ...\\n   [ 2.11003363e-01  8.82716894e-01  1.31874293e-01 ...  8.71454835e-01\\n     2.42752314e-01  3.73536050e-01]\\n   [ 4.91608948e-01 -1.55880004e-01  8.40625390e-02 ...  2.14333653e-01\\n     1.67362...2  2.81505972e-01 ...  4.30270821e-01\\n     6.34850096e-03 -3.69563103e-01]\\n   [ 8.15983832e-01  7.27352083e-01 -1.27897769e-01 ... -5.57616279e-02\\n     7.79671431e-01  9.00181174e-01]\\n   ...\\n   [ 9.38201249e-01  2.89379880e-02 -4.50358212e-01 ... -5.45014888e-02\\n     1.38011658e+00  1.34637177e+00]\\n   [ 6.89967155e-01 -6.53528988e-01  1.28930604e+00 ...  5.32465816e-01\\n    -7.93475360e-02  4.61623162e-01]\\n   [ 7.92554259e-01  2.99716681e-01  2.02750921e-01 ...  6.43168271e-01\\n     2.23002881e-01  1.06033117e-01]]\\n\\n  [[ 3.27151150e-01  3.47317010e-02  5.17835140e-01 ...  4.26491141e-01\\n    -2.05965221e-01  6.18042111e-01]\\n   [ 1.14071198e-01 -5.94645590e-02 -7.46991217e-01 ... -1.30947936e+00\\n    -3.16619992e-01 -1.06311285e+00]\\n   [ 3.78764898e-01  4.13930006e-02 -5.37174821e-01 ...  2.72973269e-01\\n    -4.19536203e-01 -7.99152255e-02]\\n   ...\\n   [-5.57190835e-01 -4.72976506e-01 -5.51198602e-01 ... -1.53226149e+00\\n    -3.23101997e-01 -6.69011831e-01]\\n   [ 3.28084826e-01 -9.52885449e-01 -8.02080452e-01 ... -4.01418582e-02\\n    -8.54934454e-01 -1.50654107e-01]\\n   [ 3.39581043e-01 -8.95585895e-01 -3.51220369e-01 ... -1.84171915e-01\\n    -2.05860622e-02 -2.81132698e-01]]]], device=cuda()) = needle.Tensor([[[[ 9.50395107e-01  3.21526706e-01  1.63950473e-01 ...  5.05320251e-01\\n     1.34905100e-01  3.84345680e-01]\\n   [ 6.13426208e-01  1.68655366e-01  4.52038616e-01 ...  1.14690971e+00\\n     3.88191551e-01  7.21741199e-01]\\n   [ 1.19367230e+00  1.25065315e+00  5.98395824e-01 ...  3.59696448e-01\\n     5.48729420e-01  4.41675156e-01]\\n   ...\\n   [ 1.28314316e+00  9.73905444e-01  2.57270396e-01 ...  3.70159060e-01\\n    -1.23191074e-01  3.93700421e-01]\\n   [ 7.89439142e-01  2.82939762e-01  1.67972654e-01 ... -9.02334228e-02\\n     2.07455784e-01 -5.99997282e-01]\\n   [ 5.98105490e-01  2.36299396e-01  2.44247615e-01 ...  1.42445803e-01\\n    -1.59476861e-01 -2.63356447e-01]]\\n\\n  [[-6.10701323e-01 -6.14604473e-01  2.05927879e-01 ...  1.83845937e-01\\n    -9.11953032e-01  4.73720044e-01]\\n   [-1.10629126e-01  4.44203138e-01  7.91594744e-01 ...  3.40120047e-01\\n     6.55336440e-01  6.95094764e-01]\\n   [ 5.34845173e-01  3.94934684e-01 -4.08148438e-01 ...  9.55740437e-02\\n    -4.10786606e-02  1.64239645e-01]\\n   ...\\n   [ 2.11003363e-01  8.82716894e-01  1.31874293e-01 ...  8.71454835e-01\\n     2.42752314e-01  3.73536050e-01]\\n   [ 4.91608948e-01 -1.55880004e-01  8.40625390e-02 ...  2.14333653e-01\\n     1...  2.56281551e-02  2.81505972e-01 ...  4.30270821e-01\\n     6.34850096e-03 -3.69563103e-01]\\n   [ 8.15983832e-01  7.27352083e-01 -1.27897769e-01 ... -5.57616279e-02\\n     7.79671431e-01  9.00181174e-01]\\n   ...\\n   [ 9.38201249e-01  2.89379880e-02 -4.50358212e-01 ... -5.45014888e-02\\n     1.38011658e+00  1.34637177e+00]\\n   [ 6.89967155e-01 -6.53528988e-01  1.28930604e+00 ...  5.32465816e-01\\n    -7.93475360e-02  4.61623162e-01]\\n   [ 7.92554259e-01  2.99716681e-01  2.02750921e-01 ...  6.43168271e-01\\n     2.23002881e-01  1.06033117e-01]]\\n\\n  [[ 3.27151150e-01  3.47317010e-02  5.17835140e-01 ...  4.26491141e-01\\n    -2.05965221e-01  6.18042111e-01]\\n   [ 1.14071198e-01 -5.94645590e-02 -7.46991217e-01 ... -1.30947936e+00\\n    -3.16619992e-01 -1.06311285e+00]\\n   [ 3.78764898e-01  4.13930006e-02 -5.37174821e-01 ...  2.72973269e-01\\n    -4.19536203e-01 -7.99152255e-02]\\n   ...\\n   [-5.57190835e-01 -4.72976506e-01 -5.51198602e-01 ... -1.53226149e+00\\n    -3.23101997e-01 -6.69011831e-01]\\n   [ 3.28084826e-01 -9.52885449e-01 -8.02080452e-01 ... -4.01418582e-02\\n    -8.54934454e-01 -1.50654107e-01]\\n   [ 3.39581043e-01 -8.95585895e-01 -3.51220369e-01 ... -1.84171915e-01\\n    -2.05860622e-02 -2.81132698e-01]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where needle.Tensor([[[[ 9.50395107e-01  3.21526706e-01  1.63950473e-01 ...  5.05320251e-01\\n     1.34905100e-01  3.84345680e-01]\\n   [ 6.13426208e-01  1.68655366e-01  4.52038616e-01 ...  1.14690971e+00\\n     3.88191551e-01  7.21741199e-01]\\n   [ 1.19367230e+00  1.25065315e+00  5.98395824e-01 ...  3.59696448e-01\\n     5.48729420e-01  4.41675156e-01]\\n   ...\\n   [ 1.28314316e+00  9.73905444e-01  2.57270396e-01 ...  3.70159060e-01\\n    -1.23191074e-01  3.93700421e-01]\\n   [ 7.89439142e-01  2.82939762e-01  1.67972654e-01 ... -9.02334228e-02\\n     2.07455784e-01 -5.99997282e-01]\\n   [ 5.98105490e-01  2.36299396e-01  2.44247615e-01 ...  1.42445803e-01\\n    -1.59476861e-01 -2.63356447e-01]]\\n\\n  [[-6.10701323e-01 -6.14604473e-01  2.05927879e-01 ...  1.83845937e-01\\n    -9.11953032e-01  4.73720044e-01]\\n   [-1.10629126e-01  4.44203138e-01  7.91594744e-01 ...  3.40120047e-01\\n     6.55336440e-01  6.95094764e-01]\\n   [ 5.34845173e-01  3.94934684e-01 -4.08148438e-01 ...  9.55740437e-02\\n    -4.10786606e-02  1.64239645e-01]\\n   ...\\n   [ 2.11003363e-01  8.82716894e-01  1.31874293e-01 ...  8.71454835e-01\\n     2.42752314e-01  3.73536050e-01]\\n   [ 4.91608948e-01 -1.55880004e-01  8.40625390e-02 ...  2.14333653e-01\\n     1...  2.56281551e-02  2.81505972e-01 ...  4.30270821e-01\\n     6.34850096e-03 -3.69563103e-01]\\n   [ 8.15983832e-01  7.27352083e-01 -1.27897769e-01 ... -5.57616279e-02\\n     7.79671431e-01  9.00181174e-01]\\n   ...\\n   [ 9.38201249e-01  2.89379880e-02 -4.50358212e-01 ... -5.45014888e-02\\n     1.38011658e+00  1.34637177e+00]\\n   [ 6.89967155e-01 -6.53528988e-01  1.28930604e+00 ...  5.32465816e-01\\n    -7.93475360e-02  4.61623162e-01]\\n   [ 7.92554259e-01  2.99716681e-01  2.02750921e-01 ...  6.43168271e-01\\n     2.23002881e-01  1.06033117e-01]]\\n\\n  [[ 3.27151150e-01  3.47317010e-02  5.17835140e-01 ...  4.26491141e-01\\n    -2.05965221e-01  6.18042111e-01]\\n   [ 1.14071198e-01 -5.94645590e-02 -7.46991217e-01 ... -1.30947936e+00\\n    -3.16619992e-01 -1.06311285e+00]\\n   [ 3.78764898e-01  4.13930006e-02 -5.37174821e-01 ...  2.72973269e-01\\n    -4.19536203e-01 -7.99152255e-02]\\n   ...\\n   [-5.57190835e-01 -4.72976506e-01 -5.51198602e-01 ... -1.53226149e+00\\n    -3.23101997e-01 -6.69011831e-01]\\n   [ 3.28084826e-01 -9.52885449e-01 -8.02080452e-01 ... -4.01418582e-02\\n    -8.54934454e-01 -1.50654107e-01]\\n   [ 3.39581043e-01 -8.95585895e-01 -3.51220369e-01 ... -1.84171915e-01\\n    -2.05860622e-02 -2.81132698e-01]]]]) = <needle.nn.nn_conv.Conv object at 0x78de6d9cb3b0>(needle.Tensor([[[[7.98689246e-01 9.23455536e-01 2.99153656e-01 ... 2.86716670e-01\\n    1.94624681e-02 3.99222374e-01]\\n   [3.08527946e-01 9.42184746e-01 8.88265014e-01 ... 5.66311598e-01\\n    1.85816750e-01 1.04736105e-01]\\n   [1.16558611e-01 3.57639045e-01 4.65483684e-03 ... 7.58193731e-01\\n    4.59875196e-01 5.73609769e-01]\\n   ...\\n   [5.83137989e-01 2.58035958e-01 4.73385721e-01 ... 4.09021497e-01\\n    3.32248926e-01 9.89525080e-01]\\n   [6.44415557e-01 3.65998030e-01 1.02019534e-01 ... 3.11449409e-01\\n    2.48276561e-01 2.77935356e-01]\\n   [3.18402946e-01 7.28947699e-01 5.69195986e-01 ... 6.31904125e-01\\n    9.55912292e-01 5.85051000e-01]]\\n\\n  [[9.67400610e-01 9.61606145e-01 6.50200307e-01 ... 4.39745307e-01\\n    1.05857393e-02 9.64927971e-01]\\n   [9.62023258e-01 2.17552215e-01 4.13463712e-02 ... 7.80748576e-02\\n    3.23215187e-01 9.13392186e-01]\\n   [2.01005489e-01 8.43590379e-01 6.96323693e-01 ... 6.38084590e-01\\n    5.85109115e-01 9.01562810e-01]\\n   ...\\n   [9.17539477e-01 7.57734299e-01 6.13006838e-02 ... 6.05390489e-01\\n    5.66088438e-01 5.75838387e-01]\\n   [3.01289201e-01 6.18867040e-01 2.43580267e-01 ... 2.75665343e-01\\n    2.39580035e-01 7.34296203e-01]\\n   [7.16975093e-01 5.84482968e-01 9...6220199e-01\\n    9.47245300e-01 7.90944040e-01]\\n   [3.13023239e-01 2.37184212e-01 8.52788508e-01 ... 8.89857590e-01\\n    2.16290846e-01 3.55848640e-01]\\n   [7.55352318e-01 7.98110664e-01 7.07496703e-01 ... 3.19811888e-02\\n    7.54800916e-01 2.12117389e-01]\\n   ...\\n   [3.10562938e-01 8.96285176e-01 9.21801627e-01 ... 5.01892149e-01\\n    8.28521311e-01 1.88935921e-01]\\n   [2.69967705e-01 7.24371195e-01 4.81093913e-01 ... 7.13700593e-01\\n    5.14470339e-01 7.08962262e-01]\\n   [1.78249896e-01 3.33613068e-01 7.81454265e-01 ... 3.69055241e-01\\n    3.81516188e-01 3.23596269e-01]]\\n\\n  [[2.47220576e-01 2.97148794e-01 2.59316325e-01 ... 1.12927690e-01\\n    6.38698344e-04 8.84175956e-01]\\n   [6.19208097e-01 3.84194463e-01 5.65075397e-01 ... 5.84037662e-01\\n    3.08480412e-01 8.08276415e-01]\\n   [6.35976851e-01 5.82032800e-01 9.83472168e-01 ... 5.08742690e-01\\n    6.64737344e-01 8.72716010e-01]\\n   ...\\n   [4.89139318e-01 6.49093211e-01 3.12372208e-01 ... 2.72779584e-01\\n    1.65092692e-01 1.54684763e-02]\\n   [3.94311816e-01 8.85334313e-01 2.10236609e-02 ... 3.84952545e-01\\n    3.36870641e-01 4.97488052e-01]\\n   [3.27695936e-01 3.37259332e-03 4.18287754e-01 ... 8.71726155e-01\\n    1.33087680e-01 2.05006897e-01]]]]))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 1.25517499e+00,  1.23805308e+00,  5.06362855e-01, ...,\\n           3.76563638e-01,  1.92835450e-01,  4.68248636e-01],\\n         [ 6.87683582e-01, -9.25929770e-02,  8.39353919e-01, ...,\\n           6.96082592e-01,  1.18835187e+00, -3.01308870e-01],\\n         [ 7.39141524e-01,  3.88867825e-01,  4.94218498e-01, ...,\\n           4.01363045e-01,  7.63477802e-01,  7.20197916e-01],\\n         ...,\\n         [ 4.52959210e-01,  4.24301773e-01,  7.03548864e-02, ...,\\n          -2.59804912e-02, -1.27740011e-01,  3.21708381e-01],\\n         [ 7.04538345e-01,  4.93652672e-02,  5.52885652e-01, ...,\\n          -8.52732956e-02,  1.01796591e+00, -1.58051938e-01],\\n         [ 9.65068221e-01,  2.02497691e-01,  2.69775808e-01, ...,\\n           1.53577477e-01,  1.72773600e-02,  2.94009775e-01]],\\n\\n        [[-1.17994428e-01,  8.70674372e-01, -3.34805667e-01, ...,\\n          -4.80107933e-01,  3.73688996e-01,  6.93071932e-02],\\n         [ 5.98219991e-01,  7.39419237e-02,  5.07466793e-01, ...,\\n           1.39197969e+00,  4.62339550e-01,  6.54042065e-01],\\n         [ 5.23016095e-01, -3.37546796e-01,  3.69948447e-01, ...,\\n           1.00172080e-01,  6.31091356e-01,  4.25991982e-01],\\n         ...,\\n         [-1.743...   ...,\\n         [ 8.86188686e-01,  5.88466585e-01, -4.42435801e-01, ...,\\n           5.20224988e-01,  6.71351492e-01,  4.22686487e-01],\\n         [ 6.32111132e-01,  4.58991557e-01,  1.77357495e-01, ...,\\n          -4.59594101e-01,  5.48739314e-01,  4.59446669e-01],\\n         [ 1.87763977e+00, -1.69312418e-01,  9.62234974e-01, ...,\\n          -1.87873214e-01, -2.08155155e-01,  3.72916669e-01]],\\n\\n        [[ 1.49956733e-01,  2.92518139e-01, -1.99758917e-01, ...,\\n          -2.80823916e-01, -1.99688263e-02, -2.60857552e-01],\\n         [-2.82422990e-01, -5.30835986e-01, -9.93221998e-01, ...,\\n          -6.44835830e-01, -5.30486763e-01, -5.19809306e-01],\\n         [-2.64891349e-02,  4.13195670e-01, -6.94190264e-01, ...,\\n          -4.13916022e-01, -1.42627567e-01, -2.81290799e-01],\\n         ...,\\n         [ 2.59776384e-01, -4.74356860e-01, -1.39674291e-01, ...,\\n          -8.22058916e-01, -3.14598009e-02, -7.50814676e-01],\\n         [ 3.83682728e-01, -7.49206722e-01,  3.03213410e-02, ...,\\n          -3.31378341e-01, -3.83156687e-01, -3.59465331e-01],\\n         [-1.41593695e-01, -4.57422912e-01, -2.30891585e-01, ...,\\n           9.08953547e-02, -4.65405762e-01, -6.65843785e-01]]]],\\n      dtype=float32) = <built-in method numpy of Tensor object at 0x78dd757e2850>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x78dd757e2850> = tensor([[[[ 1.2552e+00,  1.2381e+00,  5.0636e-01,  ...,  3.7656e-01,\\n            1.9284e-01,  4.6825e-01],\\n          [ 6.8768e-01, -9.2593e-02,  8.3935e-01,  ...,  6.9608e-01,\\n            1.1884e+00, -3.0131e-01],\\n          [ 7.3914e-01,  3.8887e-01,  4.9422e-01,  ...,  4.0136e-01,\\n            7.6348e-01,  7.2020e-01],\\n          ...,\\n          [ 4.5296e-01,  4.2430e-01,  7.0355e-02,  ..., -2.5980e-02,\\n           -1.2774e-01,  3.2171e-01],\\n          [ 7.0454e-01,  4.9365e-02,  5.5289e-01,  ..., -8.5273e-02,\\n            1.0180e+00, -1.5805e-01],\\n          [ 9.6507e-01,  2.0250e-01,  2.6978e-01,  ...,  1.5358e-01,\\n            1.7277e-02,  2.9401e-01]],\\n\\n         [[-1.1799e-01,  8.7067e-01, -3.3481e-01,  ..., -4.8011e-01,\\n            3.7369e-01,  6.9307e-02],\\n          [ 5.9822e-01,  7.3942e-02,  5.0747e-01,  ...,  1.3920e+00,\\n            4.6234e-01,  6.5404e-01],\\n          [ 5.2302e-01, -3.3755e-01,  3.6995e-01,  ...,  1.0017e-01,\\n            6.3109e-01,  4.2599e-01],\\n          ...,\\n          [-1.7431e-01,  7.1056e-01,  5.7635e-01,  ..., -1.1300e-01,\\n            4.9866e-01,  7.8781e-01],\\n          [ 3.6621e-01,  2.9579e-02,  2.3601e-02,  ...,  3.5178e-01,\\n            9.0717e-02,  4....1.1916e+00,  6.2653e-01,  2.0148e-01,  ...,  7.0958e-01,\\n            3.9824e-01,  6.8232e-01],\\n          [ 2.5796e-01,  2.5387e-01, -4.3429e-01,  ..., -3.7384e-02,\\n           -1.5162e-01,  4.0899e-01],\\n          ...,\\n          [ 8.8619e-01,  5.8847e-01, -4.4244e-01,  ...,  5.2022e-01,\\n            6.7135e-01,  4.2269e-01],\\n          [ 6.3211e-01,  4.5899e-01,  1.7736e-01,  ..., -4.5959e-01,\\n            5.4874e-01,  4.5945e-01],\\n          [ 1.8776e+00, -1.6931e-01,  9.6223e-01,  ..., -1.8787e-01,\\n           -2.0816e-01,  3.7292e-01]],\\n\\n         [[ 1.4996e-01,  2.9252e-01, -1.9976e-01,  ..., -2.8082e-01,\\n           -1.9969e-02, -2.6086e-01],\\n          [-2.8242e-01, -5.3084e-01, -9.9322e-01,  ..., -6.4484e-01,\\n           -5.3049e-01, -5.1981e-01],\\n          [-2.6489e-02,  4.1320e-01, -6.9419e-01,  ..., -4.1392e-01,\\n           -1.4263e-01, -2.8129e-01],\\n          ...,\\n          [ 2.5978e-01, -4.7436e-01, -1.3967e-01,  ..., -8.2206e-01,\\n           -3.1460e-02, -7.5081e-01],\\n          [ 3.8368e-01, -7.4921e-01,  3.0321e-02,  ..., -3.3138e-01,\\n           -3.8316e-01, -3.5947e-01],\\n          [-1.4159e-01, -4.5742e-01, -2.3089e-01,  ...,  9.0895e-02,\\n           -4.6541e-01, -6.6584e-01]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[ 1.2552e+00,  1.2381e+00,  5.0636e-01,  ...,  3.7656e-01,\\n            1.9284e-01,  4.6825e-01],\\n          [ 6.8768e-01, -9.2593e-02,  8.3935e-01,  ...,  6.9608e-01,\\n            1.1884e+00, -3.0131e-01],\\n          [ 7.3914e-01,  3.8887e-01,  4.9422e-01,  ...,  4.0136e-01,\\n            7.6348e-01,  7.2020e-01],\\n          ...,\\n          [ 4.5296e-01,  4.2430e-01,  7.0355e-02,  ..., -2.5980e-02,\\n           -1.2774e-01,  3.2171e-01],\\n          [ 7.0454e-01,  4.9365e-02,  5.5289e-01,  ..., -8.5273e-02,\\n            1.0180e+00, -1.5805e-01],\\n          [ 9.6507e-01,  2.0250e-01,  2.6978e-01,  ...,  1.5358e-01,\\n            1.7277e-02,  2.9401e-01]],\\n\\n         [[-1.1799e-01,  8.7067e-01, -3.3481e-01,  ..., -4.8011e-01,\\n            3.7369e-01,  6.9307e-02],\\n          [ 5.9822e-01,  7.3942e-02,  5.0747e-01,  ...,  1.3920e+00,\\n            4.6234e-01,  6.5404e-01],\\n          [ 5.2302e-01, -3.3755e-01,  3.6995e-01,  ...,  1.0017e-01,\\n            6.3109e-01,  4.2599e-01],\\n          ...,\\n          [-1.7431e-01,  7.1056e-01,  5.7635e-01,  ..., -1.1300e-01,\\n            4.9866e-01,  7.8781e-01],\\n          [ 3.6621e-01,  2.9579e-02,  2.3601e-02,  ...,  3.5178e-01,\\n            9.0717e-02,  4....1.1916e+00,  6.2653e-01,  2.0148e-01,  ...,  7.0958e-01,\\n            3.9824e-01,  6.8232e-01],\\n          [ 2.5796e-01,  2.5387e-01, -4.3429e-01,  ..., -3.7384e-02,\\n           -1.5162e-01,  4.0899e-01],\\n          ...,\\n          [ 8.8619e-01,  5.8847e-01, -4.4244e-01,  ...,  5.2022e-01,\\n            6.7135e-01,  4.2269e-01],\\n          [ 6.3211e-01,  4.5899e-01,  1.7736e-01,  ..., -4.5959e-01,\\n            5.4874e-01,  4.5945e-01],\\n          [ 1.8776e+00, -1.6931e-01,  9.6223e-01,  ..., -1.8787e-01,\\n           -2.0816e-01,  3.7292e-01]],\\n\\n         [[ 1.4996e-01,  2.9252e-01, -1.9976e-01,  ..., -2.8082e-01,\\n           -1.9969e-02, -2.6086e-01],\\n          [-2.8242e-01, -5.3084e-01, -9.9322e-01,  ..., -6.4484e-01,\\n           -5.3049e-01, -5.1981e-01],\\n          [-2.6489e-02,  4.1320e-01, -6.9419e-01,  ..., -4.1392e-01,\\n           -1.4263e-01, -2.8129e-01],\\n          ...,\\n          [ 2.5978e-01, -4.7436e-01, -1.3967e-01,  ..., -8.2206e-01,\\n           -3.1460e-02, -7.5081e-01],\\n          [ 3.8368e-01, -7.4921e-01,  3.0321e-02,  ..., -3.3138e-01,\\n           -3.8316e-01, -3.5947e-01],\\n          [-1.4159e-01, -4.5742e-01, -2.3089e-01,  ...,  9.0895e-02,\\n           -4.6541e-01, -6.6584e-01]]]]) = tensor([[[[ 1.2552e+00,  1.2381e+00,  5.0636e-01,  ...,  3.7656e-01,\\n            1.9284e-01,  4.6825e-01],\\n          [ 6.8768e-01, -9.2593e-02,  8.3935e-01,  ...,  6.9608e-01,\\n            1.1884e+00, -3.0131e-01],\\n          [ 7.3914e-01,  3.8887e-01,  4.9422e-01,  ...,  4.0136e-01,\\n            7.6348e-01,  7.2020e-01],\\n          ...,\\n          [ 4.5296e-01,  4.2430e-01,  7.0355e-02,  ..., -2.5980e-02,\\n           -1.2774e-01,  3.2171e-01],\\n          [ 7.0454e-01,  4.9365e-02,  5.5289e-01,  ..., -8.5273e-02,\\n            1.0180e+00, -1.5805e-01],\\n          [ 9.6507e-01,  2.0250e-01,  2.6978e-01,  ...,  1.5358e-01,\\n            1.7277e-02,  2.9401e-01]],\\n\\n         [[-1.1799e-01,  8.7067e-01, -3.3481e-01,  ..., -4.8011e-01,\\n            3.7369e-01,  6.9307e-02],\\n          [ 5.9822e-01,  7.3942e-02,  5.0747e-01,  ...,  1.3920e+00,\\n            4.6234e-01,  6.5404e-01],\\n          [ 5.2302e-01, -3.3755e-01,  3.6995e-01,  ...,  1.0017e-01,\\n            6.3109e-01,  4.2599e-01],\\n          ...,\\n          [-1.7431e-01,  7.1056e-01,  5.7635e-01,  ..., -1.1300e-01,\\n            4.9866e-01,  7.8781e-01],\\n          [ 3.6621e-01,  2.9579e-02,  2.3601e-02,  ...,  3.5178e-01,\\n            9.0717e-02,  4....e-01,  ...,  7.0958e-01,\\n            3.9824e-01,  6.8232e-01],\\n          [ 2.5796e-01,  2.5387e-01, -4.3429e-01,  ..., -3.7384e-02,\\n           -1.5162e-01,  4.0899e-01],\\n          ...,\\n          [ 8.8619e-01,  5.8847e-01, -4.4244e-01,  ...,  5.2022e-01,\\n            6.7135e-01,  4.2269e-01],\\n          [ 6.3211e-01,  4.5899e-01,  1.7736e-01,  ..., -4.5959e-01,\\n            5.4874e-01,  4.5945e-01],\\n          [ 1.8776e+00, -1.6931e-01,  9.6223e-01,  ..., -1.8787e-01,\\n           -2.0816e-01,  3.7292e-01]],\\n\\n         [[ 1.4996e-01,  2.9252e-01, -1.9976e-01,  ..., -2.8082e-01,\\n           -1.9969e-02, -2.6086e-01],\\n          [-2.8242e-01, -5.3084e-01, -9.9322e-01,  ..., -6.4484e-01,\\n           -5.3049e-01, -5.1981e-01],\\n          [-2.6489e-02,  4.1320e-01, -6.9419e-01,  ..., -4.1392e-01,\\n           -1.4263e-01, -2.8129e-01],\\n          ...,\\n          [ 2.5978e-01, -4.7436e-01, -1.3967e-01,  ..., -8.2206e-01,\\n           -3.1460e-02, -7.5081e-01],\\n          [ 3.8368e-01, -7.4921e-01,  3.0321e-02,  ..., -3.3138e-01,\\n           -3.8316e-01, -3.5947e-01],\\n          [-1.4159e-01, -4.5742e-01, -2.3089e-01,  ...,  9.0895e-02,\\n           -4.6541e-01, -6.6584e-01]]]], grad_fn=<ConvolutionBackward0>).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[ 1.2552e+00,  1.2381e+00,  5.0636e-01,  ...,  3.7656e-01,\\n            1.9284e-01,  4.6825e-01],\\n          [ 6.8768e-01, -9.2593e-02,  8.3935e-01,  ...,  6.9608e-01,\\n            1.1884e+00, -3.0131e-01],\\n          [ 7.3914e-01,  3.8887e-01,  4.9422e-01,  ...,  4.0136e-01,\\n            7.6348e-01,  7.2020e-01],\\n          ...,\\n          [ 4.5296e-01,  4.2430e-01,  7.0355e-02,  ..., -2.5980e-02,\\n           -1.2774e-01,  3.2171e-01],\\n          [ 7.0454e-01,  4.9365e-02,  5.5289e-01,  ..., -8.5273e-02,\\n            1.0180e+00, -1.5805e-01],\\n          [ 9.6507e-01,  2.0250e-01,  2.6978e-01,  ...,  1.5358e-01,\\n            1.7277e-02,  2.9401e-01]],\\n\\n         [[-1.1799e-01,  8.7067e-01, -3.3481e-01,  ..., -4.8011e-01,\\n            3.7369e-01,  6.9307e-02],\\n          [ 5.9822e-01,  7.3942e-02,  5.0747e-01,  ...,  1.3920e+00,\\n            4.6234e-01,  6.5404e-01],\\n          [ 5.2302e-01, -3.3755e-01,  3.6995e-01,  ...,  1.0017e-01,\\n            6.3109e-01,  4.2599e-01],\\n          ...,\\n          [-1.7431e-01,  7.1056e-01,  5.7635e-01,  ..., -1.1300e-01,\\n            4.9866e-01,  7.8781e-01],\\n          [ 3.6621e-01,  2.9579e-02,  2.3601e-02,  ...,  3.5178e-01,\\n            9.0717e-02,  4....e-01,  ...,  7.0958e-01,\\n            3.9824e-01,  6.8232e-01],\\n          [ 2.5796e-01,  2.5387e-01, -4.3429e-01,  ..., -3.7384e-02,\\n           -1.5162e-01,  4.0899e-01],\\n          ...,\\n          [ 8.8619e-01,  5.8847e-01, -4.4244e-01,  ...,  5.2022e-01,\\n            6.7135e-01,  4.2269e-01],\\n          [ 6.3211e-01,  4.5899e-01,  1.7736e-01,  ..., -4.5959e-01,\\n            5.4874e-01,  4.5945e-01],\\n          [ 1.8776e+00, -1.6931e-01,  9.6223e-01,  ..., -1.8787e-01,\\n           -2.0816e-01,  3.7292e-01]],\\n\\n         [[ 1.4996e-01,  2.9252e-01, -1.9976e-01,  ..., -2.8082e-01,\\n           -1.9969e-02, -2.6086e-01],\\n          [-2.8242e-01, -5.3084e-01, -9.9322e-01,  ..., -6.4484e-01,\\n           -5.3049e-01, -5.1981e-01],\\n          [-2.6489e-02,  4.1320e-01, -6.9419e-01,  ..., -4.1392e-01,\\n           -1.4263e-01, -2.8129e-01],\\n          ...,\\n          [ 2.5978e-01, -4.7436e-01, -1.3967e-01,  ..., -8.2206e-01,\\n           -3.1460e-02, -7.5081e-01],\\n          [ 3.8368e-01, -7.4921e-01,  3.0321e-02,  ..., -3.3138e-01,\\n           -3.8316e-01, -3.5947e-01],\\n          [-1.4159e-01, -4.5742e-01, -2.3089e-01,  ...,  9.0895e-02,\\n           -4.6541e-01, -6.6584e-01]]]], grad_fn=<ConvolutionBackward0>) = Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))(tensor([[[[7.9869e-01, 9.2346e-01, 2.9915e-01,  ..., 2.8672e-01,\\n           1.9462e-02, 3.9922e-01],\\n          [3.0853e-01, 9.4218e-01, 8.8827e-01,  ..., 5.6631e-01,\\n           1.8582e-01, 1.0474e-01],\\n          [1.1656e-01, 3.5764e-01, 4.6548e-03,  ..., 7.5819e-01,\\n           4.5988e-01, 5.7361e-01],\\n          ...,\\n          [5.8314e-01, 2.5804e-01, 4.7339e-01,  ..., 4.0902e-01,\\n           3.3225e-01, 9.8953e-01],\\n          [6.4442e-01, 3.6600e-01, 1.0202e-01,  ..., 3.1145e-01,\\n           2.4828e-01, 2.7794e-01],\\n          [3.1840e-01, 7.2895e-01, 5.6920e-01,  ..., 6.3190e-01,\\n           9.5591e-01, 5.8505e-01]],\\n\\n         [[9.6740e-01, 9.6161e-01, 6.5020e-01,  ..., 4.3975e-01,\\n           1.0586e-02, 9.6493e-01],\\n          [9.6202e-01, 2.1755e-01, 4.1346e-02,  ..., 7.8075e-02,\\n           3.2322e-01, 9.1339e-01],\\n          [2.0101e-01, 8.4359e-01, 6.9632e-01,  ..., 6.3808e-01,\\n           5.8511e-01, 9.0156e-01],\\n          ...,\\n          [9.1754e-01, 7.5773e-01, 6.1301e-02,  ..., 6.0539e-01,\\n           5.6609e-01, 5.7584e-01],\\n          [3.0129e-01, 6.1887e-01, 2.4358e-01,  ..., 2.7567e-01,\\n           2.3958e-01, 7.3430e-01],\\n          [7.1698e-01, 5.8448e-01, 9.1334e-02,  ..., 4.... ..., 1.1622e-01,\\n           9.4725e-01, 7.9094e-01],\\n          [3.1302e-01, 2.3718e-01, 8.5279e-01,  ..., 8.8986e-01,\\n           2.1629e-01, 3.5585e-01],\\n          [7.5535e-01, 7.9811e-01, 7.0750e-01,  ..., 3.1981e-02,\\n           7.5480e-01, 2.1212e-01],\\n          ...,\\n          [3.1056e-01, 8.9629e-01, 9.2180e-01,  ..., 5.0189e-01,\\n           8.2852e-01, 1.8894e-01],\\n          [2.6997e-01, 7.2437e-01, 4.8109e-01,  ..., 7.1370e-01,\\n           5.1447e-01, 7.0896e-01],\\n          [1.7825e-01, 3.3361e-01, 7.8145e-01,  ..., 3.6906e-01,\\n           3.8152e-01, 3.2360e-01]],\\n\\n         [[2.4722e-01, 2.9715e-01, 2.5932e-01,  ..., 1.1293e-01,\\n           6.3870e-04, 8.8418e-01],\\n          [6.1921e-01, 3.8419e-01, 5.6508e-01,  ..., 5.8404e-01,\\n           3.0848e-01, 8.0828e-01],\\n          [6.3598e-01, 5.8203e-01, 9.8347e-01,  ..., 5.0874e-01,\\n           6.6474e-01, 8.7272e-01],\\n          ...,\\n          [4.8914e-01, 6.4909e-01, 3.1237e-01,  ..., 2.7278e-01,\\n           1.6509e-01, 1.5468e-02],\\n          [3.9431e-01, 8.8533e-01, 2.1024e-02,  ..., 3.8495e-01,\\n           3.3687e-01, 4.9749e-01],\\n          [3.2770e-01, 3.3726e-03, 4.1829e-01,  ..., 8.7173e-01,\\n           1.3309e-01, 2.0501e-01]]]]))\u001b[0m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78de6d9cb3b0>\n",
            "g          = Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[7.98689246e-01 9.23455536e-01 2.99153656e-01 ... 2.86716670e-01\n",
            "    1.94624681e-02 3.99222374e-01]\n",
            " ...7488052e-01]\n",
            "   [3.27695936e-01 3.37259332e-03 4.18287754e-01 ... 8.71726155e-01\n",
            "    1.33087680e-01 2.05006897e-01]]]])\n",
            "z          = tensor([[[[7.9869e-01, 9.2346e-01, 2.9915e-01,  ..., 2.8672e-01,\n",
            "           1.9462e-02, 3.9922e-01],\n",
            "          [3.0853...1, 4.9749e-01],\n",
            "          [3.2770e-01, 3.3726e-03, 4.1829e-01,  ..., 8.7173e-01,\n",
            "           1.3309e-01, 2.0501e-01]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 8, cout = 8, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert np.float32(81.6244) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(81.6244) = <function norm at 0x78de681e28f0>((array([[[[-3.16596150e-01, -8.15706611e-01, -3.94609094e-01, ...,\\n          -6.22140288e-01, -1.01680934e-01, -2.77818859e-01],\\n         [ 1.33420303e-01, -4.79246914e-01,  1.79765925e-01, ...,\\n          -2.86437601e-01, -4.48553741e-01,  7.99116790e-02],\\n         [ 3.24135303e-01, -4.13915336e-01, -1.45003080e-01, ...,\\n          -4.81096625e-01, -3.15255553e-01, -3.35355699e-01],\\n         ...,\\n         [ 4.35845256e-02, -1.39948893e+00, -3.15938532e-01, ...,\\n          -3.46324481e-02, -9.14328635e-01,  5.79333454e-02],\\n         [ 5.12307286e-01, -3.77829313e-01, -4.01772380e-01, ...,\\n          -1.64861292e-01,  4.25997734e-01, -8.90473247e-01],\\n         [ 3.26211989e-01,  7.65064716e-01, -6.29494369e-01, ...,\\n           1.26469061e-02, -6.71023652e-02, -2.17865989e-01]],\\n\\n        [[ 6.62597835e-01,  1.08361161e+00,  2.71318167e-01, ...,\\n           7.69758999e-01, -2.76906639e-02,  6.64739728e-01],\\n         [ 4.57817316e-01,  1.06722450e+00,  9.49379206e-01, ...,\\n           1.22077155e+00, -4.20149043e-02,  7.11223841e-01],\\n         [ 5.97819313e-02,  2.79295117e-01,  4.93351281e-01, ...,\\n          -4.10490111e-02,  1.22383535e+00,  6.75179362e-01],\\n         ...,\\n         [ 1.225...   ...,\\n         [ 1.20167506e+00,  2.23389998e-01, -1.03075767e+00, ...,\\n           5.08284211e-01, -8.87246013e-01, -5.38884886e-02],\\n         [ 8.54392231e-01,  2.40312114e-01, -3.23326170e-01, ...,\\n           2.64516473e-01, -6.93678319e-01, -5.64908311e-02],\\n         [ 7.69061029e-01, -3.24202657e-01, -1.13704994e-01, ...,\\n          -5.26159883e-01,  6.14097536e-01, -4.90208924e-01]],\\n\\n        [[ 6.62424922e-01,  6.69097602e-02, -3.20708543e-01, ...,\\n          -3.49201620e-01,  1.41733080e-01, -3.61750275e-01],\\n         [ 8.00202042e-02, -1.19769514e+00,  1.16299301e-01, ...,\\n          -1.72086641e-01, -6.28960848e-01, -8.93193841e-01],\\n         [ 2.41245598e-01, -6.58544302e-01,  6.94404691e-02, ...,\\n          -5.58113694e-01, -5.16438663e-01, -4.03193742e-01],\\n         ...,\\n         [ 1.08436778e-01,  4.13774759e-01, -4.90078390e-01, ...,\\n           2.51673311e-01, -1.08472593e-01, -6.98948979e-01],\\n         [ 7.15953112e-03, -6.13456964e-02, -4.57585961e-01, ...,\\n          -4.71747309e-01,  3.33481312e-01, -1.04577020e-02],\\n         [ 6.08053446e-01, -1.12046552e+00,  1.99071378e-01, ...,\\n          -1.98962212e-01, -6.41048551e-01, -3.80702347e-01]]]],\\n      dtype=float32) - array([[[[ 1.86229452e-01, -3.91856015e-01, -3.17667156e-01, ...,\\n          -5.05033791e-01, -8.52318481e-02, -1.78847775e-01],\\n         [ 1.60047531e-01,  1.98195323e-01,  1.80274025e-01, ...,\\n          -4.69669163e-01, -1.96545184e-01,  3.66828516e-02],\\n         [-1.22242123e-02, -4.43704963e-01, -5.12855768e-01, ...,\\n          -5.56952834e-01,  5.06025106e-02, -6.66310549e-01],\\n         ...,\\n         [ 5.77968299e-01, -7.69176856e-02, -1.12048797e-01, ...,\\n          -6.62365183e-02, -7.65469968e-02, -4.31290567e-01],\\n         [ 3.19758832e-01, -2.28127480e-01, -4.00415897e-01, ...,\\n          -5.83878577e-01, -5.57763055e-02, -2.99187005e-01],\\n         [ 6.41506016e-01, -2.01809019e-01, -4.41759348e-01, ...,\\n          -1.83796203e+00,  1.91242695e-02,  5.26003093e-02]],\\n\\n        [[ 9.91411209e-01, -1.11412235e-01,  6.22702897e-01, ...,\\n           1.24105966e+00,  1.09410739e+00,  8.08167756e-01],\\n         [ 6.02919519e-01,  8.49899113e-01,  1.18084514e+00, ...,\\n          -1.82486624e-02,  7.80538023e-01,  8.76008868e-01],\\n         [ 2.06834897e-01,  1.71162260e+00,  9.74906445e-01, ...,\\n           5.55899382e-01,  1.04683816e-01,  1.07173562e+00],\\n         ...,\\n         [ 4.903...   ...,\\n         [ 7.12682426e-01,  3.70482564e-01, -5.91027260e-01, ...,\\n           7.26458430e-02,  7.43716210e-02, -1.92457065e-01],\\n         [ 8.73000979e-01, -2.52403855e-01,  2.28113875e-01, ...,\\n           3.98519635e-01,  5.04673049e-02, -3.84123385e-01],\\n         [ 1.03238380e+00, -1.45382300e-01,  1.35883719e-01, ...,\\n          -2.85485163e-02, -4.68475521e-01,  1.28526539e-01]],\\n\\n        [[ 4.36959475e-01, -2.56069779e-01,  9.18245018e-02, ...,\\n           2.53883094e-01,  1.33719295e-01,  1.07970595e-01],\\n         [ 5.75301766e-01, -9.79530215e-01, -1.73143670e-01, ...,\\n           6.82247877e-02, -2.86234736e-01, -3.04604352e-01],\\n         [ 5.16664863e-01,  1.20414406e-01, -4.88719821e-01, ...,\\n          -6.02895856e-01,  2.92354822e-02, -7.69516826e-01],\\n         ...,\\n         [-4.84010354e-02, -1.06694591e+00, -2.70521224e-01, ...,\\n          -2.86947012e-01, -3.60516310e-01, -4.33617771e-01],\\n         [ 2.05358982e-01, -2.77648091e-01, -5.48413575e-01, ...,\\n          -7.26423025e-01, -1.25347245e+00, -1.20354629e+00],\\n         [-3.08604479e-01, -4.61909652e-01, -3.92321974e-01, ...,\\n          -9.17044640e-01, -3.51328790e-01, -1.34872288e-01]]]],\\n      dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78de681e28f0> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[-3.16596150e-01, -8.15706611e-01, -3.94609094e-01, ...,\\n          -6.22140288e-01, -1.01680934e-01, -2.77818859e-01],\\n         [ 1.33420303e-01, -4.79246914e-01,  1.79765925e-01, ...,\\n          -2.86437601e-01, -4.48553741e-01,  7.99116790e-02],\\n         [ 3.24135303e-01, -4.13915336e-01, -1.45003080e-01, ...,\\n          -4.81096625e-01, -3.15255553e-01, -3.35355699e-01],\\n         ...,\\n         [ 4.35845256e-02, -1.39948893e+00, -3.15938532e-01, ...,\\n          -3.46324481e-02, -9.14328635e-01,  5.79333454e-02],\\n         [ 5.12307286e-01, -3.77829313e-01, -4.01772380e-01, ...,\\n          -1.64861292e-01,  4.25997734e-01, -8.90473247e-01],\\n         [ 3.26211989e-01,  7.65064716e-01, -6.29494369e-01, ...,\\n           1.26469061e-02, -6.71023652e-02, -2.17865989e-01]],\\n\\n        [[ 6.62597835e-01,  1.08361161e+00,  2.71318167e-01, ...,\\n           7.69758999e-01, -2.76906639e-02,  6.64739728e-01],\\n         [ 4.57817316e-01,  1.06722450e+00,  9.49379206e-01, ...,\\n           1.22077155e+00, -4.20149043e-02,  7.11223841e-01],\\n         [ 5.97819313e-02,  2.79295117e-01,  4.93351281e-01, ...,\\n          -4.10490111e-02,  1.22383535e+00,  6.75179362e-01],\\n         ...,\\n         [ 1.225...   ...,\\n         [ 1.20167506e+00,  2.23389998e-01, -1.03075767e+00, ...,\\n           5.08284211e-01, -8.87246013e-01, -5.38884886e-02],\\n         [ 8.54392231e-01,  2.40312114e-01, -3.23326170e-01, ...,\\n           2.64516473e-01, -6.93678319e-01, -5.64908311e-02],\\n         [ 7.69061029e-01, -3.24202657e-01, -1.13704994e-01, ...,\\n          -5.26159883e-01,  6.14097536e-01, -4.90208924e-01]],\\n\\n        [[ 6.62424922e-01,  6.69097602e-02, -3.20708543e-01, ...,\\n          -3.49201620e-01,  1.41733080e-01, -3.61750275e-01],\\n         [ 8.00202042e-02, -1.19769514e+00,  1.16299301e-01, ...,\\n          -1.72086641e-01, -6.28960848e-01, -8.93193841e-01],\\n         [ 2.41245598e-01, -6.58544302e-01,  6.94404691e-02, ...,\\n          -5.58113694e-01, -5.16438663e-01, -4.03193742e-01],\\n         ...,\\n         [ 1.08436778e-01,  4.13774759e-01, -4.90078390e-01, ...,\\n           2.51673311e-01, -1.08472593e-01, -6.98948979e-01],\\n         [ 7.15953112e-03, -6.13456964e-02, -4.57585961e-01, ...,\\n          -4.71747309e-01,  3.33481312e-01, -1.04577020e-02],\\n         [ 6.08053446e-01, -1.12046552e+00,  1.99071378e-01, ...,\\n          -1.98962212e-01, -6.41048551e-01, -3.80702347e-01]]]],\\n      dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where numpy = NDArray([[[[-3.16596150e-01 -8.15706611e-01 -3.94609094e-01 ... -6.22140288e-01\\n    -1.01680934e-01 -2.77818859e-01]\\n   [ 1.33420303e-01 -4.79246914e-01  1.79765925e-01 ... -2.86437601e-01\\n    -4.48553741e-01  7.99116790e-02]\\n   [ 3.24135303e-01 -4.13915336e-01 -1.45003080e-01 ... -4.81096625e-01\\n    -3.15255553e-01 -3.35355699e-01]\\n   ...\\n   [ 4.35845256e-02 -1.39948893e+00 -3.15938532e-01 ... -3.46324481e-02\\n    -9.14328635e-01  5.79333454e-02]\\n   [ 5.12307286e-01 -3.77829313e-01 -4.01772380e-01 ... -1.64861292e-01\\n     4.25997734e-01 -8.90473247e-01]\\n   [ 3.26211989e-01  7.65064716e-01 -6.29494369e-01 ...  1.26469061e-02\\n    -6.71023652e-02 -2.17865989e-01]]\\n\\n  [[ 6.62597835e-01  1.08361161e+00  2.71318167e-01 ...  7.69758999e-01\\n    -2.76906639e-02  6.64739728e-01]\\n   [ 4.57817316e-01  1.06722450e+00  9.49379206e-01 ...  1.22077155e+00\\n    -4.20149043e-02  7.11223841e-01]\\n   [ 5.97819313e-02  2.79295117e-01  4.93351281e-01 ... -4.10490111e-02\\n     1.22383535e+00  6.75179362e-01]\\n   ...\\n   [ 1.22561902e-02  1.67251229e+00  1.04345918e+00 ...  1.23708582e+00\\n     1.05481958e+00  5.80894887e-01]\\n   [ 9.23567414e-01  8.10096681e-01  1.07596326e+00 ...  5.78549743e-01\\n     2.84193...3  2.14669824e-01 ...  9.94484425e-02\\n     3.94910038e-01  5.21991313e-01]\\n   [ 3.82474422e-01  6.15222752e-01  1.26509476e+00 ...  3.73964131e-01\\n    -4.04718339e-01 -2.28198379e-01]\\n   ...\\n   [ 1.20167506e+00  2.23389998e-01 -1.03075767e+00 ...  5.08284211e-01\\n    -8.87246013e-01 -5.38884886e-02]\\n   [ 8.54392231e-01  2.40312114e-01 -3.23326170e-01 ...  2.64516473e-01\\n    -6.93678319e-01 -5.64908311e-02]\\n   [ 7.69061029e-01 -3.24202657e-01 -1.13704994e-01 ... -5.26159883e-01\\n     6.14097536e-01 -4.90208924e-01]]\\n\\n  [[ 6.62424922e-01  6.69097602e-02 -3.20708543e-01 ... -3.49201620e-01\\n     1.41733080e-01 -3.61750275e-01]\\n   [ 8.00202042e-02 -1.19769514e+00  1.16299301e-01 ... -1.72086641e-01\\n    -6.28960848e-01 -8.93193841e-01]\\n   [ 2.41245598e-01 -6.58544302e-01  6.94404691e-02 ... -5.58113694e-01\\n    -5.16438663e-01 -4.03193742e-01]\\n   ...\\n   [ 1.08436778e-01  4.13774759e-01 -4.90078390e-01 ...  2.51673311e-01\\n    -1.08472593e-01 -6.98948979e-01]\\n   [ 7.15953112e-03 -6.13456964e-02 -4.57585961e-01 ... -4.71747309e-01\\n     3.33481312e-01 -1.04577020e-02]\\n   [ 6.08053446e-01 -1.12046552e+00  1.99071378e-01 ... -1.98962212e-01\\n    -6.41048551e-01 -3.80702347e-01]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where NDArray([[[[-3.16596150e-01 -8.15706611e-01 -3.94609094e-01 ... -6.22140288e-01\\n    -1.01680934e-01 -2.77818859e-01]\\n   [ 1.33420303e-01 -4.79246914e-01  1.79765925e-01 ... -2.86437601e-01\\n    -4.48553741e-01  7.99116790e-02]\\n   [ 3.24135303e-01 -4.13915336e-01 -1.45003080e-01 ... -4.81096625e-01\\n    -3.15255553e-01 -3.35355699e-01]\\n   ...\\n   [ 4.35845256e-02 -1.39948893e+00 -3.15938532e-01 ... -3.46324481e-02\\n    -9.14328635e-01  5.79333454e-02]\\n   [ 5.12307286e-01 -3.77829313e-01 -4.01772380e-01 ... -1.64861292e-01\\n     4.25997734e-01 -8.90473247e-01]\\n   [ 3.26211989e-01  7.65064716e-01 -6.29494369e-01 ...  1.26469061e-02\\n    -6.71023652e-02 -2.17865989e-01]]\\n\\n  [[ 6.62597835e-01  1.08361161e+00  2.71318167e-01 ...  7.69758999e-01\\n    -2.76906639e-02  6.64739728e-01]\\n   [ 4.57817316e-01  1.06722450e+00  9.49379206e-01 ...  1.22077155e+00\\n    -4.20149043e-02  7.11223841e-01]\\n   [ 5.97819313e-02  2.79295117e-01  4.93351281e-01 ... -4.10490111e-02\\n     1.22383535e+00  6.75179362e-01]\\n   ...\\n   [ 1.22561902e-02  1.67251229e+00  1.04345918e+00 ...  1.23708582e+00\\n     1.05481958e+00  5.80894887e-01]\\n   [ 9.23567414e-01  8.10096681e-01  1.07596326e+00 ...  5.78549743e-01\\n     2.84193...3  2.14669824e-01 ...  9.94484425e-02\\n     3.94910038e-01  5.21991313e-01]\\n   [ 3.82474422e-01  6.15222752e-01  1.26509476e+00 ...  3.73964131e-01\\n    -4.04718339e-01 -2.28198379e-01]\\n   ...\\n   [ 1.20167506e+00  2.23389998e-01 -1.03075767e+00 ...  5.08284211e-01\\n    -8.87246013e-01 -5.38884886e-02]\\n   [ 8.54392231e-01  2.40312114e-01 -3.23326170e-01 ...  2.64516473e-01\\n    -6.93678319e-01 -5.64908311e-02]\\n   [ 7.69061029e-01 -3.24202657e-01 -1.13704994e-01 ... -5.26159883e-01\\n     6.14097536e-01 -4.90208924e-01]]\\n\\n  [[ 6.62424922e-01  6.69097602e-02 -3.20708543e-01 ... -3.49201620e-01\\n     1.41733080e-01 -3.61750275e-01]\\n   [ 8.00202042e-02 -1.19769514e+00  1.16299301e-01 ... -1.72086641e-01\\n    -6.28960848e-01 -8.93193841e-01]\\n   [ 2.41245598e-01 -6.58544302e-01  6.94404691e-02 ... -5.58113694e-01\\n    -5.16438663e-01 -4.03193742e-01]\\n   ...\\n   [ 1.08436778e-01  4.13774759e-01 -4.90078390e-01 ...  2.51673311e-01\\n    -1.08472593e-01 -6.98948979e-01]\\n   [ 7.15953112e-03 -6.13456964e-02 -4.57585961e-01 ... -4.71747309e-01\\n     3.33481312e-01 -1.04577020e-02]\\n   [ 6.08053446e-01 -1.12046552e+00  1.99071378e-01 ... -1.98962212e-01\\n    -6.41048551e-01 -3.80702347e-01]]]], device=cuda()) = needle.Tensor([[[[-3.16596150e-01 -8.15706611e-01 -3.94609094e-01 ... -6.22140288e-01\\n    -1.01680934e-01 -2.77818859e-01]\\n   [ 1.33420303e-01 -4.79246914e-01  1.79765925e-01 ... -2.86437601e-01\\n    -4.48553741e-01  7.99116790e-02]\\n   [ 3.24135303e-01 -4.13915336e-01 -1.45003080e-01 ... -4.81096625e-01\\n    -3.15255553e-01 -3.35355699e-01]\\n   ...\\n   [ 4.35845256e-02 -1.39948893e+00 -3.15938532e-01 ... -3.46324481e-02\\n    -9.14328635e-01  5.79333454e-02]\\n   [ 5.12307286e-01 -3.77829313e-01 -4.01772380e-01 ... -1.64861292e-01\\n     4.25997734e-01 -8.90473247e-01]\\n   [ 3.26211989e-01  7.65064716e-01 -6.29494369e-01 ...  1.26469061e-02\\n    -6.71023652e-02 -2.17865989e-01]]\\n\\n  [[ 6.62597835e-01  1.08361161e+00  2.71318167e-01 ...  7.69758999e-01\\n    -2.76906639e-02  6.64739728e-01]\\n   [ 4.57817316e-01  1.06722450e+00  9.49379206e-01 ...  1.22077155e+00\\n    -4.20149043e-02  7.11223841e-01]\\n   [ 5.97819313e-02  2.79295117e-01  4.93351281e-01 ... -4.10490111e-02\\n     1.22383535e+00  6.75179362e-01]\\n   ...\\n   [ 1.22561902e-02  1.67251229e+00  1.04345918e+00 ...  1.23708582e+00\\n     1.05481958e+00  5.80894887e-01]\\n   [ 9.23567414e-01  8.10096681e-01  1.07596326e+00 ...  5.78549743e-01\\n     2... -8.71395692e-03  2.14669824e-01 ...  9.94484425e-02\\n     3.94910038e-01  5.21991313e-01]\\n   [ 3.82474422e-01  6.15222752e-01  1.26509476e+00 ...  3.73964131e-01\\n    -4.04718339e-01 -2.28198379e-01]\\n   ...\\n   [ 1.20167506e+00  2.23389998e-01 -1.03075767e+00 ...  5.08284211e-01\\n    -8.87246013e-01 -5.38884886e-02]\\n   [ 8.54392231e-01  2.40312114e-01 -3.23326170e-01 ...  2.64516473e-01\\n    -6.93678319e-01 -5.64908311e-02]\\n   [ 7.69061029e-01 -3.24202657e-01 -1.13704994e-01 ... -5.26159883e-01\\n     6.14097536e-01 -4.90208924e-01]]\\n\\n  [[ 6.62424922e-01  6.69097602e-02 -3.20708543e-01 ... -3.49201620e-01\\n     1.41733080e-01 -3.61750275e-01]\\n   [ 8.00202042e-02 -1.19769514e+00  1.16299301e-01 ... -1.72086641e-01\\n    -6.28960848e-01 -8.93193841e-01]\\n   [ 2.41245598e-01 -6.58544302e-01  6.94404691e-02 ... -5.58113694e-01\\n    -5.16438663e-01 -4.03193742e-01]\\n   ...\\n   [ 1.08436778e-01  4.13774759e-01 -4.90078390e-01 ...  2.51673311e-01\\n    -1.08472593e-01 -6.98948979e-01]\\n   [ 7.15953112e-03 -6.13456964e-02 -4.57585961e-01 ... -4.71747309e-01\\n     3.33481312e-01 -1.04577020e-02]\\n   [ 6.08053446e-01 -1.12046552e+00  1.99071378e-01 ... -1.98962212e-01\\n    -6.41048551e-01 -3.80702347e-01]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where needle.Tensor([[[[-3.16596150e-01 -8.15706611e-01 -3.94609094e-01 ... -6.22140288e-01\\n    -1.01680934e-01 -2.77818859e-01]\\n   [ 1.33420303e-01 -4.79246914e-01  1.79765925e-01 ... -2.86437601e-01\\n    -4.48553741e-01  7.99116790e-02]\\n   [ 3.24135303e-01 -4.13915336e-01 -1.45003080e-01 ... -4.81096625e-01\\n    -3.15255553e-01 -3.35355699e-01]\\n   ...\\n   [ 4.35845256e-02 -1.39948893e+00 -3.15938532e-01 ... -3.46324481e-02\\n    -9.14328635e-01  5.79333454e-02]\\n   [ 5.12307286e-01 -3.77829313e-01 -4.01772380e-01 ... -1.64861292e-01\\n     4.25997734e-01 -8.90473247e-01]\\n   [ 3.26211989e-01  7.65064716e-01 -6.29494369e-01 ...  1.26469061e-02\\n    -6.71023652e-02 -2.17865989e-01]]\\n\\n  [[ 6.62597835e-01  1.08361161e+00  2.71318167e-01 ...  7.69758999e-01\\n    -2.76906639e-02  6.64739728e-01]\\n   [ 4.57817316e-01  1.06722450e+00  9.49379206e-01 ...  1.22077155e+00\\n    -4.20149043e-02  7.11223841e-01]\\n   [ 5.97819313e-02  2.79295117e-01  4.93351281e-01 ... -4.10490111e-02\\n     1.22383535e+00  6.75179362e-01]\\n   ...\\n   [ 1.22561902e-02  1.67251229e+00  1.04345918e+00 ...  1.23708582e+00\\n     1.05481958e+00  5.80894887e-01]\\n   [ 9.23567414e-01  8.10096681e-01  1.07596326e+00 ...  5.78549743e-01\\n     2... -8.71395692e-03  2.14669824e-01 ...  9.94484425e-02\\n     3.94910038e-01  5.21991313e-01]\\n   [ 3.82474422e-01  6.15222752e-01  1.26509476e+00 ...  3.73964131e-01\\n    -4.04718339e-01 -2.28198379e-01]\\n   ...\\n   [ 1.20167506e+00  2.23389998e-01 -1.03075767e+00 ...  5.08284211e-01\\n    -8.87246013e-01 -5.38884886e-02]\\n   [ 8.54392231e-01  2.40312114e-01 -3.23326170e-01 ...  2.64516473e-01\\n    -6.93678319e-01 -5.64908311e-02]\\n   [ 7.69061029e-01 -3.24202657e-01 -1.13704994e-01 ... -5.26159883e-01\\n     6.14097536e-01 -4.90208924e-01]]\\n\\n  [[ 6.62424922e-01  6.69097602e-02 -3.20708543e-01 ... -3.49201620e-01\\n     1.41733080e-01 -3.61750275e-01]\\n   [ 8.00202042e-02 -1.19769514e+00  1.16299301e-01 ... -1.72086641e-01\\n    -6.28960848e-01 -8.93193841e-01]\\n   [ 2.41245598e-01 -6.58544302e-01  6.94404691e-02 ... -5.58113694e-01\\n    -5.16438663e-01 -4.03193742e-01]\\n   ...\\n   [ 1.08436778e-01  4.13774759e-01 -4.90078390e-01 ...  2.51673311e-01\\n    -1.08472593e-01 -6.98948979e-01]\\n   [ 7.15953112e-03 -6.13456964e-02 -4.57585961e-01 ... -4.71747309e-01\\n     3.33481312e-01 -1.04577020e-02]\\n   [ 6.08053446e-01 -1.12046552e+00  1.99071378e-01 ... -1.98962212e-01\\n    -6.41048551e-01 -3.80702347e-01]]]]) = <needle.nn.nn_conv.Conv object at 0x78dd70b38080>(needle.Tensor([[[[6.96463168e-01 2.47398749e-01 3.96155231e-02 ... 1.33439437e-01\\n    9.68039557e-02 3.43391716e-01]\\n   [5.91026902e-01 6.59176469e-01 3.97256762e-01 ... 1.47808671e-01\\n    6.84934437e-01 6.56761944e-01]\\n   [8.62062573e-01 9.72579941e-02 4.97776896e-01 ... 5.36922991e-01\\n    1.10477112e-01 4.05035615e-01]\\n   ...\\n   [4.04773623e-01 6.01277173e-01 7.71930873e-01 ... 7.01785743e-01\\n    1.38436839e-01 1.93990797e-01]\\n   [4.81042445e-01 2.98245788e-01 8.62559259e-01 ... 3.28953773e-01\\n    1.96916424e-02 4.08748612e-02]\\n   [2.57821709e-01 7.40244985e-01 6.28313839e-01 ... 1.98892221e-01\\n    6.56838357e-01 1.06495313e-01]]\\n\\n  [[6.50914013e-01 8.27313244e-01 6.84498549e-01 ... 1.01770267e-01\\n    6.73010111e-01 8.01815867e-01]\\n   [1.85312927e-01 4.15125251e-01 5.19984961e-01 ... 1.66542068e-01\\n    8.51198494e-01 7.71077335e-01]\\n   [2.81453729e-01 3.77268940e-01 9.26026523e-01 ... 7.69871533e-01\\n    8.49689901e-01 3.29454467e-02]\\n   ...\\n   [7.63861835e-01 4.65091795e-01 8.33934665e-01 ... 7.20801577e-02\\n    8.96424726e-02 4.21110749e-01]\\n   [2.61218965e-01 4.06037301e-01 4.54386294e-01 ... 1.54869422e-01\\n    7.83836663e-01 7.14932382e-01]\\n   [1.45947888e-01 6.32765651e-01 7...5906604e-01\\n    3.40839267e-01 3.54627579e-01]\\n   [2.64212906e-01 8.35785806e-01 5.17622113e-01 ... 7.42123842e-01\\n    4.93210316e-01 5.76824605e-01]\\n   [5.03235638e-01 3.19219708e-01 6.52476430e-01 ... 6.96852684e-01\\n    8.83167624e-01 3.75692576e-01]\\n   ...\\n   [9.44791257e-01 3.07768226e-01 9.07985568e-01 ... 5.69257848e-02\\n    3.14697593e-01 1.31645709e-01]\\n   [5.91600358e-01 2.75181025e-01 9.10362244e-01 ... 4.48005915e-01\\n    9.91251290e-01 4.69704032e-01]\\n   [4.51755702e-01 4.70763445e-01 3.34433943e-01 ... 1.82534605e-01\\n    2.65399605e-01 9.28772271e-01]]\\n\\n  [[5.38596749e-01 8.87136698e-01 2.37634540e-01 ... 1.81042925e-01\\n    6.85105443e-01 3.08706820e-01]\\n   [4.39746201e-01 7.35744536e-01 6.59922183e-01 ... 6.70376122e-01\\n    4.63832885e-01 8.60889912e-01]\\n   [7.39598215e-01 9.21502411e-01 8.70144010e-01 ... 8.41397107e-01\\n    2.90767521e-01 3.32837462e-01]\\n   ...\\n   [1.78019330e-01 2.93750465e-01 4.17306781e-01 ... 8.74954581e-01\\n    9.50466633e-01 5.48950672e-01]\\n   [8.56303692e-01 2.60515958e-02 3.65912080e-01 ... 6.45105422e-01\\n    4.11212206e-01 8.82012665e-01]\\n   [7.22939610e-01 7.99886882e-01 2.19014451e-01 ... 8.74586344e-01\\n    1.68598425e-02 5.95317602e-01]]]]))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 1.86229452e-01, -3.91856015e-01, -3.17667156e-01, ...,\\n          -5.05033791e-01, -8.52318481e-02, -1.78847775e-01],\\n         [ 1.60047531e-01,  1.98195323e-01,  1.80274025e-01, ...,\\n          -4.69669163e-01, -1.96545184e-01,  3.66828516e-02],\\n         [-1.22242123e-02, -4.43704963e-01, -5.12855768e-01, ...,\\n          -5.56952834e-01,  5.06025106e-02, -6.66310549e-01],\\n         ...,\\n         [ 5.77968299e-01, -7.69176856e-02, -1.12048797e-01, ...,\\n          -6.62365183e-02, -7.65469968e-02, -4.31290567e-01],\\n         [ 3.19758832e-01, -2.28127480e-01, -4.00415897e-01, ...,\\n          -5.83878577e-01, -5.57763055e-02, -2.99187005e-01],\\n         [ 6.41506016e-01, -2.01809019e-01, -4.41759348e-01, ...,\\n          -1.83796203e+00,  1.91242695e-02,  5.26003093e-02]],\\n\\n        [[ 9.91411209e-01, -1.11412235e-01,  6.22702897e-01, ...,\\n           1.24105966e+00,  1.09410739e+00,  8.08167756e-01],\\n         [ 6.02919519e-01,  8.49899113e-01,  1.18084514e+00, ...,\\n          -1.82486624e-02,  7.80538023e-01,  8.76008868e-01],\\n         [ 2.06834897e-01,  1.71162260e+00,  9.74906445e-01, ...,\\n           5.55899382e-01,  1.04683816e-01,  1.07173562e+00],\\n         ...,\\n         [ 4.903...   ...,\\n         [ 7.12682426e-01,  3.70482564e-01, -5.91027260e-01, ...,\\n           7.26458430e-02,  7.43716210e-02, -1.92457065e-01],\\n         [ 8.73000979e-01, -2.52403855e-01,  2.28113875e-01, ...,\\n           3.98519635e-01,  5.04673049e-02, -3.84123385e-01],\\n         [ 1.03238380e+00, -1.45382300e-01,  1.35883719e-01, ...,\\n          -2.85485163e-02, -4.68475521e-01,  1.28526539e-01]],\\n\\n        [[ 4.36959475e-01, -2.56069779e-01,  9.18245018e-02, ...,\\n           2.53883094e-01,  1.33719295e-01,  1.07970595e-01],\\n         [ 5.75301766e-01, -9.79530215e-01, -1.73143670e-01, ...,\\n           6.82247877e-02, -2.86234736e-01, -3.04604352e-01],\\n         [ 5.16664863e-01,  1.20414406e-01, -4.88719821e-01, ...,\\n          -6.02895856e-01,  2.92354822e-02, -7.69516826e-01],\\n         ...,\\n         [-4.84010354e-02, -1.06694591e+00, -2.70521224e-01, ...,\\n          -2.86947012e-01, -3.60516310e-01, -4.33617771e-01],\\n         [ 2.05358982e-01, -2.77648091e-01, -5.48413575e-01, ...,\\n          -7.26423025e-01, -1.25347245e+00, -1.20354629e+00],\\n         [-3.08604479e-01, -4.61909652e-01, -3.92321974e-01, ...,\\n          -9.17044640e-01, -3.51328790e-01, -1.34872288e-01]]]],\\n      dtype=float32) = <built-in method numpy of Tensor object at 0x78dd757e36b0>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x78dd757e36b0> = tensor([[[[ 1.8623e-01, -3.9186e-01, -3.1767e-01,  ..., -5.0503e-01,\\n           -8.5232e-02, -1.7885e-01],\\n          [ 1.6005e-01,  1.9820e-01,  1.8027e-01,  ..., -4.6967e-01,\\n           -1.9655e-01,  3.6683e-02],\\n          [-1.2224e-02, -4.4370e-01, -5.1286e-01,  ..., -5.5695e-01,\\n            5.0603e-02, -6.6631e-01],\\n          ...,\\n          [ 5.7797e-01, -7.6918e-02, -1.1205e-01,  ..., -6.6237e-02,\\n           -7.6547e-02, -4.3129e-01],\\n          [ 3.1976e-01, -2.2813e-01, -4.0042e-01,  ..., -5.8388e-01,\\n           -5.5776e-02, -2.9919e-01],\\n          [ 6.4151e-01, -2.0181e-01, -4.4176e-01,  ..., -1.8380e+00,\\n            1.9124e-02,  5.2600e-02]],\\n\\n         [[ 9.9141e-01, -1.1141e-01,  6.2270e-01,  ...,  1.2411e+00,\\n            1.0941e+00,  8.0817e-01],\\n          [ 6.0292e-01,  8.4990e-01,  1.1808e+00,  ..., -1.8249e-02,\\n            7.8054e-01,  8.7601e-01],\\n          [ 2.0683e-01,  1.7116e+00,  9.7491e-01,  ...,  5.5590e-01,\\n            1.0468e-01,  1.0717e+00],\\n          ...,\\n          [ 4.9037e-01,  5.3236e-01,  1.1361e+00,  ...,  3.5791e-01,\\n            1.2195e+00,  7.7502e-01],\\n          [ 1.2470e-01, -1.2162e-01,  2.2913e-01,  ...,  1.2063e+00,\\n            7.4907e-01,  1....9.5521e-01,  1.7071e-01,  4.4781e-01,  ..., -3.2708e-01,\\n            9.5107e-02, -9.6287e-01],\\n          [ 4.1118e-01,  2.4842e-01,  1.0480e-01,  ...,  1.9956e-01,\\n            3.3510e-01, -3.2450e-01],\\n          ...,\\n          [ 7.1268e-01,  3.7048e-01, -5.9103e-01,  ...,  7.2646e-02,\\n            7.4372e-02, -1.9246e-01],\\n          [ 8.7300e-01, -2.5240e-01,  2.2811e-01,  ...,  3.9852e-01,\\n            5.0467e-02, -3.8412e-01],\\n          [ 1.0324e+00, -1.4538e-01,  1.3588e-01,  ..., -2.8549e-02,\\n           -4.6848e-01,  1.2853e-01]],\\n\\n         [[ 4.3696e-01, -2.5607e-01,  9.1825e-02,  ...,  2.5388e-01,\\n            1.3372e-01,  1.0797e-01],\\n          [ 5.7530e-01, -9.7953e-01, -1.7314e-01,  ...,  6.8225e-02,\\n           -2.8623e-01, -3.0460e-01],\\n          [ 5.1666e-01,  1.2041e-01, -4.8872e-01,  ..., -6.0290e-01,\\n            2.9235e-02, -7.6952e-01],\\n          ...,\\n          [-4.8401e-02, -1.0669e+00, -2.7052e-01,  ..., -2.8695e-01,\\n           -3.6052e-01, -4.3362e-01],\\n          [ 2.0536e-01, -2.7765e-01, -5.4841e-01,  ..., -7.2642e-01,\\n           -1.2535e+00, -1.2035e+00],\\n          [-3.0860e-01, -4.6191e-01, -3.9232e-01,  ..., -9.1704e-01,\\n           -3.5133e-01, -1.3487e-01]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[ 1.8623e-01, -3.9186e-01, -3.1767e-01,  ..., -5.0503e-01,\\n           -8.5232e-02, -1.7885e-01],\\n          [ 1.6005e-01,  1.9820e-01,  1.8027e-01,  ..., -4.6967e-01,\\n           -1.9655e-01,  3.6683e-02],\\n          [-1.2224e-02, -4.4370e-01, -5.1286e-01,  ..., -5.5695e-01,\\n            5.0603e-02, -6.6631e-01],\\n          ...,\\n          [ 5.7797e-01, -7.6918e-02, -1.1205e-01,  ..., -6.6237e-02,\\n           -7.6547e-02, -4.3129e-01],\\n          [ 3.1976e-01, -2.2813e-01, -4.0042e-01,  ..., -5.8388e-01,\\n           -5.5776e-02, -2.9919e-01],\\n          [ 6.4151e-01, -2.0181e-01, -4.4176e-01,  ..., -1.8380e+00,\\n            1.9124e-02,  5.2600e-02]],\\n\\n         [[ 9.9141e-01, -1.1141e-01,  6.2270e-01,  ...,  1.2411e+00,\\n            1.0941e+00,  8.0817e-01],\\n          [ 6.0292e-01,  8.4990e-01,  1.1808e+00,  ..., -1.8249e-02,\\n            7.8054e-01,  8.7601e-01],\\n          [ 2.0683e-01,  1.7116e+00,  9.7491e-01,  ...,  5.5590e-01,\\n            1.0468e-01,  1.0717e+00],\\n          ...,\\n          [ 4.9037e-01,  5.3236e-01,  1.1361e+00,  ...,  3.5791e-01,\\n            1.2195e+00,  7.7502e-01],\\n          [ 1.2470e-01, -1.2162e-01,  2.2913e-01,  ...,  1.2063e+00,\\n            7.4907e-01,  1....9.5521e-01,  1.7071e-01,  4.4781e-01,  ..., -3.2708e-01,\\n            9.5107e-02, -9.6287e-01],\\n          [ 4.1118e-01,  2.4842e-01,  1.0480e-01,  ...,  1.9956e-01,\\n            3.3510e-01, -3.2450e-01],\\n          ...,\\n          [ 7.1268e-01,  3.7048e-01, -5.9103e-01,  ...,  7.2646e-02,\\n            7.4372e-02, -1.9246e-01],\\n          [ 8.7300e-01, -2.5240e-01,  2.2811e-01,  ...,  3.9852e-01,\\n            5.0467e-02, -3.8412e-01],\\n          [ 1.0324e+00, -1.4538e-01,  1.3588e-01,  ..., -2.8549e-02,\\n           -4.6848e-01,  1.2853e-01]],\\n\\n         [[ 4.3696e-01, -2.5607e-01,  9.1825e-02,  ...,  2.5388e-01,\\n            1.3372e-01,  1.0797e-01],\\n          [ 5.7530e-01, -9.7953e-01, -1.7314e-01,  ...,  6.8225e-02,\\n           -2.8623e-01, -3.0460e-01],\\n          [ 5.1666e-01,  1.2041e-01, -4.8872e-01,  ..., -6.0290e-01,\\n            2.9235e-02, -7.6952e-01],\\n          ...,\\n          [-4.8401e-02, -1.0669e+00, -2.7052e-01,  ..., -2.8695e-01,\\n           -3.6052e-01, -4.3362e-01],\\n          [ 2.0536e-01, -2.7765e-01, -5.4841e-01,  ..., -7.2642e-01,\\n           -1.2535e+00, -1.2035e+00],\\n          [-3.0860e-01, -4.6191e-01, -3.9232e-01,  ..., -9.1704e-01,\\n           -3.5133e-01, -1.3487e-01]]]]) = tensor([[[[ 1.8623e-01, -3.9186e-01, -3.1767e-01,  ..., -5.0503e-01,\\n           -8.5232e-02, -1.7885e-01],\\n          [ 1.6005e-01,  1.9820e-01,  1.8027e-01,  ..., -4.6967e-01,\\n           -1.9655e-01,  3.6683e-02],\\n          [-1.2224e-02, -4.4370e-01, -5.1286e-01,  ..., -5.5695e-01,\\n            5.0603e-02, -6.6631e-01],\\n          ...,\\n          [ 5.7797e-01, -7.6918e-02, -1.1205e-01,  ..., -6.6237e-02,\\n           -7.6547e-02, -4.3129e-01],\\n          [ 3.1976e-01, -2.2813e-01, -4.0042e-01,  ..., -5.8388e-01,\\n           -5.5776e-02, -2.9919e-01],\\n          [ 6.4151e-01, -2.0181e-01, -4.4176e-01,  ..., -1.8380e+00,\\n            1.9124e-02,  5.2600e-02]],\\n\\n         [[ 9.9141e-01, -1.1141e-01,  6.2270e-01,  ...,  1.2411e+00,\\n            1.0941e+00,  8.0817e-01],\\n          [ 6.0292e-01,  8.4990e-01,  1.1808e+00,  ..., -1.8249e-02,\\n            7.8054e-01,  8.7601e-01],\\n          [ 2.0683e-01,  1.7116e+00,  9.7491e-01,  ...,  5.5590e-01,\\n            1.0468e-01,  1.0717e+00],\\n          ...,\\n          [ 4.9037e-01,  5.3236e-01,  1.1361e+00,  ...,  3.5791e-01,\\n            1.2195e+00,  7.7502e-01],\\n          [ 1.2470e-01, -1.2162e-01,  2.2913e-01,  ...,  1.2063e+00,\\n            7.4907e-01,  1....e-01,  ..., -3.2708e-01,\\n            9.5107e-02, -9.6287e-01],\\n          [ 4.1118e-01,  2.4842e-01,  1.0480e-01,  ...,  1.9956e-01,\\n            3.3510e-01, -3.2450e-01],\\n          ...,\\n          [ 7.1268e-01,  3.7048e-01, -5.9103e-01,  ...,  7.2646e-02,\\n            7.4372e-02, -1.9246e-01],\\n          [ 8.7300e-01, -2.5240e-01,  2.2811e-01,  ...,  3.9852e-01,\\n            5.0467e-02, -3.8412e-01],\\n          [ 1.0324e+00, -1.4538e-01,  1.3588e-01,  ..., -2.8549e-02,\\n           -4.6848e-01,  1.2853e-01]],\\n\\n         [[ 4.3696e-01, -2.5607e-01,  9.1825e-02,  ...,  2.5388e-01,\\n            1.3372e-01,  1.0797e-01],\\n          [ 5.7530e-01, -9.7953e-01, -1.7314e-01,  ...,  6.8225e-02,\\n           -2.8623e-01, -3.0460e-01],\\n          [ 5.1666e-01,  1.2041e-01, -4.8872e-01,  ..., -6.0290e-01,\\n            2.9235e-02, -7.6952e-01],\\n          ...,\\n          [-4.8401e-02, -1.0669e+00, -2.7052e-01,  ..., -2.8695e-01,\\n           -3.6052e-01, -4.3362e-01],\\n          [ 2.0536e-01, -2.7765e-01, -5.4841e-01,  ..., -7.2642e-01,\\n           -1.2535e+00, -1.2035e+00],\\n          [-3.0860e-01, -4.6191e-01, -3.9232e-01,  ..., -9.1704e-01,\\n           -3.5133e-01, -1.3487e-01]]]], grad_fn=<ConvolutionBackward0>).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[ 1.8623e-01, -3.9186e-01, -3.1767e-01,  ..., -5.0503e-01,\\n           -8.5232e-02, -1.7885e-01],\\n          [ 1.6005e-01,  1.9820e-01,  1.8027e-01,  ..., -4.6967e-01,\\n           -1.9655e-01,  3.6683e-02],\\n          [-1.2224e-02, -4.4370e-01, -5.1286e-01,  ..., -5.5695e-01,\\n            5.0603e-02, -6.6631e-01],\\n          ...,\\n          [ 5.7797e-01, -7.6918e-02, -1.1205e-01,  ..., -6.6237e-02,\\n           -7.6547e-02, -4.3129e-01],\\n          [ 3.1976e-01, -2.2813e-01, -4.0042e-01,  ..., -5.8388e-01,\\n           -5.5776e-02, -2.9919e-01],\\n          [ 6.4151e-01, -2.0181e-01, -4.4176e-01,  ..., -1.8380e+00,\\n            1.9124e-02,  5.2600e-02]],\\n\\n         [[ 9.9141e-01, -1.1141e-01,  6.2270e-01,  ...,  1.2411e+00,\\n            1.0941e+00,  8.0817e-01],\\n          [ 6.0292e-01,  8.4990e-01,  1.1808e+00,  ..., -1.8249e-02,\\n            7.8054e-01,  8.7601e-01],\\n          [ 2.0683e-01,  1.7116e+00,  9.7491e-01,  ...,  5.5590e-01,\\n            1.0468e-01,  1.0717e+00],\\n          ...,\\n          [ 4.9037e-01,  5.3236e-01,  1.1361e+00,  ...,  3.5791e-01,\\n            1.2195e+00,  7.7502e-01],\\n          [ 1.2470e-01, -1.2162e-01,  2.2913e-01,  ...,  1.2063e+00,\\n            7.4907e-01,  1....e-01,  ..., -3.2708e-01,\\n            9.5107e-02, -9.6287e-01],\\n          [ 4.1118e-01,  2.4842e-01,  1.0480e-01,  ...,  1.9956e-01,\\n            3.3510e-01, -3.2450e-01],\\n          ...,\\n          [ 7.1268e-01,  3.7048e-01, -5.9103e-01,  ...,  7.2646e-02,\\n            7.4372e-02, -1.9246e-01],\\n          [ 8.7300e-01, -2.5240e-01,  2.2811e-01,  ...,  3.9852e-01,\\n            5.0467e-02, -3.8412e-01],\\n          [ 1.0324e+00, -1.4538e-01,  1.3588e-01,  ..., -2.8549e-02,\\n           -4.6848e-01,  1.2853e-01]],\\n\\n         [[ 4.3696e-01, -2.5607e-01,  9.1825e-02,  ...,  2.5388e-01,\\n            1.3372e-01,  1.0797e-01],\\n          [ 5.7530e-01, -9.7953e-01, -1.7314e-01,  ...,  6.8225e-02,\\n           -2.8623e-01, -3.0460e-01],\\n          [ 5.1666e-01,  1.2041e-01, -4.8872e-01,  ..., -6.0290e-01,\\n            2.9235e-02, -7.6952e-01],\\n          ...,\\n          [-4.8401e-02, -1.0669e+00, -2.7052e-01,  ..., -2.8695e-01,\\n           -3.6052e-01, -4.3362e-01],\\n          [ 2.0536e-01, -2.7765e-01, -5.4841e-01,  ..., -7.2642e-01,\\n           -1.2535e+00, -1.2035e+00],\\n          [-3.0860e-01, -4.6191e-01, -3.9232e-01,  ..., -9.1704e-01,\\n           -3.5133e-01, -1.3487e-01]]]], grad_fn=<ConvolutionBackward0>) = Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))(tensor([[[[6.9646e-01, 2.4740e-01, 3.9616e-02,  ..., 1.3344e-01,\\n           9.6804e-02, 3.4339e-01],\\n          [5.9103e-01, 6.5918e-01, 3.9726e-01,  ..., 1.4781e-01,\\n           6.8493e-01, 6.5676e-01],\\n          [8.6206e-01, 9.7258e-02, 4.9778e-01,  ..., 5.3692e-01,\\n           1.1048e-01, 4.0504e-01],\\n          ...,\\n          [4.0477e-01, 6.0128e-01, 7.7193e-01,  ..., 7.0179e-01,\\n           1.3844e-01, 1.9399e-01],\\n          [4.8104e-01, 2.9825e-01, 8.6256e-01,  ..., 3.2895e-01,\\n           1.9692e-02, 4.0875e-02],\\n          [2.5782e-01, 7.4024e-01, 6.2831e-01,  ..., 1.9889e-01,\\n           6.5684e-01, 1.0650e-01]],\\n\\n         [[6.5091e-01, 8.2731e-01, 6.8450e-01,  ..., 1.0177e-01,\\n           6.7301e-01, 8.0182e-01],\\n          [1.8531e-01, 4.1513e-01, 5.1998e-01,  ..., 1.6654e-01,\\n           8.5120e-01, 7.7108e-01],\\n          [2.8145e-01, 3.7727e-01, 9.2603e-01,  ..., 7.6987e-01,\\n           8.4969e-01, 3.2945e-02],\\n          ...,\\n          [7.6386e-01, 4.6509e-01, 8.3393e-01,  ..., 7.2080e-02,\\n           8.9642e-02, 4.2111e-01],\\n          [2.6122e-01, 4.0604e-01, 4.5439e-01,  ..., 1.5487e-01,\\n           7.8384e-01, 7.1493e-01],\\n          [1.4595e-01, 6.3277e-01, 7.9256e-01,  ..., 7.... ..., 1.8591e-01,\\n           3.4084e-01, 3.5463e-01],\\n          [2.6421e-01, 8.3579e-01, 5.1762e-01,  ..., 7.4212e-01,\\n           4.9321e-01, 5.7682e-01],\\n          [5.0324e-01, 3.1922e-01, 6.5248e-01,  ..., 6.9685e-01,\\n           8.8317e-01, 3.7569e-01],\\n          ...,\\n          [9.4479e-01, 3.0777e-01, 9.0799e-01,  ..., 5.6926e-02,\\n           3.1470e-01, 1.3165e-01],\\n          [5.9160e-01, 2.7518e-01, 9.1036e-01,  ..., 4.4801e-01,\\n           9.9125e-01, 4.6970e-01],\\n          [4.5176e-01, 4.7076e-01, 3.3443e-01,  ..., 1.8253e-01,\\n           2.6540e-01, 9.2877e-01]],\\n\\n         [[5.3860e-01, 8.8714e-01, 2.3763e-01,  ..., 1.8104e-01,\\n           6.8511e-01, 3.0871e-01],\\n          [4.3975e-01, 7.3574e-01, 6.5992e-01,  ..., 6.7038e-01,\\n           4.6383e-01, 8.6089e-01],\\n          [7.3960e-01, 9.2150e-01, 8.7014e-01,  ..., 8.4140e-01,\\n           2.9077e-01, 3.3284e-01],\\n          ...,\\n          [1.7802e-01, 2.9375e-01, 4.1731e-01,  ..., 8.7495e-01,\\n           9.5047e-01, 5.4895e-01],\\n          [8.5630e-01, 2.6052e-02, 3.6591e-01,  ..., 6.4511e-01,\\n           4.1121e-01, 8.8201e-01],\\n          [7.2294e-01, 7.9989e-01, 2.1901e-01,  ..., 8.7459e-01,\\n           1.6860e-02, 5.9532e-01]]]]))\u001b[0m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78dd70b38080>\n",
            "g          = Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[6.96463168e-01 2.47398749e-01 3.96155231e-02 ... 1.33439437e-01\n",
            "    9.68039557e-02 3.43391716e-01]\n",
            " ...2012665e-01]\n",
            "   [7.22939610e-01 7.99886882e-01 2.19014451e-01 ... 8.74586344e-01\n",
            "    1.68598425e-02 5.95317602e-01]]]])\n",
            "z          = tensor([[[[6.9646e-01, 2.4740e-01, 3.9616e-02,  ..., 1.3344e-01,\n",
            "           9.6804e-02, 3.4339e-01],\n",
            "          [5.9103...1, 8.8201e-01],\n",
            "          [7.2294e-01, 7.9989e-01, 2.1901e-01,  ..., 8.7459e-01,\n",
            "           1.6860e-02, 5.9532e-01]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-1] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 16, cout = 8, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert np.float32(164.71808) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(164.71808) = <function norm at 0x78de681e28f0>((array([[[[ 2.58434892e-01,  6.68774128e-01,  7.28128493e-01, ...,\\n           5.41465700e-01,  4.01308358e-01, -1.86308801e-01],\\n         [ 5.45022011e-01,  5.49053133e-01, -6.89279795e-01, ...,\\n           7.12093234e-01,  7.52698258e-03,  5.34177683e-02],\\n         [ 1.01901281e+00,  7.18842089e-01, -3.49450231e-01, ...,\\n           6.80122972e-01, -1.05138533e-01,  2.13540182e-01],\\n         ...,\\n         [ 1.86875500e-02,  2.11971216e-02, -7.44111836e-02, ...,\\n           2.31502131e-01, -2.03336671e-01,  3.79588366e-01],\\n         [ 2.66516834e-01,  3.52152973e-01, -4.90741938e-01, ...,\\n          -5.96780241e-01, -1.86072029e-02,  4.01699059e-02],\\n         [ 2.44527563e-01,  2.43374839e-01,  5.09735763e-01, ...,\\n          -1.84012458e-01,  2.97663897e-01,  2.50560731e-01]],\\n\\n        [[ 8.31717998e-02,  5.14942050e-01,  1.90630481e-01, ...,\\n           3.32386829e-02, -2.10481972e-01,  4.34559822e-01],\\n         [ 5.44740260e-01,  6.63887858e-01,  5.79722583e-01, ...,\\n           4.63191241e-01,  3.42198789e-01,  3.44051421e-01],\\n         [ 2.00627074e-02, -1.52686134e-01,  6.26266122e-01, ...,\\n          -1.69819474e-01, -3.66022915e-01,  6.09085619e-01],\\n         ...,\\n         [ 3.737...   ...,\\n         [-1.49487782e+00, -4.66923416e-01,  2.56963551e-01, ...,\\n          -1.10972449e-01,  5.00308812e-01,  1.00457869e-01],\\n         [-8.08237016e-01, -3.99968237e-01, -5.82323611e-01, ...,\\n          -2.71219820e-01, -1.03540659e+00, -6.45899296e-01],\\n         [-2.16447145e-01,  3.87087166e-02, -1.75402805e-01, ...,\\n          -3.18432480e-01, -7.57476687e-01, -8.85946155e-01]],\\n\\n        [[ 4.03352082e-01,  5.03248394e-01,  2.24167913e-01, ...,\\n           3.29077952e-02, -3.72576624e-01,  4.46527898e-01],\\n         [-9.92917046e-02, -1.05010152e+00, -7.84987748e-01, ...,\\n          -4.37325597e-01, -4.81403232e-01, -4.16543096e-01],\\n         [-6.21268824e-02, -4.43560123e-01,  4.04966593e-01, ...,\\n          -5.36499083e-01,  2.74275020e-02, -9.19806361e-01],\\n         ...,\\n         [-6.78998604e-02, -1.00427830e+00, -2.41210312e-02, ...,\\n          -9.49540377e-01,  3.45810175e-01, -5.90842068e-01],\\n         [-1.11202829e-01,  2.91139960e-01, -2.90144384e-01, ...,\\n          -8.04006100e-01, -1.51190430e-01, -2.04243809e-01],\\n         [-2.64604688e-01,  3.81887108e-01, -7.81450331e-01, ...,\\n          -1.89272910e-01, -2.77937353e-01, -7.46987045e-01]]]],\\n      dtype=float32) - array([[[[ 5.23679316e-01,  2.13915959e-01,  5.82584023e-01, ...,\\n           7.19269872e-01,  1.00129676e+00, -4.86715659e-02],\\n         [ 3.15320313e-01,  1.87322780e-01,  2.46372744e-01, ...,\\n           2.79850572e-01,  1.71869457e-01,  1.96789168e-02],\\n         [-2.69167334e-01,  1.59196496e-01,  3.46153140e-01, ...,\\n           4.95310992e-01,  7.43805528e-01, -1.96332231e-01],\\n         ...,\\n         [ 9.77673709e-01, -1.17386445e-01, -8.45591575e-02, ...,\\n           3.68173152e-01,  3.64102572e-01,  4.13744897e-01],\\n         [ 5.50246775e-01, -6.66352391e-01,  5.76834381e-01, ...,\\n          -1.97760865e-01,  5.81579246e-02,  6.24587387e-03],\\n         [ 7.28949964e-01,  5.35076857e-01, -1.07188337e-01, ...,\\n           4.47044790e-01,  8.81984234e-02,  1.91143036e-01]],\\n\\n        [[-5.25224566e-01, -5.16548038e-01, -6.38858676e-02, ...,\\n           3.64006519e-01,  1.21483892e-01,  3.02948296e-01],\\n         [ 8.47281367e-02,  1.49384871e-01,  2.44897693e-01, ...,\\n           9.82519388e-01,  8.27697515e-01, -2.08935186e-01],\\n         [ 3.77760410e-01,  1.65947169e-01,  4.06834841e-01, ...,\\n           7.02849448e-01,  6.24601424e-01, -5.15315771e-01],\\n         ...,\\n         [-1.289...   ...,\\n         [-4.18083936e-01, -6.01937473e-01, -4.28134471e-01, ...,\\n          -5.57750404e-01, -2.58385479e-01, -3.84492457e-01],\\n         [-4.24006999e-01,  6.10027686e-02, -1.09072244e+00, ...,\\n          -5.45230031e-01, -2.87531853e-01, -4.94983613e-01],\\n         [-3.71857703e-01, -3.22979420e-01, -7.30517805e-01, ...,\\n          -4.17887300e-01, -8.10227036e-01, -8.83965433e-01]],\\n\\n        [[ 2.47564733e-01, -5.41408360e-01, -7.23834932e-01, ...,\\n          -2.34204084e-01,  1.21958829e-01, -5.25535643e-02],\\n         [ 2.38547802e-01, -2.94529736e-01,  3.60737771e-01, ...,\\n          -6.02916479e-01, -4.73645210e-01, -9.74114835e-01],\\n         [ 2.62586266e-01, -5.44498384e-01, -4.97562826e-01, ...,\\n          -9.03218985e-01, -1.14899732e-01, -1.15462589e+00],\\n         ...,\\n         [ 2.30978638e-01, -8.68940577e-02, -5.77925861e-01, ...,\\n          -1.24748707e+00, -1.47982508e-01, -6.76362067e-02],\\n         [-2.69828975e-01,  7.17218161e-01, -3.85661572e-01, ...,\\n          -5.43708920e-01, -2.21028656e-01, -5.12874544e-01],\\n         [-4.16421831e-01, -7.05561280e-01, -3.33799720e-01, ...,\\n          -6.71589971e-01, -7.38962531e-01, -1.04927160e-01]]]],\\n      dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78de681e28f0> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 2.58434892e-01,  6.68774128e-01,  7.28128493e-01, ...,\\n           5.41465700e-01,  4.01308358e-01, -1.86308801e-01],\\n         [ 5.45022011e-01,  5.49053133e-01, -6.89279795e-01, ...,\\n           7.12093234e-01,  7.52698258e-03,  5.34177683e-02],\\n         [ 1.01901281e+00,  7.18842089e-01, -3.49450231e-01, ...,\\n           6.80122972e-01, -1.05138533e-01,  2.13540182e-01],\\n         ...,\\n         [ 1.86875500e-02,  2.11971216e-02, -7.44111836e-02, ...,\\n           2.31502131e-01, -2.03336671e-01,  3.79588366e-01],\\n         [ 2.66516834e-01,  3.52152973e-01, -4.90741938e-01, ...,\\n          -5.96780241e-01, -1.86072029e-02,  4.01699059e-02],\\n         [ 2.44527563e-01,  2.43374839e-01,  5.09735763e-01, ...,\\n          -1.84012458e-01,  2.97663897e-01,  2.50560731e-01]],\\n\\n        [[ 8.31717998e-02,  5.14942050e-01,  1.90630481e-01, ...,\\n           3.32386829e-02, -2.10481972e-01,  4.34559822e-01],\\n         [ 5.44740260e-01,  6.63887858e-01,  5.79722583e-01, ...,\\n           4.63191241e-01,  3.42198789e-01,  3.44051421e-01],\\n         [ 2.00627074e-02, -1.52686134e-01,  6.26266122e-01, ...,\\n          -1.69819474e-01, -3.66022915e-01,  6.09085619e-01],\\n         ...,\\n         [ 3.737...   ...,\\n         [-1.49487782e+00, -4.66923416e-01,  2.56963551e-01, ...,\\n          -1.10972449e-01,  5.00308812e-01,  1.00457869e-01],\\n         [-8.08237016e-01, -3.99968237e-01, -5.82323611e-01, ...,\\n          -2.71219820e-01, -1.03540659e+00, -6.45899296e-01],\\n         [-2.16447145e-01,  3.87087166e-02, -1.75402805e-01, ...,\\n          -3.18432480e-01, -7.57476687e-01, -8.85946155e-01]],\\n\\n        [[ 4.03352082e-01,  5.03248394e-01,  2.24167913e-01, ...,\\n           3.29077952e-02, -3.72576624e-01,  4.46527898e-01],\\n         [-9.92917046e-02, -1.05010152e+00, -7.84987748e-01, ...,\\n          -4.37325597e-01, -4.81403232e-01, -4.16543096e-01],\\n         [-6.21268824e-02, -4.43560123e-01,  4.04966593e-01, ...,\\n          -5.36499083e-01,  2.74275020e-02, -9.19806361e-01],\\n         ...,\\n         [-6.78998604e-02, -1.00427830e+00, -2.41210312e-02, ...,\\n          -9.49540377e-01,  3.45810175e-01, -5.90842068e-01],\\n         [-1.11202829e-01,  2.91139960e-01, -2.90144384e-01, ...,\\n          -8.04006100e-01, -1.51190430e-01, -2.04243809e-01],\\n         [-2.64604688e-01,  3.81887108e-01, -7.81450331e-01, ...,\\n          -1.89272910e-01, -2.77937353e-01, -7.46987045e-01]]]],\\n      dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where numpy = NDArray([[[[ 2.58434892e-01  6.68774128e-01  7.28128493e-01 ...  5.41465700e-01\\n     4.01308358e-01 -1.86308801e-01]\\n   [ 5.45022011e-01  5.49053133e-01 -6.89279795e-01 ...  7.12093234e-01\\n     7.52698258e-03  5.34177683e-02]\\n   [ 1.01901281e+00  7.18842089e-01 -3.49450231e-01 ...  6.80122972e-01\\n    -1.05138533e-01  2.13540182e-01]\\n   ...\\n   [ 1.86875500e-02  2.11971216e-02 -7.44111836e-02 ...  2.31502131e-01\\n    -2.03336671e-01  3.79588366e-01]\\n   [ 2.66516834e-01  3.52152973e-01 -4.90741938e-01 ... -5.96780241e-01\\n    -1.86072029e-02  4.01699059e-02]\\n   [ 2.44527563e-01  2.43374839e-01  5.09735763e-01 ... -1.84012458e-01\\n     2.97663897e-01  2.50560731e-01]]\\n\\n  [[ 8.31717998e-02  5.14942050e-01  1.90630481e-01 ...  3.32386829e-02\\n    -2.10481972e-01  4.34559822e-01]\\n   [ 5.44740260e-01  6.63887858e-01  5.79722583e-01 ...  4.63191241e-01\\n     3.42198789e-01  3.44051421e-01]\\n   [ 2.00627074e-02 -1.52686134e-01  6.26266122e-01 ... -1.69819474e-01\\n    -3.66022915e-01  6.09085619e-01]\\n   ...\\n   [ 3.73777866e-01 -7.45605305e-02  6.62172377e-01 ... -3.21551710e-01\\n     2.77708828e-01  2.15932727e-01]\\n   [ 6.77886486e-01 -8.00591558e-02  5.71590543e-01 ...  3.09671670e-01\\n     3.96527...0 -7.05254078e-01 ... -7.23572314e-01\\n    -2.21611679e-01 -6.91096112e-02]\\n   [ 1.59382895e-02 -3.60623151e-01 -5.58808982e-01 ... -1.20419753e+00\\n    -3.14003855e-01 -2.51379870e-02]\\n   ...\\n   [-1.49487782e+00 -4.66923416e-01  2.56963551e-01 ... -1.10972449e-01\\n     5.00308812e-01  1.00457869e-01]\\n   [-8.08237016e-01 -3.99968237e-01 -5.82323611e-01 ... -2.71219820e-01\\n    -1.03540659e+00 -6.45899296e-01]\\n   [-2.16447145e-01  3.87087166e-02 -1.75402805e-01 ... -3.18432480e-01\\n    -7.57476687e-01 -8.85946155e-01]]\\n\\n  [[ 4.03352082e-01  5.03248394e-01  2.24167913e-01 ...  3.29077952e-02\\n    -3.72576624e-01  4.46527898e-01]\\n   [-9.92917046e-02 -1.05010152e+00 -7.84987748e-01 ... -4.37325597e-01\\n    -4.81403232e-01 -4.16543096e-01]\\n   [-6.21268824e-02 -4.43560123e-01  4.04966593e-01 ... -5.36499083e-01\\n     2.74275020e-02 -9.19806361e-01]\\n   ...\\n   [-6.78998604e-02 -1.00427830e+00 -2.41210312e-02 ... -9.49540377e-01\\n     3.45810175e-01 -5.90842068e-01]\\n   [-1.11202829e-01  2.91139960e-01 -2.90144384e-01 ... -8.04006100e-01\\n    -1.51190430e-01 -2.04243809e-01]\\n   [-2.64604688e-01  3.81887108e-01 -7.81450331e-01 ... -1.89272910e-01\\n    -2.77937353e-01 -7.46987045e-01]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where NDArray([[[[ 2.58434892e-01  6.68774128e-01  7.28128493e-01 ...  5.41465700e-01\\n     4.01308358e-01 -1.86308801e-01]\\n   [ 5.45022011e-01  5.49053133e-01 -6.89279795e-01 ...  7.12093234e-01\\n     7.52698258e-03  5.34177683e-02]\\n   [ 1.01901281e+00  7.18842089e-01 -3.49450231e-01 ...  6.80122972e-01\\n    -1.05138533e-01  2.13540182e-01]\\n   ...\\n   [ 1.86875500e-02  2.11971216e-02 -7.44111836e-02 ...  2.31502131e-01\\n    -2.03336671e-01  3.79588366e-01]\\n   [ 2.66516834e-01  3.52152973e-01 -4.90741938e-01 ... -5.96780241e-01\\n    -1.86072029e-02  4.01699059e-02]\\n   [ 2.44527563e-01  2.43374839e-01  5.09735763e-01 ... -1.84012458e-01\\n     2.97663897e-01  2.50560731e-01]]\\n\\n  [[ 8.31717998e-02  5.14942050e-01  1.90630481e-01 ...  3.32386829e-02\\n    -2.10481972e-01  4.34559822e-01]\\n   [ 5.44740260e-01  6.63887858e-01  5.79722583e-01 ...  4.63191241e-01\\n     3.42198789e-01  3.44051421e-01]\\n   [ 2.00627074e-02 -1.52686134e-01  6.26266122e-01 ... -1.69819474e-01\\n    -3.66022915e-01  6.09085619e-01]\\n   ...\\n   [ 3.73777866e-01 -7.45605305e-02  6.62172377e-01 ... -3.21551710e-01\\n     2.77708828e-01  2.15932727e-01]\\n   [ 6.77886486e-01 -8.00591558e-02  5.71590543e-01 ...  3.09671670e-01\\n     3.96527...0 -7.05254078e-01 ... -7.23572314e-01\\n    -2.21611679e-01 -6.91096112e-02]\\n   [ 1.59382895e-02 -3.60623151e-01 -5.58808982e-01 ... -1.20419753e+00\\n    -3.14003855e-01 -2.51379870e-02]\\n   ...\\n   [-1.49487782e+00 -4.66923416e-01  2.56963551e-01 ... -1.10972449e-01\\n     5.00308812e-01  1.00457869e-01]\\n   [-8.08237016e-01 -3.99968237e-01 -5.82323611e-01 ... -2.71219820e-01\\n    -1.03540659e+00 -6.45899296e-01]\\n   [-2.16447145e-01  3.87087166e-02 -1.75402805e-01 ... -3.18432480e-01\\n    -7.57476687e-01 -8.85946155e-01]]\\n\\n  [[ 4.03352082e-01  5.03248394e-01  2.24167913e-01 ...  3.29077952e-02\\n    -3.72576624e-01  4.46527898e-01]\\n   [-9.92917046e-02 -1.05010152e+00 -7.84987748e-01 ... -4.37325597e-01\\n    -4.81403232e-01 -4.16543096e-01]\\n   [-6.21268824e-02 -4.43560123e-01  4.04966593e-01 ... -5.36499083e-01\\n     2.74275020e-02 -9.19806361e-01]\\n   ...\\n   [-6.78998604e-02 -1.00427830e+00 -2.41210312e-02 ... -9.49540377e-01\\n     3.45810175e-01 -5.90842068e-01]\\n   [-1.11202829e-01  2.91139960e-01 -2.90144384e-01 ... -8.04006100e-01\\n    -1.51190430e-01 -2.04243809e-01]\\n   [-2.64604688e-01  3.81887108e-01 -7.81450331e-01 ... -1.89272910e-01\\n    -2.77937353e-01 -7.46987045e-01]]]], device=cuda()) = needle.Tensor([[[[ 2.58434892e-01  6.68774128e-01  7.28128493e-01 ...  5.41465700e-01\\n     4.01308358e-01 -1.86308801e-01]\\n   [ 5.45022011e-01  5.49053133e-01 -6.89279795e-01 ...  7.12093234e-01\\n     7.52698258e-03  5.34177683e-02]\\n   [ 1.01901281e+00  7.18842089e-01 -3.49450231e-01 ...  6.80122972e-01\\n    -1.05138533e-01  2.13540182e-01]\\n   ...\\n   [ 1.86875500e-02  2.11971216e-02 -7.44111836e-02 ...  2.31502131e-01\\n    -2.03336671e-01  3.79588366e-01]\\n   [ 2.66516834e-01  3.52152973e-01 -4.90741938e-01 ... -5.96780241e-01\\n    -1.86072029e-02  4.01699059e-02]\\n   [ 2.44527563e-01  2.43374839e-01  5.09735763e-01 ... -1.84012458e-01\\n     2.97663897e-01  2.50560731e-01]]\\n\\n  [[ 8.31717998e-02  5.14942050e-01  1.90630481e-01 ...  3.32386829e-02\\n    -2.10481972e-01  4.34559822e-01]\\n   [ 5.44740260e-01  6.63887858e-01  5.79722583e-01 ...  4.63191241e-01\\n     3.42198789e-01  3.44051421e-01]\\n   [ 2.00627074e-02 -1.52686134e-01  6.26266122e-01 ... -1.69819474e-01\\n    -3.66022915e-01  6.09085619e-01]\\n   ...\\n   [ 3.73777866e-01 -7.45605305e-02  6.62172377e-01 ... -3.21551710e-01\\n     2.77708828e-01  2.15932727e-01]\\n   [ 6.77886486e-01 -8.00591558e-02  5.71590543e-01 ...  3.09671670e-01\\n     3... -1.39332914e+00 -7.05254078e-01 ... -7.23572314e-01\\n    -2.21611679e-01 -6.91096112e-02]\\n   [ 1.59382895e-02 -3.60623151e-01 -5.58808982e-01 ... -1.20419753e+00\\n    -3.14003855e-01 -2.51379870e-02]\\n   ...\\n   [-1.49487782e+00 -4.66923416e-01  2.56963551e-01 ... -1.10972449e-01\\n     5.00308812e-01  1.00457869e-01]\\n   [-8.08237016e-01 -3.99968237e-01 -5.82323611e-01 ... -2.71219820e-01\\n    -1.03540659e+00 -6.45899296e-01]\\n   [-2.16447145e-01  3.87087166e-02 -1.75402805e-01 ... -3.18432480e-01\\n    -7.57476687e-01 -8.85946155e-01]]\\n\\n  [[ 4.03352082e-01  5.03248394e-01  2.24167913e-01 ...  3.29077952e-02\\n    -3.72576624e-01  4.46527898e-01]\\n   [-9.92917046e-02 -1.05010152e+00 -7.84987748e-01 ... -4.37325597e-01\\n    -4.81403232e-01 -4.16543096e-01]\\n   [-6.21268824e-02 -4.43560123e-01  4.04966593e-01 ... -5.36499083e-01\\n     2.74275020e-02 -9.19806361e-01]\\n   ...\\n   [-6.78998604e-02 -1.00427830e+00 -2.41210312e-02 ... -9.49540377e-01\\n     3.45810175e-01 -5.90842068e-01]\\n   [-1.11202829e-01  2.91139960e-01 -2.90144384e-01 ... -8.04006100e-01\\n    -1.51190430e-01 -2.04243809e-01]\\n   [-2.64604688e-01  3.81887108e-01 -7.81450331e-01 ... -1.89272910e-01\\n    -2.77937353e-01 -7.46987045e-01]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where needle.Tensor([[[[ 2.58434892e-01  6.68774128e-01  7.28128493e-01 ...  5.41465700e-01\\n     4.01308358e-01 -1.86308801e-01]\\n   [ 5.45022011e-01  5.49053133e-01 -6.89279795e-01 ...  7.12093234e-01\\n     7.52698258e-03  5.34177683e-02]\\n   [ 1.01901281e+00  7.18842089e-01 -3.49450231e-01 ...  6.80122972e-01\\n    -1.05138533e-01  2.13540182e-01]\\n   ...\\n   [ 1.86875500e-02  2.11971216e-02 -7.44111836e-02 ...  2.31502131e-01\\n    -2.03336671e-01  3.79588366e-01]\\n   [ 2.66516834e-01  3.52152973e-01 -4.90741938e-01 ... -5.96780241e-01\\n    -1.86072029e-02  4.01699059e-02]\\n   [ 2.44527563e-01  2.43374839e-01  5.09735763e-01 ... -1.84012458e-01\\n     2.97663897e-01  2.50560731e-01]]\\n\\n  [[ 8.31717998e-02  5.14942050e-01  1.90630481e-01 ...  3.32386829e-02\\n    -2.10481972e-01  4.34559822e-01]\\n   [ 5.44740260e-01  6.63887858e-01  5.79722583e-01 ...  4.63191241e-01\\n     3.42198789e-01  3.44051421e-01]\\n   [ 2.00627074e-02 -1.52686134e-01  6.26266122e-01 ... -1.69819474e-01\\n    -3.66022915e-01  6.09085619e-01]\\n   ...\\n   [ 3.73777866e-01 -7.45605305e-02  6.62172377e-01 ... -3.21551710e-01\\n     2.77708828e-01  2.15932727e-01]\\n   [ 6.77886486e-01 -8.00591558e-02  5.71590543e-01 ...  3.09671670e-01\\n     3... -1.39332914e+00 -7.05254078e-01 ... -7.23572314e-01\\n    -2.21611679e-01 -6.91096112e-02]\\n   [ 1.59382895e-02 -3.60623151e-01 -5.58808982e-01 ... -1.20419753e+00\\n    -3.14003855e-01 -2.51379870e-02]\\n   ...\\n   [-1.49487782e+00 -4.66923416e-01  2.56963551e-01 ... -1.10972449e-01\\n     5.00308812e-01  1.00457869e-01]\\n   [-8.08237016e-01 -3.99968237e-01 -5.82323611e-01 ... -2.71219820e-01\\n    -1.03540659e+00 -6.45899296e-01]\\n   [-2.16447145e-01  3.87087166e-02 -1.75402805e-01 ... -3.18432480e-01\\n    -7.57476687e-01 -8.85946155e-01]]\\n\\n  [[ 4.03352082e-01  5.03248394e-01  2.24167913e-01 ...  3.29077952e-02\\n    -3.72576624e-01  4.46527898e-01]\\n   [-9.92917046e-02 -1.05010152e+00 -7.84987748e-01 ... -4.37325597e-01\\n    -4.81403232e-01 -4.16543096e-01]\\n   [-6.21268824e-02 -4.43560123e-01  4.04966593e-01 ... -5.36499083e-01\\n     2.74275020e-02 -9.19806361e-01]\\n   ...\\n   [-6.78998604e-02 -1.00427830e+00 -2.41210312e-02 ... -9.49540377e-01\\n     3.45810175e-01 -5.90842068e-01]\\n   [-1.11202829e-01  2.91139960e-01 -2.90144384e-01 ... -8.04006100e-01\\n    -1.51190430e-01 -2.04243809e-01]\\n   [-2.64604688e-01  3.81887108e-01 -7.81450331e-01 ... -1.89272910e-01\\n    -2.77937353e-01 -7.46987045e-01]]]]) = <needle.nn.nn_conv.Conv object at 0x78dd70b642c0>(needle.Tensor([[[[7.51032293e-01 1.55977935e-01 4.26002383e-01 ... 8.66860926e-01\\n    8.16150725e-01 9.11450863e-01]\\n   [2.76337147e-01 3.69523555e-01 3.79893899e-01 ... 9.82247770e-01\\n    9.92667019e-01 1.18615516e-01]\\n   [9.38256145e-01 2.44569615e-01 4.58212256e-01 ... 9.55465913e-01\\n    5.98315954e-01 1.18916944e-01]\\n   ...\\n   [7.05306768e-01 3.65676343e-01 3.95410717e-01 ... 8.20462167e-01\\n    2.30773941e-01 3.25923949e-01]\\n   [7.08360255e-01 3.92758936e-01 2.92709395e-02 ... 5.61398745e-01\\n    7.13245988e-01 9.81864214e-01]\\n   [4.28198665e-01 8.81066620e-01 7.28101376e-03 ... 1.92320589e-02\\n    5.69872141e-01 2.94650257e-01]]\\n\\n  [[8.49028647e-01 6.32849634e-01 5.38877010e-01 ... 5.28081954e-01\\n    8.01273406e-01 5.02910614e-02]\\n   [4.20910150e-01 2.56975472e-01 2.66975909e-01 ... 3.62692922e-01\\n    7.76749671e-01 9.67005551e-01]\\n   [3.87567163e-01 6.86690032e-01 9.94901896e-01 ... 4.47322875e-01\\n    8.20734262e-01 9.23878312e-01]\\n   ...\\n   [2.39857987e-01 8.71297181e-01 3.46534163e-01 ... 7.99730122e-01\\n    1.62170872e-01 1.94574520e-01]\\n   [8.82035911e-01 9.38964903e-01 3.18471253e-01 ... 1.74082518e-01\\n    4.76540327e-01 1.73072264e-01]\\n   [4.62426394e-01 3.96819681e-01 4...4292269e-01\\n    6.71649516e-01 5.07325470e-01]\\n   [3.45140189e-01 8.96334499e-02 8.41704786e-01 ... 9.35227513e-01\\n    1.34437010e-01 8.15641165e-01]\\n   [3.23829204e-01 5.19954264e-01 6.69752419e-01 ... 5.14791787e-01\\n    1.93027958e-01 6.91878051e-02]\\n   ...\\n   [2.56760895e-01 5.18177569e-01 1.58639312e-01 ... 4.52608615e-01\\n    2.13869601e-01 5.23449540e-01]\\n   [2.21188918e-01 9.12276506e-01 6.43553495e-01 ... 6.07078016e-01\\n    6.63995385e-01 8.55302513e-01]\\n   [8.04294109e-01 4.07190830e-01 2.22389743e-01 ... 7.31954873e-01\\n    3.19931418e-01 9.35044050e-01]]\\n\\n  [[5.48553526e-01 2.27439925e-01 2.32894808e-01 ... 7.19932437e-01\\n    7.64594615e-01 1.77171946e-01]\\n   [9.27534699e-01 3.58361691e-01 2.34949797e-01 ... 3.55137050e-01\\n    2.69719988e-01 9.61764574e-01]\\n   [8.61650407e-01 5.33731639e-01 8.32363725e-01 ... 3.21728408e-01\\n    9.25663114e-01 5.37845492e-01]\\n   ...\\n   [3.98562610e-01 7.63842106e-01 6.98767483e-01 ... 7.27313384e-02\\n    5.16509473e-01 9.15419519e-01]\\n   [3.76324385e-01 4.17884946e-01 5.40873885e-01 ... 6.02395475e-01\\n    1.55160144e-01 2.56504536e-01]\\n   [4.68549311e-01 8.67467165e-01 2.42747739e-01 ... 7.15565860e-01\\n    5.56286812e-01 7.09560752e-01]]]]))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 5.23679316e-01,  2.13915959e-01,  5.82584023e-01, ...,\\n           7.19269872e-01,  1.00129676e+00, -4.86715659e-02],\\n         [ 3.15320313e-01,  1.87322780e-01,  2.46372744e-01, ...,\\n           2.79850572e-01,  1.71869457e-01,  1.96789168e-02],\\n         [-2.69167334e-01,  1.59196496e-01,  3.46153140e-01, ...,\\n           4.95310992e-01,  7.43805528e-01, -1.96332231e-01],\\n         ...,\\n         [ 9.77673709e-01, -1.17386445e-01, -8.45591575e-02, ...,\\n           3.68173152e-01,  3.64102572e-01,  4.13744897e-01],\\n         [ 5.50246775e-01, -6.66352391e-01,  5.76834381e-01, ...,\\n          -1.97760865e-01,  5.81579246e-02,  6.24587387e-03],\\n         [ 7.28949964e-01,  5.35076857e-01, -1.07188337e-01, ...,\\n           4.47044790e-01,  8.81984234e-02,  1.91143036e-01]],\\n\\n        [[-5.25224566e-01, -5.16548038e-01, -6.38858676e-02, ...,\\n           3.64006519e-01,  1.21483892e-01,  3.02948296e-01],\\n         [ 8.47281367e-02,  1.49384871e-01,  2.44897693e-01, ...,\\n           9.82519388e-01,  8.27697515e-01, -2.08935186e-01],\\n         [ 3.77760410e-01,  1.65947169e-01,  4.06834841e-01, ...,\\n           7.02849448e-01,  6.24601424e-01, -5.15315771e-01],\\n         ...,\\n         [-1.289...   ...,\\n         [-4.18083936e-01, -6.01937473e-01, -4.28134471e-01, ...,\\n          -5.57750404e-01, -2.58385479e-01, -3.84492457e-01],\\n         [-4.24006999e-01,  6.10027686e-02, -1.09072244e+00, ...,\\n          -5.45230031e-01, -2.87531853e-01, -4.94983613e-01],\\n         [-3.71857703e-01, -3.22979420e-01, -7.30517805e-01, ...,\\n          -4.17887300e-01, -8.10227036e-01, -8.83965433e-01]],\\n\\n        [[ 2.47564733e-01, -5.41408360e-01, -7.23834932e-01, ...,\\n          -2.34204084e-01,  1.21958829e-01, -5.25535643e-02],\\n         [ 2.38547802e-01, -2.94529736e-01,  3.60737771e-01, ...,\\n          -6.02916479e-01, -4.73645210e-01, -9.74114835e-01],\\n         [ 2.62586266e-01, -5.44498384e-01, -4.97562826e-01, ...,\\n          -9.03218985e-01, -1.14899732e-01, -1.15462589e+00],\\n         ...,\\n         [ 2.30978638e-01, -8.68940577e-02, -5.77925861e-01, ...,\\n          -1.24748707e+00, -1.47982508e-01, -6.76362067e-02],\\n         [-2.69828975e-01,  7.17218161e-01, -3.85661572e-01, ...,\\n          -5.43708920e-01, -2.21028656e-01, -5.12874544e-01],\\n         [-4.16421831e-01, -7.05561280e-01, -3.33799720e-01, ...,\\n          -6.71589971e-01, -7.38962531e-01, -1.04927160e-01]]]],\\n      dtype=float32) = <built-in method numpy of Tensor object at 0x78dd757e3de0>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x78dd757e3de0> = tensor([[[[ 5.2368e-01,  2.1392e-01,  5.8258e-01,  ...,  7.1927e-01,\\n            1.0013e+00, -4.8672e-02],\\n          [ 3.1532e-01,  1.8732e-01,  2.4637e-01,  ...,  2.7985e-01,\\n            1.7187e-01,  1.9679e-02],\\n          [-2.6917e-01,  1.5920e-01,  3.4615e-01,  ...,  4.9531e-01,\\n            7.4381e-01, -1.9633e-01],\\n          ...,\\n          [ 9.7767e-01, -1.1739e-01, -8.4559e-02,  ...,  3.6817e-01,\\n            3.6410e-01,  4.1374e-01],\\n          [ 5.5025e-01, -6.6635e-01,  5.7683e-01,  ..., -1.9776e-01,\\n            5.8158e-02,  6.2459e-03],\\n          [ 7.2895e-01,  5.3508e-01, -1.0719e-01,  ...,  4.4704e-01,\\n            8.8198e-02,  1.9114e-01]],\\n\\n         [[-5.2522e-01, -5.1655e-01, -6.3886e-02,  ...,  3.6401e-01,\\n            1.2148e-01,  3.0295e-01],\\n          [ 8.4728e-02,  1.4938e-01,  2.4490e-01,  ...,  9.8252e-01,\\n            8.2770e-01, -2.0894e-01],\\n          [ 3.7776e-01,  1.6595e-01,  4.0683e-01,  ...,  7.0285e-01,\\n            6.2460e-01, -5.1532e-01],\\n          ...,\\n          [-1.2898e-01,  1.0577e+00,  8.8125e-01,  ...,  1.7367e-01,\\n            4.2079e-01,  1.1461e+00],\\n          [ 2.1591e-01,  2.0644e-01, -2.1737e-01,  ...,  6.7314e-01,\\n            2.8885e-01, -9....1.3997e-01, -8.9332e-01, -4.0077e-01,  ...,  9.2509e-02,\\n           -6.2084e-01,  1.9004e-01],\\n          [-3.8195e-01, -8.0248e-01, -1.2974e+00,  ..., -6.7314e-01,\\n           -1.0257e-01, -5.6420e-01],\\n          ...,\\n          [-4.1808e-01, -6.0194e-01, -4.2813e-01,  ..., -5.5775e-01,\\n           -2.5839e-01, -3.8449e-01],\\n          [-4.2401e-01,  6.1003e-02, -1.0907e+00,  ..., -5.4523e-01,\\n           -2.8753e-01, -4.9498e-01],\\n          [-3.7186e-01, -3.2298e-01, -7.3052e-01,  ..., -4.1789e-01,\\n           -8.1023e-01, -8.8397e-01]],\\n\\n         [[ 2.4756e-01, -5.4141e-01, -7.2383e-01,  ..., -2.3420e-01,\\n            1.2196e-01, -5.2554e-02],\\n          [ 2.3855e-01, -2.9453e-01,  3.6074e-01,  ..., -6.0292e-01,\\n           -4.7365e-01, -9.7411e-01],\\n          [ 2.6259e-01, -5.4450e-01, -4.9756e-01,  ..., -9.0322e-01,\\n           -1.1490e-01, -1.1546e+00],\\n          ...,\\n          [ 2.3098e-01, -8.6894e-02, -5.7793e-01,  ..., -1.2475e+00,\\n           -1.4798e-01, -6.7636e-02],\\n          [-2.6983e-01,  7.1722e-01, -3.8566e-01,  ..., -5.4371e-01,\\n           -2.2103e-01, -5.1287e-01],\\n          [-4.1642e-01, -7.0556e-01, -3.3380e-01,  ..., -6.7159e-01,\\n           -7.3896e-01, -1.0493e-01]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[ 5.2368e-01,  2.1392e-01,  5.8258e-01,  ...,  7.1927e-01,\\n            1.0013e+00, -4.8672e-02],\\n          [ 3.1532e-01,  1.8732e-01,  2.4637e-01,  ...,  2.7985e-01,\\n            1.7187e-01,  1.9679e-02],\\n          [-2.6917e-01,  1.5920e-01,  3.4615e-01,  ...,  4.9531e-01,\\n            7.4381e-01, -1.9633e-01],\\n          ...,\\n          [ 9.7767e-01, -1.1739e-01, -8.4559e-02,  ...,  3.6817e-01,\\n            3.6410e-01,  4.1374e-01],\\n          [ 5.5025e-01, -6.6635e-01,  5.7683e-01,  ..., -1.9776e-01,\\n            5.8158e-02,  6.2459e-03],\\n          [ 7.2895e-01,  5.3508e-01, -1.0719e-01,  ...,  4.4704e-01,\\n            8.8198e-02,  1.9114e-01]],\\n\\n         [[-5.2522e-01, -5.1655e-01, -6.3886e-02,  ...,  3.6401e-01,\\n            1.2148e-01,  3.0295e-01],\\n          [ 8.4728e-02,  1.4938e-01,  2.4490e-01,  ...,  9.8252e-01,\\n            8.2770e-01, -2.0894e-01],\\n          [ 3.7776e-01,  1.6595e-01,  4.0683e-01,  ...,  7.0285e-01,\\n            6.2460e-01, -5.1532e-01],\\n          ...,\\n          [-1.2898e-01,  1.0577e+00,  8.8125e-01,  ...,  1.7367e-01,\\n            4.2079e-01,  1.1461e+00],\\n          [ 2.1591e-01,  2.0644e-01, -2.1737e-01,  ...,  6.7314e-01,\\n            2.8885e-01, -9....1.3997e-01, -8.9332e-01, -4.0077e-01,  ...,  9.2509e-02,\\n           -6.2084e-01,  1.9004e-01],\\n          [-3.8195e-01, -8.0248e-01, -1.2974e+00,  ..., -6.7314e-01,\\n           -1.0257e-01, -5.6420e-01],\\n          ...,\\n          [-4.1808e-01, -6.0194e-01, -4.2813e-01,  ..., -5.5775e-01,\\n           -2.5839e-01, -3.8449e-01],\\n          [-4.2401e-01,  6.1003e-02, -1.0907e+00,  ..., -5.4523e-01,\\n           -2.8753e-01, -4.9498e-01],\\n          [-3.7186e-01, -3.2298e-01, -7.3052e-01,  ..., -4.1789e-01,\\n           -8.1023e-01, -8.8397e-01]],\\n\\n         [[ 2.4756e-01, -5.4141e-01, -7.2383e-01,  ..., -2.3420e-01,\\n            1.2196e-01, -5.2554e-02],\\n          [ 2.3855e-01, -2.9453e-01,  3.6074e-01,  ..., -6.0292e-01,\\n           -4.7365e-01, -9.7411e-01],\\n          [ 2.6259e-01, -5.4450e-01, -4.9756e-01,  ..., -9.0322e-01,\\n           -1.1490e-01, -1.1546e+00],\\n          ...,\\n          [ 2.3098e-01, -8.6894e-02, -5.7793e-01,  ..., -1.2475e+00,\\n           -1.4798e-01, -6.7636e-02],\\n          [-2.6983e-01,  7.1722e-01, -3.8566e-01,  ..., -5.4371e-01,\\n           -2.2103e-01, -5.1287e-01],\\n          [-4.1642e-01, -7.0556e-01, -3.3380e-01,  ..., -6.7159e-01,\\n           -7.3896e-01, -1.0493e-01]]]]) = tensor([[[[ 5.2368e-01,  2.1392e-01,  5.8258e-01,  ...,  7.1927e-01,\\n            1.0013e+00, -4.8672e-02],\\n          [ 3.1532e-01,  1.8732e-01,  2.4637e-01,  ...,  2.7985e-01,\\n            1.7187e-01,  1.9679e-02],\\n          [-2.6917e-01,  1.5920e-01,  3.4615e-01,  ...,  4.9531e-01,\\n            7.4381e-01, -1.9633e-01],\\n          ...,\\n          [ 9.7767e-01, -1.1739e-01, -8.4559e-02,  ...,  3.6817e-01,\\n            3.6410e-01,  4.1374e-01],\\n          [ 5.5025e-01, -6.6635e-01,  5.7683e-01,  ..., -1.9776e-01,\\n            5.8158e-02,  6.2459e-03],\\n          [ 7.2895e-01,  5.3508e-01, -1.0719e-01,  ...,  4.4704e-01,\\n            8.8198e-02,  1.9114e-01]],\\n\\n         [[-5.2522e-01, -5.1655e-01, -6.3886e-02,  ...,  3.6401e-01,\\n            1.2148e-01,  3.0295e-01],\\n          [ 8.4728e-02,  1.4938e-01,  2.4490e-01,  ...,  9.8252e-01,\\n            8.2770e-01, -2.0894e-01],\\n          [ 3.7776e-01,  1.6595e-01,  4.0683e-01,  ...,  7.0285e-01,\\n            6.2460e-01, -5.1532e-01],\\n          ...,\\n          [-1.2898e-01,  1.0577e+00,  8.8125e-01,  ...,  1.7367e-01,\\n            4.2079e-01,  1.1461e+00],\\n          [ 2.1591e-01,  2.0644e-01, -2.1737e-01,  ...,  6.7314e-01,\\n            2.8885e-01, -9....e-01,  ...,  9.2509e-02,\\n           -6.2084e-01,  1.9004e-01],\\n          [-3.8195e-01, -8.0248e-01, -1.2974e+00,  ..., -6.7314e-01,\\n           -1.0257e-01, -5.6420e-01],\\n          ...,\\n          [-4.1808e-01, -6.0194e-01, -4.2813e-01,  ..., -5.5775e-01,\\n           -2.5839e-01, -3.8449e-01],\\n          [-4.2401e-01,  6.1003e-02, -1.0907e+00,  ..., -5.4523e-01,\\n           -2.8753e-01, -4.9498e-01],\\n          [-3.7186e-01, -3.2298e-01, -7.3052e-01,  ..., -4.1789e-01,\\n           -8.1023e-01, -8.8397e-01]],\\n\\n         [[ 2.4756e-01, -5.4141e-01, -7.2383e-01,  ..., -2.3420e-01,\\n            1.2196e-01, -5.2554e-02],\\n          [ 2.3855e-01, -2.9453e-01,  3.6074e-01,  ..., -6.0292e-01,\\n           -4.7365e-01, -9.7411e-01],\\n          [ 2.6259e-01, -5.4450e-01, -4.9756e-01,  ..., -9.0322e-01,\\n           -1.1490e-01, -1.1546e+00],\\n          ...,\\n          [ 2.3098e-01, -8.6894e-02, -5.7793e-01,  ..., -1.2475e+00,\\n           -1.4798e-01, -6.7636e-02],\\n          [-2.6983e-01,  7.1722e-01, -3.8566e-01,  ..., -5.4371e-01,\\n           -2.2103e-01, -5.1287e-01],\\n          [-4.1642e-01, -7.0556e-01, -3.3380e-01,  ..., -6.7159e-01,\\n           -7.3896e-01, -1.0493e-01]]]], grad_fn=<ConvolutionBackward0>).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[ 5.2368e-01,  2.1392e-01,  5.8258e-01,  ...,  7.1927e-01,\\n            1.0013e+00, -4.8672e-02],\\n          [ 3.1532e-01,  1.8732e-01,  2.4637e-01,  ...,  2.7985e-01,\\n            1.7187e-01,  1.9679e-02],\\n          [-2.6917e-01,  1.5920e-01,  3.4615e-01,  ...,  4.9531e-01,\\n            7.4381e-01, -1.9633e-01],\\n          ...,\\n          [ 9.7767e-01, -1.1739e-01, -8.4559e-02,  ...,  3.6817e-01,\\n            3.6410e-01,  4.1374e-01],\\n          [ 5.5025e-01, -6.6635e-01,  5.7683e-01,  ..., -1.9776e-01,\\n            5.8158e-02,  6.2459e-03],\\n          [ 7.2895e-01,  5.3508e-01, -1.0719e-01,  ...,  4.4704e-01,\\n            8.8198e-02,  1.9114e-01]],\\n\\n         [[-5.2522e-01, -5.1655e-01, -6.3886e-02,  ...,  3.6401e-01,\\n            1.2148e-01,  3.0295e-01],\\n          [ 8.4728e-02,  1.4938e-01,  2.4490e-01,  ...,  9.8252e-01,\\n            8.2770e-01, -2.0894e-01],\\n          [ 3.7776e-01,  1.6595e-01,  4.0683e-01,  ...,  7.0285e-01,\\n            6.2460e-01, -5.1532e-01],\\n          ...,\\n          [-1.2898e-01,  1.0577e+00,  8.8125e-01,  ...,  1.7367e-01,\\n            4.2079e-01,  1.1461e+00],\\n          [ 2.1591e-01,  2.0644e-01, -2.1737e-01,  ...,  6.7314e-01,\\n            2.8885e-01, -9....e-01,  ...,  9.2509e-02,\\n           -6.2084e-01,  1.9004e-01],\\n          [-3.8195e-01, -8.0248e-01, -1.2974e+00,  ..., -6.7314e-01,\\n           -1.0257e-01, -5.6420e-01],\\n          ...,\\n          [-4.1808e-01, -6.0194e-01, -4.2813e-01,  ..., -5.5775e-01,\\n           -2.5839e-01, -3.8449e-01],\\n          [-4.2401e-01,  6.1003e-02, -1.0907e+00,  ..., -5.4523e-01,\\n           -2.8753e-01, -4.9498e-01],\\n          [-3.7186e-01, -3.2298e-01, -7.3052e-01,  ..., -4.1789e-01,\\n           -8.1023e-01, -8.8397e-01]],\\n\\n         [[ 2.4756e-01, -5.4141e-01, -7.2383e-01,  ..., -2.3420e-01,\\n            1.2196e-01, -5.2554e-02],\\n          [ 2.3855e-01, -2.9453e-01,  3.6074e-01,  ..., -6.0292e-01,\\n           -4.7365e-01, -9.7411e-01],\\n          [ 2.6259e-01, -5.4450e-01, -4.9756e-01,  ..., -9.0322e-01,\\n           -1.1490e-01, -1.1546e+00],\\n          ...,\\n          [ 2.3098e-01, -8.6894e-02, -5.7793e-01,  ..., -1.2475e+00,\\n           -1.4798e-01, -6.7636e-02],\\n          [-2.6983e-01,  7.1722e-01, -3.8566e-01,  ..., -5.4371e-01,\\n           -2.2103e-01, -5.1287e-01],\\n          [-4.1642e-01, -7.0556e-01, -3.3380e-01,  ..., -6.7159e-01,\\n           -7.3896e-01, -1.0493e-01]]]], grad_fn=<ConvolutionBackward0>) = Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(tensor([[[[7.5103e-01, 1.5598e-01, 4.2600e-01,  ..., 8.6686e-01,\\n           8.1615e-01, 9.1145e-01],\\n          [2.7634e-01, 3.6952e-01, 3.7989e-01,  ..., 9.8225e-01,\\n           9.9267e-01, 1.1862e-01],\\n          [9.3826e-01, 2.4457e-01, 4.5821e-01,  ..., 9.5547e-01,\\n           5.9832e-01, 1.1892e-01],\\n          ...,\\n          [7.0531e-01, 3.6568e-01, 3.9541e-01,  ..., 8.2046e-01,\\n           2.3077e-01, 3.2592e-01],\\n          [7.0836e-01, 3.9276e-01, 2.9271e-02,  ..., 5.6140e-01,\\n           7.1325e-01, 9.8186e-01],\\n          [4.2820e-01, 8.8107e-01, 7.2810e-03,  ..., 1.9232e-02,\\n           5.6987e-01, 2.9465e-01]],\\n\\n         [[8.4903e-01, 6.3285e-01, 5.3888e-01,  ..., 5.2808e-01,\\n           8.0127e-01, 5.0291e-02],\\n          [4.2091e-01, 2.5698e-01, 2.6698e-01,  ..., 3.6269e-01,\\n           7.7675e-01, 9.6701e-01],\\n          [3.8757e-01, 6.8669e-01, 9.9490e-01,  ..., 4.4732e-01,\\n           8.2073e-01, 9.2388e-01],\\n          ...,\\n          [2.3986e-01, 8.7130e-01, 3.4653e-01,  ..., 7.9973e-01,\\n           1.6217e-01, 1.9457e-01],\\n          [8.8204e-01, 9.3896e-01, 3.1847e-01,  ..., 1.7408e-01,\\n           4.7654e-01, 1.7307e-01],\\n          [4.6243e-01, 3.9682e-01, 4.3326e-01,  ..., 1.... ..., 2.3429e-01,\\n           6.7165e-01, 5.0733e-01],\\n          [3.4514e-01, 8.9633e-02, 8.4170e-01,  ..., 9.3523e-01,\\n           1.3444e-01, 8.1564e-01],\\n          [3.2383e-01, 5.1995e-01, 6.6975e-01,  ..., 5.1479e-01,\\n           1.9303e-01, 6.9188e-02],\\n          ...,\\n          [2.5676e-01, 5.1818e-01, 1.5864e-01,  ..., 4.5261e-01,\\n           2.1387e-01, 5.2345e-01],\\n          [2.2119e-01, 9.1228e-01, 6.4355e-01,  ..., 6.0708e-01,\\n           6.6400e-01, 8.5530e-01],\\n          [8.0429e-01, 4.0719e-01, 2.2239e-01,  ..., 7.3195e-01,\\n           3.1993e-01, 9.3504e-01]],\\n\\n         [[5.4855e-01, 2.2744e-01, 2.3289e-01,  ..., 7.1993e-01,\\n           7.6459e-01, 1.7717e-01],\\n          [9.2753e-01, 3.5836e-01, 2.3495e-01,  ..., 3.5514e-01,\\n           2.6972e-01, 9.6176e-01],\\n          [8.6165e-01, 5.3373e-01, 8.3236e-01,  ..., 3.2173e-01,\\n           9.2566e-01, 5.3785e-01],\\n          ...,\\n          [3.9856e-01, 7.6384e-01, 6.9877e-01,  ..., 7.2731e-02,\\n           5.1651e-01, 9.1542e-01],\\n          [3.7632e-01, 4.1788e-01, 5.4087e-01,  ..., 6.0240e-01,\\n           1.5516e-01, 2.5650e-01],\\n          [4.6855e-01, 8.6747e-01, 2.4275e-01,  ..., 7.1557e-01,\\n           5.5629e-01, 7.0956e-01]]]]))\u001b[0m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78dd70b642c0>\n",
            "g          = Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[7.51032293e-01 1.55977935e-01 4.26002383e-01 ... 8.66860926e-01\n",
            "    8.16150725e-01 9.11450863e-01]\n",
            " ...6504536e-01]\n",
            "   [4.68549311e-01 8.67467165e-01 2.42747739e-01 ... 7.15565860e-01\n",
            "    5.56286812e-01 7.09560752e-01]]]])\n",
            "z          = tensor([[[[7.5103e-01, 1.5598e-01, 4.2600e-01,  ..., 8.6686e-01,\n",
            "           8.1615e-01, 9.1145e-01],\n",
            "          [2.7634...1, 2.5650e-01],\n",
            "          [4.6855e-01, 8.6747e-01, 2.4275e-01,  ..., 7.1557e-01,\n",
            "           5.5629e-01, 7.0956e-01]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 16, cout = 8, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert np.float32(82.73932) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(82.73932) = <function norm at 0x78de681e28f0>((array([[[[ 2.58434892e-01,  7.28128493e-01,  4.80445355e-01, ...,\\n           5.36917210e-01,  5.05219340e-01,  4.01308358e-01],\\n         [ 1.01901281e+00, -3.49450231e-01,  9.77876127e-01, ...,\\n          -3.07390541e-01, -5.58665514e-01, -1.05138533e-01],\\n         [ 9.03846502e-01, -6.18082508e-02, -5.72444737e-01, ...,\\n          -3.77199389e-02, -7.11712241e-02,  4.46973711e-01],\\n         ...,\\n         [ 6.83595955e-01,  3.38825613e-01,  1.18643314e-01, ...,\\n          -4.41742688e-01, -3.45223069e-01, -2.79511362e-02],\\n         [ 6.65733397e-01, -8.91723484e-03,  2.64310181e-01, ...,\\n           5.33751585e-02,  1.66198984e-01, -2.67285910e-02],\\n         [ 2.66516834e-01, -4.90741938e-01, -6.25833690e-01, ...,\\n           4.51264948e-01,  4.08310562e-01, -1.86072029e-02]],\\n\\n        [[ 8.31717998e-02,  1.90630481e-01, -8.33328217e-02, ...,\\n           8.02566111e-02,  7.20171750e-01, -2.10481972e-01],\\n         [ 2.00627074e-02,  6.26266122e-01, -3.51569295e-01, ...,\\n           3.95451367e-01,  2.92020738e-01, -3.66022915e-01],\\n         [-1.62807152e-01,  9.93413627e-02,  2.64848322e-01, ...,\\n           5.63911200e-01,  8.09847653e-01,  8.89805317e-01],\\n         ...,\\n         [-1.540...   ...,\\n         [-6.20422184e-01,  2.29914367e-01, -7.18901217e-01, ...,\\n          -1.74811363e-01, -1.85915041e+00, -5.07850051e-01],\\n         [-1.09314394e+00,  2.05168664e-01, -1.67571992e-01, ...,\\n           1.28321946e-01, -3.37294638e-01, -7.57337868e-01],\\n         [-8.08237016e-01, -5.82323611e-01, -4.39341739e-03, ...,\\n          -3.21099937e-01, -1.44567937e-01, -1.03540659e+00]],\\n\\n        [[ 4.03352082e-01,  2.24167913e-01,  8.58936906e-02, ...,\\n           2.06499338e-01,  2.09988624e-01, -3.72576624e-01],\\n         [-6.21268824e-02,  4.04966593e-01, -2.90069312e-01, ...,\\n           1.64702326e-01, -4.04034793e-01,  2.74275020e-02],\\n         [ 1.97760671e-01, -1.14499234e-01, -1.75282449e-01, ...,\\n          -6.41349018e-01, -1.14581847e+00, -3.08733165e-01],\\n         ...,\\n         [ 4.48394477e-01, -1.42384619e-01, -5.99928498e-01, ...,\\n          -1.06355131e+00, -4.70424086e-01, -2.51730502e-01],\\n         [-3.39026861e-02, -9.84218478e-01, -4.17112142e-01, ...,\\n          -3.20503950e-01,  1.74953669e-01, -6.72448575e-01],\\n         [-1.11202829e-01, -2.90144384e-01,  5.95982015e-01, ...,\\n          -6.80092931e-01, -6.64290786e-01, -1.51190430e-01]]]],\\n      dtype=float32) - array([[[[ 5.23679316e-01,  5.82584023e-01,  5.91605067e-01, ...,\\n           7.06130862e-01,  6.21283591e-01,  1.00129676e+00],\\n         [-2.69167334e-01,  3.46153140e-01,  1.77420706e-01, ...,\\n          -1.21162280e-01, -3.65549549e-02,  7.43805528e-01],\\n         [ 4.73670512e-01,  2.69724816e-01, -8.56547877e-02, ...,\\n          -3.43913019e-01, -3.01579148e-01,  4.25172113e-02],\\n         ...,\\n         [ 7.21747875e-01, -7.32133761e-02,  8.79364192e-01, ...,\\n          -3.91460955e-03, -3.66159797e-01, -3.63300890e-01],\\n         [ 7.58253783e-02, -3.53973508e-01, -2.71131605e-01, ...,\\n           9.80640829e-01,  5.12130558e-01,  5.92080414e-01],\\n         [ 5.50246775e-01,  5.76834381e-01,  2.94245124e-01, ...,\\n           3.27713460e-01,  1.49979666e-02,  5.81579246e-02]],\\n\\n        [[-5.25224566e-01, -6.38858676e-02, -1.59413546e-01, ...,\\n           1.53699294e-01, -7.61453658e-02,  1.21483892e-01],\\n         [ 3.77760410e-01,  4.06834841e-01,  9.89006400e-01, ...,\\n          -4.74781811e-01,  7.41527021e-01,  6.24601424e-01],\\n         [ 4.86530811e-01,  4.86754090e-01,  5.70856750e-01, ...,\\n           2.09926113e-01,  9.75390673e-01,  6.01741135e-01],\\n         ...,\\n         [ 3.805...   ...,\\n         [-5.51339686e-01, -6.40662134e-01, -2.13818699e-02, ...,\\n          -9.03686464e-01, -6.49750113e-01, -7.03504145e-01],\\n         [-1.08455586e+00, -4.11900491e-01,  4.58310604e-01, ...,\\n          -1.07442759e-01, -2.40667641e-01, -9.63293195e-01],\\n         [-4.24006999e-01, -1.09072244e+00, -4.33448255e-01, ...,\\n          -9.03708458e-01, -2.35029429e-01, -2.87531853e-01]],\\n\\n        [[ 2.47564733e-01, -7.23834932e-01,  3.97465259e-01, ...,\\n           2.24675238e-01,  7.99378604e-02,  1.21958829e-01],\\n         [ 2.62586266e-01, -4.97562826e-01, -1.72811806e-01, ...,\\n          -2.27830708e-01, -4.06945795e-01, -1.14899732e-01],\\n         [-5.91269583e-02, -6.40348792e-01,  1.44862413e-01, ...,\\n          -2.29941875e-01, -1.99108243e-01,  1.54250115e-01],\\n         ...,\\n         [ 5.01843750e-01, -1.84037313e-02, -4.58208978e-01, ...,\\n           2.46519953e-01, -8.28511119e-01, -7.28213340e-02],\\n         [ 3.11642110e-01, -2.60093689e-01, -2.57699311e-01, ...,\\n          -3.42586815e-01, -1.09993303e+00, -4.01190341e-01],\\n         [-2.69828975e-01, -3.85661572e-01, -3.80432010e-02, ...,\\n          -5.01784384e-01,  5.03717601e-01, -2.21028656e-01]]]],\\n      dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78de681e28f0> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 2.58434892e-01,  7.28128493e-01,  4.80445355e-01, ...,\\n           5.36917210e-01,  5.05219340e-01,  4.01308358e-01],\\n         [ 1.01901281e+00, -3.49450231e-01,  9.77876127e-01, ...,\\n          -3.07390541e-01, -5.58665514e-01, -1.05138533e-01],\\n         [ 9.03846502e-01, -6.18082508e-02, -5.72444737e-01, ...,\\n          -3.77199389e-02, -7.11712241e-02,  4.46973711e-01],\\n         ...,\\n         [ 6.83595955e-01,  3.38825613e-01,  1.18643314e-01, ...,\\n          -4.41742688e-01, -3.45223069e-01, -2.79511362e-02],\\n         [ 6.65733397e-01, -8.91723484e-03,  2.64310181e-01, ...,\\n           5.33751585e-02,  1.66198984e-01, -2.67285910e-02],\\n         [ 2.66516834e-01, -4.90741938e-01, -6.25833690e-01, ...,\\n           4.51264948e-01,  4.08310562e-01, -1.86072029e-02]],\\n\\n        [[ 8.31717998e-02,  1.90630481e-01, -8.33328217e-02, ...,\\n           8.02566111e-02,  7.20171750e-01, -2.10481972e-01],\\n         [ 2.00627074e-02,  6.26266122e-01, -3.51569295e-01, ...,\\n           3.95451367e-01,  2.92020738e-01, -3.66022915e-01],\\n         [-1.62807152e-01,  9.93413627e-02,  2.64848322e-01, ...,\\n           5.63911200e-01,  8.09847653e-01,  8.89805317e-01],\\n         ...,\\n         [-1.540...   ...,\\n         [-6.20422184e-01,  2.29914367e-01, -7.18901217e-01, ...,\\n          -1.74811363e-01, -1.85915041e+00, -5.07850051e-01],\\n         [-1.09314394e+00,  2.05168664e-01, -1.67571992e-01, ...,\\n           1.28321946e-01, -3.37294638e-01, -7.57337868e-01],\\n         [-8.08237016e-01, -5.82323611e-01, -4.39341739e-03, ...,\\n          -3.21099937e-01, -1.44567937e-01, -1.03540659e+00]],\\n\\n        [[ 4.03352082e-01,  2.24167913e-01,  8.58936906e-02, ...,\\n           2.06499338e-01,  2.09988624e-01, -3.72576624e-01],\\n         [-6.21268824e-02,  4.04966593e-01, -2.90069312e-01, ...,\\n           1.64702326e-01, -4.04034793e-01,  2.74275020e-02],\\n         [ 1.97760671e-01, -1.14499234e-01, -1.75282449e-01, ...,\\n          -6.41349018e-01, -1.14581847e+00, -3.08733165e-01],\\n         ...,\\n         [ 4.48394477e-01, -1.42384619e-01, -5.99928498e-01, ...,\\n          -1.06355131e+00, -4.70424086e-01, -2.51730502e-01],\\n         [-3.39026861e-02, -9.84218478e-01, -4.17112142e-01, ...,\\n          -3.20503950e-01,  1.74953669e-01, -6.72448575e-01],\\n         [-1.11202829e-01, -2.90144384e-01,  5.95982015e-01, ...,\\n          -6.80092931e-01, -6.64290786e-01, -1.51190430e-01]]]],\\n      dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where numpy = NDArray([[[[ 2.58434892e-01  7.28128493e-01  4.80445355e-01 ...  5.36917210e-01\\n     5.05219340e-01  4.01308358e-01]\\n   [ 1.01901281e+00 -3.49450231e-01  9.77876127e-01 ... -3.07390541e-01\\n    -5.58665514e-01 -1.05138533e-01]\\n   [ 9.03846502e-01 -6.18082508e-02 -5.72444737e-01 ... -3.77199389e-02\\n    -7.11712241e-02  4.46973711e-01]\\n   ...\\n   [ 6.83595955e-01  3.38825613e-01  1.18643314e-01 ... -4.41742688e-01\\n    -3.45223069e-01 -2.79511362e-02]\\n   [ 6.65733397e-01 -8.91723484e-03  2.64310181e-01 ...  5.33751585e-02\\n     1.66198984e-01 -2.67285910e-02]\\n   [ 2.66516834e-01 -4.90741938e-01 -6.25833690e-01 ...  4.51264948e-01\\n     4.08310562e-01 -1.86072029e-02]]\\n\\n  [[ 8.31717998e-02  1.90630481e-01 -8.33328217e-02 ...  8.02566111e-02\\n     7.20171750e-01 -2.10481972e-01]\\n   [ 2.00627074e-02  6.26266122e-01 -3.51569295e-01 ...  3.95451367e-01\\n     2.92020738e-01 -3.66022915e-01]\\n   [-1.62807152e-01  9.93413627e-02  2.64848322e-01 ...  5.63911200e-01\\n     8.09847653e-01  8.89805317e-01]\\n   ...\\n   [-1.54051870e-01  4.84474152e-01  4.48876858e-01 ...  5.08048654e-01\\n     1.42523035e-01  1.49878192e+00]\\n   [ 3.45937073e-01 -2.04177707e-01  4.05486137e-01 ...  3.81733060e-01\\n     2.99720...1 -4.55172926e-01 ...  3.46784294e-02\\n    -8.27614844e-01 -3.14003855e-01]\\n   [-1.25105590e-01 -6.77775681e-01 -7.93328047e-01 ... -2.77488410e-01\\n    -2.70667344e-01 -3.13808441e-01]\\n   ...\\n   [-6.20422184e-01  2.29914367e-01 -7.18901217e-01 ... -1.74811363e-01\\n    -1.85915041e+00 -5.07850051e-01]\\n   [-1.09314394e+00  2.05168664e-01 -1.67571992e-01 ...  1.28321946e-01\\n    -3.37294638e-01 -7.57337868e-01]\\n   [-8.08237016e-01 -5.82323611e-01 -4.39341739e-03 ... -3.21099937e-01\\n    -1.44567937e-01 -1.03540659e+00]]\\n\\n  [[ 4.03352082e-01  2.24167913e-01  8.58936906e-02 ...  2.06499338e-01\\n     2.09988624e-01 -3.72576624e-01]\\n   [-6.21268824e-02  4.04966593e-01 -2.90069312e-01 ...  1.64702326e-01\\n    -4.04034793e-01  2.74275020e-02]\\n   [ 1.97760671e-01 -1.14499234e-01 -1.75282449e-01 ... -6.41349018e-01\\n    -1.14581847e+00 -3.08733165e-01]\\n   ...\\n   [ 4.48394477e-01 -1.42384619e-01 -5.99928498e-01 ... -1.06355131e+00\\n    -4.70424086e-01 -2.51730502e-01]\\n   [-3.39026861e-02 -9.84218478e-01 -4.17112142e-01 ... -3.20503950e-01\\n     1.74953669e-01 -6.72448575e-01]\\n   [-1.11202829e-01 -2.90144384e-01  5.95982015e-01 ... -6.80092931e-01\\n    -6.64290786e-01 -1.51190430e-01]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where NDArray([[[[ 2.58434892e-01  7.28128493e-01  4.80445355e-01 ...  5.36917210e-01\\n     5.05219340e-01  4.01308358e-01]\\n   [ 1.01901281e+00 -3.49450231e-01  9.77876127e-01 ... -3.07390541e-01\\n    -5.58665514e-01 -1.05138533e-01]\\n   [ 9.03846502e-01 -6.18082508e-02 -5.72444737e-01 ... -3.77199389e-02\\n    -7.11712241e-02  4.46973711e-01]\\n   ...\\n   [ 6.83595955e-01  3.38825613e-01  1.18643314e-01 ... -4.41742688e-01\\n    -3.45223069e-01 -2.79511362e-02]\\n   [ 6.65733397e-01 -8.91723484e-03  2.64310181e-01 ...  5.33751585e-02\\n     1.66198984e-01 -2.67285910e-02]\\n   [ 2.66516834e-01 -4.90741938e-01 -6.25833690e-01 ...  4.51264948e-01\\n     4.08310562e-01 -1.86072029e-02]]\\n\\n  [[ 8.31717998e-02  1.90630481e-01 -8.33328217e-02 ...  8.02566111e-02\\n     7.20171750e-01 -2.10481972e-01]\\n   [ 2.00627074e-02  6.26266122e-01 -3.51569295e-01 ...  3.95451367e-01\\n     2.92020738e-01 -3.66022915e-01]\\n   [-1.62807152e-01  9.93413627e-02  2.64848322e-01 ...  5.63911200e-01\\n     8.09847653e-01  8.89805317e-01]\\n   ...\\n   [-1.54051870e-01  4.84474152e-01  4.48876858e-01 ...  5.08048654e-01\\n     1.42523035e-01  1.49878192e+00]\\n   [ 3.45937073e-01 -2.04177707e-01  4.05486137e-01 ...  3.81733060e-01\\n     2.99720...1 -4.55172926e-01 ...  3.46784294e-02\\n    -8.27614844e-01 -3.14003855e-01]\\n   [-1.25105590e-01 -6.77775681e-01 -7.93328047e-01 ... -2.77488410e-01\\n    -2.70667344e-01 -3.13808441e-01]\\n   ...\\n   [-6.20422184e-01  2.29914367e-01 -7.18901217e-01 ... -1.74811363e-01\\n    -1.85915041e+00 -5.07850051e-01]\\n   [-1.09314394e+00  2.05168664e-01 -1.67571992e-01 ...  1.28321946e-01\\n    -3.37294638e-01 -7.57337868e-01]\\n   [-8.08237016e-01 -5.82323611e-01 -4.39341739e-03 ... -3.21099937e-01\\n    -1.44567937e-01 -1.03540659e+00]]\\n\\n  [[ 4.03352082e-01  2.24167913e-01  8.58936906e-02 ...  2.06499338e-01\\n     2.09988624e-01 -3.72576624e-01]\\n   [-6.21268824e-02  4.04966593e-01 -2.90069312e-01 ...  1.64702326e-01\\n    -4.04034793e-01  2.74275020e-02]\\n   [ 1.97760671e-01 -1.14499234e-01 -1.75282449e-01 ... -6.41349018e-01\\n    -1.14581847e+00 -3.08733165e-01]\\n   ...\\n   [ 4.48394477e-01 -1.42384619e-01 -5.99928498e-01 ... -1.06355131e+00\\n    -4.70424086e-01 -2.51730502e-01]\\n   [-3.39026861e-02 -9.84218478e-01 -4.17112142e-01 ... -3.20503950e-01\\n     1.74953669e-01 -6.72448575e-01]\\n   [-1.11202829e-01 -2.90144384e-01  5.95982015e-01 ... -6.80092931e-01\\n    -6.64290786e-01 -1.51190430e-01]]]], device=cuda()) = needle.Tensor([[[[ 2.58434892e-01  7.28128493e-01  4.80445355e-01 ...  5.36917210e-01\\n     5.05219340e-01  4.01308358e-01]\\n   [ 1.01901281e+00 -3.49450231e-01  9.77876127e-01 ... -3.07390541e-01\\n    -5.58665514e-01 -1.05138533e-01]\\n   [ 9.03846502e-01 -6.18082508e-02 -5.72444737e-01 ... -3.77199389e-02\\n    -7.11712241e-02  4.46973711e-01]\\n   ...\\n   [ 6.83595955e-01  3.38825613e-01  1.18643314e-01 ... -4.41742688e-01\\n    -3.45223069e-01 -2.79511362e-02]\\n   [ 6.65733397e-01 -8.91723484e-03  2.64310181e-01 ...  5.33751585e-02\\n     1.66198984e-01 -2.67285910e-02]\\n   [ 2.66516834e-01 -4.90741938e-01 -6.25833690e-01 ...  4.51264948e-01\\n     4.08310562e-01 -1.86072029e-02]]\\n\\n  [[ 8.31717998e-02  1.90630481e-01 -8.33328217e-02 ...  8.02566111e-02\\n     7.20171750e-01 -2.10481972e-01]\\n   [ 2.00627074e-02  6.26266122e-01 -3.51569295e-01 ...  3.95451367e-01\\n     2.92020738e-01 -3.66022915e-01]\\n   [-1.62807152e-01  9.93413627e-02  2.64848322e-01 ...  5.63911200e-01\\n     8.09847653e-01  8.89805317e-01]\\n   ...\\n   [-1.54051870e-01  4.84474152e-01  4.48876858e-01 ...  5.08048654e-01\\n     1.42523035e-01  1.49878192e+00]\\n   [ 3.45937073e-01 -2.04177707e-01  4.05486137e-01 ...  3.81733060e-01\\n     2... -5.58808982e-01 -4.55172926e-01 ...  3.46784294e-02\\n    -8.27614844e-01 -3.14003855e-01]\\n   [-1.25105590e-01 -6.77775681e-01 -7.93328047e-01 ... -2.77488410e-01\\n    -2.70667344e-01 -3.13808441e-01]\\n   ...\\n   [-6.20422184e-01  2.29914367e-01 -7.18901217e-01 ... -1.74811363e-01\\n    -1.85915041e+00 -5.07850051e-01]\\n   [-1.09314394e+00  2.05168664e-01 -1.67571992e-01 ...  1.28321946e-01\\n    -3.37294638e-01 -7.57337868e-01]\\n   [-8.08237016e-01 -5.82323611e-01 -4.39341739e-03 ... -3.21099937e-01\\n    -1.44567937e-01 -1.03540659e+00]]\\n\\n  [[ 4.03352082e-01  2.24167913e-01  8.58936906e-02 ...  2.06499338e-01\\n     2.09988624e-01 -3.72576624e-01]\\n   [-6.21268824e-02  4.04966593e-01 -2.90069312e-01 ...  1.64702326e-01\\n    -4.04034793e-01  2.74275020e-02]\\n   [ 1.97760671e-01 -1.14499234e-01 -1.75282449e-01 ... -6.41349018e-01\\n    -1.14581847e+00 -3.08733165e-01]\\n   ...\\n   [ 4.48394477e-01 -1.42384619e-01 -5.99928498e-01 ... -1.06355131e+00\\n    -4.70424086e-01 -2.51730502e-01]\\n   [-3.39026861e-02 -9.84218478e-01 -4.17112142e-01 ... -3.20503950e-01\\n     1.74953669e-01 -6.72448575e-01]\\n   [-1.11202829e-01 -2.90144384e-01  5.95982015e-01 ... -6.80092931e-01\\n    -6.64290786e-01 -1.51190430e-01]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where needle.Tensor([[[[ 2.58434892e-01  7.28128493e-01  4.80445355e-01 ...  5.36917210e-01\\n     5.05219340e-01  4.01308358e-01]\\n   [ 1.01901281e+00 -3.49450231e-01  9.77876127e-01 ... -3.07390541e-01\\n    -5.58665514e-01 -1.05138533e-01]\\n   [ 9.03846502e-01 -6.18082508e-02 -5.72444737e-01 ... -3.77199389e-02\\n    -7.11712241e-02  4.46973711e-01]\\n   ...\\n   [ 6.83595955e-01  3.38825613e-01  1.18643314e-01 ... -4.41742688e-01\\n    -3.45223069e-01 -2.79511362e-02]\\n   [ 6.65733397e-01 -8.91723484e-03  2.64310181e-01 ...  5.33751585e-02\\n     1.66198984e-01 -2.67285910e-02]\\n   [ 2.66516834e-01 -4.90741938e-01 -6.25833690e-01 ...  4.51264948e-01\\n     4.08310562e-01 -1.86072029e-02]]\\n\\n  [[ 8.31717998e-02  1.90630481e-01 -8.33328217e-02 ...  8.02566111e-02\\n     7.20171750e-01 -2.10481972e-01]\\n   [ 2.00627074e-02  6.26266122e-01 -3.51569295e-01 ...  3.95451367e-01\\n     2.92020738e-01 -3.66022915e-01]\\n   [-1.62807152e-01  9.93413627e-02  2.64848322e-01 ...  5.63911200e-01\\n     8.09847653e-01  8.89805317e-01]\\n   ...\\n   [-1.54051870e-01  4.84474152e-01  4.48876858e-01 ...  5.08048654e-01\\n     1.42523035e-01  1.49878192e+00]\\n   [ 3.45937073e-01 -2.04177707e-01  4.05486137e-01 ...  3.81733060e-01\\n     2... -5.58808982e-01 -4.55172926e-01 ...  3.46784294e-02\\n    -8.27614844e-01 -3.14003855e-01]\\n   [-1.25105590e-01 -6.77775681e-01 -7.93328047e-01 ... -2.77488410e-01\\n    -2.70667344e-01 -3.13808441e-01]\\n   ...\\n   [-6.20422184e-01  2.29914367e-01 -7.18901217e-01 ... -1.74811363e-01\\n    -1.85915041e+00 -5.07850051e-01]\\n   [-1.09314394e+00  2.05168664e-01 -1.67571992e-01 ...  1.28321946e-01\\n    -3.37294638e-01 -7.57337868e-01]\\n   [-8.08237016e-01 -5.82323611e-01 -4.39341739e-03 ... -3.21099937e-01\\n    -1.44567937e-01 -1.03540659e+00]]\\n\\n  [[ 4.03352082e-01  2.24167913e-01  8.58936906e-02 ...  2.06499338e-01\\n     2.09988624e-01 -3.72576624e-01]\\n   [-6.21268824e-02  4.04966593e-01 -2.90069312e-01 ...  1.64702326e-01\\n    -4.04034793e-01  2.74275020e-02]\\n   [ 1.97760671e-01 -1.14499234e-01 -1.75282449e-01 ... -6.41349018e-01\\n    -1.14581847e+00 -3.08733165e-01]\\n   ...\\n   [ 4.48394477e-01 -1.42384619e-01 -5.99928498e-01 ... -1.06355131e+00\\n    -4.70424086e-01 -2.51730502e-01]\\n   [-3.39026861e-02 -9.84218478e-01 -4.17112142e-01 ... -3.20503950e-01\\n     1.74953669e-01 -6.72448575e-01]\\n   [-1.11202829e-01 -2.90144384e-01  5.95982015e-01 ... -6.80092931e-01\\n    -6.64290786e-01 -1.51190430e-01]]]]) = <needle.nn.nn_conv.Conv object at 0x78dd70af02c0>(needle.Tensor([[[[7.51032293e-01 1.55977935e-01 4.26002383e-01 ... 8.66860926e-01\\n    8.16150725e-01 9.11450863e-01]\\n   [2.76337147e-01 3.69523555e-01 3.79893899e-01 ... 9.82247770e-01\\n    9.92667019e-01 1.18615516e-01]\\n   [9.38256145e-01 2.44569615e-01 4.58212256e-01 ... 9.55465913e-01\\n    5.98315954e-01 1.18916944e-01]\\n   ...\\n   [7.05306768e-01 3.65676343e-01 3.95410717e-01 ... 8.20462167e-01\\n    2.30773941e-01 3.25923949e-01]\\n   [7.08360255e-01 3.92758936e-01 2.92709395e-02 ... 5.61398745e-01\\n    7.13245988e-01 9.81864214e-01]\\n   [4.28198665e-01 8.81066620e-01 7.28101376e-03 ... 1.92320589e-02\\n    5.69872141e-01 2.94650257e-01]]\\n\\n  [[8.49028647e-01 6.32849634e-01 5.38877010e-01 ... 5.28081954e-01\\n    8.01273406e-01 5.02910614e-02]\\n   [4.20910150e-01 2.56975472e-01 2.66975909e-01 ... 3.62692922e-01\\n    7.76749671e-01 9.67005551e-01]\\n   [3.87567163e-01 6.86690032e-01 9.94901896e-01 ... 4.47322875e-01\\n    8.20734262e-01 9.23878312e-01]\\n   ...\\n   [2.39857987e-01 8.71297181e-01 3.46534163e-01 ... 7.99730122e-01\\n    1.62170872e-01 1.94574520e-01]\\n   [8.82035911e-01 9.38964903e-01 3.18471253e-01 ... 1.74082518e-01\\n    4.76540327e-01 1.73072264e-01]\\n   [4.62426394e-01 3.96819681e-01 4...4292269e-01\\n    6.71649516e-01 5.07325470e-01]\\n   [3.45140189e-01 8.96334499e-02 8.41704786e-01 ... 9.35227513e-01\\n    1.34437010e-01 8.15641165e-01]\\n   [3.23829204e-01 5.19954264e-01 6.69752419e-01 ... 5.14791787e-01\\n    1.93027958e-01 6.91878051e-02]\\n   ...\\n   [2.56760895e-01 5.18177569e-01 1.58639312e-01 ... 4.52608615e-01\\n    2.13869601e-01 5.23449540e-01]\\n   [2.21188918e-01 9.12276506e-01 6.43553495e-01 ... 6.07078016e-01\\n    6.63995385e-01 8.55302513e-01]\\n   [8.04294109e-01 4.07190830e-01 2.22389743e-01 ... 7.31954873e-01\\n    3.19931418e-01 9.35044050e-01]]\\n\\n  [[5.48553526e-01 2.27439925e-01 2.32894808e-01 ... 7.19932437e-01\\n    7.64594615e-01 1.77171946e-01]\\n   [9.27534699e-01 3.58361691e-01 2.34949797e-01 ... 3.55137050e-01\\n    2.69719988e-01 9.61764574e-01]\\n   [8.61650407e-01 5.33731639e-01 8.32363725e-01 ... 3.21728408e-01\\n    9.25663114e-01 5.37845492e-01]\\n   ...\\n   [3.98562610e-01 7.63842106e-01 6.98767483e-01 ... 7.27313384e-02\\n    5.16509473e-01 9.15419519e-01]\\n   [3.76324385e-01 4.17884946e-01 5.40873885e-01 ... 6.02395475e-01\\n    1.55160144e-01 2.56504536e-01]\\n   [4.68549311e-01 8.67467165e-01 2.42747739e-01 ... 7.15565860e-01\\n    5.56286812e-01 7.09560752e-01]]]]))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 5.23679316e-01,  5.82584023e-01,  5.91605067e-01, ...,\\n           7.06130862e-01,  6.21283591e-01,  1.00129676e+00],\\n         [-2.69167334e-01,  3.46153140e-01,  1.77420706e-01, ...,\\n          -1.21162280e-01, -3.65549549e-02,  7.43805528e-01],\\n         [ 4.73670512e-01,  2.69724816e-01, -8.56547877e-02, ...,\\n          -3.43913019e-01, -3.01579148e-01,  4.25172113e-02],\\n         ...,\\n         [ 7.21747875e-01, -7.32133761e-02,  8.79364192e-01, ...,\\n          -3.91460955e-03, -3.66159797e-01, -3.63300890e-01],\\n         [ 7.58253783e-02, -3.53973508e-01, -2.71131605e-01, ...,\\n           9.80640829e-01,  5.12130558e-01,  5.92080414e-01],\\n         [ 5.50246775e-01,  5.76834381e-01,  2.94245124e-01, ...,\\n           3.27713460e-01,  1.49979666e-02,  5.81579246e-02]],\\n\\n        [[-5.25224566e-01, -6.38858676e-02, -1.59413546e-01, ...,\\n           1.53699294e-01, -7.61453658e-02,  1.21483892e-01],\\n         [ 3.77760410e-01,  4.06834841e-01,  9.89006400e-01, ...,\\n          -4.74781811e-01,  7.41527021e-01,  6.24601424e-01],\\n         [ 4.86530811e-01,  4.86754090e-01,  5.70856750e-01, ...,\\n           2.09926113e-01,  9.75390673e-01,  6.01741135e-01],\\n         ...,\\n         [ 3.805...   ...,\\n         [-5.51339686e-01, -6.40662134e-01, -2.13818699e-02, ...,\\n          -9.03686464e-01, -6.49750113e-01, -7.03504145e-01],\\n         [-1.08455586e+00, -4.11900491e-01,  4.58310604e-01, ...,\\n          -1.07442759e-01, -2.40667641e-01, -9.63293195e-01],\\n         [-4.24006999e-01, -1.09072244e+00, -4.33448255e-01, ...,\\n          -9.03708458e-01, -2.35029429e-01, -2.87531853e-01]],\\n\\n        [[ 2.47564733e-01, -7.23834932e-01,  3.97465259e-01, ...,\\n           2.24675238e-01,  7.99378604e-02,  1.21958829e-01],\\n         [ 2.62586266e-01, -4.97562826e-01, -1.72811806e-01, ...,\\n          -2.27830708e-01, -4.06945795e-01, -1.14899732e-01],\\n         [-5.91269583e-02, -6.40348792e-01,  1.44862413e-01, ...,\\n          -2.29941875e-01, -1.99108243e-01,  1.54250115e-01],\\n         ...,\\n         [ 5.01843750e-01, -1.84037313e-02, -4.58208978e-01, ...,\\n           2.46519953e-01, -8.28511119e-01, -7.28213340e-02],\\n         [ 3.11642110e-01, -2.60093689e-01, -2.57699311e-01, ...,\\n          -3.42586815e-01, -1.09993303e+00, -4.01190341e-01],\\n         [-2.69828975e-01, -3.85661572e-01, -3.80432010e-02, ...,\\n          -5.01784384e-01,  5.03717601e-01, -2.21028656e-01]]]],\\n      dtype=float32) = <built-in method numpy of Tensor object at 0x78dd757e3750>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x78dd757e3750> = tensor([[[[ 5.2368e-01,  5.8258e-01,  5.9161e-01,  ...,  7.0613e-01,\\n            6.2128e-01,  1.0013e+00],\\n          [-2.6917e-01,  3.4615e-01,  1.7742e-01,  ..., -1.2116e-01,\\n           -3.6555e-02,  7.4381e-01],\\n          [ 4.7367e-01,  2.6972e-01, -8.5655e-02,  ..., -3.4391e-01,\\n           -3.0158e-01,  4.2517e-02],\\n          ...,\\n          [ 7.2175e-01, -7.3213e-02,  8.7936e-01,  ..., -3.9146e-03,\\n           -3.6616e-01, -3.6330e-01],\\n          [ 7.5825e-02, -3.5397e-01, -2.7113e-01,  ...,  9.8064e-01,\\n            5.1213e-01,  5.9208e-01],\\n          [ 5.5025e-01,  5.7683e-01,  2.9425e-01,  ...,  3.2771e-01,\\n            1.4998e-02,  5.8158e-02]],\\n\\n         [[-5.2522e-01, -6.3886e-02, -1.5941e-01,  ...,  1.5370e-01,\\n           -7.6145e-02,  1.2148e-01],\\n          [ 3.7776e-01,  4.0683e-01,  9.8901e-01,  ..., -4.7478e-01,\\n            7.4153e-01,  6.2460e-01],\\n          [ 4.8653e-01,  4.8675e-01,  5.7086e-01,  ...,  2.0993e-01,\\n            9.7539e-01,  6.0174e-01],\\n          ...,\\n          [ 3.8058e-02,  1.2553e-01,  6.6266e-01,  ..., -1.0945e-01,\\n           -3.1587e-01,  4.5346e-01],\\n          [ 4.5156e-01, -1.9887e-01,  2.1838e-01,  ...,  2.6799e-01,\\n           -1.9396e-01,  5....3.8195e-01, -1.2974e+00, -1.9437e-01,  ..., -3.9380e-01,\\n           -1.7441e-01, -1.0257e-01],\\n          [-1.0668e+00, -4.8148e-01, -2.8766e-01,  ..., -8.5505e-01,\\n            8.5678e-02, -2.5488e-01],\\n          ...,\\n          [-5.5134e-01, -6.4066e-01, -2.1382e-02,  ..., -9.0369e-01,\\n           -6.4975e-01, -7.0350e-01],\\n          [-1.0846e+00, -4.1190e-01,  4.5831e-01,  ..., -1.0744e-01,\\n           -2.4067e-01, -9.6329e-01],\\n          [-4.2401e-01, -1.0907e+00, -4.3345e-01,  ..., -9.0371e-01,\\n           -2.3503e-01, -2.8753e-01]],\\n\\n         [[ 2.4756e-01, -7.2383e-01,  3.9747e-01,  ...,  2.2468e-01,\\n            7.9938e-02,  1.2196e-01],\\n          [ 2.6259e-01, -4.9756e-01, -1.7281e-01,  ..., -2.2783e-01,\\n           -4.0695e-01, -1.1490e-01],\\n          [-5.9127e-02, -6.4035e-01,  1.4486e-01,  ..., -2.2994e-01,\\n           -1.9911e-01,  1.5425e-01],\\n          ...,\\n          [ 5.0184e-01, -1.8404e-02, -4.5821e-01,  ...,  2.4652e-01,\\n           -8.2851e-01, -7.2821e-02],\\n          [ 3.1164e-01, -2.6009e-01, -2.5770e-01,  ..., -3.4259e-01,\\n           -1.0999e+00, -4.0119e-01],\\n          [-2.6983e-01, -3.8566e-01, -3.8043e-02,  ..., -5.0178e-01,\\n            5.0372e-01, -2.2103e-01]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[ 5.2368e-01,  5.8258e-01,  5.9161e-01,  ...,  7.0613e-01,\\n            6.2128e-01,  1.0013e+00],\\n          [-2.6917e-01,  3.4615e-01,  1.7742e-01,  ..., -1.2116e-01,\\n           -3.6555e-02,  7.4381e-01],\\n          [ 4.7367e-01,  2.6972e-01, -8.5655e-02,  ..., -3.4391e-01,\\n           -3.0158e-01,  4.2517e-02],\\n          ...,\\n          [ 7.2175e-01, -7.3213e-02,  8.7936e-01,  ..., -3.9146e-03,\\n           -3.6616e-01, -3.6330e-01],\\n          [ 7.5825e-02, -3.5397e-01, -2.7113e-01,  ...,  9.8064e-01,\\n            5.1213e-01,  5.9208e-01],\\n          [ 5.5025e-01,  5.7683e-01,  2.9425e-01,  ...,  3.2771e-01,\\n            1.4998e-02,  5.8158e-02]],\\n\\n         [[-5.2522e-01, -6.3886e-02, -1.5941e-01,  ...,  1.5370e-01,\\n           -7.6145e-02,  1.2148e-01],\\n          [ 3.7776e-01,  4.0683e-01,  9.8901e-01,  ..., -4.7478e-01,\\n            7.4153e-01,  6.2460e-01],\\n          [ 4.8653e-01,  4.8675e-01,  5.7086e-01,  ...,  2.0993e-01,\\n            9.7539e-01,  6.0174e-01],\\n          ...,\\n          [ 3.8058e-02,  1.2553e-01,  6.6266e-01,  ..., -1.0945e-01,\\n           -3.1587e-01,  4.5346e-01],\\n          [ 4.5156e-01, -1.9887e-01,  2.1838e-01,  ...,  2.6799e-01,\\n           -1.9396e-01,  5....3.8195e-01, -1.2974e+00, -1.9437e-01,  ..., -3.9380e-01,\\n           -1.7441e-01, -1.0257e-01],\\n          [-1.0668e+00, -4.8148e-01, -2.8766e-01,  ..., -8.5505e-01,\\n            8.5678e-02, -2.5488e-01],\\n          ...,\\n          [-5.5134e-01, -6.4066e-01, -2.1382e-02,  ..., -9.0369e-01,\\n           -6.4975e-01, -7.0350e-01],\\n          [-1.0846e+00, -4.1190e-01,  4.5831e-01,  ..., -1.0744e-01,\\n           -2.4067e-01, -9.6329e-01],\\n          [-4.2401e-01, -1.0907e+00, -4.3345e-01,  ..., -9.0371e-01,\\n           -2.3503e-01, -2.8753e-01]],\\n\\n         [[ 2.4756e-01, -7.2383e-01,  3.9747e-01,  ...,  2.2468e-01,\\n            7.9938e-02,  1.2196e-01],\\n          [ 2.6259e-01, -4.9756e-01, -1.7281e-01,  ..., -2.2783e-01,\\n           -4.0695e-01, -1.1490e-01],\\n          [-5.9127e-02, -6.4035e-01,  1.4486e-01,  ..., -2.2994e-01,\\n           -1.9911e-01,  1.5425e-01],\\n          ...,\\n          [ 5.0184e-01, -1.8404e-02, -4.5821e-01,  ...,  2.4652e-01,\\n           -8.2851e-01, -7.2821e-02],\\n          [ 3.1164e-01, -2.6009e-01, -2.5770e-01,  ..., -3.4259e-01,\\n           -1.0999e+00, -4.0119e-01],\\n          [-2.6983e-01, -3.8566e-01, -3.8043e-02,  ..., -5.0178e-01,\\n            5.0372e-01, -2.2103e-01]]]]) = tensor([[[[ 5.2368e-01,  5.8258e-01,  5.9161e-01,  ...,  7.0613e-01,\\n            6.2128e-01,  1.0013e+00],\\n          [-2.6917e-01,  3.4615e-01,  1.7742e-01,  ..., -1.2116e-01,\\n           -3.6555e-02,  7.4381e-01],\\n          [ 4.7367e-01,  2.6972e-01, -8.5655e-02,  ..., -3.4391e-01,\\n           -3.0158e-01,  4.2517e-02],\\n          ...,\\n          [ 7.2175e-01, -7.3213e-02,  8.7936e-01,  ..., -3.9146e-03,\\n           -3.6616e-01, -3.6330e-01],\\n          [ 7.5825e-02, -3.5397e-01, -2.7113e-01,  ...,  9.8064e-01,\\n            5.1213e-01,  5.9208e-01],\\n          [ 5.5025e-01,  5.7683e-01,  2.9425e-01,  ...,  3.2771e-01,\\n            1.4998e-02,  5.8158e-02]],\\n\\n         [[-5.2522e-01, -6.3886e-02, -1.5941e-01,  ...,  1.5370e-01,\\n           -7.6145e-02,  1.2148e-01],\\n          [ 3.7776e-01,  4.0683e-01,  9.8901e-01,  ..., -4.7478e-01,\\n            7.4153e-01,  6.2460e-01],\\n          [ 4.8653e-01,  4.8675e-01,  5.7086e-01,  ...,  2.0993e-01,\\n            9.7539e-01,  6.0174e-01],\\n          ...,\\n          [ 3.8058e-02,  1.2553e-01,  6.6266e-01,  ..., -1.0945e-01,\\n           -3.1587e-01,  4.5346e-01],\\n          [ 4.5156e-01, -1.9887e-01,  2.1838e-01,  ...,  2.6799e-01,\\n           -1.9396e-01,  5....e-01,  ..., -3.9380e-01,\\n           -1.7441e-01, -1.0257e-01],\\n          [-1.0668e+00, -4.8148e-01, -2.8766e-01,  ..., -8.5505e-01,\\n            8.5678e-02, -2.5488e-01],\\n          ...,\\n          [-5.5134e-01, -6.4066e-01, -2.1382e-02,  ..., -9.0369e-01,\\n           -6.4975e-01, -7.0350e-01],\\n          [-1.0846e+00, -4.1190e-01,  4.5831e-01,  ..., -1.0744e-01,\\n           -2.4067e-01, -9.6329e-01],\\n          [-4.2401e-01, -1.0907e+00, -4.3345e-01,  ..., -9.0371e-01,\\n           -2.3503e-01, -2.8753e-01]],\\n\\n         [[ 2.4756e-01, -7.2383e-01,  3.9747e-01,  ...,  2.2468e-01,\\n            7.9938e-02,  1.2196e-01],\\n          [ 2.6259e-01, -4.9756e-01, -1.7281e-01,  ..., -2.2783e-01,\\n           -4.0695e-01, -1.1490e-01],\\n          [-5.9127e-02, -6.4035e-01,  1.4486e-01,  ..., -2.2994e-01,\\n           -1.9911e-01,  1.5425e-01],\\n          ...,\\n          [ 5.0184e-01, -1.8404e-02, -4.5821e-01,  ...,  2.4652e-01,\\n           -8.2851e-01, -7.2821e-02],\\n          [ 3.1164e-01, -2.6009e-01, -2.5770e-01,  ..., -3.4259e-01,\\n           -1.0999e+00, -4.0119e-01],\\n          [-2.6983e-01, -3.8566e-01, -3.8043e-02,  ..., -5.0178e-01,\\n            5.0372e-01, -2.2103e-01]]]], grad_fn=<ConvolutionBackward0>).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[ 5.2368e-01,  5.8258e-01,  5.9161e-01,  ...,  7.0613e-01,\\n            6.2128e-01,  1.0013e+00],\\n          [-2.6917e-01,  3.4615e-01,  1.7742e-01,  ..., -1.2116e-01,\\n           -3.6555e-02,  7.4381e-01],\\n          [ 4.7367e-01,  2.6972e-01, -8.5655e-02,  ..., -3.4391e-01,\\n           -3.0158e-01,  4.2517e-02],\\n          ...,\\n          [ 7.2175e-01, -7.3213e-02,  8.7936e-01,  ..., -3.9146e-03,\\n           -3.6616e-01, -3.6330e-01],\\n          [ 7.5825e-02, -3.5397e-01, -2.7113e-01,  ...,  9.8064e-01,\\n            5.1213e-01,  5.9208e-01],\\n          [ 5.5025e-01,  5.7683e-01,  2.9425e-01,  ...,  3.2771e-01,\\n            1.4998e-02,  5.8158e-02]],\\n\\n         [[-5.2522e-01, -6.3886e-02, -1.5941e-01,  ...,  1.5370e-01,\\n           -7.6145e-02,  1.2148e-01],\\n          [ 3.7776e-01,  4.0683e-01,  9.8901e-01,  ..., -4.7478e-01,\\n            7.4153e-01,  6.2460e-01],\\n          [ 4.8653e-01,  4.8675e-01,  5.7086e-01,  ...,  2.0993e-01,\\n            9.7539e-01,  6.0174e-01],\\n          ...,\\n          [ 3.8058e-02,  1.2553e-01,  6.6266e-01,  ..., -1.0945e-01,\\n           -3.1587e-01,  4.5346e-01],\\n          [ 4.5156e-01, -1.9887e-01,  2.1838e-01,  ...,  2.6799e-01,\\n           -1.9396e-01,  5....e-01,  ..., -3.9380e-01,\\n           -1.7441e-01, -1.0257e-01],\\n          [-1.0668e+00, -4.8148e-01, -2.8766e-01,  ..., -8.5505e-01,\\n            8.5678e-02, -2.5488e-01],\\n          ...,\\n          [-5.5134e-01, -6.4066e-01, -2.1382e-02,  ..., -9.0369e-01,\\n           -6.4975e-01, -7.0350e-01],\\n          [-1.0846e+00, -4.1190e-01,  4.5831e-01,  ..., -1.0744e-01,\\n           -2.4067e-01, -9.6329e-01],\\n          [-4.2401e-01, -1.0907e+00, -4.3345e-01,  ..., -9.0371e-01,\\n           -2.3503e-01, -2.8753e-01]],\\n\\n         [[ 2.4756e-01, -7.2383e-01,  3.9747e-01,  ...,  2.2468e-01,\\n            7.9938e-02,  1.2196e-01],\\n          [ 2.6259e-01, -4.9756e-01, -1.7281e-01,  ..., -2.2783e-01,\\n           -4.0695e-01, -1.1490e-01],\\n          [-5.9127e-02, -6.4035e-01,  1.4486e-01,  ..., -2.2994e-01,\\n           -1.9911e-01,  1.5425e-01],\\n          ...,\\n          [ 5.0184e-01, -1.8404e-02, -4.5821e-01,  ...,  2.4652e-01,\\n           -8.2851e-01, -7.2821e-02],\\n          [ 3.1164e-01, -2.6009e-01, -2.5770e-01,  ..., -3.4259e-01,\\n           -1.0999e+00, -4.0119e-01],\\n          [-2.6983e-01, -3.8566e-01, -3.8043e-02,  ..., -5.0178e-01,\\n            5.0372e-01, -2.2103e-01]]]], grad_fn=<ConvolutionBackward0>) = Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))(tensor([[[[7.5103e-01, 1.5598e-01, 4.2600e-01,  ..., 8.6686e-01,\\n           8.1615e-01, 9.1145e-01],\\n          [2.7634e-01, 3.6952e-01, 3.7989e-01,  ..., 9.8225e-01,\\n           9.9267e-01, 1.1862e-01],\\n          [9.3826e-01, 2.4457e-01, 4.5821e-01,  ..., 9.5547e-01,\\n           5.9832e-01, 1.1892e-01],\\n          ...,\\n          [7.0531e-01, 3.6568e-01, 3.9541e-01,  ..., 8.2046e-01,\\n           2.3077e-01, 3.2592e-01],\\n          [7.0836e-01, 3.9276e-01, 2.9271e-02,  ..., 5.6140e-01,\\n           7.1325e-01, 9.8186e-01],\\n          [4.2820e-01, 8.8107e-01, 7.2810e-03,  ..., 1.9232e-02,\\n           5.6987e-01, 2.9465e-01]],\\n\\n         [[8.4903e-01, 6.3285e-01, 5.3888e-01,  ..., 5.2808e-01,\\n           8.0127e-01, 5.0291e-02],\\n          [4.2091e-01, 2.5698e-01, 2.6698e-01,  ..., 3.6269e-01,\\n           7.7675e-01, 9.6701e-01],\\n          [3.8757e-01, 6.8669e-01, 9.9490e-01,  ..., 4.4732e-01,\\n           8.2073e-01, 9.2388e-01],\\n          ...,\\n          [2.3986e-01, 8.7130e-01, 3.4653e-01,  ..., 7.9973e-01,\\n           1.6217e-01, 1.9457e-01],\\n          [8.8204e-01, 9.3896e-01, 3.1847e-01,  ..., 1.7408e-01,\\n           4.7654e-01, 1.7307e-01],\\n          [4.6243e-01, 3.9682e-01, 4.3326e-01,  ..., 1.... ..., 2.3429e-01,\\n           6.7165e-01, 5.0733e-01],\\n          [3.4514e-01, 8.9633e-02, 8.4170e-01,  ..., 9.3523e-01,\\n           1.3444e-01, 8.1564e-01],\\n          [3.2383e-01, 5.1995e-01, 6.6975e-01,  ..., 5.1479e-01,\\n           1.9303e-01, 6.9188e-02],\\n          ...,\\n          [2.5676e-01, 5.1818e-01, 1.5864e-01,  ..., 4.5261e-01,\\n           2.1387e-01, 5.2345e-01],\\n          [2.2119e-01, 9.1228e-01, 6.4355e-01,  ..., 6.0708e-01,\\n           6.6400e-01, 8.5530e-01],\\n          [8.0429e-01, 4.0719e-01, 2.2239e-01,  ..., 7.3195e-01,\\n           3.1993e-01, 9.3504e-01]],\\n\\n         [[5.4855e-01, 2.2744e-01, 2.3289e-01,  ..., 7.1993e-01,\\n           7.6459e-01, 1.7717e-01],\\n          [9.2753e-01, 3.5836e-01, 2.3495e-01,  ..., 3.5514e-01,\\n           2.6972e-01, 9.6176e-01],\\n          [8.6165e-01, 5.3373e-01, 8.3236e-01,  ..., 3.2173e-01,\\n           9.2566e-01, 5.3785e-01],\\n          ...,\\n          [3.9856e-01, 7.6384e-01, 6.9877e-01,  ..., 7.2731e-02,\\n           5.1651e-01, 9.1542e-01],\\n          [3.7632e-01, 4.1788e-01, 5.4087e-01,  ..., 6.0240e-01,\\n           1.5516e-01, 2.5650e-01],\\n          [4.6855e-01, 8.6747e-01, 2.4275e-01,  ..., 7.1557e-01,\\n           5.5629e-01, 7.0956e-01]]]]))\u001b[0m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78dd70af02c0>\n",
            "g          = Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[7.51032293e-01 1.55977935e-01 4.26002383e-01 ... 8.66860926e-01\n",
            "    8.16150725e-01 9.11450863e-01]\n",
            " ...6504536e-01]\n",
            "   [4.68549311e-01 8.67467165e-01 2.42747739e-01 ... 7.15565860e-01\n",
            "    5.56286812e-01 7.09560752e-01]]]])\n",
            "z          = tensor([[[[7.5103e-01, 1.5598e-01, 4.2600e-01,  ..., 8.6686e-01,\n",
            "           8.1615e-01, 9.1145e-01],\n",
            "          [2.7634...1, 2.5650e-01],\n",
            "          [4.6855e-01, 8.6747e-01, 2.4275e-01,  ..., 7.1557e-01,\n",
            "           5.5629e-01, 7.0956e-01]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-4-8-16-3-1]\u001b[0m - AssertionError: assert np.float32(24.799076) < 0.001\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-16-3-2]\u001b[0m - AssertionError: assert np.float32(116.216415) < 0.001\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-8-3-2]\u001b[0m - AssertionError: assert np.float32(81.6244) < 0.001\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-1]\u001b[0m - AssertionError: assert np.float32(164.71808) < 0.001\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-2]\u001b[0m - AssertionError: assert np.float32(82.73932) < 0.001\n",
            "\u001b[31m================= \u001b[31m\u001b[1m5 failed\u001b[0m, \u001b[32m5 passed\u001b[0m, \u001b[33m1793 deselected\u001b[0m\u001b[31m in 3.35s\u001b[0m\u001b[31m =================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"nn_conv_forward\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "cGXgKEzqnJnq",
        "outputId": "d4171e8f-b19e-400f-9dfb-d2948c300dd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1789 deselected / 14 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-4-1-1-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-4-1-1-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-4-1-1-3-1] _\u001b[0m\n",
            "\n",
            "s = 4, cin = 1, cout = 1, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "        y1 = res1.sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y2 = g(z).sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y1.backward()\u001b[90m\u001b[39;49;00m\n",
            "        y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(g.weight.grad.data.numpy() - f.weight.grad.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)) < \u001b[94m1e-3\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight gradients match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: weight gradients match\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(2.8380766) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(2.8380766) = <function norm at 0x78322a53a730>((array([[[[4.6938353, 7.2512107, 5.610293 ],\\n         [6.054118 , 9.251414 , 7.1490173],\\n         [4.165454 , 6.437154 , 5.126481 ]]]], dtype=float32) - array([[[[4.6938353, 6.054118 , 4.165454 ],\\n         [7.25121  , 9.251414 , 6.4371533],\\n         [5.610293 , 7.1490173, 5.1264815]]]], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78322a53a730> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[4.6938353, 7.2512107, 5.610293 ],\\n         [6.054118 , 9.251414 , 7.1490173],\\n         [4.165454 , 6.437154 , 5.126481 ]]]], dtype=float32) = <built-in method numpy of Tensor object at 0x7831499e8140>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x7831499e8140> = tensor([[[[4.6938, 7.2512, 5.6103],\\n          [6.0541, 9.2514, 7.1490],\\n          [4.1655, 6.4372, 5.1265]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[4.6938, 7.2512, 5.6103],\\n          [6.0541, 9.2514, 7.1490],\\n          [4.1655, 6.4372, 5.1265]]]]) = tensor([[[[4.6938, 7.2512, 5.6103],\\n          [6.0541, 9.2514, 7.1490],\\n          [4.1655, 6.4372, 5.1265]]]]).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[4.6938, 7.2512, 5.6103],\\n          [6.0541, 9.2514, 7.1490],\\n          [4.1655, 6.4372, 5.1265]]]]) = Parameter containing:\\ntensor([[[[ 0.0797,  0.3514,  0.1678],\\n          [ 0.0733, -0.1247,  0.2382],\\n          [-0.1019,  0.6398,  0.7572]]]], requires_grad=True).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where Parameter containing:\\ntensor([[[[ 0.0797,  0.3514,  0.1678],\\n          [ 0.0733, -0.1247,  0.2382],\\n          [-0.1019,  0.6398,  0.7572]]]], requires_grad=True) = Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).weight\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[4.6938353, 6.054118 , 4.165454 ],\\n         [7.25121  , 9.251414 , 6.4371533],\\n         [5.610293 , 7.1490173, 5.1264815]]]], dtype=float32) = <built-in method transpose of numpy.ndarray object at 0x78314a4640f0>(3, 2, 0, 1)\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method transpose of numpy.ndarray object at 0x78314a4640f0> = array([[[[4.6938353]],\\n\\n        [[6.054118 ]],\\n\\n        [[4.165454 ]]],\\n\\n\\n       [[[7.25121  ]],\\n\\n        [[9.251414 ]],\\n\\n        [[6.4371533]]],\\n\\n\\n       [[[5.610293 ]],\\n\\n        [[7.1490173]],\\n\\n        [[5.1264815]]]], dtype=float32).transpose\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where array([[[[4.6938353]],\\n\\n        [[6.054118 ]],\\n\\n        [[4.165454 ]]],\\n\\n\\n       [[[7.25121  ]],\\n\\n        [[9.251414 ]],\\n\\n        [[6.4371533]]],\\n\\n\\n       [[[5.610293 ]],\\n\\n        [[7.1490173]],\\n\\n        [[5.1264815]]]], dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where numpy = NDArray([[[[4.6938353]]\\n\\n  [[6.054118 ]]\\n\\n  [[4.165454 ]]]\\n\\n\\n [[[7.25121  ]]\\n\\n  [[9.251414 ]]\\n\\n  [[6.4371533]]]\\n\\n\\n [[[5.610293 ]]\\n\\n  [[7.1490173]]\\n\\n  [[5.1264815]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where NDArray([[[[4.6938353]]\\n\\n  [[6.054118 ]]\\n\\n  [[4.165454 ]]]\\n\\n\\n [[[7.25121  ]]\\n\\n  [[9.251414 ]]\\n\\n  [[6.4371533]]]\\n\\n\\n [[[5.610293 ]]\\n\\n  [[7.1490173]]\\n\\n  [[5.1264815]]]], device=cuda()) = needle.Tensor([[[[4.6938353]]\\n\\n  [[6.054118 ]]\\n\\n  [[4.165454 ]]]\\n\\n\\n [[[7.25121  ]]\\n\\n  [[9.251414 ]]\\n\\n  [[6.4371533]]]\\n\\n\\n [[[5.610293 ]]\\n\\n  [[7.1490173]]\\n\\n  [[5.1264815]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +              where needle.Tensor([[[[4.6938353]]\\n\\n  [[6.054118 ]]\\n\\n  [[4.165454 ]]]\\n\\n\\n [[[7.25121  ]]\\n\\n  [[9.251414 ]]\\n\\n  [[6.4371533]]]\\n\\n\\n [[[5.610293 ]]\\n\\n  [[7.1490173]]\\n\\n  [[5.1264815]]]]) = needle.Tensor([[[[ 0.07971215]]\\n\\n  [[ 0.35140276]]\\n\\n  [[ 0.16781187]]]\\n\\n\\n [[[ 0.07329392]]\\n\\n  [[-0.12467122]]\\n\\n  [[ 0.23824406]]]\\n\\n\\n [[[-0.10191965]]\\n\\n  [[ 0.63976264]]\\n\\n  [[ 0.75715816]]]]).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +                where needle.Tensor([[[[ 0.07971215]]\\n\\n  [[ 0.35140276]]\\n\\n  [[ 0.16781187]]]\\n\\n\\n [[[ 0.07329392]]\\n\\n  [[-0.12467122]]\\n\\n  [[ 0.23824406]]]\\n\\n\\n [[[-0.10191965]]\\n\\n  [[ 0.63976264]]\\n\\n  [[ 0.75715816]]]]) = <needle.nn.nn_conv.Conv object at 0x78314a5bd100>.weight\u001b[0m\n",
            "\n",
            "cin        = 1\n",
            "cout       = 1\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78314a5bd100>\n",
            "g          = Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "res1       = needle.Tensor([[[[0.24485078 0.81743217 1.079137   0.3324774 ]\n",
            "   [0.54597163 1.0721371  1.0762972  0.08887224]\n",
            "   [1.279356   1.4567652  1.1845338  0.650854  ]\n",
            "   [0.20827112 0.29333463 0.4014943  0.02065782]]]])\n",
            "s          = 4\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.79172504 0.5288949  0.56804454 0.92559665]\n",
            "   [0.07103606 0.0871293  0.0202184  0.83261985]\n",
            "   [0.77815676 0.87001216 0.9786183  0.7991586 ]\n",
            "   [0.46147937 0.7805292  0.11827443 0.639921  ]]]])\n",
            "y1         = needle.Tensor([10.752442])\n",
            "y2         = tensor(11.1893, grad_fn=<SumBackward0>)\n",
            "z          = tensor([[[[0.7917, 0.5289, 0.5680, 0.9256],\n",
            "          [0.0710, 0.0871, 0.0202, 0.8326],\n",
            "          [0.7782, 0.8700, 0.9786, 0.7992],\n",
            "          [0.4615, 0.7805, 0.1183, 0.6399]]]], requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:391: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-1] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 16, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "        y1 = res1.sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y2 = g(z).sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y1.backward()\u001b[90m\u001b[39;49;00m\n",
            "        y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(g.weight.grad.data.numpy() - f.weight.grad.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)) < \u001b[94m1e-3\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight gradients match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: weight gradients match\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(176.62637) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(176.62637) = <function norm at 0x78322a53a730>((array([[[[ 91.87275 ,  98.36838 ,  91.74943 ],\\n         [ 97.95815 , 105.00204 ,  98.0872  ],\\n         [ 90.33907 ,  96.45755 ,  90.34141 ]],\\n\\n        [[ 88.054405,  96.02423 ,  90.19237 ],\\n         [ 96.063644, 104.99424 ,  98.29982 ],\\n         [ 88.76921 ,  97.18369 ,  91.03263 ]],\\n\\n        [[ 82.98829 ,  89.79989 ,  83.337875],\\n         [ 88.475   ,  95.59929 ,  88.8993  ],\\n         [ 82.98029 ,  89.775635,  83.71621 ]],\\n\\n        ...,\\n\\n        [[ 91.990425,  98.29538 ,  90.978264],\\n         [ 97.78013 , 104.70786 ,  96.89022 ],\\n         [ 91.57957 ,  97.77837 ,  90.80845 ]],\\n\\n        [[ 82.432755,  89.03777 ,  83.157135],\\n         [ 90.16655 ,  96.89195 ,  90.072235],\\n         [ 84.40859 ,  90.15921 ,  84.17772 ]],\\n\\n        [[ 89.35553 ,  96.77081 ,  90.46783 ],\\n         [ 96.130356, 104.01386 ,  96.90733 ],\\n         [ 88.28464 ,  95.314674,  88.89144 ]]],\\n\\n\\n       [[[ 91.87275 ,  98.36838 ,  91.74943 ],\\n         [ 97.95815 , 105.00204 ,  98.0872  ],\\n         [ 90.33907 ,  96.45755 ,  90.34141 ]],\\n\\n        [[ 88.054405,  96.02423 ,  90.19237 ],\\n         [ 96.063644, 104.99424 ,  98.29982 ],\\n         [ 88.76921 ,  97.18369 ,  91.03263 ]],\\n\\n        [[ 82.98829 ,  89.79989 ,  83.....77837 ,  90.80845 ]],\\n\\n        [[ 82.432755,  89.03777 ,  83.157135],\\n         [ 90.16655 ,  96.89195 ,  90.072235],\\n         [ 84.40859 ,  90.15921 ,  84.17772 ]],\\n\\n        [[ 89.35553 ,  96.77081 ,  90.46783 ],\\n         [ 96.130356, 104.01386 ,  96.90733 ],\\n         [ 88.28464 ,  95.314674,  88.89144 ]]],\\n\\n\\n       [[[ 91.87275 ,  98.36838 ,  91.74943 ],\\n         [ 97.95815 , 105.00204 ,  98.0872  ],\\n         [ 90.33907 ,  96.45755 ,  90.34141 ]],\\n\\n        [[ 88.054405,  96.02423 ,  90.19237 ],\\n         [ 96.063644, 104.99424 ,  98.29982 ],\\n         [ 88.76921 ,  97.18369 ,  91.03263 ]],\\n\\n        [[ 82.98829 ,  89.79989 ,  83.337875],\\n         [ 88.475   ,  95.59929 ,  88.8993  ],\\n         [ 82.98029 ,  89.775635,  83.71621 ]],\\n\\n        ...,\\n\\n        [[ 91.990425,  98.29538 ,  90.978264],\\n         [ 97.78013 , 104.70786 ,  96.89022 ],\\n         [ 91.57957 ,  97.77837 ,  90.80845 ]],\\n\\n        [[ 82.432755,  89.03777 ,  83.157135],\\n         [ 90.16655 ,  96.89195 ,  90.072235],\\n         [ 84.40859 ,  90.15921 ,  84.17772 ]],\\n\\n        [[ 89.35553 ,  96.77081 ,  90.46783 ],\\n         [ 96.130356, 104.01386 ,  96.90733 ],\\n         [ 88.28464 ,  95.314674,  88.89144 ]]]], dtype=float32) - array([[[[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        ...,\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]]],\\n\\n\\n       [[[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.....80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]]],\\n\\n\\n       [[[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        ...,\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]]]], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78322a53a730> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 91.87275 ,  98.36838 ,  91.74943 ],\\n         [ 97.95815 , 105.00204 ,  98.0872  ],\\n         [ 90.33907 ,  96.45755 ,  90.34141 ]],\\n\\n        [[ 88.054405,  96.02423 ,  90.19237 ],\\n         [ 96.063644, 104.99424 ,  98.29982 ],\\n         [ 88.76921 ,  97.18369 ,  91.03263 ]],\\n\\n        [[ 82.98829 ,  89.79989 ,  83.337875],\\n         [ 88.475   ,  95.59929 ,  88.8993  ],\\n         [ 82.98029 ,  89.775635,  83.71621 ]],\\n\\n        ...,\\n\\n        [[ 91.990425,  98.29538 ,  90.978264],\\n         [ 97.78013 , 104.70786 ,  96.89022 ],\\n         [ 91.57957 ,  97.77837 ,  90.80845 ]],\\n\\n        [[ 82.432755,  89.03777 ,  83.157135],\\n         [ 90.16655 ,  96.89195 ,  90.072235],\\n         [ 84.40859 ,  90.15921 ,  84.17772 ]],\\n\\n        [[ 89.35553 ,  96.77081 ,  90.46783 ],\\n         [ 96.130356, 104.01386 ,  96.90733 ],\\n         [ 88.28464 ,  95.314674,  88.89144 ]]],\\n\\n\\n       [[[ 91.87275 ,  98.36838 ,  91.74943 ],\\n         [ 97.95815 , 105.00204 ,  98.0872  ],\\n         [ 90.33907 ,  96.45755 ,  90.34141 ]],\\n\\n        [[ 88.054405,  96.02423 ,  90.19237 ],\\n         [ 96.063644, 104.99424 ,  98.29982 ],\\n         [ 88.76921 ,  97.18369 ,  91.03263 ]],\\n\\n        [[ 82.98829 ,  89.79989 ,  83.....77837 ,  90.80845 ]],\\n\\n        [[ 82.432755,  89.03777 ,  83.157135],\\n         [ 90.16655 ,  96.89195 ,  90.072235],\\n         [ 84.40859 ,  90.15921 ,  84.17772 ]],\\n\\n        [[ 89.35553 ,  96.77081 ,  90.46783 ],\\n         [ 96.130356, 104.01386 ,  96.90733 ],\\n         [ 88.28464 ,  95.314674,  88.89144 ]]],\\n\\n\\n       [[[ 91.87275 ,  98.36838 ,  91.74943 ],\\n         [ 97.95815 , 105.00204 ,  98.0872  ],\\n         [ 90.33907 ,  96.45755 ,  90.34141 ]],\\n\\n        [[ 88.054405,  96.02423 ,  90.19237 ],\\n         [ 96.063644, 104.99424 ,  98.29982 ],\\n         [ 88.76921 ,  97.18369 ,  91.03263 ]],\\n\\n        [[ 82.98829 ,  89.79989 ,  83.337875],\\n         [ 88.475   ,  95.59929 ,  88.8993  ],\\n         [ 82.98029 ,  89.775635,  83.71621 ]],\\n\\n        ...,\\n\\n        [[ 91.990425,  98.29538 ,  90.978264],\\n         [ 97.78013 , 104.70786 ,  96.89022 ],\\n         [ 91.57957 ,  97.77837 ,  90.80845 ]],\\n\\n        [[ 82.432755,  89.03777 ,  83.157135],\\n         [ 90.16655 ,  96.89195 ,  90.072235],\\n         [ 84.40859 ,  90.15921 ,  84.17772 ]],\\n\\n        [[ 89.35553 ,  96.77081 ,  90.46783 ],\\n         [ 96.130356, 104.01386 ,  96.90733 ],\\n         [ 88.28464 ,  95.314674,  88.89144 ]]]], dtype=float32) = <built-in method numpy of Tensor object at 0x7831499fc320>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x7831499fc320> = tensor([[[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]],\\n\\n\\n        [[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91...,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]],\\n\\n\\n        [[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]],\\n\\n\\n        [[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91...,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]],\\n\\n\\n        [[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]]]) = tensor([[[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]],\\n\\n\\n        [[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91...,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]],\\n\\n\\n        [[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]]]).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]],\\n\\n\\n        [[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91...,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]],\\n\\n\\n        [[[ 91.8727,  98.3684,  91.7494],\\n          [ 97.9582, 105.0020,  98.0872],\\n          [ 90.3391,  96.4576,  90.3414]],\\n\\n         [[ 88.0544,  96.0242,  90.1924],\\n          [ 96.0636, 104.9942,  98.2998],\\n          [ 88.7692,  97.1837,  91.0326]],\\n\\n         [[ 82.9883,  89.7999,  83.3379],\\n          [ 88.4750,  95.5993,  88.8993],\\n          [ 82.9803,  89.7756,  83.7162]],\\n\\n         ...,\\n\\n         [[ 91.9904,  98.2954,  90.9783],\\n          [ 97.7801, 104.7079,  96.8902],\\n          [ 91.5796,  97.7784,  90.8084]],\\n\\n         [[ 82.4328,  89.0378,  83.1571],\\n          [ 90.1665,  96.8920,  90.0722],\\n          [ 84.4086,  90.1592,  84.1777]],\\n\\n         [[ 89.3555,  96.7708,  90.4678],\\n          [ 96.1304, 104.0139,  96.9073],\\n          [ 88.2846,  95.3147,  88.8914]]]]) = Parameter containing:\\ntensor([[[[ 0.0282,  0.0925,  0.0301],\\n          [ 0.1852,  0.1386,  0.2010],\\n          [ 0.2691,  0.2118,  0.1607]],\\n\\n         [[-0.2770,  0.1768, -0.0934],\\n          [-0.0570, -0.2370, -0.0170],\\n          [-0.2295,  0.2774, -0.2068]],\\n\\n         [[-0.0253,  0.1140, -0.0015],\\n          [-0.2130,  0.2672,  0.0661],\\n          [-0.2656,  0.1577, -0.1093]],\\n\\n         ...,\\n\\n         [[-0.1051,  0.0211, -0.1389],\\n          [-0.1514,  0.0996,  0.1449],\\n          [-0.0730,  0.0202,  0.2801]],\\n\\n         [[ 0.0499, -0.1815, -0.0402],\\n          [-0.2478,  0.0084, -0.1286],\\n          [ 0.0579, -0.1561,  0.0304]],\\n\\n         [[ 0.1152,  0.2101,  0.2333],\\n          [-0.0257,  0.2749,  0.2487],\\n          [ 0.1314, -0.1591,  0.2586]]],\\n\\n\\n        [[[ 0.1242, -0.1212,  0.0488],\\n          [ 0.2360,  0.1042,  0.2516],\\n          [ 0.1685,  0.0737,  0.2011]],\\n\\n         [[ 0.1920,  0.1177,  0.2665],\\n          [ 0.2479, -0.0543, -0.2218],\\n          [-0.1984, -0.2330, -0.1058]],\\n\\n         [[ 0.0395, -0.0268,  0.0805],\\n          [-0.2817, -0.2789, -0.2482],\\n          [ 0.0807, -0.1635,  0.1681]],\\n\\n         ...,\\n\\n         [[-0.0495,  0.2290, -0.0729],\\n          [-0.1895,  0.0167,  0.24...      [-0.1493,  0.0712,  0.1173],\\n          [-0.2238, -0.2489, -0.2883]],\\n\\n         ...,\\n\\n         [[-0.1216, -0.1307,  0.0840],\\n          [ 0.2854, -0.1247, -0.0023],\\n          [-0.1254, -0.2816,  0.2345]],\\n\\n         [[-0.0305, -0.1284,  0.1294],\\n          [ 0.0301,  0.0794, -0.1152],\\n          [ 0.2396,  0.0116,  0.0799]],\\n\\n         [[-0.2776,  0.2331,  0.2609],\\n          [-0.2283,  0.0518,  0.2840],\\n          [ 0.0700,  0.0806, -0.2745]]],\\n\\n\\n        [[[-0.2384,  0.2263,  0.2174],\\n          [-0.1817,  0.2437, -0.2549],\\n          [ 0.1836, -0.2558,  0.0149]],\\n\\n         [[ 0.1583, -0.2487, -0.0125],\\n          [-0.1425,  0.0512, -0.0394],\\n          [-0.0096, -0.2664, -0.1543]],\\n\\n         [[-0.2142, -0.1594, -0.2419],\\n          [ 0.0938,  0.2234,  0.0778],\\n          [-0.1660,  0.1188,  0.2550]],\\n\\n         ...,\\n\\n         [[-0.1829,  0.1721, -0.2683],\\n          [-0.0278, -0.1510,  0.1049],\\n          [-0.0926, -0.1023,  0.1827]],\\n\\n         [[ 0.2000,  0.0501, -0.0583],\\n          [-0.1318,  0.1807,  0.0286],\\n          [ 0.1338, -0.2710, -0.1265]],\\n\\n         [[-0.1146, -0.2405,  0.0437],\\n          [-0.0875,  0.1417, -0.0712],\\n          [-0.0011,  0.2590,  0.0774]]]], requires_grad=True).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where Parameter containing:\\ntensor([[[[ 0.0282,  0.0925,  0.0301],\\n          [ 0.1852,  0.1386,  0.2010],\\n          [ 0.2691,  0.2118,  0.1607]],\\n\\n         [[-0.2770,  0.1768, -0.0934],\\n          [-0.0570, -0.2370, -0.0170],\\n          [-0.2295,  0.2774, -0.2068]],\\n\\n         [[-0.0253,  0.1140, -0.0015],\\n          [-0.2130,  0.2672,  0.0661],\\n          [-0.2656,  0.1577, -0.1093]],\\n\\n         ...,\\n\\n         [[-0.1051,  0.0211, -0.1389],\\n          [-0.1514,  0.0996,  0.1449],\\n          [-0.0730,  0.0202,  0.2801]],\\n\\n         [[ 0.0499, -0.1815, -0.0402],\\n          [-0.2478,  0.0084, -0.1286],\\n          [ 0.0579, -0.1561,  0.0304]],\\n\\n         [[ 0.1152,  0.2101,  0.2333],\\n          [-0.0257,  0.2749,  0.2487],\\n          [ 0.1314, -0.1591,  0.2586]]],\\n\\n\\n        [[[ 0.1242, -0.1212,  0.0488],\\n          [ 0.2360,  0.1042,  0.2516],\\n          [ 0.1685,  0.0737,  0.2011]],\\n\\n         [[ 0.1920,  0.1177,  0.2665],\\n          [ 0.2479, -0.0543, -0.2218],\\n          [-0.1984, -0.2330, -0.1058]],\\n\\n         [[ 0.0395, -0.0268,  0.0805],\\n          [-0.2817, -0.2789, -0.2482],\\n          [ 0.0807, -0.1635,  0.1681]],\\n\\n         ...,\\n\\n         [[-0.0495,  0.2290, -0.0729],\\n          [-0.1895,  0.0167,  0.24...      [-0.1493,  0.0712,  0.1173],\\n          [-0.2238, -0.2489, -0.2883]],\\n\\n         ...,\\n\\n         [[-0.1216, -0.1307,  0.0840],\\n          [ 0.2854, -0.1247, -0.0023],\\n          [-0.1254, -0.2816,  0.2345]],\\n\\n         [[-0.0305, -0.1284,  0.1294],\\n          [ 0.0301,  0.0794, -0.1152],\\n          [ 0.2396,  0.0116,  0.0799]],\\n\\n         [[-0.2776,  0.2331,  0.2609],\\n          [-0.2283,  0.0518,  0.2840],\\n          [ 0.0700,  0.0806, -0.2745]]],\\n\\n\\n        [[[-0.2384,  0.2263,  0.2174],\\n          [-0.1817,  0.2437, -0.2549],\\n          [ 0.1836, -0.2558,  0.0149]],\\n\\n         [[ 0.1583, -0.2487, -0.0125],\\n          [-0.1425,  0.0512, -0.0394],\\n          [-0.0096, -0.2664, -0.1543]],\\n\\n         [[-0.2142, -0.1594, -0.2419],\\n          [ 0.0938,  0.2234,  0.0778],\\n          [-0.1660,  0.1188,  0.2550]],\\n\\n         ...,\\n\\n         [[-0.1829,  0.1721, -0.2683],\\n          [-0.0278, -0.1510,  0.1049],\\n          [-0.0926, -0.1023,  0.1827]],\\n\\n         [[ 0.2000,  0.0501, -0.0583],\\n          [-0.1318,  0.1807,  0.0286],\\n          [ 0.1338, -0.2710, -0.1265]],\\n\\n         [[-0.1146, -0.2405,  0.0437],\\n          [-0.0875,  0.1417, -0.0712],\\n          [-0.0011,  0.2590,  0.0774]]]], requires_grad=True) = Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).weight\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        ...,\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]]],\\n\\n\\n       [[[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.17542 ],\\n         [ 95.44504 , 103.45944 ,  93.275856],\\n         [ 87.383575,  94.40188 ,  85.01698 ]],\\n\\n        [[ 87.55481 ,  94.79761 ,  85.....80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]]],\\n\\n\\n       [[[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        ...,\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]],\\n\\n        [[ 82.439606,  89.72052 ,  82.22363 ],\\n         [ 89.28989 ,  97.039024,  88.63564 ],\\n         [ 84.20885 ,  91.80355 ,  83.83514 ]]]], dtype=float32) = <built-in method transpose of numpy.ndarray object at 0x783149b7ecd0>(3, 2, 0, 1)\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method transpose of numpy.ndarray object at 0x783149b7ecd0> = array([[[[ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         ...,\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606]],\\n\\n        [[ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         ...,\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.7...4.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         ...,\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ]],\\n\\n        [[ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         ...,\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ]]]], dtype=float32).transpose\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where array([[[[ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         ...,\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606],\\n         [ 87.55481 ,  87.55481 ,  89.520355, ...,  89.37971 ,\\n           82.439606,  82.439606]],\\n\\n        [[ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         ...,\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.72052 ],\\n         [ 94.79761 ,  94.79761 ,  95.53067 , ...,  95.08359 ,\\n           89.72052 ,  89.7...4.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         ...,\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ],\\n         [ 94.40188 ,  94.40188 ,  96.90785 , ...,  94.72217 ,\\n           91.80355 ,  91.80355 ]],\\n\\n        [[ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         ...,\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ],\\n         [ 85.01698 ,  85.01698 ,  91.28675 , ...,  88.60911 ,\\n           83.83514 ,  83.83514 ]]]], dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where numpy = NDArray([[[[ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   ...\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]]\\n\\n  [[ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   ...\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]]\\n\\n  [[ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.22363 ]\\n   [ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.22363 ]\\n   [ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.2236....383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]]\\n\\n  [[ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   ...\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]]\\n\\n  [[ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   ...\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where NDArray([[[[ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   ...\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]]\\n\\n  [[ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   ...\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]]\\n\\n  [[ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.22363 ]\\n   [ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.22363 ]\\n   [ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.2236....383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]]\\n\\n  [[ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   ...\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]]\\n\\n  [[ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   ...\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]]]], device=cuda()) = needle.Tensor([[[[ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   ...\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]]\\n\\n  [[ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   ...\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]]\\n\\n  [[ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.22363 ]\\n   [ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.22363 ]\\n   [ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     8...\\n   ...\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]]\\n\\n  [[ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   ...\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]]\\n\\n  [[ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   ...\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +              where needle.Tensor([[[[ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   ...\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]\\n   [ 87.55481   87.55481   89.520355 ...  89.37971   82.439606\\n     82.439606]]\\n\\n  [[ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   ...\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]\\n   [ 94.79761   94.79761   95.53067  ...  95.08359   89.72052\\n     89.72052 ]]\\n\\n  [[ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.22363 ]\\n   [ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     82.22363 ]\\n   [ 85.17542   85.17542   89.9638   ...  88.69262   82.22363\\n     8...\\n   ...\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]\\n   [ 87.383575  87.383575  90.60353  ...  89.03718   84.20885\\n     84.20885 ]]\\n\\n  [[ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   ...\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]\\n   [ 94.40188   94.40188   96.90785  ...  94.72217   91.80355\\n     91.80355 ]]\\n\\n  [[ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   ...\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]\\n   [ 85.01698   85.01698   91.28675  ...  88.60911   83.83514\\n     83.83514 ]]]]) = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\\n    -0.238371  ]\\n   [-0.27700204  0.19203815  0.16059387 ... -0.04926994 -0.13593388\\n     0.15832889]\\n   [-0.02531663  0.03951034 -0.27782685 ...  0.09851781 -0.1672107\\n    -0.21423951]\\n   ...\\n   [-0.10508746 -0.04950029 -0.25163954 ...  0.12489656 -0.12158644\\n    -0.18290955]\\n   [ 0.04994825 -0.27706602  0.1899136  ...  0.26139474 -0.03052717\\n     0.19999912]\\n   [ 0.11516941 -0.11694983  0.18117127 ...  0.06142616 -0.27759394\\n    -0.11456083]]\\n\\n  [[ 0.09247622 -0.12119876  0.06813622 ... -0.07646318 -0.0370284\\n     0.22627705]\\n   [ 0.17678118  0.11771512 -0.2308091  ...  0.03989533 -0.05358775\\n    -0.24874154]\\n   [ 0.11398554 -0.02682215  0.12820387 ... -0.27798158  0.16956645\\n    -0.15939216]\\n   ...\\n   [ 0.021119    0.22901827  0.28309733 ...  0.21514994 -0.13074556\\n     0.17207742]\\n   [-0.18149817  0.26141936  0.10824639 ... -0.02102974 -0.12838611\\n     0.05010498]\\n   [ 0.21007213 -0.22081807  0.01003382 ...  0.14356598  0.23308766\\n    -0.24051116]]\\n\\n  [[ 0.03013334  0.04877228  0.26669908 ... -0.00829792  0.2756819\\n     0.2173754 ]\\n   [-0.09343897  0.26648766 -0.15490213 ... -0.20314597  0.27818...5785793  0.2674271  -0.20334199 ... -0.0823608   0.23958349\\n     0.13379756]\\n   [ 0.1313743  -0.12129353  0.04486555 ...  0.03917089  0.06995711\\n    -0.00105104]]\\n\\n  [[ 0.21176547  0.07374769 -0.05691059 ... -0.22176112  0.23086315\\n    -0.25583702]\\n   [ 0.27740854 -0.2329892   0.2098499  ...  0.18871364  0.13023493\\n    -0.2664141 ]\\n   [ 0.15768015 -0.16346504  0.23275858 ... -0.15740736 -0.24892344\\n     0.11876675]\\n   ...\\n   [ 0.02015424 -0.12110035 -0.11306044 ...  0.15659207 -0.2816481\\n    -0.10228941]\\n   [-0.1561343   0.00396231  0.13674724 ...  0.2191168   0.011594\\n    -0.27097297]\\n   [-0.15910988  0.26192975  0.04752731 ...  0.06957066  0.08061096\\n     0.2589649 ]]\\n\\n  [[ 0.1606628   0.20111725 -0.00553107 ... -0.13550219 -0.21518189\\n     0.0149008 ]\\n   [-0.20679688 -0.1058106   0.07315403 ... -0.14080776  0.18689847\\n    -0.15428376]\\n   [-0.10933328  0.16814026  0.12421301 ... -0.20090216 -0.28829163\\n     0.25499701]\\n   ...\\n   [ 0.28007764  0.16361913  0.01096383 ... -0.26837546  0.23453778\\n     0.18265301]\\n   [ 0.03035784  0.2031168   0.2669639  ... -0.09789518  0.07989958\\n    -0.12652083]\\n   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\\n     0.07735741]]]]).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +                where needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\\n    -0.238371  ]\\n   [-0.27700204  0.19203815  0.16059387 ... -0.04926994 -0.13593388\\n     0.15832889]\\n   [-0.02531663  0.03951034 -0.27782685 ...  0.09851781 -0.1672107\\n    -0.21423951]\\n   ...\\n   [-0.10508746 -0.04950029 -0.25163954 ...  0.12489656 -0.12158644\\n    -0.18290955]\\n   [ 0.04994825 -0.27706602  0.1899136  ...  0.26139474 -0.03052717\\n     0.19999912]\\n   [ 0.11516941 -0.11694983  0.18117127 ...  0.06142616 -0.27759394\\n    -0.11456083]]\\n\\n  [[ 0.09247622 -0.12119876  0.06813622 ... -0.07646318 -0.0370284\\n     0.22627705]\\n   [ 0.17678118  0.11771512 -0.2308091  ...  0.03989533 -0.05358775\\n    -0.24874154]\\n   [ 0.11398554 -0.02682215  0.12820387 ... -0.27798158  0.16956645\\n    -0.15939216]\\n   ...\\n   [ 0.021119    0.22901827  0.28309733 ...  0.21514994 -0.13074556\\n     0.17207742]\\n   [-0.18149817  0.26141936  0.10824639 ... -0.02102974 -0.12838611\\n     0.05010498]\\n   [ 0.21007213 -0.22081807  0.01003382 ...  0.14356598  0.23308766\\n    -0.24051116]]\\n\\n  [[ 0.03013334  0.04877228  0.26669908 ... -0.00829792  0.2756819\\n     0.2173754 ]\\n   [-0.09343897  0.26648766 -0.15490213 ... -0.20314597  0.27818...5785793  0.2674271  -0.20334199 ... -0.0823608   0.23958349\\n     0.13379756]\\n   [ 0.1313743  -0.12129353  0.04486555 ...  0.03917089  0.06995711\\n    -0.00105104]]\\n\\n  [[ 0.21176547  0.07374769 -0.05691059 ... -0.22176112  0.23086315\\n    -0.25583702]\\n   [ 0.27740854 -0.2329892   0.2098499  ...  0.18871364  0.13023493\\n    -0.2664141 ]\\n   [ 0.15768015 -0.16346504  0.23275858 ... -0.15740736 -0.24892344\\n     0.11876675]\\n   ...\\n   [ 0.02015424 -0.12110035 -0.11306044 ...  0.15659207 -0.2816481\\n    -0.10228941]\\n   [-0.1561343   0.00396231  0.13674724 ...  0.2191168   0.011594\\n    -0.27097297]\\n   [-0.15910988  0.26192975  0.04752731 ...  0.06957066  0.08061096\\n     0.2589649 ]]\\n\\n  [[ 0.1606628   0.20111725 -0.00553107 ... -0.13550219 -0.21518189\\n     0.0149008 ]\\n   [-0.20679688 -0.1058106   0.07315403 ... -0.14080776  0.18689847\\n    -0.15428376]\\n   [-0.10933328  0.16814026  0.12421301 ... -0.20090216 -0.28829163\\n     0.25499701]\\n   ...\\n   [ 0.28007764  0.16361913  0.01096383 ... -0.26837546  0.23453778\\n     0.18265301]\\n   [ 0.03035784  0.2031168   0.2669639  ... -0.09789518  0.07989958\\n    -0.12652083]\\n   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\\n     0.07735741]]]]) = <needle.nn.nn_conv.Conv object at 0x78314a4d2fc0>.weight\u001b[0m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78314a4d2fc0>\n",
            "g          = Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "res1       = needle.Tensor([[[[ 4.47612375e-01  1.20483387e+00  5.88808835e-01 ...  5.73270738e-01\n",
            "     3.02611470e-01 -1.56252831e...2e-01]\n",
            "   [ 2.62064606e-01 -5.48389591e-02 -9.19025302e-01 ... -1.38986081e-01\n",
            "    -3.37119997e-01  3.68726462e-01]]]])\n",
            "s          = 14\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.79868925 0.92345554 0.29915366 ... 0.13554843 0.72026587\n",
            "    0.925395  ]\n",
            "   [0.6646656  0.42305443...0.4892255  0.48206186\n",
            "    0.45311075]\n",
            "   [0.8035453  0.47169307 0.7583655  ... 0.07899625 0.9464155\n",
            "    0.4682215 ]]]])\n",
            "y1         = needle.Tensor([-365.78763])\n",
            "y2         = tensor(-316.8438, grad_fn=<SumBackward0>)\n",
            "z          = tensor([[[[0.7987, 0.9235, 0.2992,  ..., 0.1355, 0.7203, 0.9254],\n",
            "          [0.6647, 0.4231, 0.1990,  ..., 0.3695, 0.3....4892, 0.4821, 0.4531],\n",
            "          [0.8035, 0.4717, 0.7584,  ..., 0.0790, 0.9464, 0.4682]]]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:391: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-2] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 16, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "        y1 = res1.sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y2 = g(z).sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y1.backward()\u001b[90m\u001b[39;49;00m\n",
            "        y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(g.weight.grad.data.numpy() - f.weight.grad.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)) < \u001b[94m1e-3\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight gradients match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: weight gradients match\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(100.43126) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(100.43126) = <function norm at 0x78322a53a730>((array([[[[17.34189 , 26.2379  , 19.623785],\\n         [23.66088 , 24.632048, 27.8746  ],\\n         [20.35794 , 29.307243, 23.188091]],\\n\\n        [[18.569857, 18.257563, 22.471216],\\n         [23.70113 , 27.525879, 27.769596],\\n         [22.60869 , 22.227966, 27.470816]],\\n\\n        [[18.61932 , 20.705956, 21.65325 ],\\n         [18.025957, 25.637058, 21.803625],\\n         [21.204256, 23.607733, 24.550877]],\\n\\n        ...,\\n\\n        [[22.792725, 22.644112, 25.860159],\\n         [19.72237 , 26.831223, 22.95988 ],\\n         [24.945404, 26.281126, 28.635628]],\\n\\n        [[17.409254, 19.013481, 20.38957 ],\\n         [22.493893, 23.51609 , 26.11859 ],\\n         [20.329645, 23.826887, 23.43035 ]],\\n\\n        [[18.46697 , 22.515152, 22.19686 ],\\n         [22.917883, 25.455564, 26.603277],\\n         [20.657942, 27.099007, 24.856052]]],\\n\\n\\n       [[[17.34189 , 26.2379  , 19.623785],\\n         [23.66088 , 24.632048, 27.8746  ],\\n         [20.35794 , 29.307243, 23.188091]],\\n\\n        [[18.569857, 18.257563, 22.471216],\\n         [23.70113 , 27.525879, 27.769596],\\n         [22.60869 , 22.227966, 27.470816]],\\n\\n        [[18.61932 , 20.705956, 21.65325 ],\\n         [18.025957, 25.637058, 21.803625],\\n         [21.204256, 2...159],\\n         [19.72237 , 26.831223, 22.95988 ],\\n         [24.945404, 26.281126, 28.635628]],\\n\\n        [[17.409254, 19.013481, 20.38957 ],\\n         [22.493893, 23.51609 , 26.11859 ],\\n         [20.329645, 23.826887, 23.43035 ]],\\n\\n        [[18.46697 , 22.515152, 22.19686 ],\\n         [22.917883, 25.455564, 26.603277],\\n         [20.657942, 27.099007, 24.856052]]],\\n\\n\\n       [[[17.34189 , 26.2379  , 19.623785],\\n         [23.66088 , 24.632048, 27.8746  ],\\n         [20.35794 , 29.307243, 23.188091]],\\n\\n        [[18.569857, 18.257563, 22.471216],\\n         [23.70113 , 27.525879, 27.769596],\\n         [22.60869 , 22.227966, 27.470816]],\\n\\n        [[18.61932 , 20.705956, 21.65325 ],\\n         [18.025957, 25.637058, 21.803625],\\n         [21.204256, 23.607733, 24.550877]],\\n\\n        ...,\\n\\n        [[22.792725, 22.644112, 25.860159],\\n         [19.72237 , 26.831223, 22.95988 ],\\n         [24.945404, 26.281126, 28.635628]],\\n\\n        [[17.409254, 19.013481, 20.38957 ],\\n         [22.493893, 23.51609 , 26.11859 ],\\n         [20.329645, 23.826887, 23.43035 ]],\\n\\n        [[18.46697 , 22.515152, 22.19686 ],\\n         [22.917883, 25.455564, 26.603277],\\n         [20.657942, 27.099007, 24.856052]]]], dtype=float32) - array([[[[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        ...,\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]]],\\n\\n\\n       [[[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 2...225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]]],\\n\\n\\n       [[[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        ...,\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]]]], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78322a53a730> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[17.34189 , 26.2379  , 19.623785],\\n         [23.66088 , 24.632048, 27.8746  ],\\n         [20.35794 , 29.307243, 23.188091]],\\n\\n        [[18.569857, 18.257563, 22.471216],\\n         [23.70113 , 27.525879, 27.769596],\\n         [22.60869 , 22.227966, 27.470816]],\\n\\n        [[18.61932 , 20.705956, 21.65325 ],\\n         [18.025957, 25.637058, 21.803625],\\n         [21.204256, 23.607733, 24.550877]],\\n\\n        ...,\\n\\n        [[22.792725, 22.644112, 25.860159],\\n         [19.72237 , 26.831223, 22.95988 ],\\n         [24.945404, 26.281126, 28.635628]],\\n\\n        [[17.409254, 19.013481, 20.38957 ],\\n         [22.493893, 23.51609 , 26.11859 ],\\n         [20.329645, 23.826887, 23.43035 ]],\\n\\n        [[18.46697 , 22.515152, 22.19686 ],\\n         [22.917883, 25.455564, 26.603277],\\n         [20.657942, 27.099007, 24.856052]]],\\n\\n\\n       [[[17.34189 , 26.2379  , 19.623785],\\n         [23.66088 , 24.632048, 27.8746  ],\\n         [20.35794 , 29.307243, 23.188091]],\\n\\n        [[18.569857, 18.257563, 22.471216],\\n         [23.70113 , 27.525879, 27.769596],\\n         [22.60869 , 22.227966, 27.470816]],\\n\\n        [[18.61932 , 20.705956, 21.65325 ],\\n         [18.025957, 25.637058, 21.803625],\\n         [21.204256, 2...159],\\n         [19.72237 , 26.831223, 22.95988 ],\\n         [24.945404, 26.281126, 28.635628]],\\n\\n        [[17.409254, 19.013481, 20.38957 ],\\n         [22.493893, 23.51609 , 26.11859 ],\\n         [20.329645, 23.826887, 23.43035 ]],\\n\\n        [[18.46697 , 22.515152, 22.19686 ],\\n         [22.917883, 25.455564, 26.603277],\\n         [20.657942, 27.099007, 24.856052]]],\\n\\n\\n       [[[17.34189 , 26.2379  , 19.623785],\\n         [23.66088 , 24.632048, 27.8746  ],\\n         [20.35794 , 29.307243, 23.188091]],\\n\\n        [[18.569857, 18.257563, 22.471216],\\n         [23.70113 , 27.525879, 27.769596],\\n         [22.60869 , 22.227966, 27.470816]],\\n\\n        [[18.61932 , 20.705956, 21.65325 ],\\n         [18.025957, 25.637058, 21.803625],\\n         [21.204256, 23.607733, 24.550877]],\\n\\n        ...,\\n\\n        [[22.792725, 22.644112, 25.860159],\\n         [19.72237 , 26.831223, 22.95988 ],\\n         [24.945404, 26.281126, 28.635628]],\\n\\n        [[17.409254, 19.013481, 20.38957 ],\\n         [22.493893, 23.51609 , 26.11859 ],\\n         [20.329645, 23.826887, 23.43035 ]],\\n\\n        [[18.46697 , 22.515152, 22.19686 ],\\n         [22.917883, 25.455564, 26.603277],\\n         [20.657942, 27.099007, 24.856052]]]], dtype=float32) = <built-in method numpy of Tensor object at 0x7831499fd310>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x7831499fd310> = tensor([[[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]],\\n\\n\\n        [[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.945...7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]],\\n\\n\\n        [[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]],\\n\\n\\n        [[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.945...7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]],\\n\\n\\n        [[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]]]) = tensor([[[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]],\\n\\n\\n        [[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.945...7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]],\\n\\n\\n        [[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]]]).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]],\\n\\n\\n        [[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.945...7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]],\\n\\n\\n        [[[17.3419, 26.2379, 19.6238],\\n          [23.6609, 24.6320, 27.8746],\\n          [20.3579, 29.3072, 23.1881]],\\n\\n         [[18.5699, 18.2576, 22.4712],\\n          [23.7011, 27.5259, 27.7696],\\n          [22.6087, 22.2280, 27.4708]],\\n\\n         [[18.6193, 20.7060, 21.6532],\\n          [18.0260, 25.6371, 21.8036],\\n          [21.2043, 23.6077, 24.5509]],\\n\\n         ...,\\n\\n         [[22.7927, 22.6441, 25.8602],\\n          [19.7224, 26.8312, 22.9599],\\n          [24.9454, 26.2811, 28.6356]],\\n\\n         [[17.4093, 19.0135, 20.3896],\\n          [22.4939, 23.5161, 26.1186],\\n          [20.3296, 23.8269, 23.4303]],\\n\\n         [[18.4670, 22.5152, 22.1969],\\n          [22.9179, 25.4556, 26.6033],\\n          [20.6579, 27.0990, 24.8561]]]]) = Parameter containing:\\ntensor([[[[ 0.0282,  0.0925,  0.0301],\\n          [ 0.1852,  0.1386,  0.2010],\\n          [ 0.2691,  0.2118,  0.1607]],\\n\\n         [[-0.2770,  0.1768, -0.0934],\\n          [-0.0570, -0.2370, -0.0170],\\n          [-0.2295,  0.2774, -0.2068]],\\n\\n         [[-0.0253,  0.1140, -0.0015],\\n          [-0.2130,  0.2672,  0.0661],\\n          [-0.2656,  0.1577, -0.1093]],\\n\\n         ...,\\n\\n         [[-0.1051,  0.0211, -0.1389],\\n          [-0.1514,  0.0996,  0.1449],\\n          [-0.0730,  0.0202,  0.2801]],\\n\\n         [[ 0.0499, -0.1815, -0.0402],\\n          [-0.2478,  0.0084, -0.1286],\\n          [ 0.0579, -0.1561,  0.0304]],\\n\\n         [[ 0.1152,  0.2101,  0.2333],\\n          [-0.0257,  0.2749,  0.2487],\\n          [ 0.1314, -0.1591,  0.2586]]],\\n\\n\\n        [[[ 0.1242, -0.1212,  0.0488],\\n          [ 0.2360,  0.1042,  0.2516],\\n          [ 0.1685,  0.0737,  0.2011]],\\n\\n         [[ 0.1920,  0.1177,  0.2665],\\n          [ 0.2479, -0.0543, -0.2218],\\n          [-0.1984, -0.2330, -0.1058]],\\n\\n         [[ 0.0395, -0.0268,  0.0805],\\n          [-0.2817, -0.2789, -0.2482],\\n          [ 0.0807, -0.1635,  0.1681]],\\n\\n         ...,\\n\\n         [[-0.0495,  0.2290, -0.0729],\\n          [-0.1895,  0.0167,  0.24...      [-0.1493,  0.0712,  0.1173],\\n          [-0.2238, -0.2489, -0.2883]],\\n\\n         ...,\\n\\n         [[-0.1216, -0.1307,  0.0840],\\n          [ 0.2854, -0.1247, -0.0023],\\n          [-0.1254, -0.2816,  0.2345]],\\n\\n         [[-0.0305, -0.1284,  0.1294],\\n          [ 0.0301,  0.0794, -0.1152],\\n          [ 0.2396,  0.0116,  0.0799]],\\n\\n         [[-0.2776,  0.2331,  0.2609],\\n          [-0.2283,  0.0518,  0.2840],\\n          [ 0.0700,  0.0806, -0.2745]]],\\n\\n\\n        [[[-0.2384,  0.2263,  0.2174],\\n          [-0.1817,  0.2437, -0.2549],\\n          [ 0.1836, -0.2558,  0.0149]],\\n\\n         [[ 0.1583, -0.2487, -0.0125],\\n          [-0.1425,  0.0512, -0.0394],\\n          [-0.0096, -0.2664, -0.1543]],\\n\\n         [[-0.2142, -0.1594, -0.2419],\\n          [ 0.0938,  0.2234,  0.0778],\\n          [-0.1660,  0.1188,  0.2550]],\\n\\n         ...,\\n\\n         [[-0.1829,  0.1721, -0.2683],\\n          [-0.0278, -0.1510,  0.1049],\\n          [-0.0926, -0.1023,  0.1827]],\\n\\n         [[ 0.2000,  0.0501, -0.0583],\\n          [-0.1318,  0.1807,  0.0286],\\n          [ 0.1338, -0.2710, -0.1265]],\\n\\n         [[-0.1146, -0.2405,  0.0437],\\n          [-0.0875,  0.1417, -0.0712],\\n          [-0.0011,  0.2590,  0.0774]]]], requires_grad=True).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where Parameter containing:\\ntensor([[[[ 0.0282,  0.0925,  0.0301],\\n          [ 0.1852,  0.1386,  0.2010],\\n          [ 0.2691,  0.2118,  0.1607]],\\n\\n         [[-0.2770,  0.1768, -0.0934],\\n          [-0.0570, -0.2370, -0.0170],\\n          [-0.2295,  0.2774, -0.2068]],\\n\\n         [[-0.0253,  0.1140, -0.0015],\\n          [-0.2130,  0.2672,  0.0661],\\n          [-0.2656,  0.1577, -0.1093]],\\n\\n         ...,\\n\\n         [[-0.1051,  0.0211, -0.1389],\\n          [-0.1514,  0.0996,  0.1449],\\n          [-0.0730,  0.0202,  0.2801]],\\n\\n         [[ 0.0499, -0.1815, -0.0402],\\n          [-0.2478,  0.0084, -0.1286],\\n          [ 0.0579, -0.1561,  0.0304]],\\n\\n         [[ 0.1152,  0.2101,  0.2333],\\n          [-0.0257,  0.2749,  0.2487],\\n          [ 0.1314, -0.1591,  0.2586]]],\\n\\n\\n        [[[ 0.1242, -0.1212,  0.0488],\\n          [ 0.2360,  0.1042,  0.2516],\\n          [ 0.1685,  0.0737,  0.2011]],\\n\\n         [[ 0.1920,  0.1177,  0.2665],\\n          [ 0.2479, -0.0543, -0.2218],\\n          [-0.1984, -0.2330, -0.1058]],\\n\\n         [[ 0.0395, -0.0268,  0.0805],\\n          [-0.2817, -0.2789, -0.2482],\\n          [ 0.0807, -0.1635,  0.1681]],\\n\\n         ...,\\n\\n         [[-0.0495,  0.2290, -0.0729],\\n          [-0.1895,  0.0167,  0.24...      [-0.1493,  0.0712,  0.1173],\\n          [-0.2238, -0.2489, -0.2883]],\\n\\n         ...,\\n\\n         [[-0.1216, -0.1307,  0.0840],\\n          [ 0.2854, -0.1247, -0.0023],\\n          [-0.1254, -0.2816,  0.2345]],\\n\\n         [[-0.0305, -0.1284,  0.1294],\\n          [ 0.0301,  0.0794, -0.1152],\\n          [ 0.2396,  0.0116,  0.0799]],\\n\\n         [[-0.2776,  0.2331,  0.2609],\\n          [-0.2283,  0.0518,  0.2840],\\n          [ 0.0700,  0.0806, -0.2745]]],\\n\\n\\n        [[[-0.2384,  0.2263,  0.2174],\\n          [-0.1817,  0.2437, -0.2549],\\n          [ 0.1836, -0.2558,  0.0149]],\\n\\n         [[ 0.1583, -0.2487, -0.0125],\\n          [-0.1425,  0.0512, -0.0394],\\n          [-0.0096, -0.2664, -0.1543]],\\n\\n         [[-0.2142, -0.1594, -0.2419],\\n          [ 0.0938,  0.2234,  0.0778],\\n          [-0.1660,  0.1188,  0.2550]],\\n\\n         ...,\\n\\n         [[-0.1829,  0.1721, -0.2683],\\n          [-0.0278, -0.1510,  0.1049],\\n          [-0.0926, -0.1023,  0.1827]],\\n\\n         [[ 0.2000,  0.0501, -0.0583],\\n          [-0.1318,  0.1807,  0.0286],\\n          [ 0.1338, -0.2710, -0.1265]],\\n\\n         [[-0.1146, -0.2405,  0.0437],\\n          [-0.0875,  0.1417, -0.0712],\\n          [-0.0011,  0.2590,  0.0774]]]], requires_grad=True) = Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)).weight\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        ...,\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]]],\\n\\n\\n       [[[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 27.101204, 25.97298 ]],\\n\\n        [[18.125475, 23.891779, 20.52058 ],\\n         [20.48573 , 25.05182 , 25.333433],\\n         [22.806274, 2...225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]]],\\n\\n\\n       [[[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        ...,\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]],\\n\\n        [[18.520235, 18.659752, 23.034225],\\n         [22.543406, 22.716204, 25.310328],\\n         [20.929718, 23.10056 , 25.91193 ]]]], dtype=float32) = <built-in method transpose of numpy.ndarray object at 0x78314a315530>(3, 2, 0, 1)\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method transpose of numpy.ndarray object at 0x78314a315530> = array([[[[18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         ...,\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235]],\\n\\n        [[23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         ...,\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752]],\\n\\n        [[20.52058 , 20.52058 , 21.844236, ..., 22.354303, 23...., 22.30257 , 20.929718,\\n          20.929718]],\\n\\n        [[27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         ...,\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ]],\\n\\n        [[25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         ...,\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ]]]], dtype=float32).transpose\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where array([[[[18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         ...,\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235],\\n         [18.125475, 18.125475, 19.640402, ..., 19.438278, 18.520235,\\n          18.520235]],\\n\\n        [[23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         ...,\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752],\\n         [23.891779, 23.891779, 23.3418  , ..., 23.43067 , 18.659752,\\n          18.659752]],\\n\\n        [[20.52058 , 20.52058 , 21.844236, ..., 22.354303, 23...., 22.30257 , 20.929718,\\n          20.929718]],\\n\\n        [[27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         ...,\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ],\\n         [27.101204, 27.101204, 27.882328, ..., 26.958399, 23.10056 ,\\n          23.10056 ]],\\n\\n        [[25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         ...,\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ],\\n         [25.97298 , 25.97298 , 25.496048, ..., 26.061516, 25.91193 ,\\n          25.91193 ]]]], dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where numpy = NDArray([[[[18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   ...\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]]\\n\\n  [[23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   ...\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]]\\n\\n  [[20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   ...\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23....806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   ...\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]]\\n\\n  [[27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   ...\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]]\\n\\n  [[25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   ...\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where NDArray([[[[18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   ...\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]]\\n\\n  [[23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   ...\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]]\\n\\n  [[20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   ...\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23....806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   ...\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]]\\n\\n  [[27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   ...\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]]\\n\\n  [[25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   ...\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]]]], device=cuda()) = needle.Tensor([[[[18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   ...\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]]\\n\\n  [[23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   ...\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]]\\n\\n  [[20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   ...\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.0342... [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   ...\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]]\\n\\n  [[27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   ...\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]]\\n\\n  [[25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   ...\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +              where needle.Tensor([[[[18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   ...\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]\\n   [18.125475 18.125475 19.640402 ... 19.438278 18.520235 18.520235]]\\n\\n  [[23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   ...\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]\\n   [23.891779 23.891779 23.3418   ... 23.43067  18.659752 18.659752]]\\n\\n  [[20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   ...\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.034225 23.034225]\\n   [20.52058  20.52058  21.844236 ... 22.354303 23.0342... [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   ...\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]\\n   [22.806274 22.806274 22.891703 ... 22.30257  20.929718 20.929718]]\\n\\n  [[27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   ...\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]\\n   [27.101204 27.101204 27.882328 ... 26.958399 23.10056  23.10056 ]]\\n\\n  [[25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   ...\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]\\n   [25.97298  25.97298  25.496048 ... 26.061516 25.91193  25.91193 ]]]]) = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\\n    -0.238371  ]\\n   [-0.27700204  0.19203815  0.16059387 ... -0.04926994 -0.13593388\\n     0.15832889]\\n   [-0.02531663  0.03951034 -0.27782685 ...  0.09851781 -0.1672107\\n    -0.21423951]\\n   ...\\n   [-0.10508746 -0.04950029 -0.25163954 ...  0.12489656 -0.12158644\\n    -0.18290955]\\n   [ 0.04994825 -0.27706602  0.1899136  ...  0.26139474 -0.03052717\\n     0.19999912]\\n   [ 0.11516941 -0.11694983  0.18117127 ...  0.06142616 -0.27759394\\n    -0.11456083]]\\n\\n  [[ 0.09247622 -0.12119876  0.06813622 ... -0.07646318 -0.0370284\\n     0.22627705]\\n   [ 0.17678118  0.11771512 -0.2308091  ...  0.03989533 -0.05358775\\n    -0.24874154]\\n   [ 0.11398554 -0.02682215  0.12820387 ... -0.27798158  0.16956645\\n    -0.15939216]\\n   ...\\n   [ 0.021119    0.22901827  0.28309733 ...  0.21514994 -0.13074556\\n     0.17207742]\\n   [-0.18149817  0.26141936  0.10824639 ... -0.02102974 -0.12838611\\n     0.05010498]\\n   [ 0.21007213 -0.22081807  0.01003382 ...  0.14356598  0.23308766\\n    -0.24051116]]\\n\\n  [[ 0.03013334  0.04877228  0.26669908 ... -0.00829792  0.2756819\\n     0.2173754 ]\\n   [-0.09343897  0.26648766 -0.15490213 ... -0.20314597  0.27818...5785793  0.2674271  -0.20334199 ... -0.0823608   0.23958349\\n     0.13379756]\\n   [ 0.1313743  -0.12129353  0.04486555 ...  0.03917089  0.06995711\\n    -0.00105104]]\\n\\n  [[ 0.21176547  0.07374769 -0.05691059 ... -0.22176112  0.23086315\\n    -0.25583702]\\n   [ 0.27740854 -0.2329892   0.2098499  ...  0.18871364  0.13023493\\n    -0.2664141 ]\\n   [ 0.15768015 -0.16346504  0.23275858 ... -0.15740736 -0.24892344\\n     0.11876675]\\n   ...\\n   [ 0.02015424 -0.12110035 -0.11306044 ...  0.15659207 -0.2816481\\n    -0.10228941]\\n   [-0.1561343   0.00396231  0.13674724 ...  0.2191168   0.011594\\n    -0.27097297]\\n   [-0.15910988  0.26192975  0.04752731 ...  0.06957066  0.08061096\\n     0.2589649 ]]\\n\\n  [[ 0.1606628   0.20111725 -0.00553107 ... -0.13550219 -0.21518189\\n     0.0149008 ]\\n   [-0.20679688 -0.1058106   0.07315403 ... -0.14080776  0.18689847\\n    -0.15428376]\\n   [-0.10933328  0.16814026  0.12421301 ... -0.20090216 -0.28829163\\n     0.25499701]\\n   ...\\n   [ 0.28007764  0.16361913  0.01096383 ... -0.26837546  0.23453778\\n     0.18265301]\\n   [ 0.03035784  0.2031168   0.2669639  ... -0.09789518  0.07989958\\n    -0.12652083]\\n   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\\n     0.07735741]]]]).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +                where needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\\n    -0.238371  ]\\n   [-0.27700204  0.19203815  0.16059387 ... -0.04926994 -0.13593388\\n     0.15832889]\\n   [-0.02531663  0.03951034 -0.27782685 ...  0.09851781 -0.1672107\\n    -0.21423951]\\n   ...\\n   [-0.10508746 -0.04950029 -0.25163954 ...  0.12489656 -0.12158644\\n    -0.18290955]\\n   [ 0.04994825 -0.27706602  0.1899136  ...  0.26139474 -0.03052717\\n     0.19999912]\\n   [ 0.11516941 -0.11694983  0.18117127 ...  0.06142616 -0.27759394\\n    -0.11456083]]\\n\\n  [[ 0.09247622 -0.12119876  0.06813622 ... -0.07646318 -0.0370284\\n     0.22627705]\\n   [ 0.17678118  0.11771512 -0.2308091  ...  0.03989533 -0.05358775\\n    -0.24874154]\\n   [ 0.11398554 -0.02682215  0.12820387 ... -0.27798158  0.16956645\\n    -0.15939216]\\n   ...\\n   [ 0.021119    0.22901827  0.28309733 ...  0.21514994 -0.13074556\\n     0.17207742]\\n   [-0.18149817  0.26141936  0.10824639 ... -0.02102974 -0.12838611\\n     0.05010498]\\n   [ 0.21007213 -0.22081807  0.01003382 ...  0.14356598  0.23308766\\n    -0.24051116]]\\n\\n  [[ 0.03013334  0.04877228  0.26669908 ... -0.00829792  0.2756819\\n     0.2173754 ]\\n   [-0.09343897  0.26648766 -0.15490213 ... -0.20314597  0.27818...5785793  0.2674271  -0.20334199 ... -0.0823608   0.23958349\\n     0.13379756]\\n   [ 0.1313743  -0.12129353  0.04486555 ...  0.03917089  0.06995711\\n    -0.00105104]]\\n\\n  [[ 0.21176547  0.07374769 -0.05691059 ... -0.22176112  0.23086315\\n    -0.25583702]\\n   [ 0.27740854 -0.2329892   0.2098499  ...  0.18871364  0.13023493\\n    -0.2664141 ]\\n   [ 0.15768015 -0.16346504  0.23275858 ... -0.15740736 -0.24892344\\n     0.11876675]\\n   ...\\n   [ 0.02015424 -0.12110035 -0.11306044 ...  0.15659207 -0.2816481\\n    -0.10228941]\\n   [-0.1561343   0.00396231  0.13674724 ...  0.2191168   0.011594\\n    -0.27097297]\\n   [-0.15910988  0.26192975  0.04752731 ...  0.06957066  0.08061096\\n     0.2589649 ]]\\n\\n  [[ 0.1606628   0.20111725 -0.00553107 ... -0.13550219 -0.21518189\\n     0.0149008 ]\\n   [-0.20679688 -0.1058106   0.07315403 ... -0.14080776  0.18689847\\n    -0.15428376]\\n   [-0.10933328  0.16814026  0.12421301 ... -0.20090216 -0.28829163\\n     0.25499701]\\n   ...\\n   [ 0.28007764  0.16361913  0.01096383 ... -0.26837546  0.23453778\\n     0.18265301]\\n   [ 0.03035784  0.2031168   0.2669639  ... -0.09789518  0.07989958\\n    -0.12652083]\\n   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\\n     0.07735741]]]]) = <needle.nn.nn_conv.Conv object at 0x7831401c8530>.weight\u001b[0m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x7831401c8530>\n",
            "g          = Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "res1       = needle.Tensor([[[[ 4.47612375e-01  5.88808835e-01  4.98261839e-01  1.62261248e-01\n",
            "     1.18381031e-01  9.33497965e-01 ...5.04697323e-01 -5.96949220e-01 -7.65117407e-01 -3.13595831e-02\n",
            "    -1.25493133e+00  5.87596074e-02 -5.58030665e-01]]]])\n",
            "s          = 14\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.79868925 0.92345554 0.29915366 ... 0.13554843 0.72026587\n",
            "    0.925395  ]\n",
            "   [0.6646656  0.42305443...0.4892255  0.48206186\n",
            "    0.45311075]\n",
            "   [0.8035453  0.47169307 0.7583655  ... 0.07899625 0.9464155\n",
            "    0.4682215 ]]]])\n",
            "y1         = needle.Tensor([-98.650406])\n",
            "y2         = tensor(-108.8699, grad_fn=<SumBackward0>)\n",
            "z          = tensor([[[[0.7987, 0.9235, 0.2992,  ..., 0.1355, 0.7203, 0.9254],\n",
            "          [0.6647, 0.4231, 0.1990,  ..., 0.3695, 0.3....4892, 0.4821, 0.4531],\n",
            "          [0.8035, 0.4717, 0.7584,  ..., 0.0790, 0.9464, 0.4682]]]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:391: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-1] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 8, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "        y1 = res1.sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y2 = g(z).sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y1.backward()\u001b[90m\u001b[39;49;00m\n",
            "        y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(g.weight.grad.data.numpy() - f.weight.grad.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)) < \u001b[94m1e-3\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight gradients match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: weight gradients match\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(116.230255) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(116.230255) = <function norm at 0x78322a53a730>((array([[[[ 79.93022 ,  87.3443  ,  80.289635],\\n         [ 87.30202 ,  95.56033 ,  87.51378 ],\\n         [ 80.78572 ,  88.57339 ,  81.2233  ]],\\n\\n        [[ 84.81707 ,  89.75722 ,  81.571045],\\n         [ 91.54373 ,  96.68114 ,  88.38347 ],\\n         [ 86.73502 ,  91.7549  ,  83.5963  ]],\\n\\n        [[ 83.32764 ,  90.280136,  84.302246],\\n         [ 89.46042 ,  96.80132 ,  90.71945 ],\\n         [ 81.393616,  87.963295,  82.41632 ]],\\n\\n        [[ 92.9659  ,  97.72401 ,  90.675575],\\n         [100.07403 , 105.11012 ,  97.4841  ],\\n         [ 92.65256 ,  97.32118 ,  90.181435]],\\n\\n        [[ 87.82296 ,  96.152725,  87.96817 ],\\n         [ 95.518295, 104.36255 ,  95.37311 ],\\n         [ 89.02961 ,  97.843666,  89.64751 ]],\\n\\n        [[ 84.82327 ,  90.61053 ,  83.99675 ],\\n         [ 89.97626 ,  96.55199 ,  89.8309  ],\\n         [ 85.72036 ,  91.55585 ,  85.38164 ]],\\n\\n        [[ 86.28633 ,  92.985054,  85.67972 ],\\n         [ 92.02149 ,  99.59704 ,  92.13144 ],\\n         [ 84.76547 ,  91.58157 ,  84.38933 ]],\\n\\n        [[ 84.48213 ,  88.76176 ,  80.73366 ],\\n         [ 90.986115,  96.2476  ,  88.04338 ],\\n         [ 84.42231 ,  89.37884 ,  81.93542 ]]],\\n\\n\\n       [[[ 79.93022 ,  87.3443  ,  80.289635],\\n     ...84.42231 ,  89.37884 ,  81.93542 ]]],\\n\\n\\n       [[[ 79.93022 ,  87.3443  ,  80.289635],\\n         [ 87.30202 ,  95.56033 ,  87.51378 ],\\n         [ 80.78572 ,  88.57339 ,  81.2233  ]],\\n\\n        [[ 84.81707 ,  89.75722 ,  81.571045],\\n         [ 91.54373 ,  96.68114 ,  88.38347 ],\\n         [ 86.73502 ,  91.7549  ,  83.5963  ]],\\n\\n        [[ 83.32764 ,  90.280136,  84.302246],\\n         [ 89.46042 ,  96.80132 ,  90.71945 ],\\n         [ 81.393616,  87.963295,  82.41632 ]],\\n\\n        [[ 92.9659  ,  97.72401 ,  90.675575],\\n         [100.07403 , 105.11012 ,  97.4841  ],\\n         [ 92.65256 ,  97.32118 ,  90.181435]],\\n\\n        [[ 87.82296 ,  96.152725,  87.96817 ],\\n         [ 95.518295, 104.36255 ,  95.37311 ],\\n         [ 89.02961 ,  97.843666,  89.64751 ]],\\n\\n        [[ 84.82327 ,  90.61053 ,  83.99675 ],\\n         [ 89.97626 ,  96.55199 ,  89.8309  ],\\n         [ 85.72036 ,  91.55585 ,  85.38164 ]],\\n\\n        [[ 86.28633 ,  92.985054,  85.67972 ],\\n         [ 92.02149 ,  99.59704 ,  92.13144 ],\\n         [ 84.76547 ,  91.58157 ,  84.38933 ]],\\n\\n        [[ 84.48213 ,  88.76176 ,  80.73366 ],\\n         [ 90.986115,  96.2476  ,  88.04338 ],\\n         [ 84.42231 ,  89.37884 ,  81.93542 ]]]], dtype=float32) - array([[[[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]]],\\n\\n\\n       [[[ 87.32657 ,  93.74773 ,  86.81542 ],\\n     ...81.77759 ,  88.521095,  82.35074 ]]],\\n\\n\\n       [[[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]]]], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78322a53a730> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 79.93022 ,  87.3443  ,  80.289635],\\n         [ 87.30202 ,  95.56033 ,  87.51378 ],\\n         [ 80.78572 ,  88.57339 ,  81.2233  ]],\\n\\n        [[ 84.81707 ,  89.75722 ,  81.571045],\\n         [ 91.54373 ,  96.68114 ,  88.38347 ],\\n         [ 86.73502 ,  91.7549  ,  83.5963  ]],\\n\\n        [[ 83.32764 ,  90.280136,  84.302246],\\n         [ 89.46042 ,  96.80132 ,  90.71945 ],\\n         [ 81.393616,  87.963295,  82.41632 ]],\\n\\n        [[ 92.9659  ,  97.72401 ,  90.675575],\\n         [100.07403 , 105.11012 ,  97.4841  ],\\n         [ 92.65256 ,  97.32118 ,  90.181435]],\\n\\n        [[ 87.82296 ,  96.152725,  87.96817 ],\\n         [ 95.518295, 104.36255 ,  95.37311 ],\\n         [ 89.02961 ,  97.843666,  89.64751 ]],\\n\\n        [[ 84.82327 ,  90.61053 ,  83.99675 ],\\n         [ 89.97626 ,  96.55199 ,  89.8309  ],\\n         [ 85.72036 ,  91.55585 ,  85.38164 ]],\\n\\n        [[ 86.28633 ,  92.985054,  85.67972 ],\\n         [ 92.02149 ,  99.59704 ,  92.13144 ],\\n         [ 84.76547 ,  91.58157 ,  84.38933 ]],\\n\\n        [[ 84.48213 ,  88.76176 ,  80.73366 ],\\n         [ 90.986115,  96.2476  ,  88.04338 ],\\n         [ 84.42231 ,  89.37884 ,  81.93542 ]]],\\n\\n\\n       [[[ 79.93022 ,  87.3443  ,  80.289635],\\n     ...84.42231 ,  89.37884 ,  81.93542 ]]],\\n\\n\\n       [[[ 79.93022 ,  87.3443  ,  80.289635],\\n         [ 87.30202 ,  95.56033 ,  87.51378 ],\\n         [ 80.78572 ,  88.57339 ,  81.2233  ]],\\n\\n        [[ 84.81707 ,  89.75722 ,  81.571045],\\n         [ 91.54373 ,  96.68114 ,  88.38347 ],\\n         [ 86.73502 ,  91.7549  ,  83.5963  ]],\\n\\n        [[ 83.32764 ,  90.280136,  84.302246],\\n         [ 89.46042 ,  96.80132 ,  90.71945 ],\\n         [ 81.393616,  87.963295,  82.41632 ]],\\n\\n        [[ 92.9659  ,  97.72401 ,  90.675575],\\n         [100.07403 , 105.11012 ,  97.4841  ],\\n         [ 92.65256 ,  97.32118 ,  90.181435]],\\n\\n        [[ 87.82296 ,  96.152725,  87.96817 ],\\n         [ 95.518295, 104.36255 ,  95.37311 ],\\n         [ 89.02961 ,  97.843666,  89.64751 ]],\\n\\n        [[ 84.82327 ,  90.61053 ,  83.99675 ],\\n         [ 89.97626 ,  96.55199 ,  89.8309  ],\\n         [ 85.72036 ,  91.55585 ,  85.38164 ]],\\n\\n        [[ 86.28633 ,  92.985054,  85.67972 ],\\n         [ 92.02149 ,  99.59704 ,  92.13144 ],\\n         [ 84.76547 ,  91.58157 ,  84.38933 ]],\\n\\n        [[ 84.48213 ,  88.76176 ,  80.73366 ],\\n         [ 90.986115,  96.2476  ,  88.04338 ],\\n         [ 84.42231 ,  89.37884 ,  81.93542 ]]]], dtype=float32) = <built-in method numpy of Tensor object at 0x7831499fdae0>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x7831499fdae0> = tensor([[[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n          [ 91.5437,  96.6811,  88.3835],\\n          [ 86.7350,  91.7549,  83.5963]],\\n\\n         [[ 83.3276,  90.2801,  84.3022],\\n          [ 89.4604,  96.8013,  90.7195],\\n          [ 81.3936,  87.9633,  82.4163]],\\n\\n         [[ 92.9659,  97.7240,  90.6756],\\n          [100.0740, 105.1101,  97.4841],\\n          [ 92.6526,  97.3212,  90.1814]],\\n\\n         [[ 87.8230,  96.1527,  87.9682],\\n          [ 95.5183, 104.3625,  95.3731],\\n          [ 89.0296,  97.8437,  89.6475]],\\n\\n         [[ 84.8233,  90.6105,  83.9967],\\n          [ 89.9763,  96.5520,  89.8309],\\n          [ 85.7204,  91.5558,  85.3816]],\\n\\n         [[ 86.2863,  92.9851,  85.6797],\\n          [ 92.0215,  99.5970,  92.1314],\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]],\\n\\n\\n        [[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n  ...\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]],\\n\\n\\n        [[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n          [ 91.5437,  96.6811,  88.3835],\\n          [ 86.7350,  91.7549,  83.5963]],\\n\\n         [[ 83.3276,  90.2801,  84.3022],\\n          [ 89.4604,  96.8013,  90.7195],\\n          [ 81.3936,  87.9633,  82.4163]],\\n\\n         [[ 92.9659,  97.7240,  90.6756],\\n          [100.0740, 105.1101,  97.4841],\\n          [ 92.6526,  97.3212,  90.1814]],\\n\\n         [[ 87.8230,  96.1527,  87.9682],\\n          [ 95.5183, 104.3625,  95.3731],\\n          [ 89.0296,  97.8437,  89.6475]],\\n\\n         [[ 84.8233,  90.6105,  83.9967],\\n          [ 89.9763,  96.5520,  89.8309],\\n          [ 85.7204,  91.5558,  85.3816]],\\n\\n         [[ 86.2863,  92.9851,  85.6797],\\n          [ 92.0215,  99.5970,  92.1314],\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n          [ 91.5437,  96.6811,  88.3835],\\n          [ 86.7350,  91.7549,  83.5963]],\\n\\n         [[ 83.3276,  90.2801,  84.3022],\\n          [ 89.4604,  96.8013,  90.7195],\\n          [ 81.3936,  87.9633,  82.4163]],\\n\\n         [[ 92.9659,  97.7240,  90.6756],\\n          [100.0740, 105.1101,  97.4841],\\n          [ 92.6526,  97.3212,  90.1814]],\\n\\n         [[ 87.8230,  96.1527,  87.9682],\\n          [ 95.5183, 104.3625,  95.3731],\\n          [ 89.0296,  97.8437,  89.6475]],\\n\\n         [[ 84.8233,  90.6105,  83.9967],\\n          [ 89.9763,  96.5520,  89.8309],\\n          [ 85.7204,  91.5558,  85.3816]],\\n\\n         [[ 86.2863,  92.9851,  85.6797],\\n          [ 92.0215,  99.5970,  92.1314],\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]],\\n\\n\\n        [[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n  ...\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]],\\n\\n\\n        [[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n          [ 91.5437,  96.6811,  88.3835],\\n          [ 86.7350,  91.7549,  83.5963]],\\n\\n         [[ 83.3276,  90.2801,  84.3022],\\n          [ 89.4604,  96.8013,  90.7195],\\n          [ 81.3936,  87.9633,  82.4163]],\\n\\n         [[ 92.9659,  97.7240,  90.6756],\\n          [100.0740, 105.1101,  97.4841],\\n          [ 92.6526,  97.3212,  90.1814]],\\n\\n         [[ 87.8230,  96.1527,  87.9682],\\n          [ 95.5183, 104.3625,  95.3731],\\n          [ 89.0296,  97.8437,  89.6475]],\\n\\n         [[ 84.8233,  90.6105,  83.9967],\\n          [ 89.9763,  96.5520,  89.8309],\\n          [ 85.7204,  91.5558,  85.3816]],\\n\\n         [[ 86.2863,  92.9851,  85.6797],\\n          [ 92.0215,  99.5970,  92.1314],\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]]]) = tensor([[[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n          [ 91.5437,  96.6811,  88.3835],\\n          [ 86.7350,  91.7549,  83.5963]],\\n\\n         [[ 83.3276,  90.2801,  84.3022],\\n          [ 89.4604,  96.8013,  90.7195],\\n          [ 81.3936,  87.9633,  82.4163]],\\n\\n         [[ 92.9659,  97.7240,  90.6756],\\n          [100.0740, 105.1101,  97.4841],\\n          [ 92.6526,  97.3212,  90.1814]],\\n\\n         [[ 87.8230,  96.1527,  87.9682],\\n          [ 95.5183, 104.3625,  95.3731],\\n          [ 89.0296,  97.8437,  89.6475]],\\n\\n         [[ 84.8233,  90.6105,  83.9967],\\n          [ 89.9763,  96.5520,  89.8309],\\n          [ 85.7204,  91.5558,  85.3816]],\\n\\n         [[ 86.2863,  92.9851,  85.6797],\\n          [ 92.0215,  99.5970,  92.1314],\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]],\\n\\n\\n        [[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n  ...\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]],\\n\\n\\n        [[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n          [ 91.5437,  96.6811,  88.3835],\\n          [ 86.7350,  91.7549,  83.5963]],\\n\\n         [[ 83.3276,  90.2801,  84.3022],\\n          [ 89.4604,  96.8013,  90.7195],\\n          [ 81.3936,  87.9633,  82.4163]],\\n\\n         [[ 92.9659,  97.7240,  90.6756],\\n          [100.0740, 105.1101,  97.4841],\\n          [ 92.6526,  97.3212,  90.1814]],\\n\\n         [[ 87.8230,  96.1527,  87.9682],\\n          [ 95.5183, 104.3625,  95.3731],\\n          [ 89.0296,  97.8437,  89.6475]],\\n\\n         [[ 84.8233,  90.6105,  83.9967],\\n          [ 89.9763,  96.5520,  89.8309],\\n          [ 85.7204,  91.5558,  85.3816]],\\n\\n         [[ 86.2863,  92.9851,  85.6797],\\n          [ 92.0215,  99.5970,  92.1314],\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]]]).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n          [ 91.5437,  96.6811,  88.3835],\\n          [ 86.7350,  91.7549,  83.5963]],\\n\\n         [[ 83.3276,  90.2801,  84.3022],\\n          [ 89.4604,  96.8013,  90.7195],\\n          [ 81.3936,  87.9633,  82.4163]],\\n\\n         [[ 92.9659,  97.7240,  90.6756],\\n          [100.0740, 105.1101,  97.4841],\\n          [ 92.6526,  97.3212,  90.1814]],\\n\\n         [[ 87.8230,  96.1527,  87.9682],\\n          [ 95.5183, 104.3625,  95.3731],\\n          [ 89.0296,  97.8437,  89.6475]],\\n\\n         [[ 84.8233,  90.6105,  83.9967],\\n          [ 89.9763,  96.5520,  89.8309],\\n          [ 85.7204,  91.5558,  85.3816]],\\n\\n         [[ 86.2863,  92.9851,  85.6797],\\n          [ 92.0215,  99.5970,  92.1314],\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]],\\n\\n\\n        [[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n  ...\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]],\\n\\n\\n        [[[ 79.9302,  87.3443,  80.2896],\\n          [ 87.3020,  95.5603,  87.5138],\\n          [ 80.7857,  88.5734,  81.2233]],\\n\\n         [[ 84.8171,  89.7572,  81.5710],\\n          [ 91.5437,  96.6811,  88.3835],\\n          [ 86.7350,  91.7549,  83.5963]],\\n\\n         [[ 83.3276,  90.2801,  84.3022],\\n          [ 89.4604,  96.8013,  90.7195],\\n          [ 81.3936,  87.9633,  82.4163]],\\n\\n         [[ 92.9659,  97.7240,  90.6756],\\n          [100.0740, 105.1101,  97.4841],\\n          [ 92.6526,  97.3212,  90.1814]],\\n\\n         [[ 87.8230,  96.1527,  87.9682],\\n          [ 95.5183, 104.3625,  95.3731],\\n          [ 89.0296,  97.8437,  89.6475]],\\n\\n         [[ 84.8233,  90.6105,  83.9967],\\n          [ 89.9763,  96.5520,  89.8309],\\n          [ 85.7204,  91.5558,  85.3816]],\\n\\n         [[ 86.2863,  92.9851,  85.6797],\\n          [ 92.0215,  99.5970,  92.1314],\\n          [ 84.7655,  91.5816,  84.3893]],\\n\\n         [[ 84.4821,  88.7618,  80.7337],\\n          [ 90.9861,  96.2476,  88.0434],\\n          [ 84.4223,  89.3788,  81.9354]]]]) = Parameter containing:\\ntensor([[[[ 0.0282, -0.1752,  0.0925],\\n          [-0.1812,  0.0301, -0.1326],\\n          [ 0.1852,  0.2708,  0.1386]],\\n\\n         [[ 0.2677,  0.2753,  0.0429],\\n          [-0.1087,  0.0981, -0.1250],\\n          [-0.1393,  0.1096,  0.0252]],\\n\\n         [[-0.2770, -0.1051,  0.1768],\\n          [ 0.0211, -0.0934, -0.1389],\\n          [-0.0570, -0.1514, -0.2370]],\\n\\n         [[-0.2204,  0.0438, -0.1949],\\n          [-0.1039, -0.1195,  0.1731],\\n          [ 0.0661,  0.0774,  0.0445]],\\n\\n         [[-0.0253,  0.0499,  0.1140],\\n          [-0.1815, -0.0015, -0.0402],\\n          [-0.2130, -0.2478,  0.2672]],\\n\\n         [[-0.0811, -0.1451,  0.1328],\\n          [ 0.0105, -0.2322, -0.1806],\\n          [ 0.0801,  0.2701, -0.0335]],\\n\\n         [[-0.1066,  0.1152, -0.0893],\\n          [ 0.2101, -0.0536,  0.2333],\\n          [-0.1466, -0.0257,  0.0686]],\\n\\n         [[ 0.0884,  0.1301,  0.2507],\\n          [-0.2050, -0.2428,  0.1711],\\n          [-0.0805, -0.0961,  0.1905]]],\\n\\n\\n        [[[ 0.1242, -0.0758, -0.1212],\\n          [ 0.2566,  0.0488, -0.2128],\\n          [ 0.2360,  0.2338,  0.1042]],\\n\\n         [[-0.0673,  0.0605,  0.0885],\\n          [ 0.1134,  0.1646, -0.0693],\\n          [ 0.2015, -0.25....1681,  0.2204,  0.0446],\\n          [ 0.0378,  0.1562, -0.1501],\\n          [ 0.1193,  0.0144,  0.0239]],\\n\\n         [[ 0.0903, -0.2776, -0.0588],\\n          [ 0.2331,  0.2082,  0.2609],\\n          [ 0.1818, -0.2283,  0.2610]]],\\n\\n\\n        [[[ 0.2262, -0.0181,  0.0525],\\n          [-0.0379,  0.2480,  0.1129],\\n          [-0.0439, -0.1539,  0.2190]],\\n\\n         [[-0.2384, -0.2201,  0.2263],\\n          [-0.0267,  0.2174,  0.1602],\\n          [-0.1817,  0.1436,  0.2437]],\\n\\n         [[ 0.1620, -0.2344,  0.2125],\\n          [ 0.1492,  0.2161, -0.2629],\\n          [-0.1543,  0.2555, -0.2219]],\\n\\n         [[ 0.1583, -0.1829, -0.2487],\\n          [ 0.1721, -0.0125, -0.2683],\\n          [-0.1425, -0.0278,  0.0512]],\\n\\n         [[ 0.1050,  0.2668, -0.0808],\\n          [-0.1655, -0.1592,  0.2635],\\n          [-0.1946,  0.2283, -0.2325]],\\n\\n         [[-0.2142,  0.2000, -0.1594],\\n          [ 0.0501, -0.2419, -0.0583],\\n          [ 0.0938, -0.1318,  0.2234]],\\n\\n         [[-0.1955,  0.1112, -0.1513],\\n          [-0.1829, -0.2038, -0.1960],\\n          [-0.0492,  0.1447,  0.2444]],\\n\\n         [[-0.2089, -0.1146, -0.1675],\\n          [-0.2405,  0.1311,  0.0437],\\n          [ 0.2803, -0.0875, -0.1155]]]], requires_grad=True).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where Parameter containing:\\ntensor([[[[ 0.0282, -0.1752,  0.0925],\\n          [-0.1812,  0.0301, -0.1326],\\n          [ 0.1852,  0.2708,  0.1386]],\\n\\n         [[ 0.2677,  0.2753,  0.0429],\\n          [-0.1087,  0.0981, -0.1250],\\n          [-0.1393,  0.1096,  0.0252]],\\n\\n         [[-0.2770, -0.1051,  0.1768],\\n          [ 0.0211, -0.0934, -0.1389],\\n          [-0.0570, -0.1514, -0.2370]],\\n\\n         [[-0.2204,  0.0438, -0.1949],\\n          [-0.1039, -0.1195,  0.1731],\\n          [ 0.0661,  0.0774,  0.0445]],\\n\\n         [[-0.0253,  0.0499,  0.1140],\\n          [-0.1815, -0.0015, -0.0402],\\n          [-0.2130, -0.2478,  0.2672]],\\n\\n         [[-0.0811, -0.1451,  0.1328],\\n          [ 0.0105, -0.2322, -0.1806],\\n          [ 0.0801,  0.2701, -0.0335]],\\n\\n         [[-0.1066,  0.1152, -0.0893],\\n          [ 0.2101, -0.0536,  0.2333],\\n          [-0.1466, -0.0257,  0.0686]],\\n\\n         [[ 0.0884,  0.1301,  0.2507],\\n          [-0.2050, -0.2428,  0.1711],\\n          [-0.0805, -0.0961,  0.1905]]],\\n\\n\\n        [[[ 0.1242, -0.0758, -0.1212],\\n          [ 0.2566,  0.0488, -0.2128],\\n          [ 0.2360,  0.2338,  0.1042]],\\n\\n         [[-0.0673,  0.0605,  0.0885],\\n          [ 0.1134,  0.1646, -0.0693],\\n          [ 0.2015, -0.25....1681,  0.2204,  0.0446],\\n          [ 0.0378,  0.1562, -0.1501],\\n          [ 0.1193,  0.0144,  0.0239]],\\n\\n         [[ 0.0903, -0.2776, -0.0588],\\n          [ 0.2331,  0.2082,  0.2609],\\n          [ 0.1818, -0.2283,  0.2610]]],\\n\\n\\n        [[[ 0.2262, -0.0181,  0.0525],\\n          [-0.0379,  0.2480,  0.1129],\\n          [-0.0439, -0.1539,  0.2190]],\\n\\n         [[-0.2384, -0.2201,  0.2263],\\n          [-0.0267,  0.2174,  0.1602],\\n          [-0.1817,  0.1436,  0.2437]],\\n\\n         [[ 0.1620, -0.2344,  0.2125],\\n          [ 0.1492,  0.2161, -0.2629],\\n          [-0.1543,  0.2555, -0.2219]],\\n\\n         [[ 0.1583, -0.1829, -0.2487],\\n          [ 0.1721, -0.0125, -0.2683],\\n          [-0.1425, -0.0278,  0.0512]],\\n\\n         [[ 0.1050,  0.2668, -0.0808],\\n          [-0.1655, -0.1592,  0.2635],\\n          [-0.1946,  0.2283, -0.2325]],\\n\\n         [[-0.2142,  0.2000, -0.1594],\\n          [ 0.0501, -0.2419, -0.0583],\\n          [ 0.0938, -0.1318,  0.2234]],\\n\\n         [[-0.1955,  0.1112, -0.1513],\\n          [-0.1829, -0.2038, -0.1960],\\n          [-0.0492,  0.1447,  0.2444]],\\n\\n         [[-0.2089, -0.1146, -0.1675],\\n          [-0.2405,  0.1311,  0.0437],\\n          [ 0.2803, -0.0875, -0.1155]]]], requires_grad=True) = Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).weight\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]],\\n\\n        [[ 83.16145 ,  89.44839 ,  83.004715],\\n         [ 89.841934,  96.79709 ,  90.01331 ],\\n         [ 83.11498 ,  89.09081 ,  83.00351 ]]],\\n\\n\\n       [[[ 87.32657 ,  93.74773 ,  86.81542 ],\\n     ...81.77759 ,  88.521095,  82.35074 ]]],\\n\\n\\n       [[[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]],\\n\\n        [[ 86.88946 ,  93.12273 ,  88.01287 ],\\n         [ 92.09468 ,  99.30981 ,  93.90911 ],\\n         [ 85.085434,  92.00141 ,  86.911644]]]], dtype=float32) = <built-in method transpose of numpy.ndarray object at 0x78314a6bddd0>(3, 2, 0, 1)\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method transpose of numpy.ndarray object at 0x78314a6bddd0> = array([[[[ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ]],\\n\\n        [[ 89.44839 ,  93.74773 ,  89.28964 ,  96.32932 ,  90.022354,\\n           97.35872 ,  87.51475 ,  93.12273 ],\\n         [ 89.44839 ,  93.74773 ,  89.28964 ,  96.32932 ,  90.022354,\\n           97.35872 ,  87.51475 ,  93.12273 ],\\n         [ 89.44839 ,  93.....00141 ],\\n         [ 89.09081 ,  93.117905,  88.53703 ,  96.20398 ,  89.72101 ,\\n           98.45228 ,  88.521095,  92.00141 ],\\n         [ 89.09081 ,  93.117905,  88.53703 ,  96.20398 ,  89.72101 ,\\n           98.45228 ,  88.521095,  92.00141 ]],\\n\\n        [[ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644]]]], dtype=float32).transpose\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where array([[[[ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ],\\n         [ 83.16145 ,  87.32657 ,  82.92851 ,  89.24472 ,  84.19341 ,\\n           87.90947 ,  81.27193 ,  86.88946 ]],\\n\\n        [[ 89.44839 ,  93.74773 ,  89.28964 ,  96.32932 ,  90.022354,\\n           97.35872 ,  87.51475 ,  93.12273 ],\\n         [ 89.44839 ,  93.74773 ,  89.28964 ,  96.32932 ,  90.022354,\\n           97.35872 ,  87.51475 ,  93.12273 ],\\n         [ 89.44839 ,  93.....00141 ],\\n         [ 89.09081 ,  93.117905,  88.53703 ,  96.20398 ,  89.72101 ,\\n           98.45228 ,  88.521095,  92.00141 ],\\n         [ 89.09081 ,  93.117905,  88.53703 ,  96.20398 ,  89.72101 ,\\n           98.45228 ,  88.521095,  92.00141 ]],\\n\\n        [[ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644],\\n         [ 83.00351 ,  85.54931 ,  81.19985 ,  88.4729  ,  82.82524 ,\\n           92.65146 ,  82.35074 ,  86.911644]]]], dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where numpy = NDArray([[[[ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]]\\n\\n  [[ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964 ...     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]]\\n\\n  [[ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where NDArray([[[[ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]]\\n\\n  [[ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964 ...     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]]\\n\\n  [[ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]]]], device=cuda()) = needle.Tensor([[[[ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]]\\n\\n  [[ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89....101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]]\\n\\n  [[ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +              where needle.Tensor([[[[ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]\\n   [ 83.16145   87.32657   82.92851   89.24472   84.19341   87.90947\\n     81.27193   86.88946 ]]\\n\\n  [[ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89.28964   96.32932   90.022354  97.35872\\n     87.51475   93.12273 ]\\n   [ 89.44839   93.74773   89....101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]\\n   [ 89.09081   93.117905  88.53703   96.20398   89.72101   98.45228\\n     88.521095  92.00141 ]]\\n\\n  [[ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]\\n   [ 83.00351   85.54931   81.19985   88.4729    82.82524   92.65146\\n     82.35074   86.911644]]]]) = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\\n     0.084232   -0.03603405  0.22619021]\\n   [ 0.26769578 -0.06729507  0.16842753  0.01668248  0.03928554\\n     0.24571836 -0.24766244 -0.238371  ]\\n   [-0.27700204  0.19203815  0.16059387  0.21362662  0.2763304\\n     0.17271927 -0.02223989  0.16196361]\\n   [-0.22038937  0.08078343 -0.20591007  0.25672972  0.01261413\\n    -0.04926994 -0.13593388  0.15832889]\\n   [-0.02531663  0.03951034 -0.27782685  0.06791687  0.06471848\\n     0.06751189  0.25619805  0.10497397]\\n   [-0.08111316 -0.03635463  0.11410242 -0.25390393  0.09628281\\n     0.09851781 -0.1672107  -0.21423951]\\n   [-0.1065625  -0.07868662  0.04052812 -0.03544843  0.28196275\\n    -0.22975953 -0.16808008 -0.19554305]\\n   [ 0.08839712 -0.14243716 -0.01945049 -0.14755595 -0.19689399\\n    -0.22495002  0.09025693 -0.20889518]]\\n\\n  [[-0.17517826 -0.07579155  0.18532553 -0.23261368  0.19511259\\n    -0.23319268  0.27508396 -0.01809925]\\n   [ 0.27525812  0.0605326   0.13813889 -0.26605004 -0.12539646\\n    -0.21927962 -0.11769851 -0.22012764]\\n   [-0.10508746 -0.04950029 -0.25163954  0.11112383  0.03845236\\n    -0.13545243  0.01342228 -0.23443855]\\n   [ 0.04384774  0.24785429 ...   0.06011245 -0.06766079  0.22827613]\\n   [ 0.27008134  0.027069   -0.13000567  0.05324927  0.22907019\\n    -0.05384754  0.03006738 -0.13183634]\\n   [-0.02572432 -0.05674571 -0.14525355  0.00338697 -0.10947669\\n    -0.07330336  0.01441669  0.1446811 ]\\n   [-0.0961245   0.24488819  0.20918474 -0.26056376 -0.14223455\\n    -0.03109866 -0.22826819 -0.08748242]]\\n\\n  [[ 0.13862038  0.10422006  0.07065868  0.12154862 -0.17036238\\n    -0.09139563  0.10175362  0.21895128]\\n   [ 0.02521753 -0.12545842 -0.2712188   0.121438   -0.28412324\\n    -0.07350877  0.01763067  0.24370617]\\n   [-0.23700543 -0.05430423 -0.2746379  -0.09086859  0.07057014\\n    -0.12755519 -0.16757594 -0.22187383]\\n   [ 0.04453695  0.11273918  0.09927949  0.25915003 -0.28711444\\n     0.08498403  0.05796146  0.05123386]\\n   [ 0.26718056 -0.27893427  0.11343917  0.18110242  0.00566217\\n    -0.09586042  0.16791663 -0.2325319 ]\\n   [-0.03346574  0.01151949  0.1119808  -0.23620223 -0.15717812\\n    -0.05178742  0.07118419  0.22341192]\\n   [ 0.06860432 -0.2116211   0.27746308  0.21465063  0.00157085\\n     0.24384272  0.02389124  0.24439585]\\n   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\\n    -0.06400812  0.26104474 -0.11545335]]]]).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +                where needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\\n     0.084232   -0.03603405  0.22619021]\\n   [ 0.26769578 -0.06729507  0.16842753  0.01668248  0.03928554\\n     0.24571836 -0.24766244 -0.238371  ]\\n   [-0.27700204  0.19203815  0.16059387  0.21362662  0.2763304\\n     0.17271927 -0.02223989  0.16196361]\\n   [-0.22038937  0.08078343 -0.20591007  0.25672972  0.01261413\\n    -0.04926994 -0.13593388  0.15832889]\\n   [-0.02531663  0.03951034 -0.27782685  0.06791687  0.06471848\\n     0.06751189  0.25619805  0.10497397]\\n   [-0.08111316 -0.03635463  0.11410242 -0.25390393  0.09628281\\n     0.09851781 -0.1672107  -0.21423951]\\n   [-0.1065625  -0.07868662  0.04052812 -0.03544843  0.28196275\\n    -0.22975953 -0.16808008 -0.19554305]\\n   [ 0.08839712 -0.14243716 -0.01945049 -0.14755595 -0.19689399\\n    -0.22495002  0.09025693 -0.20889518]]\\n\\n  [[-0.17517826 -0.07579155  0.18532553 -0.23261368  0.19511259\\n    -0.23319268  0.27508396 -0.01809925]\\n   [ 0.27525812  0.0605326   0.13813889 -0.26605004 -0.12539646\\n    -0.21927962 -0.11769851 -0.22012764]\\n   [-0.10508746 -0.04950029 -0.25163954  0.11112383  0.03845236\\n    -0.13545243  0.01342228 -0.23443855]\\n   [ 0.04384774  0.24785429 ...   0.06011245 -0.06766079  0.22827613]\\n   [ 0.27008134  0.027069   -0.13000567  0.05324927  0.22907019\\n    -0.05384754  0.03006738 -0.13183634]\\n   [-0.02572432 -0.05674571 -0.14525355  0.00338697 -0.10947669\\n    -0.07330336  0.01441669  0.1446811 ]\\n   [-0.0961245   0.24488819  0.20918474 -0.26056376 -0.14223455\\n    -0.03109866 -0.22826819 -0.08748242]]\\n\\n  [[ 0.13862038  0.10422006  0.07065868  0.12154862 -0.17036238\\n    -0.09139563  0.10175362  0.21895128]\\n   [ 0.02521753 -0.12545842 -0.2712188   0.121438   -0.28412324\\n    -0.07350877  0.01763067  0.24370617]\\n   [-0.23700543 -0.05430423 -0.2746379  -0.09086859  0.07057014\\n    -0.12755519 -0.16757594 -0.22187383]\\n   [ 0.04453695  0.11273918  0.09927949  0.25915003 -0.28711444\\n     0.08498403  0.05796146  0.05123386]\\n   [ 0.26718056 -0.27893427  0.11343917  0.18110242  0.00566217\\n    -0.09586042  0.16791663 -0.2325319 ]\\n   [-0.03346574  0.01151949  0.1119808  -0.23620223 -0.15717812\\n    -0.05178742  0.07118419  0.22341192]\\n   [ 0.06860432 -0.2116211   0.27746308  0.21465063  0.00157085\\n     0.24384272  0.02389124  0.24439585]\\n   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\\n    -0.06400812  0.26104474 -0.11545335]]]]) = <needle.nn.nn_conv.Conv object at 0x78314a4edfd0>.weight\u001b[0m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78314a4edfd0>\n",
            "g          = Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "res1       = needle.Tensor([[[[-0.11583248 -0.49519646 -0.23480628 ... -0.06405671 -0.5332113\n",
            "    -0.33647496]\n",
            "   [ 0.37672508 -1.0...453 -0.6852877\n",
            "    -0.47658247]\n",
            "   [-0.18230447  0.31664866 -0.34592256 ... -0.67866325 -0.6537609\n",
            "    -0.43064725]]]])\n",
            "s          = 14\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[6.96463168e-01 2.47398749e-01 3.96155231e-02 ... 9.97962236e-01\n",
            "    3.62189054e-01 4.70648944e-01]\n",
            " ...3395844e-01]\n",
            "   [1.76103845e-01 3.19807321e-01 8.16825151e-01 ... 5.61398745e-01\n",
            "    7.13245988e-01 9.81864214e-01]]]])\n",
            "y1         = needle.Tensor([-63.547318])\n",
            "y2         = tensor(-80.9834, grad_fn=<SumBackward0>)\n",
            "z          = tensor([[[[6.9646e-01, 2.4740e-01, 3.9616e-02,  ..., 9.9796e-01,\n",
            "           3.6219e-01, 4.7065e-01],\n",
            "          [3.7825...      [1.7610e-01, 3.1981e-01, 8.1683e-01,  ..., 5.6140e-01,\n",
            "           7.1325e-01, 9.8186e-01]]]], requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:391: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 8, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "        y1 = res1.sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y2 = g(z).sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y1.backward()\u001b[90m\u001b[39;49;00m\n",
            "        y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(g.weight.grad.data.numpy() - f.weight.grad.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)) < \u001b[94m1e-3\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight gradients match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: weight gradients match\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(67.58539) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(67.58539) = <function norm at 0x78322a53a730>((array([[[[16.398285 , 18.88338  , 19.63617  ],\\n         [20.26262  , 24.385939 , 24.438812 ],\\n         [18.765879 , 23.887589 , 22.847998 ]],\\n\\n        [[18.347052 , 21.939808 , 20.654964 ],\\n         [19.855345 , 24.674868 , 22.487576 ],\\n         [21.414335 , 25.59919  , 23.919508 ]],\\n\\n        [[18.544558 , 20.203562 , 21.526855 ],\\n         [22.826117 , 21.753399 , 26.796322 ],\\n         [21.60431  , 23.276594 , 24.975012 ]],\\n\\n        [[18.003235 , 27.064001 , 19.706137 ],\\n         [24.538776 , 23.359884 , 27.593983 ],\\n         [21.193579 , 30.981787 , 23.17447  ]],\\n\\n        [[17.832214 , 19.672144 , 21.351372 ],\\n         [24.496307 , 25.822298 , 29.306927 ],\\n         [22.085352 , 23.114342 , 26.11899  ]],\\n\\n        [[17.893463 , 23.779293 , 20.077415 ],\\n         [20.14108  , 23.00944  , 23.744387 ],\\n         [20.181572 , 26.64417  , 23.153992 ]],\\n\\n        [[17.388515 , 22.271631 , 20.587475 ],\\n         [22.21822  , 24.407965 , 25.71799  ],\\n         [20.551495 , 24.843813 , 24.627275 ]],\\n\\n        [[15.3762245, 22.102552 , 17.574675 ],\\n         [22.030586 , 24.972769 , 24.111757 ],\\n         [18.024008 , 25.958748 , 21.204323 ]]],\\n\\n\\n       [[[16.398285 , 18.88338  , 19.63617  ],\\n     ...8.024008 , 25.958748 , 21.204323 ]]],\\n\\n\\n       [[[16.398285 , 18.88338  , 19.63617  ],\\n         [20.26262  , 24.385939 , 24.438812 ],\\n         [18.765879 , 23.887589 , 22.847998 ]],\\n\\n        [[18.347052 , 21.939808 , 20.654964 ],\\n         [19.855345 , 24.674868 , 22.487576 ],\\n         [21.414335 , 25.59919  , 23.919508 ]],\\n\\n        [[18.544558 , 20.203562 , 21.526855 ],\\n         [22.826117 , 21.753399 , 26.796322 ],\\n         [21.60431  , 23.276594 , 24.975012 ]],\\n\\n        [[18.003235 , 27.064001 , 19.706137 ],\\n         [24.538776 , 23.359884 , 27.593983 ],\\n         [21.193579 , 30.981787 , 23.17447  ]],\\n\\n        [[17.832214 , 19.672144 , 21.351372 ],\\n         [24.496307 , 25.822298 , 29.306927 ],\\n         [22.085352 , 23.114342 , 26.11899  ]],\\n\\n        [[17.893463 , 23.779293 , 20.077415 ],\\n         [20.14108  , 23.00944  , 23.744387 ],\\n         [20.181572 , 26.64417  , 23.153992 ]],\\n\\n        [[17.388515 , 22.271631 , 20.587475 ],\\n         [22.21822  , 24.407965 , 25.71799  ],\\n         [20.551495 , 24.843813 , 24.627275 ]],\\n\\n        [[15.3762245, 22.102552 , 17.574675 ],\\n         [22.030586 , 24.972769 , 24.111757 ],\\n         [18.024008 , 25.958748 , 21.204323 ]]]], dtype=float32) - array([[[[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]]],\\n\\n\\n       [[[17.942469, 23.47784 , 21.346975],\\n         [20.680706, 25.225534, 23.697355],\\n         [20.354874, 27.875105, 24.3...600298, 18.45599 ],\\n         [22.806627, 23.433294, 26.025187],\\n         [18.585415, 22.577991, 22.558968]]],\\n\\n\\n       [[[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]]]], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78322a53a730> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[16.398285 , 18.88338  , 19.63617  ],\\n         [20.26262  , 24.385939 , 24.438812 ],\\n         [18.765879 , 23.887589 , 22.847998 ]],\\n\\n        [[18.347052 , 21.939808 , 20.654964 ],\\n         [19.855345 , 24.674868 , 22.487576 ],\\n         [21.414335 , 25.59919  , 23.919508 ]],\\n\\n        [[18.544558 , 20.203562 , 21.526855 ],\\n         [22.826117 , 21.753399 , 26.796322 ],\\n         [21.60431  , 23.276594 , 24.975012 ]],\\n\\n        [[18.003235 , 27.064001 , 19.706137 ],\\n         [24.538776 , 23.359884 , 27.593983 ],\\n         [21.193579 , 30.981787 , 23.17447  ]],\\n\\n        [[17.832214 , 19.672144 , 21.351372 ],\\n         [24.496307 , 25.822298 , 29.306927 ],\\n         [22.085352 , 23.114342 , 26.11899  ]],\\n\\n        [[17.893463 , 23.779293 , 20.077415 ],\\n         [20.14108  , 23.00944  , 23.744387 ],\\n         [20.181572 , 26.64417  , 23.153992 ]],\\n\\n        [[17.388515 , 22.271631 , 20.587475 ],\\n         [22.21822  , 24.407965 , 25.71799  ],\\n         [20.551495 , 24.843813 , 24.627275 ]],\\n\\n        [[15.3762245, 22.102552 , 17.574675 ],\\n         [22.030586 , 24.972769 , 24.111757 ],\\n         [18.024008 , 25.958748 , 21.204323 ]]],\\n\\n\\n       [[[16.398285 , 18.88338  , 19.63617  ],\\n     ...8.024008 , 25.958748 , 21.204323 ]]],\\n\\n\\n       [[[16.398285 , 18.88338  , 19.63617  ],\\n         [20.26262  , 24.385939 , 24.438812 ],\\n         [18.765879 , 23.887589 , 22.847998 ]],\\n\\n        [[18.347052 , 21.939808 , 20.654964 ],\\n         [19.855345 , 24.674868 , 22.487576 ],\\n         [21.414335 , 25.59919  , 23.919508 ]],\\n\\n        [[18.544558 , 20.203562 , 21.526855 ],\\n         [22.826117 , 21.753399 , 26.796322 ],\\n         [21.60431  , 23.276594 , 24.975012 ]],\\n\\n        [[18.003235 , 27.064001 , 19.706137 ],\\n         [24.538776 , 23.359884 , 27.593983 ],\\n         [21.193579 , 30.981787 , 23.17447  ]],\\n\\n        [[17.832214 , 19.672144 , 21.351372 ],\\n         [24.496307 , 25.822298 , 29.306927 ],\\n         [22.085352 , 23.114342 , 26.11899  ]],\\n\\n        [[17.893463 , 23.779293 , 20.077415 ],\\n         [20.14108  , 23.00944  , 23.744387 ],\\n         [20.181572 , 26.64417  , 23.153992 ]],\\n\\n        [[17.388515 , 22.271631 , 20.587475 ],\\n         [22.21822  , 24.407965 , 25.71799  ],\\n         [20.551495 , 24.843813 , 24.627275 ]],\\n\\n        [[15.3762245, 22.102552 , 17.574675 ],\\n         [22.030586 , 24.972769 , 24.111757 ],\\n         [18.024008 , 25.958748 , 21.204323 ]]]], dtype=float32) = <built-in method numpy of Tensor object at 0x7831499fe940>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x7831499fe940> = tensor([[[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n         [[18.5446, 20.2036, 21.5269],\\n          [22.8261, 21.7534, 26.7963],\\n          [21.6043, 23.2766, 24.9750]],\\n\\n         [[18.0032, 27.0640, 19.7061],\\n          [24.5388, 23.3599, 27.5940],\\n          [21.1936, 30.9818, 23.1745]],\\n\\n         [[17.8322, 19.6721, 21.3514],\\n          [24.4963, 25.8223, 29.3069],\\n          [22.0854, 23.1143, 26.1190]],\\n\\n         [[17.8935, 23.7793, 20.0774],\\n          [20.1411, 23.0094, 23.7444],\\n          [20.1816, 26.6442, 23.1540]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]],\\n\\n\\n        [[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n      ...40]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]],\\n\\n\\n        [[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n         [[18.5446, 20.2036, 21.5269],\\n          [22.8261, 21.7534, 26.7963],\\n          [21.6043, 23.2766, 24.9750]],\\n\\n         [[18.0032, 27.0640, 19.7061],\\n          [24.5388, 23.3599, 27.5940],\\n          [21.1936, 30.9818, 23.1745]],\\n\\n         [[17.8322, 19.6721, 21.3514],\\n          [24.4963, 25.8223, 29.3069],\\n          [22.0854, 23.1143, 26.1190]],\\n\\n         [[17.8935, 23.7793, 20.0774],\\n          [20.1411, 23.0094, 23.7444],\\n          [20.1816, 26.6442, 23.1540]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n         [[18.5446, 20.2036, 21.5269],\\n          [22.8261, 21.7534, 26.7963],\\n          [21.6043, 23.2766, 24.9750]],\\n\\n         [[18.0032, 27.0640, 19.7061],\\n          [24.5388, 23.3599, 27.5940],\\n          [21.1936, 30.9818, 23.1745]],\\n\\n         [[17.8322, 19.6721, 21.3514],\\n          [24.4963, 25.8223, 29.3069],\\n          [22.0854, 23.1143, 26.1190]],\\n\\n         [[17.8935, 23.7793, 20.0774],\\n          [20.1411, 23.0094, 23.7444],\\n          [20.1816, 26.6442, 23.1540]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]],\\n\\n\\n        [[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n      ...40]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]],\\n\\n\\n        [[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n         [[18.5446, 20.2036, 21.5269],\\n          [22.8261, 21.7534, 26.7963],\\n          [21.6043, 23.2766, 24.9750]],\\n\\n         [[18.0032, 27.0640, 19.7061],\\n          [24.5388, 23.3599, 27.5940],\\n          [21.1936, 30.9818, 23.1745]],\\n\\n         [[17.8322, 19.6721, 21.3514],\\n          [24.4963, 25.8223, 29.3069],\\n          [22.0854, 23.1143, 26.1190]],\\n\\n         [[17.8935, 23.7793, 20.0774],\\n          [20.1411, 23.0094, 23.7444],\\n          [20.1816, 26.6442, 23.1540]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]]]) = tensor([[[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n         [[18.5446, 20.2036, 21.5269],\\n          [22.8261, 21.7534, 26.7963],\\n          [21.6043, 23.2766, 24.9750]],\\n\\n         [[18.0032, 27.0640, 19.7061],\\n          [24.5388, 23.3599, 27.5940],\\n          [21.1936, 30.9818, 23.1745]],\\n\\n         [[17.8322, 19.6721, 21.3514],\\n          [24.4963, 25.8223, 29.3069],\\n          [22.0854, 23.1143, 26.1190]],\\n\\n         [[17.8935, 23.7793, 20.0774],\\n          [20.1411, 23.0094, 23.7444],\\n          [20.1816, 26.6442, 23.1540]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]],\\n\\n\\n        [[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n      ...40]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]],\\n\\n\\n        [[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n         [[18.5446, 20.2036, 21.5269],\\n          [22.8261, 21.7534, 26.7963],\\n          [21.6043, 23.2766, 24.9750]],\\n\\n         [[18.0032, 27.0640, 19.7061],\\n          [24.5388, 23.3599, 27.5940],\\n          [21.1936, 30.9818, 23.1745]],\\n\\n         [[17.8322, 19.6721, 21.3514],\\n          [24.4963, 25.8223, 29.3069],\\n          [22.0854, 23.1143, 26.1190]],\\n\\n         [[17.8935, 23.7793, 20.0774],\\n          [20.1411, 23.0094, 23.7444],\\n          [20.1816, 26.6442, 23.1540]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]]]).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n         [[18.5446, 20.2036, 21.5269],\\n          [22.8261, 21.7534, 26.7963],\\n          [21.6043, 23.2766, 24.9750]],\\n\\n         [[18.0032, 27.0640, 19.7061],\\n          [24.5388, 23.3599, 27.5940],\\n          [21.1936, 30.9818, 23.1745]],\\n\\n         [[17.8322, 19.6721, 21.3514],\\n          [24.4963, 25.8223, 29.3069],\\n          [22.0854, 23.1143, 26.1190]],\\n\\n         [[17.8935, 23.7793, 20.0774],\\n          [20.1411, 23.0094, 23.7444],\\n          [20.1816, 26.6442, 23.1540]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]],\\n\\n\\n        [[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n      ...40]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]],\\n\\n\\n        [[[16.3983, 18.8834, 19.6362],\\n          [20.2626, 24.3859, 24.4388],\\n          [18.7659, 23.8876, 22.8480]],\\n\\n         [[18.3471, 21.9398, 20.6550],\\n          [19.8553, 24.6749, 22.4876],\\n          [21.4143, 25.5992, 23.9195]],\\n\\n         [[18.5446, 20.2036, 21.5269],\\n          [22.8261, 21.7534, 26.7963],\\n          [21.6043, 23.2766, 24.9750]],\\n\\n         [[18.0032, 27.0640, 19.7061],\\n          [24.5388, 23.3599, 27.5940],\\n          [21.1936, 30.9818, 23.1745]],\\n\\n         [[17.8322, 19.6721, 21.3514],\\n          [24.4963, 25.8223, 29.3069],\\n          [22.0854, 23.1143, 26.1190]],\\n\\n         [[17.8935, 23.7793, 20.0774],\\n          [20.1411, 23.0094, 23.7444],\\n          [20.1816, 26.6442, 23.1540]],\\n\\n         [[17.3885, 22.2716, 20.5875],\\n          [22.2182, 24.4080, 25.7180],\\n          [20.5515, 24.8438, 24.6273]],\\n\\n         [[15.3762, 22.1026, 17.5747],\\n          [22.0306, 24.9728, 24.1118],\\n          [18.0240, 25.9587, 21.2043]]]]) = Parameter containing:\\ntensor([[[[ 0.0282, -0.1752,  0.0925],\\n          [-0.1812,  0.0301, -0.1326],\\n          [ 0.1852,  0.2708,  0.1386]],\\n\\n         [[ 0.2677,  0.2753,  0.0429],\\n          [-0.1087,  0.0981, -0.1250],\\n          [-0.1393,  0.1096,  0.0252]],\\n\\n         [[-0.2770, -0.1051,  0.1768],\\n          [ 0.0211, -0.0934, -0.1389],\\n          [-0.0570, -0.1514, -0.2370]],\\n\\n         [[-0.2204,  0.0438, -0.1949],\\n          [-0.1039, -0.1195,  0.1731],\\n          [ 0.0661,  0.0774,  0.0445]],\\n\\n         [[-0.0253,  0.0499,  0.1140],\\n          [-0.1815, -0.0015, -0.0402],\\n          [-0.2130, -0.2478,  0.2672]],\\n\\n         [[-0.0811, -0.1451,  0.1328],\\n          [ 0.0105, -0.2322, -0.1806],\\n          [ 0.0801,  0.2701, -0.0335]],\\n\\n         [[-0.1066,  0.1152, -0.0893],\\n          [ 0.2101, -0.0536,  0.2333],\\n          [-0.1466, -0.0257,  0.0686]],\\n\\n         [[ 0.0884,  0.1301,  0.2507],\\n          [-0.2050, -0.2428,  0.1711],\\n          [-0.0805, -0.0961,  0.1905]]],\\n\\n\\n        [[[ 0.1242, -0.0758, -0.1212],\\n          [ 0.2566,  0.0488, -0.2128],\\n          [ 0.2360,  0.2338,  0.1042]],\\n\\n         [[-0.0673,  0.0605,  0.0885],\\n          [ 0.1134,  0.1646, -0.0693],\\n          [ 0.2015, -0.25....1681,  0.2204,  0.0446],\\n          [ 0.0378,  0.1562, -0.1501],\\n          [ 0.1193,  0.0144,  0.0239]],\\n\\n         [[ 0.0903, -0.2776, -0.0588],\\n          [ 0.2331,  0.2082,  0.2609],\\n          [ 0.1818, -0.2283,  0.2610]]],\\n\\n\\n        [[[ 0.2262, -0.0181,  0.0525],\\n          [-0.0379,  0.2480,  0.1129],\\n          [-0.0439, -0.1539,  0.2190]],\\n\\n         [[-0.2384, -0.2201,  0.2263],\\n          [-0.0267,  0.2174,  0.1602],\\n          [-0.1817,  0.1436,  0.2437]],\\n\\n         [[ 0.1620, -0.2344,  0.2125],\\n          [ 0.1492,  0.2161, -0.2629],\\n          [-0.1543,  0.2555, -0.2219]],\\n\\n         [[ 0.1583, -0.1829, -0.2487],\\n          [ 0.1721, -0.0125, -0.2683],\\n          [-0.1425, -0.0278,  0.0512]],\\n\\n         [[ 0.1050,  0.2668, -0.0808],\\n          [-0.1655, -0.1592,  0.2635],\\n          [-0.1946,  0.2283, -0.2325]],\\n\\n         [[-0.2142,  0.2000, -0.1594],\\n          [ 0.0501, -0.2419, -0.0583],\\n          [ 0.0938, -0.1318,  0.2234]],\\n\\n         [[-0.1955,  0.1112, -0.1513],\\n          [-0.1829, -0.2038, -0.1960],\\n          [-0.0492,  0.1447,  0.2444]],\\n\\n         [[-0.2089, -0.1146, -0.1675],\\n          [-0.2405,  0.1311,  0.0437],\\n          [ 0.2803, -0.0875, -0.1155]]]], requires_grad=True).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where Parameter containing:\\ntensor([[[[ 0.0282, -0.1752,  0.0925],\\n          [-0.1812,  0.0301, -0.1326],\\n          [ 0.1852,  0.2708,  0.1386]],\\n\\n         [[ 0.2677,  0.2753,  0.0429],\\n          [-0.1087,  0.0981, -0.1250],\\n          [-0.1393,  0.1096,  0.0252]],\\n\\n         [[-0.2770, -0.1051,  0.1768],\\n          [ 0.0211, -0.0934, -0.1389],\\n          [-0.0570, -0.1514, -0.2370]],\\n\\n         [[-0.2204,  0.0438, -0.1949],\\n          [-0.1039, -0.1195,  0.1731],\\n          [ 0.0661,  0.0774,  0.0445]],\\n\\n         [[-0.0253,  0.0499,  0.1140],\\n          [-0.1815, -0.0015, -0.0402],\\n          [-0.2130, -0.2478,  0.2672]],\\n\\n         [[-0.0811, -0.1451,  0.1328],\\n          [ 0.0105, -0.2322, -0.1806],\\n          [ 0.0801,  0.2701, -0.0335]],\\n\\n         [[-0.1066,  0.1152, -0.0893],\\n          [ 0.2101, -0.0536,  0.2333],\\n          [-0.1466, -0.0257,  0.0686]],\\n\\n         [[ 0.0884,  0.1301,  0.2507],\\n          [-0.2050, -0.2428,  0.1711],\\n          [-0.0805, -0.0961,  0.1905]]],\\n\\n\\n        [[[ 0.1242, -0.0758, -0.1212],\\n          [ 0.2566,  0.0488, -0.2128],\\n          [ 0.2360,  0.2338,  0.1042]],\\n\\n         [[-0.0673,  0.0605,  0.0885],\\n          [ 0.1134,  0.1646, -0.0693],\\n          [ 0.2015, -0.25....1681,  0.2204,  0.0446],\\n          [ 0.0378,  0.1562, -0.1501],\\n          [ 0.1193,  0.0144,  0.0239]],\\n\\n         [[ 0.0903, -0.2776, -0.0588],\\n          [ 0.2331,  0.2082,  0.2609],\\n          [ 0.1818, -0.2283,  0.2610]]],\\n\\n\\n        [[[ 0.2262, -0.0181,  0.0525],\\n          [-0.0379,  0.2480,  0.1129],\\n          [-0.0439, -0.1539,  0.2190]],\\n\\n         [[-0.2384, -0.2201,  0.2263],\\n          [-0.0267,  0.2174,  0.1602],\\n          [-0.1817,  0.1436,  0.2437]],\\n\\n         [[ 0.1620, -0.2344,  0.2125],\\n          [ 0.1492,  0.2161, -0.2629],\\n          [-0.1543,  0.2555, -0.2219]],\\n\\n         [[ 0.1583, -0.1829, -0.2487],\\n          [ 0.1721, -0.0125, -0.2683],\\n          [-0.1425, -0.0278,  0.0512]],\\n\\n         [[ 0.1050,  0.2668, -0.0808],\\n          [-0.1655, -0.1592,  0.2635],\\n          [-0.1946,  0.2283, -0.2325]],\\n\\n         [[-0.2142,  0.2000, -0.1594],\\n          [ 0.0501, -0.2419, -0.0583],\\n          [ 0.0938, -0.1318,  0.2234]],\\n\\n         [[-0.1955,  0.1112, -0.1513],\\n          [-0.1829, -0.2038, -0.1960],\\n          [-0.0492,  0.1447,  0.2444]],\\n\\n         [[-0.2089, -0.1146, -0.1675],\\n          [-0.2405,  0.1311,  0.0437],\\n          [ 0.2803, -0.0875, -0.1155]]]], requires_grad=True) = Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)).weight\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]],\\n\\n        [[19.580967, 18.386   , 22.236904],\\n         [19.55754 , 25.636957, 23.18855 ],\\n         [23.009567, 21.63789 , 26.333723]]],\\n\\n\\n       [[[17.942469, 23.47784 , 21.346975],\\n         [20.680706, 25.225534, 23.697355],\\n         [20.354874, 27.875105, 24.3...600298, 18.45599 ],\\n         [22.806627, 23.433294, 26.025187],\\n         [18.585415, 22.577991, 22.558968]]],\\n\\n\\n       [[[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]],\\n\\n        [[19.71355 , 20.370325, 22.8549  ],\\n         [22.246494, 24.559095, 25.338413],\\n         [21.913477, 23.37562 , 26.036692]]]], dtype=float32) = <built-in method transpose of numpy.ndarray object at 0x78314a28bc90>(3, 2, 0, 1)\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method transpose of numpy.ndarray object at 0x78314a28bc90> = array([[[[19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ]],\\n\\n        [[18.386   , 23.47784 , 20.36815 , 23.578629, 23.511663,\\n          23.264427, 19.600298, 20.370325],\\n         [18.386   , 23.47784 , 20.36815 , 23.578629, 23.511663,\\n          23.264427, 19.600298, 20.370325],\\n         [18.386   , 23.47784 , 20.36815 , 23.578629, 23.511663,\\n          23.264427, 19.600298, 20.370325..., 27.875105, 23.970331, 27.043167, 27.105556,\\n          26.86128 , 22.577991, 23.37562 ],\\n         [21.63789 , 27.875105, 23.970331, 27.043167, 27.105556,\\n          26.86128 , 22.577991, 23.37562 ],\\n         [21.63789 , 27.875105, 23.970331, 27.043167, 27.105556,\\n          26.86128 , 22.577991, 23.37562 ]],\\n\\n        [[26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692]]]], dtype=float32).transpose\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where array([[[[19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ],\\n         [19.580967, 17.942469, 14.716158, 19.214727, 17.341494,\\n          18.429203, 15.431716, 19.71355 ]],\\n\\n        [[18.386   , 23.47784 , 20.36815 , 23.578629, 23.511663,\\n          23.264427, 19.600298, 20.370325],\\n         [18.386   , 23.47784 , 20.36815 , 23.578629, 23.511663,\\n          23.264427, 19.600298, 20.370325],\\n         [18.386   , 23.47784 , 20.36815 , 23.578629, 23.511663,\\n          23.264427, 19.600298, 20.370325..., 27.875105, 23.970331, 27.043167, 27.105556,\\n          26.86128 , 22.577991, 23.37562 ],\\n         [21.63789 , 27.875105, 23.970331, 27.043167, 27.105556,\\n          26.86128 , 22.577991, 23.37562 ],\\n         [21.63789 , 27.875105, 23.970331, 27.043167, 27.105556,\\n          26.86128 , 22.577991, 23.37562 ]],\\n\\n        [[26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692],\\n         [26.333723, 24.364424, 20.550566, 26.561111, 21.60079 ,\\n          26.137611, 22.558968, 26.036692]]]], dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where numpy = NDArray([[[[19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]]\\n\\n  [[18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.3681...8\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]]\\n\\n  [[26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where NDArray([[[[19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]]\\n\\n  [[18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.3681...8\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]]\\n\\n  [[26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]]]], device=cuda()) = needle.Tensor([[[[19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]]\\n\\n  [[18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  2....105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]]\\n\\n  [[26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +              where needle.Tensor([[[[19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]\\n   [19.580967 17.942469 14.716158 19.214727 17.341494 18.429203\\n    15.431716 19.71355 ]]\\n\\n  [[18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  20.36815  23.578629 23.511663 23.264427\\n    19.600298 20.370325]\\n   [18.386    23.47784  2....105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]\\n   [21.63789  27.875105 23.970331 27.043167 27.105556 26.86128\\n    22.577991 23.37562 ]]\\n\\n  [[26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]\\n   [26.333723 24.364424 20.550566 26.561111 21.60079  26.137611\\n    22.558968 26.036692]]]]) = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\\n     0.084232   -0.03603405  0.22619021]\\n   [ 0.26769578 -0.06729507  0.16842753  0.01668248  0.03928554\\n     0.24571836 -0.24766244 -0.238371  ]\\n   [-0.27700204  0.19203815  0.16059387  0.21362662  0.2763304\\n     0.17271927 -0.02223989  0.16196361]\\n   [-0.22038937  0.08078343 -0.20591007  0.25672972  0.01261413\\n    -0.04926994 -0.13593388  0.15832889]\\n   [-0.02531663  0.03951034 -0.27782685  0.06791687  0.06471848\\n     0.06751189  0.25619805  0.10497397]\\n   [-0.08111316 -0.03635463  0.11410242 -0.25390393  0.09628281\\n     0.09851781 -0.1672107  -0.21423951]\\n   [-0.1065625  -0.07868662  0.04052812 -0.03544843  0.28196275\\n    -0.22975953 -0.16808008 -0.19554305]\\n   [ 0.08839712 -0.14243716 -0.01945049 -0.14755595 -0.19689399\\n    -0.22495002  0.09025693 -0.20889518]]\\n\\n  [[-0.17517826 -0.07579155  0.18532553 -0.23261368  0.19511259\\n    -0.23319268  0.27508396 -0.01809925]\\n   [ 0.27525812  0.0605326   0.13813889 -0.26605004 -0.12539646\\n    -0.21927962 -0.11769851 -0.22012764]\\n   [-0.10508746 -0.04950029 -0.25163954  0.11112383  0.03845236\\n    -0.13545243  0.01342228 -0.23443855]\\n   [ 0.04384774  0.24785429 ...   0.06011245 -0.06766079  0.22827613]\\n   [ 0.27008134  0.027069   -0.13000567  0.05324927  0.22907019\\n    -0.05384754  0.03006738 -0.13183634]\\n   [-0.02572432 -0.05674571 -0.14525355  0.00338697 -0.10947669\\n    -0.07330336  0.01441669  0.1446811 ]\\n   [-0.0961245   0.24488819  0.20918474 -0.26056376 -0.14223455\\n    -0.03109866 -0.22826819 -0.08748242]]\\n\\n  [[ 0.13862038  0.10422006  0.07065868  0.12154862 -0.17036238\\n    -0.09139563  0.10175362  0.21895128]\\n   [ 0.02521753 -0.12545842 -0.2712188   0.121438   -0.28412324\\n    -0.07350877  0.01763067  0.24370617]\\n   [-0.23700543 -0.05430423 -0.2746379  -0.09086859  0.07057014\\n    -0.12755519 -0.16757594 -0.22187383]\\n   [ 0.04453695  0.11273918  0.09927949  0.25915003 -0.28711444\\n     0.08498403  0.05796146  0.05123386]\\n   [ 0.26718056 -0.27893427  0.11343917  0.18110242  0.00566217\\n    -0.09586042  0.16791663 -0.2325319 ]\\n   [-0.03346574  0.01151949  0.1119808  -0.23620223 -0.15717812\\n    -0.05178742  0.07118419  0.22341192]\\n   [ 0.06860432 -0.2116211   0.27746308  0.21465063  0.00157085\\n     0.24384272  0.02389124  0.24439585]\\n   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\\n    -0.06400812  0.26104474 -0.11545335]]]]).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +                where needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\\n     0.084232   -0.03603405  0.22619021]\\n   [ 0.26769578 -0.06729507  0.16842753  0.01668248  0.03928554\\n     0.24571836 -0.24766244 -0.238371  ]\\n   [-0.27700204  0.19203815  0.16059387  0.21362662  0.2763304\\n     0.17271927 -0.02223989  0.16196361]\\n   [-0.22038937  0.08078343 -0.20591007  0.25672972  0.01261413\\n    -0.04926994 -0.13593388  0.15832889]\\n   [-0.02531663  0.03951034 -0.27782685  0.06791687  0.06471848\\n     0.06751189  0.25619805  0.10497397]\\n   [-0.08111316 -0.03635463  0.11410242 -0.25390393  0.09628281\\n     0.09851781 -0.1672107  -0.21423951]\\n   [-0.1065625  -0.07868662  0.04052812 -0.03544843  0.28196275\\n    -0.22975953 -0.16808008 -0.19554305]\\n   [ 0.08839712 -0.14243716 -0.01945049 -0.14755595 -0.19689399\\n    -0.22495002  0.09025693 -0.20889518]]\\n\\n  [[-0.17517826 -0.07579155  0.18532553 -0.23261368  0.19511259\\n    -0.23319268  0.27508396 -0.01809925]\\n   [ 0.27525812  0.0605326   0.13813889 -0.26605004 -0.12539646\\n    -0.21927962 -0.11769851 -0.22012764]\\n   [-0.10508746 -0.04950029 -0.25163954  0.11112383  0.03845236\\n    -0.13545243  0.01342228 -0.23443855]\\n   [ 0.04384774  0.24785429 ...   0.06011245 -0.06766079  0.22827613]\\n   [ 0.27008134  0.027069   -0.13000567  0.05324927  0.22907019\\n    -0.05384754  0.03006738 -0.13183634]\\n   [-0.02572432 -0.05674571 -0.14525355  0.00338697 -0.10947669\\n    -0.07330336  0.01441669  0.1446811 ]\\n   [-0.0961245   0.24488819  0.20918474 -0.26056376 -0.14223455\\n    -0.03109866 -0.22826819 -0.08748242]]\\n\\n  [[ 0.13862038  0.10422006  0.07065868  0.12154862 -0.17036238\\n    -0.09139563  0.10175362  0.21895128]\\n   [ 0.02521753 -0.12545842 -0.2712188   0.121438   -0.28412324\\n    -0.07350877  0.01763067  0.24370617]\\n   [-0.23700543 -0.05430423 -0.2746379  -0.09086859  0.07057014\\n    -0.12755519 -0.16757594 -0.22187383]\\n   [ 0.04453695  0.11273918  0.09927949  0.25915003 -0.28711444\\n     0.08498403  0.05796146  0.05123386]\\n   [ 0.26718056 -0.27893427  0.11343917  0.18110242  0.00566217\\n    -0.09586042  0.16791663 -0.2325319 ]\\n   [-0.03346574  0.01151949  0.1119808  -0.23620223 -0.15717812\\n    -0.05178742  0.07118419  0.22341192]\\n   [ 0.06860432 -0.2116211   0.27746308  0.21465063  0.00157085\\n     0.24384272  0.02389124  0.24439585]\\n   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\\n    -0.06400812  0.26104474 -0.11545335]]]]) = <needle.nn.nn_conv.Conv object at 0x7831499bec90>.weight\u001b[0m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x7831499bec90>\n",
            "g          = Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "res1       = needle.Tensor([[[[-1.15832478e-01 -2.34806284e-01 -6.74709380e-01 -8.65024745e-01\n",
            "    -2.76363313e-01 -2.42350951e-01 ...4.42353517e-01 -4.67727840e-01  6.43736124e-01  3.71369898e-01\n",
            "     3.71544152e-01 -1.34248137e-01 -6.85287714e-01]]]])\n",
            "s          = 14\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[6.96463168e-01 2.47398749e-01 3.96155231e-02 ... 9.97962236e-01\n",
            "    3.62189054e-01 4.70648944e-01]\n",
            " ...3395844e-01]\n",
            "   [1.76103845e-01 3.19807321e-01 8.16825151e-01 ... 5.61398745e-01\n",
            "    7.13245988e-01 9.81864214e-01]]]])\n",
            "y1         = needle.Tensor([-8.716824])\n",
            "y2         = tensor(-4.8628, grad_fn=<SumBackward0>)\n",
            "z          = tensor([[[[6.9646e-01, 2.4740e-01, 3.9616e-02,  ..., 9.9796e-01,\n",
            "           3.6219e-01, 4.7065e-01],\n",
            "          [3.7825...      [1.7610e-01, 3.1981e-01, 8.1683e-01,  ..., 5.6140e-01,\n",
            "           7.1325e-01, 9.8186e-01]]]], requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:391: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-1] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 16, cout = 8, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "        y1 = res1.sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y2 = g(z).sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y1.backward()\u001b[90m\u001b[39;49;00m\n",
            "        y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(g.weight.grad.data.numpy() - f.weight.grad.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)) < \u001b[94m1e-3\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight gradients match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: weight gradients match\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(220.4438) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(220.4438) = <function norm at 0x78322a53a730>((array([[[[ 90.9057  ,  96.970985,  88.92156 ],\\n         [ 98.019554, 104.16012 ,  95.40751 ],\\n         [ 91.75005 ,  97.302475,  89.30088 ]],\\n\\n        [[ 89.42495 ,  96.81692 ,  90.8935  ],\\n         [ 96.29889 , 104.68921 ,  97.96593 ],\\n         [ 88.77235 ,  96.502686,  89.857666]],\\n\\n        [[ 85.76347 ,  90.18389 ,  83.64541 ],\\n         [ 92.70402 ,  97.1335  ,  90.20668 ],\\n         [ 85.75056 ,  89.83993 ,  83.76043 ]],\\n\\n        ...,\\n\\n        [[ 80.78976 ,  86.62534 ,  81.94917 ],\\n         [ 85.97659 ,  92.15976 ,  87.41989 ],\\n         [ 80.78209 ,  86.74479 ,  82.64606 ]],\\n\\n        [[ 76.166306,  80.701744,  75.049164],\\n         [ 82.52754 ,  87.16696 ,  80.89008 ],\\n         [ 76.99502 ,  81.504555,  75.55806 ]],\\n\\n        [[ 85.95652 ,  95.44965 ,  89.42914 ],\\n         [ 91.6464  , 101.53864 ,  95.03545 ],\\n         [ 86.135994,  95.12322 ,  88.835686]]],\\n\\n\\n       [[[ 90.9057  ,  96.970985,  88.92156 ],\\n         [ 98.019554, 104.16012 ,  95.40751 ],\\n         [ 91.75005 ,  97.302475,  89.30088 ]],\\n\\n        [[ 89.42495 ,  96.81692 ,  90.8935  ],\\n         [ 96.29889 , 104.68921 ,  97.96593 ],\\n         [ 88.77235 ,  96.502686,  89.857666]],\\n\\n        [[ 85.76347 ,  90.18389 ,  83.....74479 ,  82.64606 ]],\\n\\n        [[ 76.166306,  80.701744,  75.049164],\\n         [ 82.52754 ,  87.16696 ,  80.89008 ],\\n         [ 76.99502 ,  81.504555,  75.55806 ]],\\n\\n        [[ 85.95652 ,  95.44965 ,  89.42914 ],\\n         [ 91.6464  , 101.53864 ,  95.03545 ],\\n         [ 86.135994,  95.12322 ,  88.835686]]],\\n\\n\\n       [[[ 90.9057  ,  96.970985,  88.92156 ],\\n         [ 98.019554, 104.16012 ,  95.40751 ],\\n         [ 91.75005 ,  97.302475,  89.30088 ]],\\n\\n        [[ 89.42495 ,  96.81692 ,  90.8935  ],\\n         [ 96.29889 , 104.68921 ,  97.96593 ],\\n         [ 88.77235 ,  96.502686,  89.857666]],\\n\\n        [[ 85.76347 ,  90.18389 ,  83.64541 ],\\n         [ 92.70402 ,  97.1335  ,  90.20668 ],\\n         [ 85.75056 ,  89.83993 ,  83.76043 ]],\\n\\n        ...,\\n\\n        [[ 80.78976 ,  86.62534 ,  81.94917 ],\\n         [ 85.97659 ,  92.15976 ,  87.41989 ],\\n         [ 80.78209 ,  86.74479 ,  82.64606 ]],\\n\\n        [[ 76.166306,  80.701744,  75.049164],\\n         [ 82.52754 ,  87.16696 ,  80.89008 ],\\n         [ 76.99502 ,  81.504555,  75.55806 ]],\\n\\n        [[ 85.95652 ,  95.44965 ,  89.42914 ],\\n         [ 91.6464  , 101.53864 ,  95.03545 ],\\n         [ 86.135994,  95.12322 ,  88.835686]]]], dtype=float32) - array([[[[ 82.39589 ,  89.057785,  81.27706 ],\\n         [ 88.793915,  95.72916 ,  87.30731 ],\\n         [ 83.25403 ,  89.92989 ,  82.259094]],\\n\\n        [[ 82.39589 ,  89.057785,  81.27706 ],\\n         [ 88.793915,  95.72916 ,  87.30731 ],\\n         [ 83.25403 ,  89.92989 ,  82.259094]],\\n\\n        [[ 82.39589 ,  89.057785,  81.27706 ],\\n         [ 88.793915,  95.72916 ,  87.30731 ],\\n         [ 83.25403 ,  89.92989 ,  82.259094]],\\n\\n        ...,\\n\\n        [[ 80.69953 ,  85.84485 ,  79.948425],\\n         [ 87.57864 ,  93.71029 ,  87.15389 ],\\n         [ 80.36103 ,  86.29807 ,  80.50251 ]],\\n\\n        [[ 80.69953 ,  85.84485 ,  79.948425],\\n         [ 87.57864 ,  93.71029 ,  87.15389 ],\\n         [ 80.36103 ,  86.29807 ,  80.50251 ]],\\n\\n        [[ 80.69953 ,  85.84485 ,  79.948425],\\n         [ 87.57864 ,  93.71029 ,  87.15389 ],\\n         [ 80.36103 ,  86.29807 ,  80.50251 ]]],\\n\\n\\n       [[[ 80.80842 ,  88.05489 ,  81.40743 ],\\n         [ 86.76028 ,  94.94281 ,  87.452415],\\n         [ 78.379555,  86.24005 ,  79.2114  ]],\\n\\n        [[ 80.80842 ,  88.05489 ,  81.40743 ],\\n         [ 86.76028 ,  94.94281 ,  87.452415],\\n         [ 78.379555,  86.24005 ,  79.2114  ]],\\n\\n        [[ 80.80842 ,  88.05489 ,  81.....68666 ,  94.00358 ]],\\n\\n        [[ 91.88205 ,  97.96773 ,  90.44905 ],\\n         [ 99.39283 , 106.06671 ,  97.837975],\\n         [ 95.45493 , 101.68666 ,  94.00358 ]],\\n\\n        [[ 91.88205 ,  97.96773 ,  90.44905 ],\\n         [ 99.39283 , 106.06671 ,  97.837975],\\n         [ 95.45493 , 101.68666 ,  94.00358 ]]],\\n\\n\\n       [[[ 78.17011 ,  84.89691 ,  80.19013 ],\\n         [ 85.34047 ,  92.608734,  87.33736 ],\\n         [ 77.74933 ,  84.39329 ,  79.45383 ]],\\n\\n        [[ 78.17011 ,  84.89691 ,  80.19013 ],\\n         [ 85.34047 ,  92.608734,  87.33736 ],\\n         [ 77.74933 ,  84.39329 ,  79.45383 ]],\\n\\n        [[ 78.17011 ,  84.89691 ,  80.19013 ],\\n         [ 85.34047 ,  92.608734,  87.33736 ],\\n         [ 77.74933 ,  84.39329 ,  79.45383 ]],\\n\\n        ...,\\n\\n        [[ 84.48229 ,  89.65732 ,  82.4975  ],\\n         [ 91.18834 ,  96.762474,  88.633705],\\n         [ 84.8161  ,  90.38116 ,  82.71308 ]],\\n\\n        [[ 84.48229 ,  89.65732 ,  82.4975  ],\\n         [ 91.18834 ,  96.762474,  88.633705],\\n         [ 84.8161  ,  90.38116 ,  82.71308 ]],\\n\\n        [[ 84.48229 ,  89.65732 ,  82.4975  ],\\n         [ 91.18834 ,  96.762474,  88.633705],\\n         [ 84.8161  ,  90.38116 ,  82.71308 ]]]], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78322a53a730> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 90.9057  ,  96.970985,  88.92156 ],\\n         [ 98.019554, 104.16012 ,  95.40751 ],\\n         [ 91.75005 ,  97.302475,  89.30088 ]],\\n\\n        [[ 89.42495 ,  96.81692 ,  90.8935  ],\\n         [ 96.29889 , 104.68921 ,  97.96593 ],\\n         [ 88.77235 ,  96.502686,  89.857666]],\\n\\n        [[ 85.76347 ,  90.18389 ,  83.64541 ],\\n         [ 92.70402 ,  97.1335  ,  90.20668 ],\\n         [ 85.75056 ,  89.83993 ,  83.76043 ]],\\n\\n        ...,\\n\\n        [[ 80.78976 ,  86.62534 ,  81.94917 ],\\n         [ 85.97659 ,  92.15976 ,  87.41989 ],\\n         [ 80.78209 ,  86.74479 ,  82.64606 ]],\\n\\n        [[ 76.166306,  80.701744,  75.049164],\\n         [ 82.52754 ,  87.16696 ,  80.89008 ],\\n         [ 76.99502 ,  81.504555,  75.55806 ]],\\n\\n        [[ 85.95652 ,  95.44965 ,  89.42914 ],\\n         [ 91.6464  , 101.53864 ,  95.03545 ],\\n         [ 86.135994,  95.12322 ,  88.835686]]],\\n\\n\\n       [[[ 90.9057  ,  96.970985,  88.92156 ],\\n         [ 98.019554, 104.16012 ,  95.40751 ],\\n         [ 91.75005 ,  97.302475,  89.30088 ]],\\n\\n        [[ 89.42495 ,  96.81692 ,  90.8935  ],\\n         [ 96.29889 , 104.68921 ,  97.96593 ],\\n         [ 88.77235 ,  96.502686,  89.857666]],\\n\\n        [[ 85.76347 ,  90.18389 ,  83.....74479 ,  82.64606 ]],\\n\\n        [[ 76.166306,  80.701744,  75.049164],\\n         [ 82.52754 ,  87.16696 ,  80.89008 ],\\n         [ 76.99502 ,  81.504555,  75.55806 ]],\\n\\n        [[ 85.95652 ,  95.44965 ,  89.42914 ],\\n         [ 91.6464  , 101.53864 ,  95.03545 ],\\n         [ 86.135994,  95.12322 ,  88.835686]]],\\n\\n\\n       [[[ 90.9057  ,  96.970985,  88.92156 ],\\n         [ 98.019554, 104.16012 ,  95.40751 ],\\n         [ 91.75005 ,  97.302475,  89.30088 ]],\\n\\n        [[ 89.42495 ,  96.81692 ,  90.8935  ],\\n         [ 96.29889 , 104.68921 ,  97.96593 ],\\n         [ 88.77235 ,  96.502686,  89.857666]],\\n\\n        [[ 85.76347 ,  90.18389 ,  83.64541 ],\\n         [ 92.70402 ,  97.1335  ,  90.20668 ],\\n         [ 85.75056 ,  89.83993 ,  83.76043 ]],\\n\\n        ...,\\n\\n        [[ 80.78976 ,  86.62534 ,  81.94917 ],\\n         [ 85.97659 ,  92.15976 ,  87.41989 ],\\n         [ 80.78209 ,  86.74479 ,  82.64606 ]],\\n\\n        [[ 76.166306,  80.701744,  75.049164],\\n         [ 82.52754 ,  87.16696 ,  80.89008 ],\\n         [ 76.99502 ,  81.504555,  75.55806 ]],\\n\\n        [[ 85.95652 ,  95.44965 ,  89.42914 ],\\n         [ 91.6464  , 101.53864 ,  95.03545 ],\\n         [ 86.135994,  95.12322 ,  88.835686]]]], dtype=float32) = <built-in method numpy of Tensor object at 0x7831499ffca0>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x7831499ffca0> = tensor([[[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]],\\n\\n\\n        [[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80...,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]],\\n\\n\\n        [[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]],\\n\\n\\n        [[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80...,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]],\\n\\n\\n        [[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]]]) = tensor([[[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]],\\n\\n\\n        [[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80...,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]],\\n\\n\\n        [[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]]]).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]],\\n\\n\\n        [[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80...,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]],\\n\\n\\n        [[[ 90.9057,  96.9710,  88.9216],\\n          [ 98.0196, 104.1601,  95.4075],\\n          [ 91.7501,  97.3025,  89.3009]],\\n\\n         [[ 89.4249,  96.8169,  90.8935],\\n          [ 96.2989, 104.6892,  97.9659],\\n          [ 88.7723,  96.5027,  89.8577]],\\n\\n         [[ 85.7635,  90.1839,  83.6454],\\n          [ 92.7040,  97.1335,  90.2067],\\n          [ 85.7506,  89.8399,  83.7604]],\\n\\n         ...,\\n\\n         [[ 80.7898,  86.6253,  81.9492],\\n          [ 85.9766,  92.1598,  87.4199],\\n          [ 80.7821,  86.7448,  82.6461]],\\n\\n         [[ 76.1663,  80.7017,  75.0492],\\n          [ 82.5275,  87.1670,  80.8901],\\n          [ 76.9950,  81.5046,  75.5581]],\\n\\n         [[ 85.9565,  95.4497,  89.4291],\\n          [ 91.6464, 101.5386,  95.0355],\\n          [ 86.1360,  95.1232,  88.8357]]]]) = Parameter containing:\\ntensor([[[[ 0.0199,  0.0654,  0.0213],\\n          [ 0.1310,  0.0980,  0.1421],\\n          [ 0.1903,  0.1497,  0.1136]],\\n\\n         [[ 0.1893,  0.0303,  0.0694],\\n          [-0.0985,  0.0178,  0.1478],\\n          [-0.0191,  0.1535,  0.1812]],\\n\\n         [[-0.1959,  0.1250, -0.0661],\\n          [-0.0403, -0.1676, -0.0120],\\n          [-0.1623,  0.1962, -0.1462]],\\n\\n         ...,\\n\\n         [[-0.1026,  0.0074, -0.1277],\\n          [ 0.1910,  0.0372,  0.0461],\\n          [ 0.0133,  0.0379, -0.1519]],\\n\\n         [[ 0.0814,  0.1485,  0.1650],\\n          [-0.0182,  0.1944,  0.1759],\\n          [ 0.0929, -0.1125,  0.1828]],\\n\\n         [[ 0.0920, -0.1450,  0.1210],\\n          [-0.0680, -0.0276,  0.1465],\\n          [-0.1464, -0.0043, -0.1623]]],\\n\\n\\n        [[[ 0.0879, -0.0857,  0.0345],\\n          [ 0.1669,  0.0737,  0.1779],\\n          [ 0.1192,  0.0521,  0.1422]],\\n\\n         [[-0.0476,  0.0625,  0.1164],\\n          [ 0.1425, -0.0887, -0.1644],\\n          [-0.0025,  0.1709,  0.1898]],\\n\\n         [[ 0.1358,  0.0832,  0.1884],\\n          [ 0.1753, -0.0384, -0.1568],\\n          [-0.1403, -0.1647, -0.0748]],\\n\\n         ...,\\n\\n         [[ 0.0311, -0.1936,  0.1649],\\n          [ 0.0191,  0.0650, -0.17...      [-0.0707, -0.1185, -0.1562],\\n          [ 0.0278,  0.1051,  0.0621]],\\n\\n         ...,\\n\\n         [[-0.0216, -0.0908,  0.0915],\\n          [ 0.0213,  0.0562, -0.0815],\\n          [ 0.1694,  0.0082,  0.0565]],\\n\\n         [[ 0.1558,  0.0267, -0.1061],\\n          [ 0.0102, -0.1786, -0.1030],\\n          [ 0.1106, -0.1956, -0.1138]],\\n\\n         [[-0.1963,  0.1648,  0.1845],\\n          [-0.1614,  0.0366,  0.2008],\\n          [ 0.0495,  0.0570, -0.1941]]],\\n\\n\\n        [[[ 0.1599,  0.0371,  0.1754],\\n          [-0.0310,  0.1548,  0.0640],\\n          [-0.0841, -0.1799, -0.1763]],\\n\\n         [[-0.1686,  0.1600,  0.1537],\\n          [-0.1285,  0.1723, -0.1802],\\n          [ 0.1298, -0.1809,  0.0105]],\\n\\n         [[ 0.1145,  0.1503,  0.1528],\\n          [-0.1091, -0.1569, -0.0934],\\n          [-0.1035, -0.0757,  0.1442]],\\n\\n         ...,\\n\\n         [[ 0.1414,  0.0354, -0.0412],\\n          [-0.0932,  0.1278,  0.0202],\\n          [ 0.0946, -0.1916, -0.0895]],\\n\\n         [[ 0.0786, -0.1293, -0.1386],\\n          [ 0.1023, -0.1054, -0.0742],\\n          [ 0.0963, -0.0361,  0.0750]],\\n\\n         [[-0.0810, -0.1701,  0.0309],\\n          [-0.0619,  0.1002, -0.0503],\\n          [-0.0007,  0.1831,  0.0547]]]], requires_grad=True).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where Parameter containing:\\ntensor([[[[ 0.0199,  0.0654,  0.0213],\\n          [ 0.1310,  0.0980,  0.1421],\\n          [ 0.1903,  0.1497,  0.1136]],\\n\\n         [[ 0.1893,  0.0303,  0.0694],\\n          [-0.0985,  0.0178,  0.1478],\\n          [-0.0191,  0.1535,  0.1812]],\\n\\n         [[-0.1959,  0.1250, -0.0661],\\n          [-0.0403, -0.1676, -0.0120],\\n          [-0.1623,  0.1962, -0.1462]],\\n\\n         ...,\\n\\n         [[-0.1026,  0.0074, -0.1277],\\n          [ 0.1910,  0.0372,  0.0461],\\n          [ 0.0133,  0.0379, -0.1519]],\\n\\n         [[ 0.0814,  0.1485,  0.1650],\\n          [-0.0182,  0.1944,  0.1759],\\n          [ 0.0929, -0.1125,  0.1828]],\\n\\n         [[ 0.0920, -0.1450,  0.1210],\\n          [-0.0680, -0.0276,  0.1465],\\n          [-0.1464, -0.0043, -0.1623]]],\\n\\n\\n        [[[ 0.0879, -0.0857,  0.0345],\\n          [ 0.1669,  0.0737,  0.1779],\\n          [ 0.1192,  0.0521,  0.1422]],\\n\\n         [[-0.0476,  0.0625,  0.1164],\\n          [ 0.1425, -0.0887, -0.1644],\\n          [-0.0025,  0.1709,  0.1898]],\\n\\n         [[ 0.1358,  0.0832,  0.1884],\\n          [ 0.1753, -0.0384, -0.1568],\\n          [-0.1403, -0.1647, -0.0748]],\\n\\n         ...,\\n\\n         [[ 0.0311, -0.1936,  0.1649],\\n          [ 0.0191,  0.0650, -0.17...      [-0.0707, -0.1185, -0.1562],\\n          [ 0.0278,  0.1051,  0.0621]],\\n\\n         ...,\\n\\n         [[-0.0216, -0.0908,  0.0915],\\n          [ 0.0213,  0.0562, -0.0815],\\n          [ 0.1694,  0.0082,  0.0565]],\\n\\n         [[ 0.1558,  0.0267, -0.1061],\\n          [ 0.0102, -0.1786, -0.1030],\\n          [ 0.1106, -0.1956, -0.1138]],\\n\\n         [[-0.1963,  0.1648,  0.1845],\\n          [-0.1614,  0.0366,  0.2008],\\n          [ 0.0495,  0.0570, -0.1941]]],\\n\\n\\n        [[[ 0.1599,  0.0371,  0.1754],\\n          [-0.0310,  0.1548,  0.0640],\\n          [-0.0841, -0.1799, -0.1763]],\\n\\n         [[-0.1686,  0.1600,  0.1537],\\n          [-0.1285,  0.1723, -0.1802],\\n          [ 0.1298, -0.1809,  0.0105]],\\n\\n         [[ 0.1145,  0.1503,  0.1528],\\n          [-0.1091, -0.1569, -0.0934],\\n          [-0.1035, -0.0757,  0.1442]],\\n\\n         ...,\\n\\n         [[ 0.1414,  0.0354, -0.0412],\\n          [-0.0932,  0.1278,  0.0202],\\n          [ 0.0946, -0.1916, -0.0895]],\\n\\n         [[ 0.0786, -0.1293, -0.1386],\\n          [ 0.1023, -0.1054, -0.0742],\\n          [ 0.0963, -0.0361,  0.0750]],\\n\\n         [[-0.0810, -0.1701,  0.0309],\\n          [-0.0619,  0.1002, -0.0503],\\n          [-0.0007,  0.1831,  0.0547]]]], requires_grad=True) = Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).weight\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[ 82.39589 ,  89.057785,  81.27706 ],\\n         [ 88.793915,  95.72916 ,  87.30731 ],\\n         [ 83.25403 ,  89.92989 ,  82.259094]],\\n\\n        [[ 82.39589 ,  89.057785,  81.27706 ],\\n         [ 88.793915,  95.72916 ,  87.30731 ],\\n         [ 83.25403 ,  89.92989 ,  82.259094]],\\n\\n        [[ 82.39589 ,  89.057785,  81.27706 ],\\n         [ 88.793915,  95.72916 ,  87.30731 ],\\n         [ 83.25403 ,  89.92989 ,  82.259094]],\\n\\n        ...,\\n\\n        [[ 80.69953 ,  85.84485 ,  79.948425],\\n         [ 87.57864 ,  93.71029 ,  87.15389 ],\\n         [ 80.36103 ,  86.29807 ,  80.50251 ]],\\n\\n        [[ 80.69953 ,  85.84485 ,  79.948425],\\n         [ 87.57864 ,  93.71029 ,  87.15389 ],\\n         [ 80.36103 ,  86.29807 ,  80.50251 ]],\\n\\n        [[ 80.69953 ,  85.84485 ,  79.948425],\\n         [ 87.57864 ,  93.71029 ,  87.15389 ],\\n         [ 80.36103 ,  86.29807 ,  80.50251 ]]],\\n\\n\\n       [[[ 80.80842 ,  88.05489 ,  81.40743 ],\\n         [ 86.76028 ,  94.94281 ,  87.452415],\\n         [ 78.379555,  86.24005 ,  79.2114  ]],\\n\\n        [[ 80.80842 ,  88.05489 ,  81.40743 ],\\n         [ 86.76028 ,  94.94281 ,  87.452415],\\n         [ 78.379555,  86.24005 ,  79.2114  ]],\\n\\n        [[ 80.80842 ,  88.05489 ,  81.....68666 ,  94.00358 ]],\\n\\n        [[ 91.88205 ,  97.96773 ,  90.44905 ],\\n         [ 99.39283 , 106.06671 ,  97.837975],\\n         [ 95.45493 , 101.68666 ,  94.00358 ]],\\n\\n        [[ 91.88205 ,  97.96773 ,  90.44905 ],\\n         [ 99.39283 , 106.06671 ,  97.837975],\\n         [ 95.45493 , 101.68666 ,  94.00358 ]]],\\n\\n\\n       [[[ 78.17011 ,  84.89691 ,  80.19013 ],\\n         [ 85.34047 ,  92.608734,  87.33736 ],\\n         [ 77.74933 ,  84.39329 ,  79.45383 ]],\\n\\n        [[ 78.17011 ,  84.89691 ,  80.19013 ],\\n         [ 85.34047 ,  92.608734,  87.33736 ],\\n         [ 77.74933 ,  84.39329 ,  79.45383 ]],\\n\\n        [[ 78.17011 ,  84.89691 ,  80.19013 ],\\n         [ 85.34047 ,  92.608734,  87.33736 ],\\n         [ 77.74933 ,  84.39329 ,  79.45383 ]],\\n\\n        ...,\\n\\n        [[ 84.48229 ,  89.65732 ,  82.4975  ],\\n         [ 91.18834 ,  96.762474,  88.633705],\\n         [ 84.8161  ,  90.38116 ,  82.71308 ]],\\n\\n        [[ 84.48229 ,  89.65732 ,  82.4975  ],\\n         [ 91.18834 ,  96.762474,  88.633705],\\n         [ 84.8161  ,  90.38116 ,  82.71308 ]],\\n\\n        [[ 84.48229 ,  89.65732 ,  82.4975  ],\\n         [ 91.18834 ,  96.762474,  88.633705],\\n         [ 84.8161  ,  90.38116 ,  82.71308 ]]]], dtype=float32) = <built-in method transpose of numpy.ndarray object at 0x783149e8aa90>(3, 2, 0, 1)\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method transpose of numpy.ndarray object at 0x783149e8aa90> = array([[[[ 82.39589 ,  80.80842 ,  84.72228 , ...,  85.277885,\\n           91.92394 ,  78.17011 ],\\n         [ 82.39589 ,  80.80842 ,  84.72228 , ...,  85.277885,\\n           91.92394 ,  78.17011 ],\\n         [ 82.39589 ,  80.80842 ,  84.72228 , ...,  85.277885,\\n           91.92394 ,  78.17011 ],\\n         ...,\\n         [ 80.69953 ,  84.760216,  78.79973 , ...,  88.13894 ,\\n           91.88205 ,  84.48229 ],\\n         [ 80.69953 ,  84.760216,  78.79973 , ...,  88.13894 ,\\n           91.88205 ,  84.48229 ],\\n         [ 80.69953 ,  84.760216,  78.79973 , ...,  88.13894 ,\\n           91.88205 ,  84.48229 ]],\\n\\n        [[ 89.057785,  88.05489 ,  89.581665, ...,  90.16469 ,\\n          100.42033 ,  84.89691 ],\\n         [ 89.057785,  88.05489 ,  89.581665, ...,  90.16469 ,\\n          100.42033 ,  84.89691 ],\\n         [ 89.057785,  88.05489 ,  89.581665, ...,  90.16469 ,\\n          100.42033 ,  84.89691 ],\\n         ...,\\n         [ 85.84485 ,  91.07397 ,  86.68615 , ...,  92.97198 ,\\n           97.96773 ,  89.65732 ],\\n         [ 85.84485 ,  91.07397 ,  86.68615 , ...,  92.97198 ,\\n           97.96773 ,  89.65732 ],\\n         [ 85.84485 ,  91.07397 ,  86.68615 , ...,  92.97198 ,\\n           97.96773 ,  89.6...6.24005 ,  90.80858 , ...,  89.41281 ,\\n           98.69062 ,  84.39329 ],\\n         [ 89.92989 ,  86.24005 ,  90.80858 , ...,  89.41281 ,\\n           98.69062 ,  84.39329 ],\\n         [ 89.92989 ,  86.24005 ,  90.80858 , ...,  89.41281 ,\\n           98.69062 ,  84.39329 ],\\n         ...,\\n         [ 86.29807 ,  93.846176,  89.518684, ...,  93.269485,\\n          101.68666 ,  90.38116 ],\\n         [ 86.29807 ,  93.846176,  89.518684, ...,  93.269485,\\n          101.68666 ,  90.38116 ],\\n         [ 86.29807 ,  93.846176,  89.518684, ...,  93.269485,\\n          101.68666 ,  90.38116 ]],\\n\\n        [[ 82.259094,  79.2114  ,  84.33238 , ...,  81.77622 ,\\n           91.52595 ,  79.45383 ],\\n         [ 82.259094,  79.2114  ,  84.33238 , ...,  81.77622 ,\\n           91.52595 ,  79.45383 ],\\n         [ 82.259094,  79.2114  ,  84.33238 , ...,  81.77622 ,\\n           91.52595 ,  79.45383 ],\\n         ...,\\n         [ 80.50251 ,  87.3097  ,  82.52132 , ...,  86.7034  ,\\n           94.00358 ,  82.71308 ],\\n         [ 80.50251 ,  87.3097  ,  82.52132 , ...,  86.7034  ,\\n           94.00358 ,  82.71308 ],\\n         [ 80.50251 ,  87.3097  ,  82.52132 , ...,  86.7034  ,\\n           94.00358 ,  82.71308 ]]]], dtype=float32).transpose\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where array([[[[ 82.39589 ,  80.80842 ,  84.72228 , ...,  85.277885,\\n           91.92394 ,  78.17011 ],\\n         [ 82.39589 ,  80.80842 ,  84.72228 , ...,  85.277885,\\n           91.92394 ,  78.17011 ],\\n         [ 82.39589 ,  80.80842 ,  84.72228 , ...,  85.277885,\\n           91.92394 ,  78.17011 ],\\n         ...,\\n         [ 80.69953 ,  84.760216,  78.79973 , ...,  88.13894 ,\\n           91.88205 ,  84.48229 ],\\n         [ 80.69953 ,  84.760216,  78.79973 , ...,  88.13894 ,\\n           91.88205 ,  84.48229 ],\\n         [ 80.69953 ,  84.760216,  78.79973 , ...,  88.13894 ,\\n           91.88205 ,  84.48229 ]],\\n\\n        [[ 89.057785,  88.05489 ,  89.581665, ...,  90.16469 ,\\n          100.42033 ,  84.89691 ],\\n         [ 89.057785,  88.05489 ,  89.581665, ...,  90.16469 ,\\n          100.42033 ,  84.89691 ],\\n         [ 89.057785,  88.05489 ,  89.581665, ...,  90.16469 ,\\n          100.42033 ,  84.89691 ],\\n         ...,\\n         [ 85.84485 ,  91.07397 ,  86.68615 , ...,  92.97198 ,\\n           97.96773 ,  89.65732 ],\\n         [ 85.84485 ,  91.07397 ,  86.68615 , ...,  92.97198 ,\\n           97.96773 ,  89.65732 ],\\n         [ 85.84485 ,  91.07397 ,  86.68615 , ...,  92.97198 ,\\n           97.96773 ,  89.6...6.24005 ,  90.80858 , ...,  89.41281 ,\\n           98.69062 ,  84.39329 ],\\n         [ 89.92989 ,  86.24005 ,  90.80858 , ...,  89.41281 ,\\n           98.69062 ,  84.39329 ],\\n         [ 89.92989 ,  86.24005 ,  90.80858 , ...,  89.41281 ,\\n           98.69062 ,  84.39329 ],\\n         ...,\\n         [ 86.29807 ,  93.846176,  89.518684, ...,  93.269485,\\n          101.68666 ,  90.38116 ],\\n         [ 86.29807 ,  93.846176,  89.518684, ...,  93.269485,\\n          101.68666 ,  90.38116 ],\\n         [ 86.29807 ,  93.846176,  89.518684, ...,  93.269485,\\n          101.68666 ,  90.38116 ]],\\n\\n        [[ 82.259094,  79.2114  ,  84.33238 , ...,  81.77622 ,\\n           91.52595 ,  79.45383 ],\\n         [ 82.259094,  79.2114  ,  84.33238 , ...,  81.77622 ,\\n           91.52595 ,  79.45383 ],\\n         [ 82.259094,  79.2114  ,  84.33238 , ...,  81.77622 ,\\n           91.52595 ,  79.45383 ],\\n         ...,\\n         [ 80.50251 ,  87.3097  ,  82.52132 , ...,  86.7034  ,\\n           94.00358 ,  82.71308 ],\\n         [ 80.50251 ,  87.3097  ,  82.52132 , ...,  86.7034  ,\\n           94.00358 ,  82.71308 ],\\n         [ 80.50251 ,  87.3097  ,  82.52132 , ...,  86.7034  ,\\n           94.00358 ,  82.71308 ]]]], dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where numpy = NDArray([[[[ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   [ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   [ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   ...\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]]\\n\\n  [[ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   [ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   [ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   ...\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]]\\n\\n  [[ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n   [ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n   [ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n  ....36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]]\\n\\n  [[ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   [ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   [ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   ...\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]]\\n\\n  [[ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   [ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   [ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   ...\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where NDArray([[[[ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   [ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   [ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   ...\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]]\\n\\n  [[ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   [ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   [ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   ...\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]]\\n\\n  [[ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n   [ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n   [ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n  ....36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]]\\n\\n  [[ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   [ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   [ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   ...\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]]\\n\\n  [[ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   [ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   [ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   ...\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]]]], device=cuda()) = needle.Tensor([[[[ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   [ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   [ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   ...\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]]\\n\\n  [[ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   [ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   [ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   ...\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]]\\n\\n  [[ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n   [ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n   [ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.1901...\\n   ...\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]]\\n\\n  [[ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   [ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   [ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   ...\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]]\\n\\n  [[ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   [ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   [ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   ...\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +              where needle.Tensor([[[[ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   [ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   [ 82.39589   80.80842   84.72228  ...  85.277885  91.92394\\n     78.17011 ]\\n   ...\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]\\n   [ 80.69953   84.760216  78.79973  ...  88.13894   91.88205\\n     84.48229 ]]\\n\\n  [[ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   [ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   [ 89.057785  88.05489   89.581665 ...  90.16469  100.42033\\n     84.89691 ]\\n   ...\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]\\n   [ 85.84485   91.07397   86.68615  ...  92.97198   97.96773\\n     89.65732 ]]\\n\\n  [[ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n   [ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.19013 ]\\n   [ 81.27706   81.40743   82.62899  ...  82.75441   93.21065\\n     80.1901...\\n   ...\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]\\n   [ 80.36103   87.729454  81.541405 ...  88.01544   95.45493\\n     84.8161  ]]\\n\\n  [[ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   [ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   [ 89.92989   86.24005   90.80858  ...  89.41281   98.69062\\n     84.39329 ]\\n   ...\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]\\n   [ 86.29807   93.846176  89.518684 ...  93.269485 101.68666\\n     90.38116 ]]\\n\\n  [[ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   [ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   [ 82.259094  79.2114    84.33238  ...  81.77622   91.52595\\n     79.45383 ]\\n   ...\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]\\n   [ 80.50251   87.3097    82.52132  ...  86.7034    94.00358\\n     82.71308 ]]]]) = needle.Tensor([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\\n     0.15994066]\\n   [ 0.18928954 -0.0475848   0.11909625 ...  0.17374912 -0.17512381\\n    -0.16855377]\\n   [-0.19587003  0.13579148  0.11355701 ...  0.12213099 -0.01572599\\n     0.11452556]\\n   ...\\n   [-0.1025711   0.03109111  0.03757596 ...  0.184834   -0.02158597\\n     0.14142075]\\n   [ 0.08143708 -0.08269602  0.12810743 ...  0.03317952  0.15584281\\n     0.0786007 ]\\n   [ 0.09195969  0.00054066  0.18619537 ...  0.04343486 -0.19628856\\n    -0.08100674]]\\n\\n  [[ 0.06539059 -0.08570047  0.0481796  ... -0.0823509   0.02856305\\n     0.03709865]\\n   [ 0.03034316  0.06254396  0.06209588 ... -0.05406764 -0.02618304\\n     0.16000205]\\n   [ 0.12500319  0.08323717 -0.1632067  ...  0.20365345 -0.14311214\\n     0.15028682]\\n   ...\\n   [ 0.0074304  -0.19364738 -0.11942485 ... -0.01487027 -0.0907827\\n     0.03542957]\\n   [ 0.14854342 -0.15614197  0.00709499 ... -0.04243346  0.02670813\\n    -0.12930048]\\n   [-0.1449903  -0.004876   -0.05894586 ...  0.10151649  0.1648179\\n    -0.17006709]]\\n\\n  [[ 0.02130748  0.0344872   0.18858474 ... -0.16317932 -0.19741678\\n     0.1753546 ]\\n   [ 0.06936815  0.11641321 -0.08910831 ... -0.00586751  0.1949...89569 -0.08576748  0.03172475 ... -0.06347017  0.11058334\\n     0.09630328]\\n   [-0.14635438  0.1493966  -0.02395542 ...  0.02769801  0.04946715\\n    -0.0007432 ]]\\n\\n  [[ 0.14974082  0.05214751 -0.04024187 ... -0.06197537 -0.11779809\\n    -0.17988107]\\n   [ 0.15351233  0.17087087 -0.1550853  ... -0.1568088   0.16324493\\n    -0.1809041 ]\\n   [ 0.19615746 -0.16474825  0.1483863  ... -0.06436346  0.10506848\\n    -0.07570013]\\n   ...\\n   [ 0.03791821 -0.20001566 -0.0098689  ...  0.154939    0.0081982\\n    -0.19160683]\\n   [-0.11250767  0.18521234  0.03360689 ... -0.01767567 -0.19557132\\n    -0.03608282]\\n   [-0.0043035  -0.10464308  0.03618672 ...  0.04919389  0.05700055\\n     0.18311584]]\\n\\n  [[ 0.11360577  0.14221138 -0.00391106 ... -0.15131488 -0.0116525\\n    -0.17632526]\\n   [ 0.18120137  0.18980482  0.08956522 ... -0.09581453 -0.15215659\\n     0.01053645]\\n   [-0.1462275  -0.07481939  0.05172771 ... -0.02853003  0.06210461\\n     0.14421207]\\n   ...\\n   [-0.15185985  0.03396332 -0.20328127 ... -0.06922235  0.05649754\\n    -0.08946374]\\n   [ 0.18282253  0.09330872 -0.06954463 ... -0.04396062 -0.11381223\\n     0.07500601]\\n   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\\n     0.05469996]]]]).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +                where needle.Tensor([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\\n     0.15994066]\\n   [ 0.18928954 -0.0475848   0.11909625 ...  0.17374912 -0.17512381\\n    -0.16855377]\\n   [-0.19587003  0.13579148  0.11355701 ...  0.12213099 -0.01572599\\n     0.11452556]\\n   ...\\n   [-0.1025711   0.03109111  0.03757596 ...  0.184834   -0.02158597\\n     0.14142075]\\n   [ 0.08143708 -0.08269602  0.12810743 ...  0.03317952  0.15584281\\n     0.0786007 ]\\n   [ 0.09195969  0.00054066  0.18619537 ...  0.04343486 -0.19628856\\n    -0.08100674]]\\n\\n  [[ 0.06539059 -0.08570047  0.0481796  ... -0.0823509   0.02856305\\n     0.03709865]\\n   [ 0.03034316  0.06254396  0.06209588 ... -0.05406764 -0.02618304\\n     0.16000205]\\n   [ 0.12500319  0.08323717 -0.1632067  ...  0.20365345 -0.14311214\\n     0.15028682]\\n   ...\\n   [ 0.0074304  -0.19364738 -0.11942485 ... -0.01487027 -0.0907827\\n     0.03542957]\\n   [ 0.14854342 -0.15614197  0.00709499 ... -0.04243346  0.02670813\\n    -0.12930048]\\n   [-0.1449903  -0.004876   -0.05894586 ...  0.10151649  0.1648179\\n    -0.17006709]]\\n\\n  [[ 0.02130748  0.0344872   0.18858474 ... -0.16317932 -0.19741678\\n     0.1753546 ]\\n   [ 0.06936815  0.11641321 -0.08910831 ... -0.00586751  0.1949...89569 -0.08576748  0.03172475 ... -0.06347017  0.11058334\\n     0.09630328]\\n   [-0.14635438  0.1493966  -0.02395542 ...  0.02769801  0.04946715\\n    -0.0007432 ]]\\n\\n  [[ 0.14974082  0.05214751 -0.04024187 ... -0.06197537 -0.11779809\\n    -0.17988107]\\n   [ 0.15351233  0.17087087 -0.1550853  ... -0.1568088   0.16324493\\n    -0.1809041 ]\\n   [ 0.19615746 -0.16474825  0.1483863  ... -0.06436346  0.10506848\\n    -0.07570013]\\n   ...\\n   [ 0.03791821 -0.20001566 -0.0098689  ...  0.154939    0.0081982\\n    -0.19160683]\\n   [-0.11250767  0.18521234  0.03360689 ... -0.01767567 -0.19557132\\n    -0.03608282]\\n   [-0.0043035  -0.10464308  0.03618672 ...  0.04919389  0.05700055\\n     0.18311584]]\\n\\n  [[ 0.11360577  0.14221138 -0.00391106 ... -0.15131488 -0.0116525\\n    -0.17632526]\\n   [ 0.18120137  0.18980482  0.08956522 ... -0.09581453 -0.15215659\\n     0.01053645]\\n   [-0.1462275  -0.07481939  0.05172771 ... -0.02853003  0.06210461\\n     0.14421207]\\n   ...\\n   [-0.15185985  0.03396332 -0.20328127 ... -0.06922235  0.05649754\\n    -0.08946374]\\n   [ 0.18282253  0.09330872 -0.06954463 ... -0.04396062 -0.11381223\\n     0.07500601]\\n   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\\n     0.05469996]]]]) = <needle.nn.nn_conv.Conv object at 0x78323f90a3f0>.weight\u001b[0m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78323f90a3f0>\n",
            "g          = Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "res1       = needle.Tensor([[[[ 6.00374281e-01  1.49584204e-01  3.45377386e-01 ...  2.50348635e-02\n",
            "     3.51715028e-01 -3.93751293e...2e-01]\n",
            "   [-1.67449564e-01 -5.03415346e-01 -4.07774508e-01 ... -5.28816402e-01\n",
            "    -2.27928609e-01  2.43208200e-01]]]])\n",
            "s          = 14\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.7510323  0.15597793 0.42600238 ... 0.38840413 0.4862721\n",
            "    0.58815145]\n",
            "   [0.9838538  0.69733024 ...0.35930127 0.41500303\n",
            "    0.3384509 ]\n",
            "   [0.4826699  0.37319595 0.14424832 ... 0.36331356 0.6944434\n",
            "    0.39911222]]]])\n",
            "y1         = needle.Tensor([-239.67941])\n",
            "y2         = tensor(-223.0292, grad_fn=<SumBackward0>)\n",
            "z          = tensor([[[[0.7510, 0.1560, 0.4260,  ..., 0.3884, 0.4863, 0.5882],\n",
            "          [0.9839, 0.6973, 0.3895,  ..., 0.3675, 0.7....3593, 0.4150, 0.3385],\n",
            "          [0.4827, 0.3732, 0.1442,  ..., 0.3633, 0.6944, 0.3991]]]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:391: AssertionError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 16, cout = 8, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "        y1 = res1.sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y2 = g(z).sum()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        y1.backward()\u001b[90m\u001b[39;49;00m\n",
            "        y2.backward()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(g.weight.grad.data.numpy() - f.weight.grad.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)) < \u001b[94m1e-3\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mweight gradients match\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: weight gradients match\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert np.float32(93.498055) < 0.001\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.float32(93.498055) = <function norm at 0x78322a53a730>((array([[[[19.12849  , 23.051706 , 20.632807 ],\\n         [21.015997 , 27.709455 , 25.57697  ],\\n         [23.033    , 26.261063 , 24.612595 ]],\\n\\n        [[21.763483 , 22.14337  , 24.552076 ],\\n         [21.955843 , 23.562263 , 26.559216 ],\\n         [24.703547 , 26.077251 , 28.490494 ]],\\n\\n        [[18.629814 , 19.654263 , 21.338589 ],\\n         [21.137901 , 26.341494 , 22.849527 ],\\n         [22.03276  , 23.19186  , 24.750595 ]],\\n\\n        ...,\\n\\n        [[15.3728695, 22.995655 , 19.236153 ],\\n         [23.080357 , 19.340881 , 25.05266  ],\\n         [17.180038 , 26.37533  , 21.390905 ]],\\n\\n        [[17.22931  , 16.427547 , 18.844578 ],\\n         [20.761198 , 21.748247 , 23.681368 ],\\n         [20.433346 , 19.584755 , 22.152597 ]],\\n\\n        [[17.847752 , 25.421267 , 22.660522 ],\\n         [20.22666  , 22.460823 , 24.907057 ],\\n         [19.761505 , 29.197386 , 24.973389 ]]],\\n\\n\\n       [[[19.12849  , 23.051706 , 20.632807 ],\\n         [21.015997 , 27.709455 , 25.57697  ],\\n         [23.033    , 26.261063 , 24.612595 ]],\\n\\n        [[21.763483 , 22.14337  , 24.552076 ],\\n         [21.955843 , 23.562263 , 26.559216 ],\\n         [24.703547 , 26.077251 , 28.490494 ]],\\n\\n        [[18.629814 , 19.654263 , 21.3...37533  , 21.390905 ]],\\n\\n        [[17.22931  , 16.427547 , 18.844578 ],\\n         [20.761198 , 21.748247 , 23.681368 ],\\n         [20.433346 , 19.584755 , 22.152597 ]],\\n\\n        [[17.847752 , 25.421267 , 22.660522 ],\\n         [20.22666  , 22.460823 , 24.907057 ],\\n         [19.761505 , 29.197386 , 24.973389 ]]],\\n\\n\\n       [[[19.12849  , 23.051706 , 20.632807 ],\\n         [21.015997 , 27.709455 , 25.57697  ],\\n         [23.033    , 26.261063 , 24.612595 ]],\\n\\n        [[21.763483 , 22.14337  , 24.552076 ],\\n         [21.955843 , 23.562263 , 26.559216 ],\\n         [24.703547 , 26.077251 , 28.490494 ]],\\n\\n        [[18.629814 , 19.654263 , 21.338589 ],\\n         [21.137901 , 26.341494 , 22.849527 ],\\n         [22.03276  , 23.19186  , 24.750595 ]],\\n\\n        ...,\\n\\n        [[15.3728695, 22.995655 , 19.236153 ],\\n         [23.080357 , 19.340881 , 25.05266  ],\\n         [17.180038 , 26.37533  , 21.390905 ]],\\n\\n        [[17.22931  , 16.427547 , 18.844578 ],\\n         [20.761198 , 21.748247 , 23.681368 ],\\n         [20.433346 , 19.584755 , 22.152597 ]],\\n\\n        [[17.847752 , 25.421267 , 22.660522 ],\\n         [20.22666  , 22.460823 , 24.907057 ],\\n         [19.761505 , 29.197386 , 24.973389 ]]]], dtype=float32) - array([[[[18.771992, 21.237831, 22.086725],\\n         [17.869066, 24.517014, 21.216215],\\n         [21.500883, 24.906967, 25.088964]],\\n\\n        [[18.771992, 21.237831, 22.086725],\\n         [17.869066, 24.517014, 21.216215],\\n         [21.500883, 24.906967, 25.088964]],\\n\\n        [[18.771992, 21.237831, 22.086725],\\n         [17.869066, 24.517014, 21.216215],\\n         [21.500883, 24.906967, 25.088964]],\\n\\n        ...,\\n\\n        [[19.167946, 21.321896, 21.458403],\\n         [18.735073, 21.474642, 21.58993 ],\\n         [23.713486, 23.655466, 26.990273]],\\n\\n        [[19.167946, 21.321896, 21.458403],\\n         [18.735073, 21.474642, 21.58993 ],\\n         [23.713486, 23.655466, 26.990273]],\\n\\n        [[19.167946, 21.321896, 21.458403],\\n         [18.735073, 21.474642, 21.58993 ],\\n         [23.713486, 23.655466, 26.990273]]],\\n\\n\\n       [[[15.500876, 20.533047, 18.441025],\\n         [20.451706, 24.32279 , 24.758047],\\n         [18.785507, 23.20027 , 22.661713]],\\n\\n        [[15.500876, 20.533047, 18.441025],\\n         [20.451706, 24.32279 , 24.758047],\\n         [18.785507, 23.20027 , 22.661713]],\\n\\n        [[15.500876, 20.533047, 18.441025],\\n         [20.451706, 24.32279 , 24.758047],\\n         [18.785507, 2...53 ],\\n         [22.308655, 25.230362, 25.414932],\\n         [22.133162, 29.720654, 25.700762]],\\n\\n        [[18.54313 , 25.799896, 21.52253 ],\\n         [22.308655, 25.230362, 25.414932],\\n         [22.133162, 29.720654, 25.700762]],\\n\\n        [[18.54313 , 25.799896, 21.52253 ],\\n         [22.308655, 25.230362, 25.414932],\\n         [22.133162, 29.720654, 25.700762]]],\\n\\n\\n       [[[19.472893, 17.676086, 22.08527 ],\\n         [17.309052, 23.712118, 21.423452],\\n         [23.116304, 21.203037, 26.270147]],\\n\\n        [[19.472893, 17.676086, 22.08527 ],\\n         [17.309052, 23.712118, 21.423452],\\n         [23.116304, 21.203037, 26.270147]],\\n\\n        [[19.472893, 17.676086, 22.08527 ],\\n         [17.309052, 23.712118, 21.423452],\\n         [23.116304, 21.203037, 26.270147]],\\n\\n        ...,\\n\\n        [[16.620861, 21.255415, 19.956577],\\n         [21.056774, 25.549232, 22.896072],\\n         [20.057869, 24.524452, 23.792698]],\\n\\n        [[16.620861, 21.255415, 19.956577],\\n         [21.056774, 25.549232, 22.896072],\\n         [20.057869, 24.524452, 23.792698]],\\n\\n        [[16.620861, 21.255415, 19.956577],\\n         [21.056774, 25.549232, 22.896072],\\n         [20.057869, 24.524452, 23.792698]]]], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x78322a53a730> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[19.12849  , 23.051706 , 20.632807 ],\\n         [21.015997 , 27.709455 , 25.57697  ],\\n         [23.033    , 26.261063 , 24.612595 ]],\\n\\n        [[21.763483 , 22.14337  , 24.552076 ],\\n         [21.955843 , 23.562263 , 26.559216 ],\\n         [24.703547 , 26.077251 , 28.490494 ]],\\n\\n        [[18.629814 , 19.654263 , 21.338589 ],\\n         [21.137901 , 26.341494 , 22.849527 ],\\n         [22.03276  , 23.19186  , 24.750595 ]],\\n\\n        ...,\\n\\n        [[15.3728695, 22.995655 , 19.236153 ],\\n         [23.080357 , 19.340881 , 25.05266  ],\\n         [17.180038 , 26.37533  , 21.390905 ]],\\n\\n        [[17.22931  , 16.427547 , 18.844578 ],\\n         [20.761198 , 21.748247 , 23.681368 ],\\n         [20.433346 , 19.584755 , 22.152597 ]],\\n\\n        [[17.847752 , 25.421267 , 22.660522 ],\\n         [20.22666  , 22.460823 , 24.907057 ],\\n         [19.761505 , 29.197386 , 24.973389 ]]],\\n\\n\\n       [[[19.12849  , 23.051706 , 20.632807 ],\\n         [21.015997 , 27.709455 , 25.57697  ],\\n         [23.033    , 26.261063 , 24.612595 ]],\\n\\n        [[21.763483 , 22.14337  , 24.552076 ],\\n         [21.955843 , 23.562263 , 26.559216 ],\\n         [24.703547 , 26.077251 , 28.490494 ]],\\n\\n        [[18.629814 , 19.654263 , 21.3...37533  , 21.390905 ]],\\n\\n        [[17.22931  , 16.427547 , 18.844578 ],\\n         [20.761198 , 21.748247 , 23.681368 ],\\n         [20.433346 , 19.584755 , 22.152597 ]],\\n\\n        [[17.847752 , 25.421267 , 22.660522 ],\\n         [20.22666  , 22.460823 , 24.907057 ],\\n         [19.761505 , 29.197386 , 24.973389 ]]],\\n\\n\\n       [[[19.12849  , 23.051706 , 20.632807 ],\\n         [21.015997 , 27.709455 , 25.57697  ],\\n         [23.033    , 26.261063 , 24.612595 ]],\\n\\n        [[21.763483 , 22.14337  , 24.552076 ],\\n         [21.955843 , 23.562263 , 26.559216 ],\\n         [24.703547 , 26.077251 , 28.490494 ]],\\n\\n        [[18.629814 , 19.654263 , 21.338589 ],\\n         [21.137901 , 26.341494 , 22.849527 ],\\n         [22.03276  , 23.19186  , 24.750595 ]],\\n\\n        ...,\\n\\n        [[15.3728695, 22.995655 , 19.236153 ],\\n         [23.080357 , 19.340881 , 25.05266  ],\\n         [17.180038 , 26.37533  , 21.390905 ]],\\n\\n        [[17.22931  , 16.427547 , 18.844578 ],\\n         [20.761198 , 21.748247 , 23.681368 ],\\n         [20.433346 , 19.584755 , 22.152597 ]],\\n\\n        [[17.847752 , 25.421267 , 22.660522 ],\\n         [20.22666  , 22.460823 , 24.907057 ],\\n         [19.761505 , 29.197386 , 24.973389 ]]]], dtype=float32) = <built-in method numpy of Tensor object at 0x7831401385f0>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method numpy of Tensor object at 0x7831401385f0> = tensor([[[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]],\\n\\n\\n        [[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.180...6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]],\\n\\n\\n        [[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]]]).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where tensor([[[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]],\\n\\n\\n        [[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.180...6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]],\\n\\n\\n        [[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]]]) = tensor([[[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]],\\n\\n\\n        [[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.180...6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]],\\n\\n\\n        [[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]]]).data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where tensor([[[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]],\\n\\n\\n        [[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.180...6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]],\\n\\n\\n        [[[19.1285, 23.0517, 20.6328],\\n          [21.0160, 27.7095, 25.5770],\\n          [23.0330, 26.2611, 24.6126]],\\n\\n         [[21.7635, 22.1434, 24.5521],\\n          [21.9558, 23.5623, 26.5592],\\n          [24.7035, 26.0773, 28.4905]],\\n\\n         [[18.6298, 19.6543, 21.3386],\\n          [21.1379, 26.3415, 22.8495],\\n          [22.0328, 23.1919, 24.7506]],\\n\\n         ...,\\n\\n         [[15.3729, 22.9957, 19.2362],\\n          [23.0804, 19.3409, 25.0527],\\n          [17.1800, 26.3753, 21.3909]],\\n\\n         [[17.2293, 16.4275, 18.8446],\\n          [20.7612, 21.7482, 23.6814],\\n          [20.4333, 19.5848, 22.1526]],\\n\\n         [[17.8478, 25.4213, 22.6605],\\n          [20.2267, 22.4608, 24.9071],\\n          [19.7615, 29.1974, 24.9734]]]]) = Parameter containing:\\ntensor([[[[ 0.0199,  0.0654,  0.0213],\\n          [ 0.1310,  0.0980,  0.1421],\\n          [ 0.1903,  0.1497,  0.1136]],\\n\\n         [[ 0.1893,  0.0303,  0.0694],\\n          [-0.0985,  0.0178,  0.1478],\\n          [-0.0191,  0.1535,  0.1812]],\\n\\n         [[-0.1959,  0.1250, -0.0661],\\n          [-0.0403, -0.1676, -0.0120],\\n          [-0.1623,  0.1962, -0.1462]],\\n\\n         ...,\\n\\n         [[-0.1026,  0.0074, -0.1277],\\n          [ 0.1910,  0.0372,  0.0461],\\n          [ 0.0133,  0.0379, -0.1519]],\\n\\n         [[ 0.0814,  0.1485,  0.1650],\\n          [-0.0182,  0.1944,  0.1759],\\n          [ 0.0929, -0.1125,  0.1828]],\\n\\n         [[ 0.0920, -0.1450,  0.1210],\\n          [-0.0680, -0.0276,  0.1465],\\n          [-0.1464, -0.0043, -0.1623]]],\\n\\n\\n        [[[ 0.0879, -0.0857,  0.0345],\\n          [ 0.1669,  0.0737,  0.1779],\\n          [ 0.1192,  0.0521,  0.1422]],\\n\\n         [[-0.0476,  0.0625,  0.1164],\\n          [ 0.1425, -0.0887, -0.1644],\\n          [-0.0025,  0.1709,  0.1898]],\\n\\n         [[ 0.1358,  0.0832,  0.1884],\\n          [ 0.1753, -0.0384, -0.1568],\\n          [-0.1403, -0.1647, -0.0748]],\\n\\n         ...,\\n\\n         [[ 0.0311, -0.1936,  0.1649],\\n          [ 0.0191,  0.0650, -0.17...      [-0.0707, -0.1185, -0.1562],\\n          [ 0.0278,  0.1051,  0.0621]],\\n\\n         ...,\\n\\n         [[-0.0216, -0.0908,  0.0915],\\n          [ 0.0213,  0.0562, -0.0815],\\n          [ 0.1694,  0.0082,  0.0565]],\\n\\n         [[ 0.1558,  0.0267, -0.1061],\\n          [ 0.0102, -0.1786, -0.1030],\\n          [ 0.1106, -0.1956, -0.1138]],\\n\\n         [[-0.1963,  0.1648,  0.1845],\\n          [-0.1614,  0.0366,  0.2008],\\n          [ 0.0495,  0.0570, -0.1941]]],\\n\\n\\n        [[[ 0.1599,  0.0371,  0.1754],\\n          [-0.0310,  0.1548,  0.0640],\\n          [-0.0841, -0.1799, -0.1763]],\\n\\n         [[-0.1686,  0.1600,  0.1537],\\n          [-0.1285,  0.1723, -0.1802],\\n          [ 0.1298, -0.1809,  0.0105]],\\n\\n         [[ 0.1145,  0.1503,  0.1528],\\n          [-0.1091, -0.1569, -0.0934],\\n          [-0.1035, -0.0757,  0.1442]],\\n\\n         ...,\\n\\n         [[ 0.1414,  0.0354, -0.0412],\\n          [-0.0932,  0.1278,  0.0202],\\n          [ 0.0946, -0.1916, -0.0895]],\\n\\n         [[ 0.0786, -0.1293, -0.1386],\\n          [ 0.1023, -0.1054, -0.0742],\\n          [ 0.0963, -0.0361,  0.0750]],\\n\\n         [[-0.0810, -0.1701,  0.0309],\\n          [-0.0619,  0.1002, -0.0503],\\n          [-0.0007,  0.1831,  0.0547]]]], requires_grad=True).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where Parameter containing:\\ntensor([[[[ 0.0199,  0.0654,  0.0213],\\n          [ 0.1310,  0.0980,  0.1421],\\n          [ 0.1903,  0.1497,  0.1136]],\\n\\n         [[ 0.1893,  0.0303,  0.0694],\\n          [-0.0985,  0.0178,  0.1478],\\n          [-0.0191,  0.1535,  0.1812]],\\n\\n         [[-0.1959,  0.1250, -0.0661],\\n          [-0.0403, -0.1676, -0.0120],\\n          [-0.1623,  0.1962, -0.1462]],\\n\\n         ...,\\n\\n         [[-0.1026,  0.0074, -0.1277],\\n          [ 0.1910,  0.0372,  0.0461],\\n          [ 0.0133,  0.0379, -0.1519]],\\n\\n         [[ 0.0814,  0.1485,  0.1650],\\n          [-0.0182,  0.1944,  0.1759],\\n          [ 0.0929, -0.1125,  0.1828]],\\n\\n         [[ 0.0920, -0.1450,  0.1210],\\n          [-0.0680, -0.0276,  0.1465],\\n          [-0.1464, -0.0043, -0.1623]]],\\n\\n\\n        [[[ 0.0879, -0.0857,  0.0345],\\n          [ 0.1669,  0.0737,  0.1779],\\n          [ 0.1192,  0.0521,  0.1422]],\\n\\n         [[-0.0476,  0.0625,  0.1164],\\n          [ 0.1425, -0.0887, -0.1644],\\n          [-0.0025,  0.1709,  0.1898]],\\n\\n         [[ 0.1358,  0.0832,  0.1884],\\n          [ 0.1753, -0.0384, -0.1568],\\n          [-0.1403, -0.1647, -0.0748]],\\n\\n         ...,\\n\\n         [[ 0.0311, -0.1936,  0.1649],\\n          [ 0.0191,  0.0650, -0.17...      [-0.0707, -0.1185, -0.1562],\\n          [ 0.0278,  0.1051,  0.0621]],\\n\\n         ...,\\n\\n         [[-0.0216, -0.0908,  0.0915],\\n          [ 0.0213,  0.0562, -0.0815],\\n          [ 0.1694,  0.0082,  0.0565]],\\n\\n         [[ 0.1558,  0.0267, -0.1061],\\n          [ 0.0102, -0.1786, -0.1030],\\n          [ 0.1106, -0.1956, -0.1138]],\\n\\n         [[-0.1963,  0.1648,  0.1845],\\n          [-0.1614,  0.0366,  0.2008],\\n          [ 0.0495,  0.0570, -0.1941]]],\\n\\n\\n        [[[ 0.1599,  0.0371,  0.1754],\\n          [-0.0310,  0.1548,  0.0640],\\n          [-0.0841, -0.1799, -0.1763]],\\n\\n         [[-0.1686,  0.1600,  0.1537],\\n          [-0.1285,  0.1723, -0.1802],\\n          [ 0.1298, -0.1809,  0.0105]],\\n\\n         [[ 0.1145,  0.1503,  0.1528],\\n          [-0.1091, -0.1569, -0.0934],\\n          [-0.1035, -0.0757,  0.1442]],\\n\\n         ...,\\n\\n         [[ 0.1414,  0.0354, -0.0412],\\n          [-0.0932,  0.1278,  0.0202],\\n          [ 0.0946, -0.1916, -0.0895]],\\n\\n         [[ 0.0786, -0.1293, -0.1386],\\n          [ 0.1023, -0.1054, -0.0742],\\n          [ 0.0963, -0.0361,  0.0750]],\\n\\n         [[-0.0810, -0.1701,  0.0309],\\n          [-0.0619,  0.1002, -0.0503],\\n          [-0.0007,  0.1831,  0.0547]]]], requires_grad=True) = Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)).weight\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([[[[18.771992, 21.237831, 22.086725],\\n         [17.869066, 24.517014, 21.216215],\\n         [21.500883, 24.906967, 25.088964]],\\n\\n        [[18.771992, 21.237831, 22.086725],\\n         [17.869066, 24.517014, 21.216215],\\n         [21.500883, 24.906967, 25.088964]],\\n\\n        [[18.771992, 21.237831, 22.086725],\\n         [17.869066, 24.517014, 21.216215],\\n         [21.500883, 24.906967, 25.088964]],\\n\\n        ...,\\n\\n        [[19.167946, 21.321896, 21.458403],\\n         [18.735073, 21.474642, 21.58993 ],\\n         [23.713486, 23.655466, 26.990273]],\\n\\n        [[19.167946, 21.321896, 21.458403],\\n         [18.735073, 21.474642, 21.58993 ],\\n         [23.713486, 23.655466, 26.990273]],\\n\\n        [[19.167946, 21.321896, 21.458403],\\n         [18.735073, 21.474642, 21.58993 ],\\n         [23.713486, 23.655466, 26.990273]]],\\n\\n\\n       [[[15.500876, 20.533047, 18.441025],\\n         [20.451706, 24.32279 , 24.758047],\\n         [18.785507, 23.20027 , 22.661713]],\\n\\n        [[15.500876, 20.533047, 18.441025],\\n         [20.451706, 24.32279 , 24.758047],\\n         [18.785507, 23.20027 , 22.661713]],\\n\\n        [[15.500876, 20.533047, 18.441025],\\n         [20.451706, 24.32279 , 24.758047],\\n         [18.785507, 2...53 ],\\n         [22.308655, 25.230362, 25.414932],\\n         [22.133162, 29.720654, 25.700762]],\\n\\n        [[18.54313 , 25.799896, 21.52253 ],\\n         [22.308655, 25.230362, 25.414932],\\n         [22.133162, 29.720654, 25.700762]],\\n\\n        [[18.54313 , 25.799896, 21.52253 ],\\n         [22.308655, 25.230362, 25.414932],\\n         [22.133162, 29.720654, 25.700762]]],\\n\\n\\n       [[[19.472893, 17.676086, 22.08527 ],\\n         [17.309052, 23.712118, 21.423452],\\n         [23.116304, 21.203037, 26.270147]],\\n\\n        [[19.472893, 17.676086, 22.08527 ],\\n         [17.309052, 23.712118, 21.423452],\\n         [23.116304, 21.203037, 26.270147]],\\n\\n        [[19.472893, 17.676086, 22.08527 ],\\n         [17.309052, 23.712118, 21.423452],\\n         [23.116304, 21.203037, 26.270147]],\\n\\n        ...,\\n\\n        [[16.620861, 21.255415, 19.956577],\\n         [21.056774, 25.549232, 22.896072],\\n         [20.057869, 24.524452, 23.792698]],\\n\\n        [[16.620861, 21.255415, 19.956577],\\n         [21.056774, 25.549232, 22.896072],\\n         [20.057869, 24.524452, 23.792698]],\\n\\n        [[16.620861, 21.255415, 19.956577],\\n         [21.056774, 25.549232, 22.896072],\\n         [20.057869, 24.524452, 23.792698]]]], dtype=float32) = <built-in method transpose of numpy.ndarray object at 0x783149e880f0>(3, 2, 0, 1)\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in method transpose of numpy.ndarray object at 0x783149e880f0> = array([[[[18.771992, 15.500876, 19.784658, ..., 20.265377, 22.255096,\\n          19.472893],\\n         [18.771992, 15.500876, 19.784658, ..., 20.265377, 22.255096,\\n          19.472893],\\n         [18.771992, 15.500876, 19.784658, ..., 20.265377, 22.255096,\\n          19.472893],\\n         ...,\\n         [19.167946, 17.663925, 19.232843, ..., 20.495304, 18.54313 ,\\n          16.620861],\\n         [19.167946, 17.663925, 19.232843, ..., 20.495304, 18.54313 ,\\n          16.620861],\\n         [19.167946, 17.663925, 19.232843, ..., 20.495304, 18.54313 ,\\n          16.620861]],\\n\\n        [[21.237831, 20.533047, 18.348204, ..., 17.849451, 21.363873,\\n          17.676086],\\n         [21.237831, 20.533047, 18.348204, ..., 17.849451, 21.363873,\\n          17.676086],\\n         [21.237831, 20.533047, 18.348204, ..., 17.849451, 21.363873,\\n          17.676086],\\n         ...,\\n         [21.321896, 23.182398, 20.24112 , ..., 21.376657, 25.799896,\\n          21.255415],\\n         [21.321896, 23.182398, 20.24112 , ..., 21.376657, 25.799896,\\n          21.255415],\\n         [21.321896, 23.182398, 20.24112 , ..., 21.376657, 25.799896,\\n          21.255415]],\\n\\n        [[22.086725, 18.441025, 21.36781 , ..., 22.567696, 25...., 24.076834, 22.133162,\\n          20.057869]],\\n\\n        [[24.906967, 23.20027 , 21.956026, ..., 20.758915, 24.190678,\\n          21.203037],\\n         [24.906967, 23.20027 , 21.956026, ..., 20.758915, 24.190678,\\n          21.203037],\\n         [24.906967, 23.20027 , 21.956026, ..., 20.758915, 24.190678,\\n          21.203037],\\n         ...,\\n         [23.655466, 28.483591, 23.717907, ..., 23.634565, 29.720654,\\n          24.524452],\\n         [23.655466, 28.483591, 23.717907, ..., 23.634565, 29.720654,\\n          24.524452],\\n         [23.655466, 28.483591, 23.717907, ..., 23.634565, 29.720654,\\n          24.524452]],\\n\\n        [[25.088964, 22.661713, 26.104147, ..., 25.484823, 29.314367,\\n          26.270147],\\n         [25.088964, 22.661713, 26.104147, ..., 25.484823, 29.314367,\\n          26.270147],\\n         [25.088964, 22.661713, 26.104147, ..., 25.484823, 29.314367,\\n          26.270147],\\n         ...,\\n         [26.990273, 25.022303, 27.67881 , ..., 27.071297, 25.700762,\\n          23.792698],\\n         [26.990273, 25.022303, 27.67881 , ..., 27.071297, 25.700762,\\n          23.792698],\\n         [26.990273, 25.022303, 27.67881 , ..., 27.071297, 25.700762,\\n          23.792698]]]], dtype=float32).transpose\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +        where array([[[[18.771992, 15.500876, 19.784658, ..., 20.265377, 22.255096,\\n          19.472893],\\n         [18.771992, 15.500876, 19.784658, ..., 20.265377, 22.255096,\\n          19.472893],\\n         [18.771992, 15.500876, 19.784658, ..., 20.265377, 22.255096,\\n          19.472893],\\n         ...,\\n         [19.167946, 17.663925, 19.232843, ..., 20.495304, 18.54313 ,\\n          16.620861],\\n         [19.167946, 17.663925, 19.232843, ..., 20.495304, 18.54313 ,\\n          16.620861],\\n         [19.167946, 17.663925, 19.232843, ..., 20.495304, 18.54313 ,\\n          16.620861]],\\n\\n        [[21.237831, 20.533047, 18.348204, ..., 17.849451, 21.363873,\\n          17.676086],\\n         [21.237831, 20.533047, 18.348204, ..., 17.849451, 21.363873,\\n          17.676086],\\n         [21.237831, 20.533047, 18.348204, ..., 17.849451, 21.363873,\\n          17.676086],\\n         ...,\\n         [21.321896, 23.182398, 20.24112 , ..., 21.376657, 25.799896,\\n          21.255415],\\n         [21.321896, 23.182398, 20.24112 , ..., 21.376657, 25.799896,\\n          21.255415],\\n         [21.321896, 23.182398, 20.24112 , ..., 21.376657, 25.799896,\\n          21.255415]],\\n\\n        [[22.086725, 18.441025, 21.36781 , ..., 22.567696, 25...., 24.076834, 22.133162,\\n          20.057869]],\\n\\n        [[24.906967, 23.20027 , 21.956026, ..., 20.758915, 24.190678,\\n          21.203037],\\n         [24.906967, 23.20027 , 21.956026, ..., 20.758915, 24.190678,\\n          21.203037],\\n         [24.906967, 23.20027 , 21.956026, ..., 20.758915, 24.190678,\\n          21.203037],\\n         ...,\\n         [23.655466, 28.483591, 23.717907, ..., 23.634565, 29.720654,\\n          24.524452],\\n         [23.655466, 28.483591, 23.717907, ..., 23.634565, 29.720654,\\n          24.524452],\\n         [23.655466, 28.483591, 23.717907, ..., 23.634565, 29.720654,\\n          24.524452]],\\n\\n        [[25.088964, 22.661713, 26.104147, ..., 25.484823, 29.314367,\\n          26.270147],\\n         [25.088964, 22.661713, 26.104147, ..., 25.484823, 29.314367,\\n          26.270147],\\n         [25.088964, 22.661713, 26.104147, ..., 25.484823, 29.314367,\\n          26.270147],\\n         ...,\\n         [26.990273, 25.022303, 27.67881 , ..., 27.071297, 25.700762,\\n          23.792698],\\n         [26.990273, 25.022303, 27.67881 , ..., 27.071297, 25.700762,\\n          23.792698],\\n         [26.990273, 25.022303, 27.67881 , ..., 27.071297, 25.700762,\\n          23.792698]]]], dtype=float32) = numpy()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +          where numpy = NDArray([[[[18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   [18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   [18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   ...\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]]\\n\\n  [[21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   [21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   [21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   ...\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]]\\n\\n  [[22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   [22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   [22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   ...\\n   [21.458403 20.805967 23.513868 ... 22.648514 21.52253  19.956577]\\n   [21.458403 20.805967 23.513868 ... 22.648514 21.52253  19....785507 23.646713 ... 22.426697 25.38295  23.116304]\\n   [21.500883 18.785507 23.646713 ... 22.426697 25.38295  23.116304]\\n   ...\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]]\\n\\n  [[24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   [24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   [24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   ...\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]]\\n\\n  [[25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   [25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   [25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   ...\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]]]], device=cuda()).numpy\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +            where NDArray([[[[18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   [18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   [18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   ...\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]]\\n\\n  [[21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   [21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   [21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   ...\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]]\\n\\n  [[22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   [22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   [22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   ...\\n   [21.458403 20.805967 23.513868 ... 22.648514 21.52253  19.956577]\\n   [21.458403 20.805967 23.513868 ... 22.648514 21.52253  19....785507 23.646713 ... 22.426697 25.38295  23.116304]\\n   [21.500883 18.785507 23.646713 ... 22.426697 25.38295  23.116304]\\n   ...\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]]\\n\\n  [[24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   [24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   [24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   ...\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]]\\n\\n  [[25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   [25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   [25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   ...\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]]]], device=cuda()) = needle.Tensor([[[[18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   [18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   [18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   ...\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]]\\n\\n  [[21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   [21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   [21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   ...\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]]\\n\\n  [[22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   [22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   [22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   ...\\n   [21.458403 20.805967 23.513868 ... 22.648514 21.52253  19.956577]\\n   [21.458403 20.805967 23.513868 ... 22.648514 21.5225... [21.500883 18.785507 23.646713 ... 22.426697 25.38295  23.116304]\\n   [21.500883 18.785507 23.646713 ... 22.426697 25.38295  23.116304]\\n   ...\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]]\\n\\n  [[24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   [24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   [24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   ...\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]]\\n\\n  [[25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   [25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   [25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   ...\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]]]]).cached_data\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +              where needle.Tensor([[[[18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   [18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   [18.771992 15.500876 19.784658 ... 20.265377 22.255096 19.472893]\\n   ...\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]\\n   [19.167946 17.663925 19.232843 ... 20.495304 18.54313  16.620861]]\\n\\n  [[21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   [21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   [21.237831 20.533047 18.348204 ... 17.849451 21.363873 17.676086]\\n   ...\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]\\n   [21.321896 23.182398 20.24112  ... 21.376657 25.799896 21.255415]]\\n\\n  [[22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   [22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   [22.086725 18.441025 21.36781  ... 22.567696 25.569479 22.08527 ]\\n   ...\\n   [21.458403 20.805967 23.513868 ... 22.648514 21.52253  19.956577]\\n   [21.458403 20.805967 23.513868 ... 22.648514 21.5225... [21.500883 18.785507 23.646713 ... 22.426697 25.38295  23.116304]\\n   [21.500883 18.785507 23.646713 ... 22.426697 25.38295  23.116304]\\n   ...\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]\\n   [23.713486 21.15813  22.712273 ... 24.076834 22.133162 20.057869]]\\n\\n  [[24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   [24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   [24.906967 23.20027  21.956026 ... 20.758915 24.190678 21.203037]\\n   ...\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]\\n   [23.655466 28.483591 23.717907 ... 23.634565 29.720654 24.524452]]\\n\\n  [[25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   [25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   [25.088964 22.661713 26.104147 ... 25.484823 29.314367 26.270147]\\n   ...\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]\\n   [26.990273 25.022303 27.67881  ... 27.071297 25.700762 23.792698]]]]) = needle.Tensor([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\\n     0.15994066]\\n   [ 0.18928954 -0.0475848   0.11909625 ...  0.17374912 -0.17512381\\n    -0.16855377]\\n   [-0.19587003  0.13579148  0.11355701 ...  0.12213099 -0.01572599\\n     0.11452556]\\n   ...\\n   [-0.1025711   0.03109111  0.03757596 ...  0.184834   -0.02158597\\n     0.14142075]\\n   [ 0.08143708 -0.08269602  0.12810743 ...  0.03317952  0.15584281\\n     0.0786007 ]\\n   [ 0.09195969  0.00054066  0.18619537 ...  0.04343486 -0.19628856\\n    -0.08100674]]\\n\\n  [[ 0.06539059 -0.08570047  0.0481796  ... -0.0823509   0.02856305\\n     0.03709865]\\n   [ 0.03034316  0.06254396  0.06209588 ... -0.05406764 -0.02618304\\n     0.16000205]\\n   [ 0.12500319  0.08323717 -0.1632067  ...  0.20365345 -0.14311214\\n     0.15028682]\\n   ...\\n   [ 0.0074304  -0.19364738 -0.11942485 ... -0.01487027 -0.0907827\\n     0.03542957]\\n   [ 0.14854342 -0.15614197  0.00709499 ... -0.04243346  0.02670813\\n    -0.12930048]\\n   [-0.1449903  -0.004876   -0.05894586 ...  0.10151649  0.1648179\\n    -0.17006709]]\\n\\n  [[ 0.02130748  0.0344872   0.18858474 ... -0.16317932 -0.19741678\\n     0.1753546 ]\\n   [ 0.06936815  0.11641321 -0.08910831 ... -0.00586751  0.1949...89569 -0.08576748  0.03172475 ... -0.06347017  0.11058334\\n     0.09630328]\\n   [-0.14635438  0.1493966  -0.02395542 ...  0.02769801  0.04946715\\n    -0.0007432 ]]\\n\\n  [[ 0.14974082  0.05214751 -0.04024187 ... -0.06197537 -0.11779809\\n    -0.17988107]\\n   [ 0.15351233  0.17087087 -0.1550853  ... -0.1568088   0.16324493\\n    -0.1809041 ]\\n   [ 0.19615746 -0.16474825  0.1483863  ... -0.06436346  0.10506848\\n    -0.07570013]\\n   ...\\n   [ 0.03791821 -0.20001566 -0.0098689  ...  0.154939    0.0081982\\n    -0.19160683]\\n   [-0.11250767  0.18521234  0.03360689 ... -0.01767567 -0.19557132\\n    -0.03608282]\\n   [-0.0043035  -0.10464308  0.03618672 ...  0.04919389  0.05700055\\n     0.18311584]]\\n\\n  [[ 0.11360577  0.14221138 -0.00391106 ... -0.15131488 -0.0116525\\n    -0.17632526]\\n   [ 0.18120137  0.18980482  0.08956522 ... -0.09581453 -0.15215659\\n     0.01053645]\\n   [-0.1462275  -0.07481939  0.05172771 ... -0.02853003  0.06210461\\n     0.14421207]\\n   ...\\n   [-0.15185985  0.03396332 -0.20328127 ... -0.06922235  0.05649754\\n    -0.08946374]\\n   [ 0.18282253  0.09330872 -0.06954463 ... -0.04396062 -0.11381223\\n     0.07500601]\\n   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\\n     0.05469996]]]]).grad\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +                where needle.Tensor([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\\n     0.15994066]\\n   [ 0.18928954 -0.0475848   0.11909625 ...  0.17374912 -0.17512381\\n    -0.16855377]\\n   [-0.19587003  0.13579148  0.11355701 ...  0.12213099 -0.01572599\\n     0.11452556]\\n   ...\\n   [-0.1025711   0.03109111  0.03757596 ...  0.184834   -0.02158597\\n     0.14142075]\\n   [ 0.08143708 -0.08269602  0.12810743 ...  0.03317952  0.15584281\\n     0.0786007 ]\\n   [ 0.09195969  0.00054066  0.18619537 ...  0.04343486 -0.19628856\\n    -0.08100674]]\\n\\n  [[ 0.06539059 -0.08570047  0.0481796  ... -0.0823509   0.02856305\\n     0.03709865]\\n   [ 0.03034316  0.06254396  0.06209588 ... -0.05406764 -0.02618304\\n     0.16000205]\\n   [ 0.12500319  0.08323717 -0.1632067  ...  0.20365345 -0.14311214\\n     0.15028682]\\n   ...\\n   [ 0.0074304  -0.19364738 -0.11942485 ... -0.01487027 -0.0907827\\n     0.03542957]\\n   [ 0.14854342 -0.15614197  0.00709499 ... -0.04243346  0.02670813\\n    -0.12930048]\\n   [-0.1449903  -0.004876   -0.05894586 ...  0.10151649  0.1648179\\n    -0.17006709]]\\n\\n  [[ 0.02130748  0.0344872   0.18858474 ... -0.16317932 -0.19741678\\n     0.1753546 ]\\n   [ 0.06936815  0.11641321 -0.08910831 ... -0.00586751  0.1949...89569 -0.08576748  0.03172475 ... -0.06347017  0.11058334\\n     0.09630328]\\n   [-0.14635438  0.1493966  -0.02395542 ...  0.02769801  0.04946715\\n    -0.0007432 ]]\\n\\n  [[ 0.14974082  0.05214751 -0.04024187 ... -0.06197537 -0.11779809\\n    -0.17988107]\\n   [ 0.15351233  0.17087087 -0.1550853  ... -0.1568088   0.16324493\\n    -0.1809041 ]\\n   [ 0.19615746 -0.16474825  0.1483863  ... -0.06436346  0.10506848\\n    -0.07570013]\\n   ...\\n   [ 0.03791821 -0.20001566 -0.0098689  ...  0.154939    0.0081982\\n    -0.19160683]\\n   [-0.11250767  0.18521234  0.03360689 ... -0.01767567 -0.19557132\\n    -0.03608282]\\n   [-0.0043035  -0.10464308  0.03618672 ...  0.04919389  0.05700055\\n     0.18311584]]\\n\\n  [[ 0.11360577  0.14221138 -0.00391106 ... -0.15131488 -0.0116525\\n    -0.17632526]\\n   [ 0.18120137  0.18980482  0.08956522 ... -0.09581453 -0.15215659\\n     0.01053645]\\n   [-0.1462275  -0.07481939  0.05172771 ... -0.02853003  0.06210461\\n     0.14421207]\\n   ...\\n   [-0.15185985  0.03396332 -0.20328127 ... -0.06922235  0.05649754\\n    -0.08946374]\\n   [ 0.18282253  0.09330872 -0.06954463 ... -0.04396062 -0.11381223\\n     0.07500601]\\n   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\\n     0.05469996]]]]) = <needle.nn.nn_conv.Conv object at 0x7831400e2930>.weight\u001b[0m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x7831400e2930>\n",
            "g          = Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "res1       = needle.Tensor([[[[ 0.6003743   0.3453774  -0.32563293  0.3608924   0.39934382\n",
            "     0.9340804   0.35171503]\n",
            "   [ 0.0625....19365051 -1.0505217 ]\n",
            "   [ 0.04790778  0.34266293 -0.0792975  -0.7152328   0.05762078\n",
            "    -0.08526006 -0.2620045 ]]]])\n",
            "s          = 14\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.7510323  0.15597793 0.42600238 ... 0.38840413 0.4862721\n",
            "    0.58815145]\n",
            "   [0.9838538  0.69733024 ...0.35930127 0.41500303\n",
            "    0.3384509 ]\n",
            "   [0.4826699  0.37319595 0.14424832 ... 0.36331356 0.6944434\n",
            "    0.39911222]]]])\n",
            "y1         = needle.Tensor([-61.946304])\n",
            "y2         = tensor(-56.6445, grad_fn=<SumBackward0>)\n",
            "z          = tensor([[[[0.7510, 0.1560, 0.4260,  ..., 0.3884, 0.4863, 0.5882],\n",
            "          [0.9839, 0.6973, 0.3895,  ..., 0.3675, 0.7....3593, 0.4150, 0.3385],\n",
            "          [0.4827, 0.3732, 0.1442,  ..., 0.3633, 0.6944, 0.3991]]]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:391: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-4-1-1-3-1]\u001b[0m - AssertionError: weight gradients match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-1]\u001b[0m - AssertionError: weight gradients match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-2]\u001b[0m - AssertionError: weight gradients match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-1]\u001b[0m - AssertionError: weight gradients match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-2]\u001b[0m - AssertionError: weight gradients match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-1]\u001b[0m - AssertionError: weight gradients match\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-2]\u001b[0m - AssertionError: weight gradients match\n",
            "\u001b[31m================= \u001b[31m\u001b[1m7 failed\u001b[0m, \u001b[32m7 passed\u001b[0m, \u001b[33m1789 deselected\u001b[0m\u001b[31m in 3.34s\u001b[0m\u001b[31m =================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"nn_conv_backward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYahLVlfnJnq"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6luIBnunJnq"
      },
      "source": [
        "### Submit nn.Conv to mugrade [20 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "1vTJ_ypHnJnq",
        "outputId": "e675783f-1486-426a-d3dd-f56f8de80316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py \n",
            "Submitting conv_forward...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 passed\n",
            "Grader test 5 passed\n",
            "Grader test 6 passed\n",
            "Grader test 7 passed\n",
            "Grader test 8 passed\n",
            "Grader test 9 passed\n",
            "Grader test 10 passed\n",
            "Grader test 11 passed\n",
            "Grader test 12 passed\n",
            "Grader test 13 failed\n",
            "Grader test 14 failed\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_____________________________ submit_conv_forward ______________________________\u001b[0m\n",
            "\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_conv_forward\u001b[0m - Failed\n",
            "\u001b[31m================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 8.83s\u001b[0m\u001b[31m ==================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"conv_forward\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "6H-ZJm3NnJnq",
        "outputId": "35496b54-29d2-45fc-e8b2-808545567054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py \n",
            "Submitting conv_backward...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 passed\n",
            "Grader test 5 passed\n",
            "Grader test 6 passed\n",
            "Grader test 7 passed\n",
            "Grader test 8 passed\n",
            "Grader test 9 passed\n",
            "Grader test 10 passed\n",
            "Grader test 11 passed\n",
            "Grader test 12 passed\n",
            "Grader test 13 passed\n",
            "Grader test 14 passed\n",
            "Grader test 15 passed\n",
            "Grader test 16 passed\n",
            "Grader test 17 failed\n",
            "Grader test 18 passed\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_____________________________ submit_conv_backward _____________________________\u001b[0m\n",
            "\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_conv_backward\u001b[0m - Failed\n",
            "\u001b[31m================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 9.29s\u001b[0m\u001b[31m ==================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"conv_backward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRZoYViYnJnq"
      },
      "source": [
        "------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "PqafvMkmnJnq"
      },
      "source": [
        "### Implementing \"ResNet9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1IRcp4DnJnq"
      },
      "source": [
        "You will now use your convolutional layer to implement a model similar to _ResNet9_, which is known to be a reasonable model for getting good accuracy on CIFAR-10 quickly (see [here](https://github.com/davidcpage/cifar10-fast)). Our main change is that we used striding instead of pooling and divided all of the channels by 4 for the sake of performance (as our framework is not as well-optimized as industry-grade frameworks).\n",
        "\n",
        "In the figure below, before the first linear layer, you should \"flatten\" the tensor. You can use the module `Flatten` in `nn_basic.py`, or you can simply use `.reshape` in the `forward()` method of your ResNet9.\n",
        "\n",
        "Make sure that you pass the device to all modules in your model; otherwise, you will get errors about mismatched devices when trying to run with CUDA.\n",
        "\n",
        "<center><img src=\"https://github.com/dlsyscourse/hw4/blob/main/ResNet9.png?raw=true\" alt=\"ResNet9\" style=\"width: 400px;\" /></center>\n",
        "\n",
        "We have tried to make it easier to pass the tests here than for previous assignments where you have implemented models. In particular, we are just going to make sure it has the right number of parameters and similar accuracy and loss after 1 or 2 batches of CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "tags": [],
        "id": "Hw9YaMJKnJnq",
        "outputId": "eb4294f3-1780-4c19-90cb-e1e5e2835e2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_cpu] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m___________ test_resnet9[needle.backend_ndarray.ndarray_backend_cpu] ___________\u001b[0m\n",
            "\n",
            "device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_resnet9\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mnum_params\u001b[39;49;00m(model):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m np.sum([np.prod(x.shape) \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m model.parameters()])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        model = ResNet9(device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m num_params(model) == \u001b[94m431946\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.int64(432117) == 431946\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.int64(432117) = <function test_resnet9.<locals>.num_params at 0x7b248efc8860>(<apps.models.ResNet9 object at 0x7b248fab7770>)\u001b[0m\n",
            "\n",
            "ResNet9    = <class 'apps.models.ResNet9'>\n",
            "device     = cpu()\n",
            "model      = <apps.models.ResNet9 object at 0x7b248fab7770>\n",
            "num_params = <function test_resnet9.<locals>.num_params at 0x7b248efc8860>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:182: AssertionError\n",
            "\u001b[31m\u001b[1m__________ test_resnet9[needle.backend_ndarray.ndarray_backend_cuda] ___________\u001b[0m\n",
            "\n",
            "device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_resnet9\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mnum_params\u001b[39;49;00m(model):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m np.sum([np.prod(x.shape) \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m model.parameters()])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        model = ResNet9(device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m num_params(model) == \u001b[94m431946\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert np.int64(432117) == 431946\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where np.int64(432117) = <function test_resnet9.<locals>.num_params at 0x7b248efc9940>(<apps.models.ResNet9 object at 0x7b248fac9520>)\u001b[0m\n",
            "\n",
            "ResNet9    = <class 'apps.models.ResNet9'>\n",
            "device     = cuda()\n",
            "model      = <apps.models.ResNet9 object at 0x7b248fac9520>\n",
            "num_params = <function test_resnet9.<locals>.num_params at 0x7b248efc9940>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:182: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_resnet9[needle.backend_ndarray.ndarray_backend_cpu]\u001b[0m - assert np.int64(432117) == 431946\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_resnet9[needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - assert np.int64(432117) == 431946\n",
            "\u001b[31m====================== \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[31m in 2.21s\u001b[0m\u001b[31m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"resnet9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AygOC4QSnJnq"
      },
      "source": [
        "Now we can train a ResNet on CIFAR10: (remember to copy the solutions in `python/needle/optim.py` from previous homeworks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "_UDmQVbUnJnq",
        "outputId": "a39f23f1-3a79-420b-9037-c7674b49ad00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_cpu] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m________ test_train_cifar10[needle.backend_ndarray.ndarray_backend_cpu] ________\u001b[0m\n",
            "\n",
            "device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_train_cifar10\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataset = ndl.data.CIFAR10Dataset(\u001b[33m\"\u001b[39;49;00m\u001b[33m./data/cifar-10-batches-py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, train=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataloader = ndl.data.DataLoader(\\\n",
            "                 dataset=dataset,\u001b[90m\u001b[39;49;00m\n",
            "                 batch_size=\u001b[94m128\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "                 shuffle=\u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# collate_fn=ndl.data.collate_ndarray,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# drop_last=False,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# device=device,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# dtype=\"float32\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 )\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        model = ResNet9(device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        out = one_iter_of_cifar10_training(dataloader, model, opt=ndl.optim.Adam(model.parameters(), lr=\u001b[94m0.001\u001b[39;49;00m, weight_decay=\u001b[94m0.001\u001b[39;49;00m), device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(np.array(\u001b[96mlist\u001b[39;49;00m(out), dtype=\u001b[96mobject\u001b[39;49;00m) - np.array([\u001b[94m0.09375\u001b[39;49;00m, \u001b[94m3.5892258\u001b[39;49;00m])) < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert array([0.5489134]) < 0.01\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where array([0.5489134]) = <function norm at 0x7a935833abf0>((array([np.float64(0.0390625), array([3.0430434], dtype=float32)],\\n      dtype=object) - array([0.09375  , 3.5892258])))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x7a935833abf0> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([np.float64(0.0390625), array([3.0430434], dtype=float32)],\\n      dtype=object) = <built-in function array>([np.float64(0.0390625), array([3.0430434], dtype=float32)], dtype=object)\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in function array> = np.array\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      and   [np.float64(0.0390625), array([3.0430434], dtype=float32)] = list((np.float64(0.0390625), array([3.0430434], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([0.09375  , 3.5892258]) = <built-in function array>([0.09375, 3.5892258])\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in function array> = np.array\u001b[0m\n",
            "\n",
            "ResNet9    = <class 'apps.models.ResNet9'>\n",
            "dataloader = <needle.data.data_basic.DataLoader object at 0x7a9278225d00>\n",
            "dataset    = <needle.data.datasets.cifar10_dataset.CIFAR10Dataset object at 0x7a92783a20c0>\n",
            "device     = cpu()\n",
            "model      = <apps.models.ResNet9 object at 0x7a92784de9c0>\n",
            "out        = (np.float64(0.0390625), array([3.0430434], dtype=float32))\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:468: AssertionError\n",
            "\u001b[31m\u001b[1m_______ test_train_cifar10[needle.backend_ndarray.ndarray_backend_cuda] ________\u001b[0m\n",
            "\n",
            "device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_train_cifar10\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataset = ndl.data.CIFAR10Dataset(\u001b[33m\"\u001b[39;49;00m\u001b[33m./data/cifar-10-batches-py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, train=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataloader = ndl.data.DataLoader(\\\n",
            "                 dataset=dataset,\u001b[90m\u001b[39;49;00m\n",
            "                 batch_size=\u001b[94m128\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "                 shuffle=\u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# collate_fn=ndl.data.collate_ndarray,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# drop_last=False,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# device=device,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# dtype=\"float32\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 )\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        model = ResNet9(device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        out = one_iter_of_cifar10_training(dataloader, model, opt=ndl.optim.Adam(model.parameters(), lr=\u001b[94m0.001\u001b[39;49;00m, weight_decay=\u001b[94m0.001\u001b[39;49;00m), device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(np.array(\u001b[96mlist\u001b[39;49;00m(out), dtype=\u001b[96mobject\u001b[39;49;00m) - np.array([\u001b[94m0.09375\u001b[39;49;00m, \u001b[94m3.5892258\u001b[39;49;00m])) < \u001b[94m1e-2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert array([0.47527399]) < 0.01\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where array([0.47527399]) = <function norm at 0x7a935833abf0>((array([np.float64(0.1484375), array([3.1171086], dtype=float32)],\\n      dtype=object) - array([0.09375  , 3.5892258])))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function norm at 0x7a935833abf0> = <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'>.norm\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'numpy.linalg' from '/usr/local/lib/python3.12/dist-packages/numpy/linalg/__init__.py'> = np.linalg\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([np.float64(0.1484375), array([3.1171086], dtype=float32)],\\n      dtype=object) = <built-in function array>([np.float64(0.1484375), array([3.1171086], dtype=float32)], dtype=object)\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in function array> = np.array\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      and   [np.float64(0.1484375), array([3.1171086], dtype=float32)] = list((np.float64(0.1484375), array([3.1171086], dtype=float32)))\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    and   array([0.09375  , 3.5892258]) = <built-in function array>([0.09375, 3.5892258])\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <built-in function array> = np.array\u001b[0m\n",
            "\n",
            "ResNet9    = <class 'apps.models.ResNet9'>\n",
            "dataloader = <needle.data.data_basic.DataLoader object at 0x7a9278380bc0>\n",
            "dataset    = <needle.data.datasets.cifar10_dataset.CIFAR10Dataset object at 0x7a92784dc140>\n",
            "device     = cuda()\n",
            "model      = <apps.models.ResNet9 object at 0x7a927752c230>\n",
            "out        = (np.float64(0.1484375), array([3.1171086], dtype=float32))\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:468: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_train_cifar10[needle.backend_ndarray.ndarray_backend_cpu]\u001b[0m - AssertionError: assert array([0.5489134]) < 0.01\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_train_cifar10[needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - AssertionError: assert array([0.47527399]) < 0.01\n",
            "\u001b[31m===================== \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[31m in 14.39s\u001b[0m\u001b[31m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"train_cifar10\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4DpndxUnJnq"
      },
      "source": [
        "### Submit ResNet9 to mugrade [10 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "kyGa4egjnJnq",
        "outputId": "d04c970e-ebf5-4c69-f2e3-2e1b3e370c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py \n",
            "Submitting resnet9...\n",
            "Grader test 1 passed\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m________________________________ submit_resnet9 ________________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_resnet9\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mnum_params\u001b[39;49;00m(model):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m np.sum([np.prod(x.shape) \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m model.parameters()])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        device = ndl.cpu()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msys\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        sys.path.append(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        model = ResNet9(device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        MugradeSubmit(ndl.Tensor(num_params(model)))\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataset = ndl.data.CIFAR10Dataset(\u001b[33m\"\u001b[39;49;00m\u001b[33m./data/cifar-10-batches-py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, train=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataloader = ndl.data.DataLoader(\\\n",
            "                 dataset=dataset,\u001b[90m\u001b[39;49;00m\n",
            "                 batch_size=\u001b[94m128\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "                 shuffle=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 )\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        model = ResNet9(device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       out = one_iter_of_cifar10_training(dataloader, model, niter=\u001b[94m2\u001b[39;49;00m, opt=ndl.optim.Adam(model.parameters(), lr=\u001b[94m0.01\u001b[39;49;00m, weight_decay=\u001b[94m0.0001\u001b[39;49;00m), device=device)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:674: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:480: in one_iter_of_cifar10_training\n",
            "    \u001b[0mout = model(X)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:74: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mapps/models.py\u001b[0m:69: in forward\n",
            "    \u001b[0midentity = \u001b[96mself\u001b[39;49;00m.block1_bn_shortcut(identity)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:74: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:384: in forward\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.running_mean = (\u001b[94m1\u001b[39;49;00m - \u001b[96mself\u001b[39;49;00m.momentum) * \u001b[96mself\u001b[39;49;00m.running_mean + \u001b[96mself\u001b[39;49;00m.momentum * mean_flat.data\u001b[90m\u001b[39;49;00m\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:313: in __add__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m needle.ops.EWiseAdd()(\u001b[96mself\u001b[39;49;00m, other)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:241: in make_from_op\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m tensor.detach()\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:273: in detach\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_const(\u001b[96mself\u001b[39;49;00m.realize_cached_data())\u001b[90m\u001b[39;49;00m\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:19: in compute\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m a + b\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:519: in __add__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.ewise_or_scalar(\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = NDArray([-0.01124467 -0.01697299 -0.01829504  0.01372396 -0.04339252  0.07476905\n",
            "  0.05256209  0.0233132  -0.03569647 ...72479\n",
            "  0.00265029  0.07780222  0.05371661  0.01301924  0.02974138 -0.04419919\n",
            " -0.0468902  -0.07490143], device=cpu())\n",
            "other = NDArray([-0.01244413 -0.01847055 -0.01486883  0.01640464 -0.04757325  0.07813329\n",
            "  0.05853658  0.02522643 -0.03788179 ... -0.00192338  0.08786988  0.06013714  0.01616767  0.02776071 -0.04952963\n",
            " -0.05451627 -0.08586541], device=cpu_numpy())\n",
            "ewise_func = <built-in method ewise_add of pybind11_builtins.pybind11_detail_function_record_v1_system_libstdcpp_gxx_abi_1xxx_use_cxx11_abi_1 object at 0x7d117a02a1d0>\n",
            "scalar_func = <built-in method scalar_add of pybind11_builtins.pybind11_detail_function_record_v1_system_libstdcpp_gxx_abi_1xxx_use_cxx11_abi_1 object at 0x7d117a02a1f0>\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mewise_or_scalar\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[96mself\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        other: Union[\u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[96mfloat\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "        ewise_func: Callable[[Any, Any, Any], \u001b[94mNone\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "        scalar_func: Callable[[Any, Any, Any], \u001b[94mNone\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run either an elementwise or scalar version of a function,\u001b[39;49;00m\n",
            "    \u001b[33m    depending on whether \"other\" is an NDArray or scalar\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        out = NDArray.make(\u001b[96mself\u001b[39;49;00m.shape, device=\u001b[96mself\u001b[39;49;00m.device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(other, NDArray):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94massert\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.shape == other.shape, \u001b[33m\"\u001b[39;49;00m\u001b[33moperation needs two equal-sized arrays\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           ewise_func(\u001b[96mself\u001b[39;49;00m.compact()._handle, other.compact()._handle, out._handle)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           TypeError: ewise_add(): incompatible function arguments. The following argument types are supported:\u001b[0m\n",
            "\u001b[1m\u001b[31mE               1. (arg0: needle.backend_ndarray.ndarray_backend_cpu.Array, arg1: needle.backend_ndarray.ndarray_backend_cpu.Array, arg2: needle.backend_ndarray.ndarray_backend_cpu.Array) -> None\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Invoked with: <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x7d1097e32ff0>, <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x7d1097fdd970>, <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x7d1097e332b0>\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:513: TypeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_resnet9\u001b[0m - TypeError: ewise_add(): incompatible function arguments. The following argu...\n",
            "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 12.73s\u001b[0m\u001b[31m =======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"resnet9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkCfGWeMnJnq"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utxSyaHDnJnq"
      },
      "source": [
        "Now, you can train your model on CIFAR-10 using the following code. Note that this is likely going to be quite slow, and also  not all that accurate due to the lack of data augmentation. You should expect it to take around 500s per epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "qY-winspnJnr",
        "outputId": "2aa4828d-eebf-4ef4-d042-1da3c342224e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ewise_add(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: needle.backend_ndarray.ndarray_backend_cpu.Array, arg1: needle.backend_ndarray.ndarray_backend_cpu.Array, arg2: needle.backend_ndarray.ndarray_backend_cpu.Array) -> None\n\nInvoked with: <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x7d7508726db0>, <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x7d74f858f4d0>, <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x7d7508727270>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1616907413.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m          shuffle=True,)\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m train_cifar10(model, dataloader, n_epochs=10, optimizer=ndl.optim.Adam,\n\u001b[0m\u001b[1;32m     16\u001b[0m       lr=0.001, weight_decay=0.001)\n\u001b[1;32m     17\u001b[0m \u001b[0mevaluate_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/apps/simple_ml.py\u001b[0m in \u001b[0;36mtrain_cifar10\u001b[0;34m(model, dataloader, n_epochs, optimizer, lr, weight_decay, loss_fn)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mavg_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_general_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/apps/simple_ml.py\u001b[0m in \u001b[0;36mepoch_general_cifar10\u001b[0;34m(dataloader, model, loss_fn, opt)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/nn/nn_basic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/apps/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# Initial conv + bn + relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/nn/nn_basic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/nn/nn_basic.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mvariance_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmean_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvariance_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/autograd.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mneedle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEWiseAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mneedle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddScalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/autograd.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_from_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/autograd.py\u001b[0m in \u001b[0;36mmake_from_op\u001b[0;34m(op, inputs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mLAZY_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealize_cached_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/autograd.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;34m\"\"\"Create a new tensor that shares the data but detaches from the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealize_cached_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/autograd.py\u001b[0m in \u001b[0;36mrealize_cached_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# note: data implicitly calls realized cached data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         self.cached_data = self.op.compute(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealize_cached_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         )\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/ops/ops_mathematic.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEWiseAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorOp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/backend_ndarray/ndarray.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NDArray\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"NDArray\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         return self.ewise_or_scalar(\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mewise_add\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         )\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/backend_ndarray/ndarray.py\u001b[0m in \u001b[0;36mewise_or_scalar\u001b[0;34m(self, other, ewise_func, scalar_func)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"operation needs two equal-sized arrays\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0mewise_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mscalar_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ewise_add(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: needle.backend_ndarray.ndarray_backend_cpu.Array, arg1: needle.backend_ndarray.ndarray_backend_cpu.Array, arg2: needle.backend_ndarray.ndarray_backend_cpu.Array) -> None\n\nInvoked with: <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x7d7508726db0>, <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x7d74f858f4d0>, <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x7d7508727270>"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('./python')\n",
        "sys.path.append('./apps')\n",
        "import needle as ndl\n",
        "from models import ResNet9\n",
        "from simple_ml import train_cifar10, evaluate_cifar10\n",
        "\n",
        "device = ndl.cpu()\n",
        "dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=True)\n",
        "dataloader = ndl.data.DataLoader(\\\n",
        "         dataset=dataset,\n",
        "         batch_size=128,\n",
        "         shuffle=True,)\n",
        "model = ResNet9(device=device, dtype=\"float32\")\n",
        "train_cifar10(model, dataloader, n_epochs=10, optimizer=ndl.optim.Adam,\n",
        "      lr=0.001, weight_decay=0.001)\n",
        "evaluate_cifar10(model, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcSy6UV8nJnr"
      },
      "source": [
        "## Part 4: Recurrent neural network [10 points]\n",
        "\n",
        "**Note:** In the following sections, you may find yourself wanting to index into tensors, i.e., to use getitem or setitem. However, we have not implemented these for tensors in our library; instead, you should use `stack` and `split` operations.\n",
        "\n",
        "In `python/needle/nn/nn_sequence.py`, implement `RNNCell`.\n",
        "\n",
        "$h^\\prime = \\text{tanh}(xW_{ih} + b_{ih} + hW_{hh} + b_{hh})$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
        "\n",
        "All weights and biases should be uniformly initialized on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|hidden_size|}}$.\n",
        "\n",
        "In `python/needle/nn/nn_sequence.py`, implement `RNN`.\n",
        "\n",
        "For each element in the input sequence, each layer computes the following function:\n",
        "\n",
        "$h_t = \\text{tanh}(x_tW_{ih} + b_{ih} + h_{(t-1)}W_{hh} + b_{hh})$\n",
        "\n",
        "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $0$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
        "\n",
        "In a multi-layer RNN, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcJic5c4nJnr"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"test_rnn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFxr6W5knJnr"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"rnn\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4NsymqjnJnr"
      },
      "source": [
        "## Part 5: Long short-term memory network [10 points]\n",
        "In `python/needle/nn/nn_sequence.py`, implement `Sigmoid`.\n",
        "\n",
        "$$\\sigma(x) = \\frac{1}{1 + \\text{exp}(-x)}$$\n",
        "\n",
        "In `python/needle/nn/nn_sequence.py`, implement `LSTMCell`.\n",
        "\n",
        "\\begin{align*}\n",
        "i &= \\sigma(xW_{ii} + b_{ii} + hW_{hi} + b_{hi}) \\\\\n",
        "f &= \\sigma(xW_{if} + b_{if} + hW_{hf} + b_{hf}) \\\\\n",
        "g &= \\text{tanh}(xW_{ig} + b_{ig} + hW_{hg} + b_{hg}) \\\\\n",
        "o &= \\sigma(xW_{io} + b_{io} + hW_{ho} + b_{ho}) \\\\\n",
        "c^\\prime &= f * c + i * g \\\\\n",
        "h^\\prime &= o * \\text{tanh}(c^\\prime)\n",
        "\\end{align*}\n",
        "\n",
        "where $\\sigma$ is the sigmoid function, and $i$, $f$, $g$, $o$ are the input, forget, cell, and output gates, respectively.\n",
        "\n",
        "All weights and biases should be uniformly initialized on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|hidden_size|}}$.\n",
        "\n",
        "Now implement `LSTM` in `python/needle/nn/nn_sequence.py`, which applies a multi-layer LSTM RNN to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
        "\n",
        "\\begin{align*}\n",
        "i_t &= \\sigma(x_tW_{ii} + b_{ii} + h_{(t-1)}W_{hi} + b_{hi}) \\\\\n",
        "f_t &= \\sigma(x_tW_{if} + b_{if} + h_{(t-1)}W_{hf} + b_{hf}) \\\\\n",
        "g_t &= \\text{tanh}(x_tW_{ig} + b_{ig} + h_{(t-1)}W_{hg} + b_{hg}) \\\\\n",
        "o_t &= \\sigma(x_tW_{io} + b_{io} + h_{(t-1)}W_{ho} + b_{ho}) \\\\\n",
        "c_t &= f * c_{(t-1)} + i * g \\\\\n",
        "h_t &= o * \\text{tanh}(c_t)\n",
        "\\end{align*}\n",
        "\n",
        "where $h_t$ is the hidden state at time $t$, $c_t$ is the cell state at time $t$, $x_t$ is the input at time $t$, $h_{(t-1)}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $i_t$, $f_t$, $g_t$, $o_t$ are the input, forget, cell, and output gates at time $t$ respectively.\n",
        "\n",
        "In a multi-layer LSTM, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "hca5CX5VnJnr",
        "outputId": "bccad994-f498-4d57-eec8-549d324e8e8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "c          = needle.Tensor([[[-6.53184578e-03 -1.30418316e-01  3.68549109e-01 -1.85265616e-01\n",
            "   -5.10368466e-01  1.52175903e-01  9... -6.81590736e-02  2.24329866e-04  2.19927102e-01\n",
            "   -1.06442064e-01 -1.11458927e-01  5.48632331e-02  3.30089703e-02]]])\n",
            "c0         = array([[[ 1.31444484e-01, -7.94077158e-01,  9.86656994e-02,\n",
            "         -5.60672641e-01, -9.55029368e-01,  8.74853551e-01...,  1.40056252e+00, -6.19853795e-01,\n",
            "          8.31480086e-01,  2.17169493e-01,  1.12632047e-02]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[-6.5318e-03, -1.3042e-01,  3.6855e-01, -1.8527e-01, -5.1037e-01,\n",
            "           1.5218e-01,  9.1693e-02,  2.2960...2,  2.2433e-04,  2.1993e-01, -1.0644e-01, -1.1146e-01,\n",
            "           5.4863e-02,  3.3009e-02]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-2.66047055e-03 -3.16154100e-02  1.72896296e-01 -5.63746691e-02\n",
            "   -2.51199394e-01  8.02032873e-02  1... -3.47465649e-02  1.07174004e-04  1.13362916e-01\n",
            "   -5.59429266e-02 -5.36137335e-02  2.34538708e-02  1.60172712e-02]]])\n",
            "h0         = array([[[ 3.56491894e-01,  2.30861449e+00,  9.86380279e-02,\n",
            "         -8.70453894e-01, -6.65651143e-01, -1.19114959e+00...,  4.51493859e-01, -2.41690445e+00,\n",
            "         -9.21496689e-01, -4.78229254e-01, -6.72144592e-01]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[-2.6605e-03, -3.1615e-02,  1.7290e-01, -5.6375e-02, -2.5120e-01,\n",
            "           8.0203e-02,  1.9643e-02,  1.5214...2,  1.0717e-04,  1.1336e-01, -5.5943e-02, -5.3614e-02,\n",
            "           2.3454e-02,  1.6017e-02]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3215d49910>\n",
            "model_     = LSTM(11, 12, num_layers=2)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[-1.08300731e-01  6.21972308e-02 -3.54666524e-02  1.56866033e-02\n",
            "    7.00628608e-02 -1.17705174e-01  3... -3.47465649e-02  1.07174004e-04  1.13362916e-01\n",
            "   -5.59429266e-02 -5.36137335e-02  2.34538708e-02  1.60172712e-02]]])\n",
            "output_    = tensor([[[-1.0830e-01,  6.2197e-02, -3.5467e-02,  1.5687e-02,  7.0063e-02,\n",
            "          -1.1771e-01,  3.4427e-02,  7.4629...7e-04,  1.1336e-01, -5.5943e-02, -5.3614e-02,\n",
            "           2.3454e-02,  1.6017e-02]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.04406188,  1.0202578 , -0.15045263, -1.0234247 ,\n",
            "          0.9015678 ,  1.7106405 , -0.6382116 ,  2.215412...  -1.2235752 ,  0.52470136,  0.38073733, -0.8149948 ,\n",
            "          0.59782416,  2.0879087 , -1.5430033 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e3201700900>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...715e-03, -8.56832508e-03,  1.65297277e-02,\n",
            "        -1.88131146e-02, -6.44158153e-03,  9.62477364e-03]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 429 / 528 (81.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 1.521169\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 443.6227\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00,  0.000000e+00,  6.336337e-03, -5.669549e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -1.569688e-01,  0.000000e+00,  0.000000e+00,  0.000000e+00,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-7.493573e-03, -6.077600e-02,  8.939402e-04, -1.355923e-03,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    2.362319e-02, -7.367465e-03, -1.222222e-02, -1.709449e-03,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -3.513089e-03, -7.913508e-02,  1.382303e-02,  2.170781e-02,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e3201700900>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...715e-03, -8.56832508e-03,  1.65297277e-02,\n",
            "        -1.88131146e-02, -6.44158153e-03,  9.62477364e-03]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-True-12-11-15-2-13] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
            "hidden_size = 12, bias = True, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "c          = needle.Tensor([[[-0.3560576  -0.45338145 -0.3006407  -0.1575435  -0.05657751\n",
            "   -0.21557392  0.05490368  0.03480448  0...27 -0.39702755 -0.43243688\n",
            "    0.17633706 -0.33328718 -0.12735859  0.32533488 -0.1329881\n",
            "   -0.15667209  0.19234961]]])\n",
            "c0         = array([[[ 1.51496279e+00, -6.66881166e-03, -1.79935291e-01,\n",
            "         -1.04663742e+00, -6.11191273e-01,  4.03611243e-01..., -2.16985154e+00,  6.34999573e-01,\n",
            "         -1.32335579e+00,  9.85150635e-01, -4.49107289e-01]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[-0.3561, -0.4534, -0.3006, -0.1575, -0.0566, -0.2156,  0.0549,\n",
            "           0.0348,  0.4109, -0.0117,  0.4009,..., -0.4324,  0.1763, -0.3333,\n",
            "          -0.1274,  0.3253, -0.1330, -0.1567,  0.1923]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-0.19096325 -0.15977895 -0.12090304 -0.05508323 -0.02161711\n",
            "   -0.13270152  0.03334918  0.01697128  0...7 -0.1994737  -0.18012556\n",
            "    0.0656231  -0.13502255 -0.05918615  0.14048524 -0.07669939\n",
            "   -0.08601972  0.10046706]]])\n",
            "h0         = array([[[-0.44127107,  0.45554808, -0.50923526,  1.2937808 ,\n",
            "          1.0451738 ,  0.32072353, -1.0020804 , -1.362361...7836434, -1.1274892 ,  0.09760167,\n",
            "          0.5830532 ,  1.207975  , -0.3775419 ,  0.10933118]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[-0.1910, -0.1598, -0.1209, -0.0551, -0.0216, -0.1327,  0.0333,\n",
            "           0.0170,  0.1988, -0.0040,  0.1827,..., -0.1801,  0.0656, -0.1350,\n",
            "          -0.0592,  0.1405, -0.0767, -0.0860,  0.1005]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32162ac140>\n",
            "model_     = LSTM(11, 12, num_layers=2)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[ 0.04426911  0.06845301  0.0233041  ... -0.03667276 -0.00592951\n",
            "    0.06043629]\n",
            "  [ 0.03362602  0.072...41198 -0.07111498\n",
            "    0.11173138]\n",
            "  [ 0.04462204  0.08543843  0.00899077 ... -0.07669939 -0.08601972\n",
            "    0.10046706]]])\n",
            "output_    = tensor([[[ 0.0443,  0.0685,  0.0233,  ..., -0.0367, -0.0059,  0.0604],\n",
            "         [ 0.0336,  0.0726, -0.0119,  ...,  0.0...17],\n",
            "         [ 0.0446,  0.0854,  0.0090,  ..., -0.0767, -0.0860,  0.1005]]],\n",
            "       grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 2.35399246e+00, -7.39936829e-01,  3.94241214e-01, ...,\n",
            "          3.52175593e-01,  8.43076527e-01,  7.1847848...48337293e-01,  7.93045759e-01, ...,\n",
            "          8.05860341e-01,  1.11830783e+00, -1.79355347e+00]]],\n",
            "      dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e3201842e80>, array([[  0.        ,   0.        ,   0.        ,   0....684e-01, -9.96219993e-01,  2.76712596e-01,\n",
            "        -1.05886839e-01,  2.98931580e-02, -7.08097875e-01]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 528 / 528 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 21.960192\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 57716.547\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[  0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                     0.      ,  22.962572,   8.284391,   5.849462,   0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                     0.      ,   0.      ,  10.309208,   0.494673,  -2.72872 ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-5.710280e-01,  9.563331e-02,  6.951856e-02,  6.289836e-01,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -1.987951e-01, -1.254083e+00,  1.002380e+00,  1.774784e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    9.628396e-01, -2.200385e-01, -6.136210e-02, -6.169687e-03,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e3201842e80>, array([[  0.        ,   0.        ,   0.        ,   0....684e-01, -9.96219993e-01,  2.76712596e-01,\n",
            "        -1.05886839e-01,  2.98931580e-02, -7.08097875e-01]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-1-1-1-1-1] _____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.02877403]]])\n",
            "c0         = array([[[-2.210531]]], dtype=float32)\n",
            "c_         = tensor([[[-0.0288]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-0.01427281]]])\n",
            "h0         = array([[[-2.4207058]]], dtype=float32)\n",
            "h_         = tensor([[[-0.0143]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e320188ff80>\n",
            "model_     = LSTM(1, 1, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-0.01427281]]])\n",
            "output_    = tensor([[[-0.0143]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[0.06969538]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.01771239, -0.00048294,  0.        , -0.00050119]],\n",
            "      dtype=float32), array([[-0.00048294,  0.        ,  0.01771239, -0.00050119]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 3 / 4 (75%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.01819534\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 37.675987\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.017712, -0.000483,  0.      , -0.000501]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-0.000483,  0.      ,  0.017712, -0.000501]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.01771239, -0.00048294,  0.        , -0.00050119]],\n",
            "      dtype=float32), array([[-0.00048294,  0.        ,  0.01771239, -0.00050119]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-1-1-1-1-13] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.00973828]]])\n",
            "c0         = array([[[2.4254868]]], dtype=float32)\n",
            "c_         = tensor([[[-0.0097]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-0.0047182]]])\n",
            "h0         = array([[[1.4891118]]], dtype=float32)\n",
            "h_         = tensor([[[-0.0047]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3216220110>\n",
            "model_     = LSTM(1, 1, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-0.00218269]]\n",
            "\n",
            " [[-0.0118985 ]]\n",
            "\n",
            " [[-0.00897308]]\n",
            "\n",
            " [[-0.00423355]]\n",
            "\n",
            " [[-0.00398698]]\n",
            "\n",
            " [[-0.00513781...0226237]]\n",
            "\n",
            " [[ 0.00095056]]\n",
            "\n",
            " [[ 0.00386034]]\n",
            "\n",
            " [[ 0.00501303]]\n",
            "\n",
            " [[ 0.00235877]]\n",
            "\n",
            " [[-0.00605637]]\n",
            "\n",
            " [[-0.0047182 ]]])\n",
            "output_    = tensor([[[-0.0022]],\n",
            "\n",
            "        [[-0.0119]],\n",
            "\n",
            "        [[-0.0090]],\n",
            "\n",
            "        [[-0.0042]],\n",
            "\n",
            "        [[-0.0040]],\n",
            "\n",
            "        ...     [[ 0.0050]],\n",
            "\n",
            "        [[ 0.0024]],\n",
            "\n",
            "        [[-0.0061]],\n",
            "\n",
            "        [[-0.0047]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.4056335 ]],\n",
            "\n",
            "       [[ 2.0014782 ]],\n",
            "\n",
            "       [[-0.8131436 ]],\n",
            "\n",
            "       [[-0.0252533 ]],\n",
            "\n",
            "       [[ 0.367073...]],\n",
            "\n",
            "       [[-0.8742616 ]],\n",
            "\n",
            "       [[ 0.00749943]],\n",
            "\n",
            "       [[ 1.1853982 ]],\n",
            "\n",
            "       [[ 0.1820391 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 1.6683713 , -0.03774641,  0.00326933, -0.0243955 ]],\n",
            "      dtype=float32), array([[-0.04172054,  0.00377232,  1.8884633 , -0.02666543]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 4 / 4 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 1.885194\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 40.989212\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 1.668371, -0.037746,  0.003269, -0.024396]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-0.041721,  0.003772,  1.888463, -0.026665]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 1.6683713 , -0.03774641,  0.00326933, -0.0243955 ]],\n",
            "      dtype=float32), array([[-0.04172054,  0.00377232,  1.8884633 , -0.02666543]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-1-1-1-2-1] _____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.25669459]]\n",
            "\n",
            " [[ 0.03476725]]])\n",
            "c0         = array([[[-1.3278134 ]],\n",
            "\n",
            "       [[-0.88368934]]], dtype=float32)\n",
            "c_         = tensor([[[-0.2567]],\n",
            "\n",
            "        [[ 0.0348]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-0.08908309]]\n",
            "\n",
            " [[ 0.01719799]]])\n",
            "h0         = array([[[ 1.1198015]],\n",
            "\n",
            "       [[-0.9554047]]], dtype=float32)\n",
            "h_         = tensor([[[-0.0891]],\n",
            "\n",
            "        [[ 0.0172]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32016e6150>\n",
            "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.01719799]]])\n",
            "output_    = tensor([[[0.0172]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[0.7000449]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192bc40>, array([[-0.01837947,  0.00686086,  0.        ,  0.00902496]],\n",
            "      dtype=float32), array([[ 0.00604583,  0.        , -0.01619608,  0.00795284]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 4 / 4 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.0244253\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 4.040026\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[-0.018379,  0.006861,  0.      ,  0.009025]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 0.006046,  0.      , -0.016196,  0.007953]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192bc40>, array([[-0.01837947,  0.00686086,  0.        ,  0.00902496]],\n",
            "      dtype=float32), array([[ 0.00604583,  0.        , -0.01619608,  0.00795284]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-1-1-1-2-13] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.01161217]]\n",
            "\n",
            " [[-0.01826784]]])\n",
            "c0         = array([[[ 0.5773836]],\n",
            "\n",
            "       [[-2.037706 ]]], dtype=float32)\n",
            "c_         = tensor([[[ 0.0116]],\n",
            "\n",
            "        [[-0.0183]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.00619216]]\n",
            "\n",
            " [[-0.00921297]]])\n",
            "h0         = array([[[-0.5475445]],\n",
            "\n",
            "       [[ 1.3954216]]], dtype=float32)\n",
            "h_         = tensor([[[ 0.0062]],\n",
            "\n",
            "        [[-0.0092]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32163f95e0>\n",
            "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[ 0.01080164]]\n",
            "\n",
            " [[-0.00149025]]\n",
            "\n",
            " [[-0.0190974 ]]\n",
            "\n",
            " [[-0.01805051]]\n",
            "\n",
            " [[-0.00944491]]\n",
            "\n",
            " [[ 0.00016711...194862 ]]\n",
            "\n",
            " [[-0.03378002]]\n",
            "\n",
            " [[-0.03560957]]\n",
            "\n",
            " [[-0.0229723 ]]\n",
            "\n",
            " [[-0.0157858 ]]\n",
            "\n",
            " [[-0.01723115]]\n",
            "\n",
            " [[-0.00921297]]])\n",
            "output_    = tensor([[[ 0.0108]],\n",
            "\n",
            "        [[-0.0015]],\n",
            "\n",
            "        [[-0.0191]],\n",
            "\n",
            "        [[-0.0181]],\n",
            "\n",
            "        [[-0.0094]],\n",
            "\n",
            "        ...     [[-0.0230]],\n",
            "\n",
            "        [[-0.0158]],\n",
            "\n",
            "        [[-0.0172]],\n",
            "\n",
            "        [[-0.0092]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 1.136869  ]],\n",
            "\n",
            "       [[-0.7605026 ]],\n",
            "\n",
            "       [[-0.68856233]],\n",
            "\n",
            "       [[ 0.4507655 ]],\n",
            "\n",
            "       [[ 0.353188...]],\n",
            "\n",
            "       [[ 0.582694  ]],\n",
            "\n",
            "       [[-0.06812882]],\n",
            "\n",
            "       [[-0.3508926 ]],\n",
            "\n",
            "       [[ 0.43713468]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.08553725, -0.04521681,  0.00803697, -0.0256503 ]],\n",
            "      dtype=float32), array([[ 0.1922852 , -0.03013193, -0.36821023,  0.12198011]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 4 / 4 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.3762472\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 1.2102827\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.085537, -0.045217,  0.008037, -0.02565 ]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 0.192285, -0.030132, -0.36821 ,  0.12198 ]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.08553725, -0.04521681,  0.00803697, -0.0256503 ]],\n",
            "      dtype=float32), array([[ 0.1922852 , -0.03013193, -0.36821023,  0.12198011]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-1-1-15-1-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1, hidden_size = 1\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.01705528]\n",
            "  [ 0.04420333]\n",
            "  [-0.03615098]\n",
            "  [ 0.10975818]\n",
            "  [ 0.10411336]\n",
            "  [-0.01477228]\n",
            "  [ 0.10...442]\n",
            "  [-0.03631642]\n",
            "  [ 0.04855486]\n",
            "  [ 0.00751258]\n",
            "  [ 0.01139193]\n",
            "  [ 0.01769547]\n",
            "  [-0.03558403]\n",
            "  [-0.01620443]]])\n",
            "c0         = array([[[ 1.2665548 ],\n",
            "        [-1.1100063 ],\n",
            "        [ 1.1081209 ],\n",
            "        [-0.74726987],\n",
            "        [ 0.26151824],\n",
            "   ...694412  ],\n",
            "        [ 0.3546714 ],\n",
            "        [ 0.15651506],\n",
            "        [ 1.236867  ],\n",
            "        [-0.7952844 ]]], dtype=float32)\n",
            "c_         = tensor([[[-0.0171],\n",
            "         [ 0.0442],\n",
            "         [-0.0362],\n",
            "         [ 0.1098],\n",
            "         [ 0.1041],\n",
            "         [-0.0148]... [ 0.0075],\n",
            "         [ 0.0114],\n",
            "         [ 0.0177],\n",
            "         [-0.0356],\n",
            "         [-0.0162]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-0.00764554]\n",
            "  [ 0.02605831]\n",
            "  [-0.01164652]\n",
            "  [ 0.0744869 ]\n",
            "  [ 0.06997804]\n",
            "  [-0.0067415 ]\n",
            "  [ 0.06...083]\n",
            "  [-0.01153295]\n",
            "  [ 0.02896671]\n",
            "  [ 0.00389456]\n",
            "  [ 0.00600611]\n",
            "  [ 0.00956864]\n",
            "  [-0.01187619]\n",
            "  [-0.00731386]]])\n",
            "h0         = array([[[-1.0208324 ],\n",
            "        [ 2.4409482 ],\n",
            "        [ 1.3244752 ],\n",
            "        [-0.08911028],\n",
            "        [-2.4519498 ],\n",
            "   ...01208087],\n",
            "        [-1.6837473 ],\n",
            "        [ 0.1818824 ],\n",
            "        [-1.5871049 ],\n",
            "        [ 0.26408595]]], dtype=float32)\n",
            "h_         = tensor([[[-0.0076],\n",
            "         [ 0.0261],\n",
            "         [-0.0116],\n",
            "         [ 0.0745],\n",
            "         [ 0.0700],\n",
            "         [-0.0067]... [ 0.0039],\n",
            "         [ 0.0060],\n",
            "         [ 0.0096],\n",
            "         [-0.0119],\n",
            "         [-0.0073]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3208438fb0>\n",
            "model_     = LSTM(1, 1, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-0.00764554]\n",
            "  [ 0.02605831]\n",
            "  [-0.01164652]\n",
            "  [ 0.0744869 ]\n",
            "  [ 0.06997804]\n",
            "  [-0.0067415 ]\n",
            "  [ 0.06...083]\n",
            "  [-0.01153295]\n",
            "  [ 0.02896671]\n",
            "  [ 0.00389456]\n",
            "  [ 0.00600611]\n",
            "  [ 0.00956864]\n",
            "  [-0.01187619]\n",
            "  [-0.00731386]]])\n",
            "output_    = tensor([[[-0.0076],\n",
            "         [ 0.0261],\n",
            "         [-0.0116],\n",
            "         [ 0.0745],\n",
            "         [ 0.0700],\n",
            "         [-0.0067]...],\n",
            "         [ 0.0060],\n",
            "         [ 0.0096],\n",
            "         [-0.0119],\n",
            "         [-0.0073]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 0.49990243],\n",
            "        [-0.8760177 ],\n",
            "        [ 1.7909554 ],\n",
            "        [-1.8315897 ],\n",
            "        [-1.756439  ],\n",
            "   ...17758164],\n",
            "        [-0.26289952],\n",
            "        [-0.39411205],\n",
            "        [ 1.6642758 ],\n",
            "        [ 0.470052  ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e3201843d80>, array([[-3.0393624 , -0.17296326,  0.        , -0.19769207]],\n",
            "      dtype=float32), array([[-0.17296326,  0.        , -3.0393624 , -0.19769204]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 3 / 4 (75%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 3.0393624\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 16.572302\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[-3.039362, -0.172963,  0.      , -0.197692]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-0.172963,  0.      , -3.039362, -0.197692]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e3201843d80>, array([[-3.0393624 , -0.17296326,  0.        , -0.19769207]],\n",
            "      dtype=float32), array([[-0.17296326,  0.        , -3.0393624 , -0.19769204]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-1-1-15-1-13] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
            "hidden_size = 1, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.2789498 ]\n",
            "  [ 0.00518253]\n",
            "  [-0.04520746]\n",
            "  [ 0.2598107 ]\n",
            "  [ 0.03825681]\n",
            "  [-0.06796254]\n",
            "  [-0.06...48 ]\n",
            "  [ 0.38521117]\n",
            "  [ 0.40434027]\n",
            "  [ 0.37611803]\n",
            "  [ 0.2151949 ]\n",
            "  [ 0.01950724]\n",
            "  [ 0.16400905]\n",
            "  [-0.0108793 ]]])\n",
            "c0         = array([[[ 1.9932221 ],\n",
            "        [-1.100881  ],\n",
            "        [ 0.71262723],\n",
            "        [ 0.72109604],\n",
            "        [-0.15336317],\n",
            "   ...27775866],\n",
            "        [-0.4001022 ],\n",
            "        [-0.5080154 ],\n",
            "        [ 0.90388626],\n",
            "        [-0.88406986]]], dtype=float32)\n",
            "c_         = tensor([[[ 0.2789],\n",
            "         [ 0.0052],\n",
            "         [-0.0452],\n",
            "         [ 0.2598],\n",
            "         [ 0.0383],\n",
            "         [-0.0680]... [ 0.3761],\n",
            "         [ 0.2152],\n",
            "         [ 0.0195],\n",
            "         [ 0.1640],\n",
            "         [-0.0109]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.15045954]\n",
            "  [ 0.00273319]\n",
            "  [-0.02393665]\n",
            "  [ 0.1388989 ]\n",
            "  [ 0.02047756]\n",
            "  [-0.035762  ]\n",
            "  [-0.03...14 ]\n",
            "  [ 0.19153102]\n",
            "  [ 0.20723023]\n",
            "  [ 0.19875602]\n",
            "  [ 0.1072177 ]\n",
            "  [ 0.01069931]\n",
            "  [ 0.09299304]\n",
            "  [-0.00527998]]])\n",
            "h0         = array([[[-0.5957977 ],\n",
            "        [-0.5498138 ],\n",
            "        [ 2.1200368 ],\n",
            "        [-0.6919084 ],\n",
            "        [ 0.4933779 ],\n",
            "   ...06496233],\n",
            "        [-1.4259088 ],\n",
            "        [ 1.8374203 ],\n",
            "        [ 1.5339445 ],\n",
            "        [ 1.5319561 ]]], dtype=float32)\n",
            "h_         = tensor([[[ 0.1505],\n",
            "         [ 0.0027],\n",
            "         [-0.0239],\n",
            "         [ 0.1389],\n",
            "         [ 0.0205],\n",
            "         [-0.0358]... [ 0.1988],\n",
            "         [ 0.1072],\n",
            "         [ 0.0107],\n",
            "         [ 0.0930],\n",
            "         [-0.0053]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32083f56a0>\n",
            "model_     = LSTM(1, 1, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[ 0.10078083]\n",
            "  [ 0.01822536]\n",
            "  [-0.08997421]\n",
            "  [-0.04433507]\n",
            "  [-0.06255383]\n",
            "  [-0.08714584]\n",
            "  [ 0.03...14 ]\n",
            "  [ 0.19153102]\n",
            "  [ 0.20723023]\n",
            "  [ 0.19875602]\n",
            "  [ 0.1072177 ]\n",
            "  [ 0.01069931]\n",
            "  [ 0.09299304]\n",
            "  [-0.00527998]]])\n",
            "output_    = tensor([[[ 0.1008],\n",
            "         [ 0.0182],\n",
            "         [-0.0900],\n",
            "         [-0.0443],\n",
            "         [-0.0626],\n",
            "         [-0.0871]...],\n",
            "         [ 0.1072],\n",
            "         [ 0.0107],\n",
            "         [ 0.0930],\n",
            "         [-0.0053]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-6.59011841e-01],\n",
            "        [-1.24963112e-01],\n",
            "        [ 8.18205893e-01],\n",
            "        [ 3.39340180e-01],\n",
            "        [ ...   [-8.01904202e-01],\n",
            "        [ 8.18754017e-01],\n",
            "        [ 5.00952423e-01],\n",
            "        [-1.08361669e-01]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[-14.343448 , -14.808889 ,   0.7880784,  -8.237975 ]],\n",
            "      dtype=float32), array([[-15.762043  ,   0.61323637, -17.43176   ,  -9.262477  ]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 4 / 4 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 18.21984\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 25.148746\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[-14.343448, -14.808889,   0.788078,  -8.237975]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-15.762043,   0.613236, -17.43176 ,  -9.262477]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[-14.343448 , -14.808889 ,   0.7880784,  -8.237975 ]],\n",
            "      dtype=float32), array([[-15.762043  ,   0.61323637, -17.43176   ,  -9.262477  ]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-1-1-15-2-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 1\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 1.9310030e-01]\n",
            "  [ 1.1229659e-01]\n",
            "  [-5.3143299e-01]\n",
            "  [ 2.8008759e-01]\n",
            "  [-2.4200194e-01]\n",
            "  [-3.339...2]\n",
            "  [-1.4198337e-02]\n",
            "  [ 6.2200960e-02]\n",
            "  [-2.3232128e-02]\n",
            "  [-2.8549699e-02]\n",
            "  [ 2.5805313e-02]\n",
            "  [-1.7100129e-02]]])\n",
            "c0         = array([[[ 0.46272627],\n",
            "        [ 0.6764875 ],\n",
            "        [-0.75222164],\n",
            "        [ 0.7231672 ],\n",
            "        [ 0.17792873],\n",
            "   ...99922967],\n",
            "        [-0.6120253 ],\n",
            "        [-0.0521547 ],\n",
            "        [-0.48247576],\n",
            "        [-0.26908362]]], dtype=float32)\n",
            "c_         = tensor([[[ 1.9310e-01],\n",
            "         [ 1.1230e-01],\n",
            "         [-5.3143e-01],\n",
            "         [ 2.8009e-01],\n",
            "         [-2.4200e-01]...     [-2.3232e-02],\n",
            "         [-2.8550e-02],\n",
            "         [ 2.5805e-02],\n",
            "         [-1.7100e-02]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 9.75471362e-02]\n",
            "  [ 5.65695912e-02]\n",
            "  [-2.30072558e-01]\n",
            "  [ 1.43470615e-01]\n",
            "  [-1.16094805e-01]\n",
            "  [-...-6.90179877e-03]\n",
            "  [ 3.43678258e-02]\n",
            "  [-1.10763377e-02]\n",
            "  [-1.34490998e-02]\n",
            "  [ 1.35027431e-02]\n",
            "  [-8.26185755e-03]]])\n",
            "h0         = array([[[ 0.6519595 ],\n",
            "        [-0.36955574],\n",
            "        [ 0.30936193],\n",
            "        [ 1.0968316 ],\n",
            "        [-0.23856667],\n",
            "   ...3766232 ],\n",
            "        [ 1.6589935 ],\n",
            "        [-0.57497334],\n",
            "        [ 0.75824386],\n",
            "        [ 0.49036288]]], dtype=float32)\n",
            "h_         = tensor([[[ 9.7547e-02],\n",
            "         [ 5.6570e-02],\n",
            "         [-2.3007e-01],\n",
            "         [ 1.4347e-01],\n",
            "         [-1.1609e-01]...     [-1.1076e-02],\n",
            "         [-1.3449e-02],\n",
            "         [ 1.3503e-02],\n",
            "         [-8.2619e-03]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3208190410>\n",
            "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[-0.00983911]\n",
            "  [-0.00591624]\n",
            "  [ 0.03025035]\n",
            "  [-0.01388179]\n",
            "  [ 0.01400844]\n",
            "  [ 0.00018351]\n",
            "  [ 0.01...781]\n",
            "  [-0.0113148 ]\n",
            "  [-0.0069018 ]\n",
            "  [ 0.03436783]\n",
            "  [-0.01107634]\n",
            "  [-0.0134491 ]\n",
            "  [ 0.01350274]\n",
            "  [-0.00826186]]])\n",
            "output_    = tensor([[[-0.0098],\n",
            "         [-0.0059],\n",
            "         [ 0.0303],\n",
            "         [-0.0139],\n",
            "         [ 0.0140],\n",
            "         [ 0.0002]...],\n",
            "         [-0.0111],\n",
            "         [-0.0134],\n",
            "         [ 0.0135],\n",
            "         [-0.0083]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.59464747],\n",
            "        [-0.30531058],\n",
            "        [ 1.409526  ],\n",
            "        [-1.3311294 ],\n",
            "        [ 0.56956506],\n",
            "   ...79795   ],\n",
            "        [-0.7224089 ],\n",
            "        [-2.0859075 ],\n",
            "        [ 0.54923546],\n",
            "        [-0.4634102 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[0.00553558, 0.17942882, 0.        , 0.21915577]], dtype=float32), array([[ 0.09209156,  0.        , -0.00746689,  0.11699409]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 4 / 4 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.17942882\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 1.\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[0.005536, 0.179429, 0.      , 0.219156]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 0.092092,  0.      , -0.007467,  0.116994]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[0.00553558, 0.17942882, 0.        , 0.21915577]], dtype=float32), array([[ 0.09209156,  0.        , -0.00746689,  0.11699409]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-1-1-15-2-13] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
            "hidden_size = 1, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.04158236]\n",
            "  [-0.00254938]\n",
            "  [ 0.5438611 ]\n",
            "  [ 0.5532041 ]\n",
            "  [ 0.72823924]\n",
            "  [ 0.25466764]\n",
            "  [ 0.49...951]\n",
            "  [ 0.15145856]\n",
            "  [-0.00872909]\n",
            "  [ 0.03009383]\n",
            "  [ 0.13473615]\n",
            "  [ 0.1790038 ]\n",
            "  [ 0.11876644]\n",
            "  [ 0.1542412 ]]])\n",
            "c0         = array([[[-1.584212  ],\n",
            "        [ 0.35138452],\n",
            "        [-1.0549679 ],\n",
            "        [-0.5660254 ],\n",
            "        [-2.0630665 ],\n",
            "   ...9644221 ],\n",
            "        [-0.18096288],\n",
            "        [ 1.1133381 ],\n",
            "        [ 2.1241724 ],\n",
            "        [ 0.29286057]]], dtype=float32)\n",
            "c_         = tensor([[[ 0.0416],\n",
            "         [-0.0025],\n",
            "         [ 0.5439],\n",
            "         [ 0.5532],\n",
            "         [ 0.7282],\n",
            "         [ 0.2547]... [ 0.0301],\n",
            "         [ 0.1347],\n",
            "         [ 0.1790],\n",
            "         [ 0.1188],\n",
            "         [ 0.1542]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.01810814]\n",
            "  [-0.00108227]\n",
            "  [ 0.31575954]\n",
            "  [ 0.3462585 ]\n",
            "  [ 0.43541133]\n",
            "  [ 0.141016  ]\n",
            "  [ 0.29...783]\n",
            "  [ 0.07078654]\n",
            "  [-0.00449671]\n",
            "  [ 0.01519378]\n",
            "  [ 0.05694724]\n",
            "  [ 0.07329142]\n",
            "  [ 0.0533191 ]\n",
            "  [ 0.06341112]]])\n",
            "h0         = array([[[-1.8740114 ],\n",
            "        [ 0.27998576],\n",
            "        [ 0.55867726],\n",
            "        [-0.17799424],\n",
            "        [ 0.05168106],\n",
            "   ...95604974],\n",
            "        [ 0.09905034],\n",
            "        [ 0.42114112],\n",
            "        [ 1.038336  ],\n",
            "        [ 1.2056364 ]]], dtype=float32)\n",
            "h_         = tensor([[[ 0.0181],\n",
            "         [-0.0011],\n",
            "         [ 0.3158],\n",
            "         [ 0.3463],\n",
            "         [ 0.4354],\n",
            "         [ 0.1410]... [ 0.0152],\n",
            "         [ 0.0569],\n",
            "         [ 0.0733],\n",
            "         [ 0.0533],\n",
            "         [ 0.0634]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e320186d1f0>\n",
            "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[-0.00616499]\n",
            "  [ 0.04618116]\n",
            "  [-0.0105262 ]\n",
            "  [ 0.00685329]\n",
            "  [ 0.03309882]\n",
            "  [-0.00704565]\n",
            "  [ 0.03...783]\n",
            "  [ 0.07078654]\n",
            "  [-0.00449671]\n",
            "  [ 0.01519378]\n",
            "  [ 0.05694724]\n",
            "  [ 0.07329142]\n",
            "  [ 0.0533191 ]\n",
            "  [ 0.06341112]]])\n",
            "output_    = tensor([[[-0.0062],\n",
            "         [ 0.0462],\n",
            "         [-0.0105],\n",
            "         [ 0.0069],\n",
            "         [ 0.0331],\n",
            "         [-0.0070]...],\n",
            "         [ 0.0569],\n",
            "         [ 0.0733],\n",
            "         [ 0.0533],\n",
            "         [ 0.0634]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 1.761308  ],\n",
            "        [-2.314014  ],\n",
            "        [ 0.926872  ],\n",
            "        [-0.22506419],\n",
            "        [-1.1011095 ],\n",
            "   ...7790557 ],\n",
            "        [-1.2813827 ],\n",
            "        [-1.0128185 ],\n",
            "        [-0.88051647],\n",
            "        [-1.2160983 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 3.7082043 ,  3.2132869 , -0.22188959,  2.1404073 ]],\n",
            "      dtype=float32), array([[-3.4368858 ,  0.44952607, -2.3524556 , -1.6871707 ]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 4 / 4 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 7.14509\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 6.1481657\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 3.708204,  3.213287, -0.22189 ,  2.140407]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-3.436886,  0.449526, -2.352456, -1.687171]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 3.7082043 ,  3.2132869 , -0.22188959,  2.1404073 ]],\n",
            "      dtype=float32), array([[-3.4368858 ,  0.44952607, -2.3524556 , -1.6871707 ]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-1-11-1-1-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 1\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.79126734]]])\n",
            "c0         = array([[[0.44133106]]], dtype=float32)\n",
            "c_         = tensor([[[-0.7913]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-0.45073375]]])\n",
            "h0         = array([[[-0.03104604]]], dtype=float32)\n",
            "h_         = tensor([[[-0.4507]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3201641f10>\n",
            "model_     = LSTM(11, 1, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-0.45073375]]])\n",
            "output_    = tensor([[[-0.4507]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 1.0680463 ,  0.974951  ,  1.8817701 , -0.33548275,\n",
            "         -0.6435235 , -0.33630908, -0.5264097 , -0.34515467,\n",
            "         -1.1369104 , -0.08313777, -1.8279737 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e3201701a80>, array([[ 4.15351620e-04, -6.80581927e-02,  0.00000000e... 1.18476469e-02],\n",
            "       [ 1.16482385e-01,  0.00000000e+00, -7.10953609e-04,\n",
            "         2.60497570e-01]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 33 / 44 (75%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.12064222\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 1.0061029\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 4.153516e-04, -6.805819e-02,  0.000000e+00, -1.522032e-01],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 3.791479e-04, -6.212596e-02,  0.000000e+00, -1.389366e-01],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 7.318000e-04, -1.199104e-01,  0.000000e+00, -2.681639e-01],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-6.805819e-02,  0.000000e+00,  4.153951e-04, -1.522032e-01],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-6.212596e-02,  0.000000e+00,  3.791876e-04, -1.389365e-01],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-1.199104e-01,  0.000000e+00,  7.318766e-04, -2.681639e-01],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e3201701a80>, array([[ 4.15351620e-04, -6.80581927e-02,  0.00000000e... 1.18476469e-02],\n",
            "       [ 1.16482385e-01,  0.00000000e+00, -7.10953609e-04,\n",
            "         2.60497570e-01]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-1-11-1-1-13] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
            "hidden_size = 1, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[0.712438]]])\n",
            "c0         = array([[[-0.35910916]]], dtype=float32)\n",
            "c_         = tensor([[[0.7124]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.5620846]]])\n",
            "h0         = array([[[-0.18880388]]], dtype=float32)\n",
            "h_         = tensor([[[0.5621]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e320173b6b0>\n",
            "model_     = LSTM(11, 1, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-0.2059092 ]]\n",
            "\n",
            " [[ 0.1613779 ]]\n",
            "\n",
            " [[ 0.01037104]]\n",
            "\n",
            " [[ 0.16011386]]\n",
            "\n",
            " [[-0.09787207]]\n",
            "\n",
            " [[ 0.01357133...5251759]]\n",
            "\n",
            " [[-0.44011655]]\n",
            "\n",
            " [[-0.05926419]]\n",
            "\n",
            " [[-0.0007619 ]]\n",
            "\n",
            " [[ 0.02390445]]\n",
            "\n",
            " [[ 0.32279366]]\n",
            "\n",
            " [[ 0.5620846 ]]])\n",
            "output_    = tensor([[[-0.2059]],\n",
            "\n",
            "        [[ 0.1614]],\n",
            "\n",
            "        [[ 0.0104]],\n",
            "\n",
            "        [[ 0.1601]],\n",
            "\n",
            "        [[-0.0979]],\n",
            "\n",
            "        ...     [[-0.0008]],\n",
            "\n",
            "        [[ 0.0239]],\n",
            "\n",
            "        [[ 0.3228]],\n",
            "\n",
            "        [[ 0.5621]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.5332479 , -0.13242494, -0.08902145, -1.052389  ,\n",
            "          1.4611229 ,  0.2112934 ,  0.37239254, -1.558134...   0.509259  ,  0.4949864 , -1.0609294 ,  0.5102946 ,\n",
            "         -0.16697347, -0.7169622 , -1.1485659 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 0.1293382 , -0.51846635,  0.1303191 , -0.2562...8565371, -0.9759284 , -0.5339616 ],\n",
            "       [-0.43645576, -0.13581952, -0.18272737, -0.18534157]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 44 / 44 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 1.1456535\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 35.649498\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.129338, -0.518466,  0.130319, -0.256235],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 0.52158 , -0.250704,  0.195488,  0.193384],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.135642, -0.109446, -0.023099, -0.247772],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-0.53595 ,  0.143671,  0.123358, -0.267202],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.243442,  0.201173,  0.555573,  0.207453],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.107889, -0.028304, -0.127461, -0.262373],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 0.1293382 , -0.51846635,  0.1303191 , -0.2562...8565371, -0.9759284 , -0.5339616 ],\n",
            "       [-0.43645576, -0.13581952, -0.18272737, -0.18534157]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-1-11-1-2-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 1\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-3.5374634e-02]]\n",
            "\n",
            " [[ 6.1589177e-05]]])\n",
            "c0         = array([[[-1.3243204]],\n",
            "\n",
            "       [[ 1.0444051]]], dtype=float32)\n",
            "c_         = tensor([[[-3.5375e-02]],\n",
            "\n",
            "        [[ 6.1589e-05]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-9.0549868e-03]]\n",
            "\n",
            " [[ 3.0677373e-05]]])\n",
            "h0         = array([[[0.16221088]],\n",
            "\n",
            "       [[0.03457266]]], dtype=float32)\n",
            "h_         = tensor([[[-9.0550e-03]],\n",
            "\n",
            "        [[ 3.0677e-05]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e320123a150>\n",
            "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[3.0677373e-05]]])\n",
            "output_    = tensor([[[3.0677e-05]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 0.26979804,  0.18434593,  0.21797071,  0.7759105 ,\n",
            "         -0.48146293,  2.9234226 ,  0.4667665 ,  1.0597945 ,\n",
            "         -0.18410276, -2.1117737 ,  0.12397176]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e3201701760>, array([[ 3.54409849e-06, -8.23638984e-05,  0.00000000e...-4.79789960e-05],\n",
            "       [ 3.64639209e-06,  0.00000000e+00, -1.56903297e-07,\n",
            "         2.81660891e-06]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 26 / 44 (59.1%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.00089246\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 11.379049\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 3.544098e-06, -8.236390e-05,  0.000000e+00, -6.362094e-05],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 2.421590e-06, -5.627709e-05,  0.000000e+00, -4.347053e-05],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 2.863289e-06, -6.654206e-05,  0.000000e+00, -5.139957e-05],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 7.935593e-06,  0.000000e+00, -3.414665e-07,  6.129747e-06],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 5.422183e-06,  0.000000e+00, -2.333151e-07,  4.188295e-06],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 6.411191e-06,  0.000000e+00, -2.758719e-07,  4.952243e-06],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e3201701760>, array([[ 3.54409849e-06, -8.23638984e-05,  0.00000000e...-4.79789960e-05],\n",
            "       [ 3.64639209e-06,  0.00000000e+00, -1.56903297e-07,\n",
            "         2.81660891e-06]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-1-11-1-2-13] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
            "hidden_size = 1, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[0.9870806 ]]\n",
            "\n",
            " [[0.23304522]]])\n",
            "c0         = array([[[-1.6524299 ]],\n",
            "\n",
            "       [[ 0.26513422]]], dtype=float32)\n",
            "c_         = tensor([[[0.9871]],\n",
            "\n",
            "        [[0.2330]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.4723067 ]]\n",
            "\n",
            " [[0.10733359]]])\n",
            "h0         = array([[[-1.0953944]],\n",
            "\n",
            "       [[-0.7365833]]], dtype=float32)\n",
            "h_         = tensor([[[0.4723]],\n",
            "\n",
            "        [[0.1073]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3201227fe0>\n",
            "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[-0.00401694]]\n",
            "\n",
            " [[-0.00248171]]\n",
            "\n",
            " [[-0.03258574]]\n",
            "\n",
            " [[-0.01530324]]\n",
            "\n",
            " [[-0.03047592]]\n",
            "\n",
            " [[-0.05905668...5136172]]\n",
            "\n",
            " [[-0.07790264]]\n",
            "\n",
            " [[-0.05731715]]\n",
            "\n",
            " [[-0.024756  ]]\n",
            "\n",
            " [[ 0.00434654]]\n",
            "\n",
            " [[ 0.08171133]]\n",
            "\n",
            " [[ 0.10733359]]])\n",
            "output_    = tensor([[[-0.0040]],\n",
            "\n",
            "        [[-0.0025]],\n",
            "\n",
            "        [[-0.0326]],\n",
            "\n",
            "        [[-0.0153]],\n",
            "\n",
            "        [[-0.0305]],\n",
            "\n",
            "        ...     [[-0.0248]],\n",
            "\n",
            "        [[ 0.0043]],\n",
            "\n",
            "        [[ 0.0817]],\n",
            "\n",
            "        [[ 0.1073]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 1.8941354 ,  1.8309392 , -0.05289334,  0.64816827,\n",
            "          0.09605436, -0.8679766 ,  0.07164494,  1.757925...   1.5936254 ,  0.42365876,  0.5769426 , -0.15338807,\n",
            "         -1.4685271 , -0.0260147 ,  1.6532968 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 0.01318458,  0.00510389,  0.00937948,  0.0109...3098401,  0.46371353, -0.0750878 ],\n",
            "       [ 0.04887928,  0.03353151,  0.6974929 ,  0.12216954]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 44 / 44 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 1.046445\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 4.632132\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.013185,  0.005104,  0.009379,  0.010959],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.023568, -0.006404, -0.002834, -0.008522],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 0.033541,  0.006217,  0.000735,  0.004948],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-0.042126,  0.055542,  0.378526, -0.187299],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.09792 ,  0.020277,  1.043611, -0.080484],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 0.095839, -0.040191, -0.99752 ,  0.016969],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 0.01318458,  0.00510389,  0.00937948,  0.0109...3098401,  0.46371353, -0.0750878 ],\n",
            "       [ 0.04887928,  0.03353151,  0.6974929 ,  0.12216954]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-1-11-15-1-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
            "hidden_size = 1, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.3482462 ]\n",
            "  [-0.11456808]\n",
            "  [-0.70934474]\n",
            "  [ 0.31469935]\n",
            "  [-0.24581482]\n",
            "  [-0.19275896]\n",
            "  [ 0.82...208]\n",
            "  [ 0.7702627 ]\n",
            "  [ 0.03660552]\n",
            "  [ 0.016205  ]\n",
            "  [ 0.54839826]\n",
            "  [-0.23828167]\n",
            "  [ 0.03785563]\n",
            "  [ 0.5841752 ]]])\n",
            "c0         = array([[[ 0.58596814],\n",
            "        [-1.2079957 ],\n",
            "        [ 1.3912202 ],\n",
            "        [-0.71672106],\n",
            "        [-0.34034583],\n",
            "   ...2602219 ],\n",
            "        [-0.41665256],\n",
            "        [ 0.7836419 ],\n",
            "        [-1.241035  ],\n",
            "        [-0.26192433]]], dtype=float32)\n",
            "c_         = tensor([[[-0.3482],\n",
            "         [-0.1146],\n",
            "         [-0.7093],\n",
            "         [ 0.3147],\n",
            "         [-0.2458],\n",
            "         [-0.1928]... [ 0.0162],\n",
            "         [ 0.5484],\n",
            "         [-0.2383],\n",
            "         [ 0.0379],\n",
            "         [ 0.5842]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-0.11208291]\n",
            "  [-0.02207956]\n",
            "  [-0.16432507]\n",
            "  [ 0.26885423]\n",
            "  [-0.08363528]\n",
            "  [-0.01969672]\n",
            "  [ 0.60...782]\n",
            "  [ 0.47381824]\n",
            "  [ 0.01697824]\n",
            "  [ 0.00876712]\n",
            "  [ 0.37898764]\n",
            "  [-0.08790324]\n",
            "  [ 0.01107995]\n",
            "  [ 0.4441734 ]]])\n",
            "h0         = array([[[ 1.4861964 ],\n",
            "        [-0.84867495],\n",
            "        [-0.5260139 ],\n",
            "        [-0.39415738],\n",
            "        [-0.9628185 ],\n",
            "   ...3483095 ],\n",
            "        [ 0.14972419],\n",
            "        [ 0.30771965],\n",
            "        [-0.5856183 ],\n",
            "        [-0.30000088]]], dtype=float32)\n",
            "h_         = tensor([[[-0.1121],\n",
            "         [-0.0221],\n",
            "         [-0.1643],\n",
            "         [ 0.2689],\n",
            "         [-0.0836],\n",
            "         [-0.0197]... [ 0.0088],\n",
            "         [ 0.3790],\n",
            "         [-0.0879],\n",
            "         [ 0.0111],\n",
            "         [ 0.4442]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32010701d0>\n",
            "model_     = LSTM(11, 1, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-0.11208291]\n",
            "  [-0.02207956]\n",
            "  [-0.16432507]\n",
            "  [ 0.26885423]\n",
            "  [-0.08363528]\n",
            "  [-0.01969672]\n",
            "  [ 0.60...782]\n",
            "  [ 0.47381824]\n",
            "  [ 0.01697824]\n",
            "  [ 0.00876712]\n",
            "  [ 0.37898764]\n",
            "  [-0.08790324]\n",
            "  [ 0.01107995]\n",
            "  [ 0.4441734 ]]])\n",
            "output_    = tensor([[[-0.1121],\n",
            "         [-0.0221],\n",
            "         [-0.1643],\n",
            "         [ 0.2689],\n",
            "         [-0.0836],\n",
            "         [-0.0197]...],\n",
            "         [ 0.3790],\n",
            "         [-0.0879],\n",
            "         [ 0.0111],\n",
            "         [ 0.4442]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-1.3434441 ,  0.6392023 , -0.9370143 ,  0.68116325,\n",
            "         -0.6132659 , -0.8100488 , -0.52564716,  0.869093...  -0.15146087,  0.27503332, -1.4314864 , -0.7539335 ,\n",
            "         -1.4960686 ,  1.5639509 , -0.16373242]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e3201701620>, array([[-0.0230476 , -0.16052856,  0.        ,  0.1412...       ,  0.23271726,  0.08178992],\n",
            "       [-0.28285122,  0.        , -0.5858068 , -0.22563733]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 33 / 44 (75%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.6995613\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 3.2416966\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[-0.023048, -0.160529,  0.      ,  0.141207],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 0.142337, -0.259287,  0.      , -0.237919],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.335045,  0.364516,  0.      ,  0.341979],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-0.160529,  0.      , -0.023048,  0.141207],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.259288,  0.      ,  0.142337, -0.237919],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 0.364516,  0.      , -0.335045,  0.341979],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e3201701620>, array([[-0.0230476 , -0.16052856,  0.        ,  0.1412...       ,  0.23271726,  0.08178992],\n",
            "       [-0.28285122,  0.        , -0.5858068 , -0.22563733]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-1-11-15-1-13] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
            "hidden_size = 1, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.81566095]\n",
            "  [ 0.6590669 ]\n",
            "  [ 0.31152737]\n",
            "  [-0.28804713]\n",
            "  [ 0.05736056]\n",
            "  [ 0.8685985 ]\n",
            "  [ 0.62...75 ]\n",
            "  [-1.3647212 ]\n",
            "  [ 0.17875317]\n",
            "  [ 0.5159347 ]\n",
            "  [-0.5624093 ]\n",
            "  [-0.02949147]\n",
            "  [ 0.06344658]\n",
            "  [ 0.9546034 ]]])\n",
            "c0         = array([[[-0.72785014],\n",
            "        [-1.5902991 ],\n",
            "        [ 0.2828532 ],\n",
            "        [ 1.050924  ],\n",
            "        [-1.4927189 ],\n",
            "   ...1714906 ],\n",
            "        [-1.3444067 ],\n",
            "        [-0.28038377],\n",
            "        [-0.29022643],\n",
            "        [-0.20102857]]], dtype=float32)\n",
            "c_         = tensor([[[ 0.8157],\n",
            "         [ 0.6591],\n",
            "         [ 0.3115],\n",
            "         [-0.2880],\n",
            "         [ 0.0574],\n",
            "         [ 0.8686]... [ 0.5159],\n",
            "         [-0.5624],\n",
            "         [-0.0295],\n",
            "         [ 0.0634],\n",
            "         [ 0.9546]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.07920605]\n",
            "  [ 0.41444603]\n",
            "  [ 0.2405798 ]\n",
            "  [-0.06356084]\n",
            "  [ 0.01026593]\n",
            "  [ 0.3481592 ]\n",
            "  [ 0.38...233]\n",
            "  [-0.7116755 ]\n",
            "  [ 0.15674971]\n",
            "  [ 0.13306208]\n",
            "  [-0.32582644]\n",
            "  [-0.00110796]\n",
            "  [ 0.02152047]\n",
            "  [ 0.6540416 ]]])\n",
            "h0         = array([[[-0.16435657],\n",
            "        [ 0.568722  ],\n",
            "        [-0.7647614 ],\n",
            "        [ 1.5320107 ],\n",
            "        [-0.9737367 ],\n",
            "   ...17655317],\n",
            "        [-1.7345849 ],\n",
            "        [-0.9562785 ],\n",
            "        [ 1.0227866 ],\n",
            "        [ 0.60951114]]], dtype=float32)\n",
            "h_         = tensor([[[ 0.0792],\n",
            "         [ 0.4144],\n",
            "         [ 0.2406],\n",
            "         [-0.0636],\n",
            "         [ 0.0103],\n",
            "         [ 0.3482]... [ 0.1331],\n",
            "         [-0.3258],\n",
            "         [-0.0011],\n",
            "         [ 0.0215],\n",
            "         [ 0.6540]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3200fb9640>\n",
            "model_     = LSTM(11, 1, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-3.6973140e-01]\n",
            "  [ 2.4711277e-02]\n",
            "  [ 3.2448828e-02]\n",
            "  [ 1.5133354e-01]\n",
            "  [-6.3816595e-01]\n",
            "  [ 2.367...1]\n",
            "  [ 1.5674971e-01]\n",
            "  [ 1.3306208e-01]\n",
            "  [-3.2582644e-01]\n",
            "  [-1.1079599e-03]\n",
            "  [ 2.1520473e-02]\n",
            "  [ 6.5404159e-01]]])\n",
            "output_    = tensor([[[-3.6973e-01],\n",
            "         [ 2.4711e-02],\n",
            "         [ 3.2449e-02],\n",
            "         [ 1.5133e-01],\n",
            "         [-6.3817e-01]...2583e-01],\n",
            "         [-1.1080e-03],\n",
            "         [ 2.1520e-02],\n",
            "         [ 6.5404e-01]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-0.23728904,  0.4693333 ,  0.94431114, ...,  1.0873748 ,\n",
            "          0.71320707,  0.27052027],\n",
            "        [ 0.9742...\n",
            "        [-0.9327607 ,  0.19774854, -0.29746872, ..., -1.1225699 ,\n",
            "          0.24131125,  1.121871  ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[-12.943143  ,  -0.7795834 ,   0.4305314 ,  -2....5,  -0.75977844,   3.4119303 ],\n",
            "       [  4.62718   ,   0.62192684,   0.21046208,   2.4119291 ]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 44 / 44 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 19.177448\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 40.013622\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[-12.943143,  -0.779583,   0.430531,  -2.144437],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ -5.141861,  -4.194541,   1.327547,  -1.77721 ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 14.155138,  -5.033091,   0.249488,  -1.628743],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ -0.512278,   0.468852, -12.324634,  -2.172758],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ -3.959093,   1.301367,  -4.666145,  -1.740494],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ -5.02231 ,   0.239509,  13.063771,  -1.720619],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[-12.943143  ,  -0.7795834 ,   0.4305314 ,  -2....5,  -0.75977844,   3.4119303 ],\n",
            "       [  4.62718   ,   0.62192684,   0.21046208,   2.4119291 ]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-1-11-15-2-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
            "hidden_size = 1, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.7629884 ]\n",
            "  [ 0.6014435 ]\n",
            "  [ 0.4492452 ]\n",
            "  [ 0.21110308]\n",
            "  [-0.42748737]\n",
            "  [ 0.70314765]\n",
            "  [-0.76...762]\n",
            "  [ 0.01373881]\n",
            "  [ 0.01584393]\n",
            "  [ 0.00845214]\n",
            "  [ 0.00916673]\n",
            "  [ 0.0135313 ]\n",
            "  [-0.00827103]\n",
            "  [ 0.00113697]]])\n",
            "c0         = array([[[-0.5124194 ],\n",
            "        [ 0.99337023],\n",
            "        [-0.56605136],\n",
            "        [-0.84860927],\n",
            "        [ 0.68269217],\n",
            "   ...321982  ],\n",
            "        [ 0.01031548],\n",
            "        [ 0.34409213],\n",
            "        [ 0.9932816 ],\n",
            "        [-0.51217526]]], dtype=float32)\n",
            "c_         = tensor([[[ 0.7630],\n",
            "         [ 0.6014],\n",
            "         [ 0.4492],\n",
            "         [ 0.2111],\n",
            "         [-0.4275],\n",
            "         [ 0.7031]... [ 0.0085],\n",
            "         [ 0.0092],\n",
            "         [ 0.0135],\n",
            "         [-0.0083],\n",
            "         [ 0.0011]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 4.8870364e-01]\n",
            "  [ 3.9985347e-01]\n",
            "  [ 1.8978797e-01]\n",
            "  [ 1.8236168e-01]\n",
            "  [-2.0189169e-01]\n",
            "  [ 4.812...3]\n",
            "  [ 9.2095425e-03]\n",
            "  [ 4.6318923e-03]\n",
            "  [ 5.0554047e-03]\n",
            "  [ 7.7325110e-03]\n",
            "  [-3.5038432e-03]\n",
            "  [ 5.7692383e-04]]])\n",
            "h0         = array([[[-1.4786363 ],\n",
            "        [-1.3779323 ],\n",
            "        [-0.949386  ],\n",
            "        [-0.08436849],\n",
            "        [ 0.6362628 ],\n",
            "   ...4489844 ],\n",
            "        [-0.3728369 ],\n",
            "        [ 1.2208474 ],\n",
            "        [-0.58183104],\n",
            "        [-0.5651258 ]]], dtype=float32)\n",
            "h_         = tensor([[[ 4.8870e-01],\n",
            "         [ 3.9985e-01],\n",
            "         [ 1.8979e-01],\n",
            "         [ 1.8236e-01],\n",
            "         [-2.0189e-01]...     [ 5.0554e-03],\n",
            "         [ 7.7325e-03],\n",
            "         [-3.5038e-03],\n",
            "         [ 5.7692e-04]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32016426c0>\n",
            "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[ 0.00657839]\n",
            "  [ 0.00509783]\n",
            "  [ 0.00210836]\n",
            "  [ 0.00201554]\n",
            "  [-0.00167433]\n",
            "  [ 0.00048358]\n",
            "  [-0.00...774]\n",
            "  [ 0.00786346]\n",
            "  [ 0.00920954]\n",
            "  [ 0.00463189]\n",
            "  [ 0.0050554 ]\n",
            "  [ 0.00773251]\n",
            "  [-0.00350384]\n",
            "  [ 0.00057692]]])\n",
            "output_    = tensor([[[ 0.0066],\n",
            "         [ 0.0051],\n",
            "         [ 0.0021],\n",
            "         [ 0.0020],\n",
            "         [-0.0017],\n",
            "         [ 0.0005]...],\n",
            "         [ 0.0051],\n",
            "         [ 0.0077],\n",
            "         [-0.0035],\n",
            "         [ 0.0006]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-1.2513105 ,  0.7388367 , -0.8344293 , -1.9424688 ,\n",
            "         -1.0244879 , -0.9267826 , -0.40689582, -0.298365...  -0.19044904,  1.1621616 ,  3.397913  , -0.9240074 ,\n",
            "         -0.05148954,  1.273209  , -1.807747  ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192a5c0>, array([[ 0.21856552, -0.05594005,  0.        , -0.1146...       , -0.0056242 ,  0.00030529],\n",
            "       [-0.00341543,  0.        , -0.01252732, -0.00870406]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 44 / 44 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.31878495\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 661.1871\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.218566, -0.05594 ,  0.      , -0.114659],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 0.139149, -0.045044,  0.      , -0.143554],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.037699,  0.170203,  0.      ,  0.054656],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-0.002128,  0.      ,  0.009955, -0.004918],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.001723,  0.      ,  0.005033, -0.006363],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 0.007595,  0.      , -0.00127 ,  0.001732],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192a5c0>, array([[ 0.21856552, -0.05594005,  0.        , -0.1146...       , -0.0056242 ,  0.00030529],\n",
            "       [-0.00341543,  0.        , -0.01252732, -0.00870406]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-1-11-15-2-13] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
            "hidden_size = 1, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.3893861 ]\n",
            "  [ 0.65354073]\n",
            "  [-0.50730354]\n",
            "  [-0.13495116]\n",
            "  [ 0.69323134]\n",
            "  [ 1.0491788 ]\n",
            "  [ 0.19...996]\n",
            "  [ 0.1625592 ]\n",
            "  [ 0.11264866]\n",
            "  [-0.12701358]\n",
            "  [-0.19716378]\n",
            "  [-0.1622399 ]\n",
            "  [ 0.01302865]\n",
            "  [-0.149021  ]]])\n",
            "c0         = array([[[-0.025713  ],\n",
            "        [-0.09329171],\n",
            "        [-0.11316168],\n",
            "        [-1.4211711 ],\n",
            "        [ 0.19719766],\n",
            "   ...4184706 ],\n",
            "        [-1.3272365 ],\n",
            "        [ 0.41834188],\n",
            "        [ 0.5889051 ],\n",
            "        [-0.21038401]]], dtype=float32)\n",
            "c_         = tensor([[[-0.3894],\n",
            "         [ 0.6535],\n",
            "         [-0.5073],\n",
            "         [-0.1350],\n",
            "         [ 0.6932],\n",
            "         [ 1.0492]... [-0.1270],\n",
            "         [-0.1972],\n",
            "         [-0.1622],\n",
            "         [ 0.0130],\n",
            "         [-0.1490]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-0.32157037]\n",
            "  [ 0.07258167]\n",
            "  [-0.00963861]\n",
            "  [-0.12194321]\n",
            "  [ 0.03260498]\n",
            "  [ 0.57275534]\n",
            "  [ 0.07...77 ]\n",
            "  [ 0.08243524]\n",
            "  [ 0.0590047 ]\n",
            "  [-0.05097755]\n",
            "  [-0.0687947 ]\n",
            "  [-0.07178224]\n",
            "  [ 0.00679083]\n",
            "  [-0.06928377]]])\n",
            "h0         = array([[[-0.8879487 ],\n",
            "        [ 0.44407555],\n",
            "        [-0.43655014],\n",
            "        [ 0.22195734],\n",
            "        [-0.3910532 ],\n",
            "   ...5133197 ],\n",
            "        [-0.76993805],\n",
            "        [-0.26252997],\n",
            "        [-0.9762305 ],\n",
            "        [ 0.48720488]]], dtype=float32)\n",
            "h_         = tensor([[[-0.3216],\n",
            "         [ 0.0726],\n",
            "         [-0.0096],\n",
            "         [-0.1219],\n",
            "         [ 0.0326],\n",
            "         [ 0.5728]... [-0.0510],\n",
            "         [-0.0688],\n",
            "         [-0.0718],\n",
            "         [ 0.0068],\n",
            "         [-0.0693]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3215caa420>\n",
            "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[ 0.00439358]\n",
            "  [-0.02301092]\n",
            "  [-0.02416174]\n",
            "  [-0.00721419]\n",
            "  [-0.01668309]\n",
            "  [-0.00971931]\n",
            "  [ 0.02...77 ]\n",
            "  [ 0.08243524]\n",
            "  [ 0.0590047 ]\n",
            "  [-0.05097755]\n",
            "  [-0.0687947 ]\n",
            "  [-0.07178224]\n",
            "  [ 0.00679083]\n",
            "  [-0.06928377]]])\n",
            "output_    = tensor([[[ 0.0044],\n",
            "         [-0.0230],\n",
            "         [-0.0242],\n",
            "         [-0.0072],\n",
            "         [-0.0167],\n",
            "         [-0.0097]...],\n",
            "         [-0.0688],\n",
            "         [-0.0718],\n",
            "         [ 0.0068],\n",
            "         [-0.0693]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 1.2610476 ,  0.41159344, -0.1128009 , ...,  0.2250857 ,\n",
            "         -1.6517295 ,  0.85231954],\n",
            "        [-1.9646...\n",
            "        [ 0.4601461 ,  1.6399006 , -0.8333817 , ..., -0.8283264 ,\n",
            "         -0.22155511,  2.268523  ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[-0.36354077,  1.5474348 ,  0.12882398,  0.9542...3310854, -2.540594  ,  1.5561143 ],\n",
            "       [ 2.1186764 , -0.93485886,  2.509921  ,  0.9984814 ]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 44 / 44 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 5.6880264\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 63.529175\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[-0.363541,  1.547435,  0.128824,  0.954206],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [ 0.769472, -0.956478,  0.170597, -0.622291],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-1.779175, -0.298229,  0.202845,  0.148192],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 2.051577,  0.119507, -0.412982,  1.280849],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-1.377681,  0.248606,  1.006506, -0.908177],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [-0.37992 ,  0.25361 , -2.324973,  0.21577 ],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[-0.36354077,  1.5474348 ,  0.12882398,  0.9542...3310854, -2.540594  ,  1.5561143 ],\n",
            "       [ 2.1186764 , -0.93485886,  2.509921  ,  0.9984814 ]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-12-1-1-1-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 12\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.00279954 -0.00035824  0.00082454 -0.00461313 -0.00130025\n",
            "    0.00090027 -0.00229639 -0.0011662  -0.00373521 -0.0030066\n",
            "    0.00188168 -0.00147497]]])\n",
            "c0         = array([[[-1.5350305 , -0.42240244,  0.38567945,  0.29734212,\n",
            "          0.22674479,  0.6976185 ,  0.5213831 ,  0.10060888,\n",
            "         -1.0972829 , -0.44425535, -0.2645662 , -0.23856553]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[-0.0028, -0.0004,  0.0008, -0.0046, -0.0013,  0.0009, -0.0023,\n",
            "          -0.0012, -0.0037, -0.0030,  0.0019, -0.0015]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-0.00140177 -0.00017828  0.00041236 -0.00229881 -0.00065191\n",
            "    0.00045173 -0.00114852 -0.00058293 -0.00187194 -0.001507\n",
            "    0.0009383  -0.00073683]]])\n",
            "h0         = array([[[-1.4138421 ,  2.5898185 ,  2.0897737 , -0.4632366 ,\n",
            "          2.0417523 , -0.71339494,  1.1471795 ,  0.17965576,\n",
            "         -0.02597881, -0.0678661 ,  1.322319  , -1.7128592 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[-0.0014, -0.0002,  0.0004, -0.0023, -0.0007,  0.0005, -0.0011,\n",
            "          -0.0006, -0.0019, -0.0015,  0.0009, -0.0007]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e320859be90>\n",
            "model_     = LSTM(1, 12, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-0.00140177 -0.00017828  0.00041236 -0.00229881 -0.00065191\n",
            "    0.00045173 -0.00114852 -0.00058293 -0.00187194 -0.001507\n",
            "    0.0009383  -0.00073683]]])\n",
            "output_    = tensor([[[-0.0014, -0.0002,  0.0004, -0.0023, -0.0007,  0.0005, -0.0011,\n",
            "          -0.0006, -0.0019, -0.0015,  0.0009, -0.0007]]],\n",
            "       grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.03265951]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e3201842e80>, array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00...93e-05,  9.5218520e-06,\n",
            "         3.0497211e-05,  2.4548308e-05, -1.5363552e-05,  1.2042904e-05]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 32 / 48 (66.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.03272407\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 3450.8118\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00,  0.000000e+00, -3.253748e-02, -3.271459e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -3.268480e-02,  0.000000e+00,  0.000000e+00,  0.000000e+00,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 2.298873e-05,  2.906778e-06, -6.764138e-06,  3.758287e-05,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.063534e-05, -7.409845e-06,  1.875005e-05,  9.483007e-06,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    3.054058e-05,  2.460847e-05, -1.527644e-05,  1.205462e-05,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e3201842e80>, array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00...93e-05,  9.5218520e-06,\n",
            "         3.0497211e-05,  2.4548308e-05, -1.5363552e-05,  1.2042904e-05]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-1-1-1-13] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.10594738 -0.01835678  0.11069672 -0.02549895  0.08440849\n",
            "    0.0966952   0.05707094  0.04267731 -0.12603903  0.10508296\n",
            "    0.09882638  0.01718937]]])\n",
            "c0         = array([[[ 1.7080675 , -0.10088249, -0.0077136 ,  0.4516703 ,\n",
            "         -0.48882344,  1.5156095 ,  1.682812  ,  0.40922546,\n",
            "          0.04705485, -0.7347539 ,  1.4593488 ,  2.0553446 ]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 0.1059, -0.0184,  0.1107, -0.0255,  0.0844,  0.0967,  0.0571,\n",
            "           0.0427, -0.1260,  0.1051,  0.0988,  0.0172]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.04960556 -0.00835966  0.05933419 -0.01231052  0.04036821\n",
            "    0.04948221  0.02692194  0.01939408 -0.06466507  0.05163568\n",
            "    0.0521936   0.00887092]]])\n",
            "h0         = array([[[-0.84557754,  0.16351338, -1.3806112 ,  0.7215386 ,\n",
            "         -1.4495368 , -0.26233137,  1.2448832 ,  0.78921825,\n",
            "         -1.1029001 , -0.2575007 ,  0.01134867,  0.27030566]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 0.0496, -0.0084,  0.0593, -0.0123,  0.0404,  0.0495,  0.0269,\n",
            "           0.0194, -0.0647,  0.0516,  0.0522,  0.0089]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3208438fe0>\n",
            "model_     = LSTM(1, 12, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-0.02165601  0.00448194 -0.01663458  0.003457   -0.01823656\n",
            "   -0.01716987 -0.00982786 -0.00746282  0...9 -0.01231052  0.04036821\n",
            "    0.04948221  0.02692194  0.01939408 -0.06466507  0.05163568\n",
            "    0.0521936   0.00887092]]])\n",
            "output_    = tensor([[[-0.0217,  0.0045, -0.0166,  0.0035, -0.0182, -0.0172, -0.0098,\n",
            "          -0.0075,  0.0215, -0.0169, -0.0213,...,  0.0495,  0.0269,\n",
            "           0.0194, -0.0647,  0.0516,  0.0522,  0.0089]]],\n",
            "       grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.31341252]],\n",
            "\n",
            "       [[-0.89354646]],\n",
            "\n",
            "       [[-0.27371654]],\n",
            "\n",
            "       [[ 1.1062304 ]],\n",
            "\n",
            "       [[-0.399286...]],\n",
            "\n",
            "       [[ 0.22836213]],\n",
            "\n",
            "       [[-0.04442778]],\n",
            "\n",
            "       [[-0.6365954 ]],\n",
            "\n",
            "       [[-0.6200902 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...2, -0.10862267, -0.06480412, -0.0707413 ,  0.13178279,\n",
            "        -0.11675693, -0.1209007 , -0.0203972 ]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 48 / 48 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.73138\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 68.169014\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.234386, -0.360364,  0.372492,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.698093, -0.710152, -0.429821,  0.      ,  0.      ,  0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-0.27783 ,  0.033037, -0.215278,  0.044179, -0.274484, -0.242006,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.139059, -0.131919,  0.260805, -0.238261, -0.231112, -0.047871,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.033287, -0.010267,  0.012662, -0.007044,  0.033607,  0.044339,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...2, -0.10862267, -0.06480412, -0.0707413 ,  0.13178279,\n",
            "        -0.11675693, -0.1209007 , -0.0203972 ]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m____________________ test_lstm[cuda-False-False-12-1-1-2-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 12\n",
            "bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.03274068  0.05260257  0.05900295  0.04271158 -0.02392701\n",
            "    0.03697655  0.01566753 -0.04883898 -0...5  0.0014806   0.00544397\n",
            "   -0.00504335 -0.0080192   0.00111216  0.00325859 -0.00087151\n",
            "   -0.00019723  0.00778543]]])\n",
            "c0         = array([[[-1.1742684 ,  0.846488  ,  1.0206813 , -0.44667497,\n",
            "         -2.5610468 , -0.7426555 , -0.27352622, -0.131583...2112838,  0.7751657 ,  1.49611   ,\n",
            "          1.1282074 ,  0.41349232, -0.27746335, -0.3908234 ]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[-0.0327,  0.0526,  0.0590,  0.0427, -0.0239,  0.0370,  0.0157,\n",
            "          -0.0488, -0.0075,  0.0031, -0.0254,...,  0.0054, -0.0050, -0.0080,\n",
            "           0.0011,  0.0033, -0.0009, -0.0002,  0.0078]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-1.65381022e-02  2.65596751e-02  3.03054471e-02  2.23595332e-02\n",
            "   -1.17171565e-02  1.81140825e-02  7... -2.51214998e-03 -3.98298632e-03  5.52382378e-04\n",
            "    1.64344243e-03 -4.37105657e-04 -9.79724937e-05  3.88344331e-03]]])\n",
            "h0         = array([[[ 0.09492406,  0.8608136 , -1.6050023 ,  0.9756196 ,\n",
            "         -0.9109524 , -2.0231183 ,  0.6213703 ,  0.489160...020624 ,  1.0943083 , -0.34400082,\n",
            "          1.1558914 , -0.38870403, -1.658077  , -0.50174004]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[-1.6538e-02,  2.6560e-02,  3.0305e-02,  2.2360e-02, -1.1717e-02,\n",
            "           1.8114e-02,  7.4702e-03, -2.4724...3, -3.9830e-03,  5.5238e-04,  1.6434e-03, -4.3711e-04,\n",
            "          -9.7972e-05,  3.8834e-03]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3208141460>\n",
            "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[-3.6763826e-03 -1.3899691e-03  3.0655295e-04  7.4139569e-04\n",
            "    2.7165564e-03 -2.5121500e-03 -3.9829863e-03  5.5238238e-04\n",
            "    1.6434424e-03 -4.3710566e-04 -9.7972494e-05  3.8834433e-03]]])\n",
            "output_    = tensor([[[-3.6764e-03, -1.3900e-03,  3.0655e-04,  7.4140e-04,  2.7166e-03,\n",
            "          -2.5122e-03, -3.9830e-03,  5.5238e-04,  1.6434e-03, -4.3711e-04,\n",
            "          -9.7972e-05,  3.8834e-03]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.4496097]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192a160>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...310e-04, -8.96058627e-04,  3.64574298e-05,\n",
            "         1.09531196e-04,  2.95700622e-04,  6.41934923e-04]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 39 / 48 (81.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.1560734\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 763.41626\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.084875, -0.156948, -0.00862 ,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.003649,  0.000947, -0.000214,  0.      ,  0.      ,  0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-3.004818e-04,  2.047380e-04, -9.385962e-04,  8.467809e-04,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    5.542659e-04,  8.385661e-05, -1.110331e-04, -8.742656e-04,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    3.698184e-05,  1.009233e-04,  2.957122e-04,  6.951510e-04,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192a160>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...310e-04, -8.96058627e-04,  3.64574298e-05,\n",
            "         1.09531196e-04,  2.95700622e-04,  6.41934923e-04]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-1-1-2-13] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.03812869  0.02127094  0.05743609  0.00099458 -0.03980841\n",
            "    0.03746155 -0.09043361 -0.01462515 -0...4  0.02347594 -0.02226273\n",
            "   -0.06274943 -0.01042864  0.0233904   0.04816721 -0.00930671\n",
            "    0.00808051 -0.02129791]]])\n",
            "c0         = array([[[ 0.2033129 , -0.1270844 ,  0.02226306, -0.0665752 ,\n",
            "          1.5372467 ,  0.1724118 ,  0.13588132, -0.301098...53512  ,  0.4033994 , -0.532152  ,\n",
            "          1.688693  , -2.0337074 , -0.34269524,  0.27888438]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 0.0381,  0.0213,  0.0574,  0.0010, -0.0398,  0.0375, -0.0904,\n",
            "          -0.0146, -0.0009,  0.0163,  0.0469,..., -0.0223, -0.0627, -0.0104,\n",
            "           0.0234,  0.0482, -0.0093,  0.0081, -0.0213]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.02039382  0.01070654  0.02898595  0.00049    -0.02062541\n",
            "    0.01799353 -0.04430405 -0.00700512 -0...7  0.01171612 -0.01120522\n",
            "   -0.03122601 -0.0051477   0.01171579  0.02434562 -0.00467884\n",
            "    0.00409646 -0.01059341]]])\n",
            "h0         = array([[[-1.2120897 , -1.189858  ,  1.1636243 , -0.75188804,\n",
            "          2.2538106 ,  0.6103768 ,  0.54019016,  0.200662...997052 , -0.1319963 ,  0.49560773,\n",
            "         -0.5043369 , -0.33064425, -0.61309534, -0.64337134]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 0.0204,  0.0107,  0.0290,  0.0005, -0.0206,  0.0180, -0.0443,\n",
            "          -0.0070, -0.0004,  0.0080,  0.0237,..., -0.0112, -0.0312, -0.0051,\n",
            "           0.0117,  0.0243, -0.0047,  0.0041, -0.0106]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32194ae420>\n",
            "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[ 0.0060715  -0.00336647  0.00163266 -0.00362728  0.00182631\n",
            "    0.0065752   0.00247582 -0.00113112 -0...7  0.01171612 -0.01120522\n",
            "   -0.03122601 -0.0051477   0.01171579  0.02434562 -0.00467884\n",
            "    0.00409646 -0.01059341]]])\n",
            "output_    = tensor([[[ 0.0061, -0.0034,  0.0016, -0.0036,  0.0018,  0.0066,  0.0025,\n",
            "          -0.0011, -0.0045, -0.0010,  0.0015,..., -0.0312, -0.0051,\n",
            "           0.0117,  0.0243, -0.0047,  0.0041, -0.0106]]],\n",
            "       grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.5209067 ]],\n",
            "\n",
            "       [[-0.06241651]],\n",
            "\n",
            "       [[-1.2207935 ]],\n",
            "\n",
            "       [[ 0.4175899 ]],\n",
            "\n",
            "       [[ 0.005170...]],\n",
            "\n",
            "       [[-0.14855686]],\n",
            "\n",
            "       [[-0.716113  ]],\n",
            "\n",
            "       [[-0.59871286]],\n",
            "\n",
            "       [[ 0.3871839 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...40e-02, -9.3231583e-03,\n",
            "         7.9115316e-02,  1.3781859e-02,  2.6628720e-02,  4.1549735e-02]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 48 / 48 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 2.872472\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 183.03148\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -1.284193, -1.000603, -2.721342,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.106591, -0.066382, -0.422881,  0.      ,  0.      ,  0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-9.031354e-04, -1.664079e-03, -2.090771e-02, -3.737191e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    4.061502e-03,  1.134170e-02, -2.544620e-02, -2.036224e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.511298e-01,  2.231872e-02,  3.854295e-02,  6.700075e-02,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...40e-02, -9.3231583e-03,\n",
            "         7.9115316e-02,  1.3781859e-02,  2.6628720e-02,  4.1549735e-02]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-1-15-1-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 2.14910340e-02 -1.08395495e-01 -1.16271228e-01  4.04815488e-02\n",
            "   -1.00426197e-01 -9.36441347e-02  5... -5.81277870e-02  3.43018584e-02 -3.12274322e-02\n",
            "   -6.68226182e-02  8.42662342e-03  5.31261787e-02  6.31771460e-02]]])\n",
            "c0         = array([[[-0.23532894, -1.2091265 , -0.8561689 , -0.00473606,\n",
            "          2.0142727 ,  1.0460677 ,  0.1295192 ,  0.314726...2991817, -1.0161843 ,  0.93560344,\n",
            "          0.20495208,  2.1312158 ,  0.03564047,  1.8995107 ]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 2.1491e-02, -1.0840e-01, -1.1627e-01,  4.0482e-02, -1.0043e-01,\n",
            "          -9.3644e-02,  5.7095e-02, -5.2494...2,  3.4302e-02, -3.1227e-02, -6.6823e-02,  8.4266e-03,\n",
            "           5.3126e-02,  6.3177e-02]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 1.12106120e-02 -5.42716421e-02 -5.76636605e-02  1.78521518e-02\n",
            "   -4.45509627e-02 -4.61426936e-02  2... -2.88279448e-02  1.59272477e-02 -1.47468308e-02\n",
            "   -3.25174369e-02  4.20148904e-03  2.58456543e-02  3.30787376e-02]]])\n",
            "h0         = array([[[ 0.758401  , -0.30625364, -0.6075426 , -0.67501414,\n",
            "          0.7646013 , -0.20621875, -1.051955  , -0.187508...154177 ,  0.37513784,  0.67807996,\n",
            "         -0.49516198, -0.2632327 , -0.8719441 ,  0.1846481 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 1.1211e-02, -5.4272e-02, -5.7664e-02,  1.7852e-02, -4.4551e-02,\n",
            "          -4.6143e-02,  2.5164e-02, -2.3822...2,  1.5927e-02, -1.4747e-02, -3.2517e-02,  4.2015e-03,\n",
            "           2.5846e-02,  3.3079e-02]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e320850f3b0>\n",
            "model_     = LSTM(1, 12, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[ 1.12106120e-02 -5.42716421e-02 -5.76636605e-02  1.78521518e-02\n",
            "   -4.45509627e-02 -4.61426936e-02  2... -2.88279448e-02  1.59272477e-02 -1.47468308e-02\n",
            "   -3.25174369e-02  4.20148904e-03  2.58456543e-02  3.30787376e-02]]])\n",
            "output_    = tensor([[[ 1.1211e-02, -5.4272e-02, -5.7664e-02,  1.7852e-02, -4.4551e-02,\n",
            "          -4.6143e-02,  2.5164e-02, -2.3822...7e-02, -1.4747e-02, -3.2517e-02,  4.2015e-03,\n",
            "           2.5846e-02,  3.3079e-02]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.8468219 ],\n",
            "        [-0.35275915],\n",
            "        [-0.04375246],\n",
            "        [ 0.0046348 ],\n",
            "        [ 0.77561444],\n",
            "   ...8420272 ],\n",
            "        [ 1.4129045 ],\n",
            "        [-1.0894619 ],\n",
            "        [-0.04920205],\n",
            "        [-0.5097527 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e3201842e80>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...5,  0.3598058 , -0.21699286,  0.20399481,  0.39846122,\n",
            "        -0.05474263, -0.34746262, -0.39172912]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 39 / 48 (81.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 5.6817446\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 26.939104\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -5.383972, -4.239172, -5.277326,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.589142,  0.710408, -0.391422,  0.      ,  0.      ,  0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-0.097944,  0.426253,  0.385899, -0.125067,  0.355798,  0.368709,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.192704,  0.178605,  0.404418, -0.056955, -0.31014 , -0.428746,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e3201842e80>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...5,  0.3598058 , -0.21699286,  0.20399481,  0.39846122,\n",
            "        -0.05474263, -0.34746262, -0.39172912]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-1-15-1-13] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-5.37137538e-02 -5.33623286e-02  2.95610838e-02  1.54101253e-01\n",
            "   -1.40695602e-01  2.04719722e-01  7...  5.58944903e-02  1.56248473e-02  9.15966034e-02\n",
            "   -7.57163763e-03  4.07289714e-03 -2.15690210e-02  2.63369232e-02]]])\n",
            "c0         = array([[[ 4.3147868e-01,  3.7639496e-01, -2.5003630e-01,  4.8175164e-02,\n",
            "         -1.0220182e+00, -1.0350623e+00, -5.1...1e+00, -2.5084779e-01,\n",
            "          8.9694095e-01,  5.1951116e-01, -7.9983395e-01,  5.5758518e-01]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[-5.3714e-02, -5.3362e-02,  2.9561e-02,  1.5410e-01, -1.4070e-01,\n",
            "           2.0472e-01,  7.7442e-02,  3.6754...2,  1.5625e-02,  9.1597e-02, -7.5716e-03,  4.0729e-03,\n",
            "          -2.1569e-02,  2.6337e-02]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-2.59802211e-02 -2.89310329e-02  1.58991143e-02  7.30992779e-02\n",
            "   -6.45169094e-02  1.11183196e-01  3...  2.71907486e-02  8.06945935e-03  4.45844233e-02\n",
            "   -3.95738566e-03  2.01711757e-03 -1.07405894e-02  1.31155783e-02]]])\n",
            "h0         = array([[[-0.52799225, -1.5499772 ,  0.24589925, -0.63401896,\n",
            "          1.031737  , -0.24539638, -1.2701248 ,  0.199594...450927 , -0.62504035, -0.16939196,\n",
            "         -1.0033275 ,  0.76503295,  0.02393749, -0.5844721 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[-2.5980e-02, -2.8931e-02,  1.5899e-02,  7.3099e-02, -6.4517e-02,\n",
            "           1.1118e-01,  3.9143e-02,  1.8980...2,  8.0695e-03,  4.4584e-02, -3.9574e-03,  2.0171e-03,\n",
            "          -1.0741e-02,  1.3116e-02]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e321643c770>\n",
            "model_     = LSTM(1, 12, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-0.00783904 -0.02554419  0.01088865 ... -0.03125934 -0.03444863\n",
            "    0.00735782]\n",
            "  [-0.00475254 -0.014...92038  0.01572657\n",
            "   -0.01364342]\n",
            "  [-0.00887362  0.00064053  0.00305197 ...  0.00201712 -0.01074059\n",
            "    0.01311558]]])\n",
            "output_    = tensor([[[-0.0078, -0.0255,  0.0109,  ..., -0.0313, -0.0344,  0.0074],\n",
            "         [-0.0048, -0.0142,  0.0063,  ..., -0.0...36],\n",
            "         [-0.0089,  0.0006,  0.0031,  ...,  0.0020, -0.0107,  0.0131]]],\n",
            "       grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 1.060224  ],\n",
            "        [ 0.60536313],\n",
            "        [-0.36620247],\n",
            "        [ 1.8083078 ],\n",
            "        [-1.4495869 ],\n",
            "   ...3559117 ],\n",
            "        [ 1.9420682 ],\n",
            "        [-0.17342484],\n",
            "        [ 0.2562552 ],\n",
            "        [-0.24293268]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[  0.        ,   0.        ,   0.        ,   0....7 ,   1.9132149 ,   7.431871  ,\n",
            "         -2.067038  ,  -1.785841  ,  -2.2574196 ,   0.6708002 ]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 48 / 48 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 18.150146\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 1346.3223\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[  0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                     0.      , -13.000696,  19.47659 ,   1.72766 ,   0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                     0.      ,   0.      ,  -6.335599,  16.922077, -18.163628,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ -1.723784,  -4.975776,   1.138009,   5.097955,  -4.561642,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    10.711486,   3.41061 ,  13.165392,  -3.9573  ,  -3.591977,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    -4.054603,   1.133969,  -0.112586,  -0.035724,  -0.013481,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[  0.        ,   0.        ,   0.        ,   0....7 ,   1.9132149 ,   7.431871  ,\n",
            "         -2.067038  ,  -1.785841  ,  -2.2574196 ,   0.6708002 ]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-1-15-2-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 8.94013233e-03 -1.19667491e-02  1.43450079e-02  1.31224142e-02\n",
            "   -1.03111602e-02 -3.07882670e-03  5... -4.22346266e-03 -2.34055886e-04 -1.91472864e-04\n",
            "    1.05345552e-03  1.35914504e-03 -3.58782848e-03  2.11260103e-05]]])\n",
            "c0         = array([[[ 7.14210212e-01, -8.26429017e-03,  6.54464245e-01,\n",
            "         -3.34351987e-01, -1.42781401e+00, -2.02652439e-01..., -3.64124984e-01, -3.69986624e-01,\n",
            "          1.99852264e+00,  8.20677936e-01,  3.46319586e-01]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 8.9401e-03, -1.1967e-02,  1.4345e-02,  1.3122e-02, -1.0311e-02,\n",
            "          -3.0788e-03,  5.1854e-04, -6.8651...3, -2.3406e-04, -1.9147e-04,  1.0535e-03,  1.3591e-03,\n",
            "          -3.5878e-03,  2.1126e-05]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 4.42606304e-03 -5.90844173e-03  7.15869432e-03  6.62090071e-03\n",
            "   -5.09942835e-03 -1.53438968e-03  2... -2.10873550e-03 -1.17198411e-04 -9.60608741e-05\n",
            "    5.27103082e-04  6.81776437e-04 -1.79193658e-03  1.05728141e-05]]])\n",
            "h0         = array([[[-1.8211935 , -0.33488393,  0.65498245,  0.6284282 ,\n",
            "         -0.12448574, -0.24585392,  0.67425036, -0.038389...488447 , -1.4098895 ,  1.2757286 ,\n",
            "          0.55289835, -0.82595384, -0.39273718, -0.5284264 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 4.4261e-03, -5.9084e-03,  7.1587e-03,  6.6209e-03, -5.0994e-03,\n",
            "          -1.5344e-03,  2.6214e-04, -3.4702...3, -1.1720e-04, -9.6061e-05,  5.2710e-04,  6.8178e-04,\n",
            "          -1.7919e-03,  1.0573e-05]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3216474c20>\n",
            "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[ 6.58015953e-04 -3.75082920e-04 -7.10712338e-04 -5.89913398e-04\n",
            "   -7.96065142e-04 -1.09755958e-03 -5... -2.10873550e-03 -1.17198411e-04 -9.60608741e-05\n",
            "    5.27103082e-04  6.81776437e-04 -1.79193658e-03  1.05728141e-05]]])\n",
            "output_    = tensor([[[ 6.5802e-04, -3.7508e-04, -7.1071e-04, -5.8991e-04, -7.9607e-04,\n",
            "          -1.0976e-03, -5.1365e-05, -6.4762...0e-04, -9.6061e-05,  5.2710e-04,  6.8178e-04,\n",
            "          -1.7919e-03,  1.0573e-05]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.09975182],\n",
            "        [-0.688927  ],\n",
            "        [-1.2765723 ],\n",
            "        [-1.4100746 ],\n",
            "        [-0.09238588],\n",
            "   ...093975  ],\n",
            "        [ 0.01688888],\n",
            "        [ 2.1132472 ],\n",
            "        [ 0.6673504 ],\n",
            "        [-0.19144629]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...96e-04, -1.3299183e-03,\n",
            "         2.1154497e-02,  8.3487578e-02, -4.8088845e-02,  5.3066976e-02]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 39 / 48 (81.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.660243\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 1182.176\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.554978,  0.010635, -0.204519,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.40303 , -0.016642,  0.178778,  0.      ,  0.      ,  0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 2.035393e-01, -9.222940e-02,  2.663401e-02,  1.323128e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -1.439247e-02, -3.357830e-03, -4.698517e-04, -1.786158e-03,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.958141e-02,  8.404782e-02, -4.950815e-02,  6.465885e-02,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...96e-04, -1.3299183e-03,\n",
            "         2.1154497e-02,  8.3487578e-02, -4.8088845e-02,  5.3066976e-02]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-1-15-2-13] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 2.35592648e-02  1.14944624e-02 -9.98857804e-03 -2.61834799e-03\n",
            "    2.30686907e-02  1.73649434e-02 -2... -2.19151825e-02 -7.98213575e-03 -3.21922218e-03\n",
            "   -1.81975961e-02  1.54272327e-02 -6.82286033e-03  2.18022428e-02]]])\n",
            "c0         = array([[[ 0.4159489 , -0.5373655 ,  0.5623904 ,  0.4602612 ,\n",
            "          0.2159898 , -0.19715945,  2.0922585 , -1.540067...0387062, -0.12006336, -0.9770597 ,\n",
            "         -0.5508733 , -0.48776114,  1.180714  ,  1.6367991 ]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 2.3559e-02,  1.1494e-02, -9.9886e-03, -2.6183e-03,  2.3069e-02,\n",
            "           1.7365e-02, -2.4883e-03,  5.8605...2, -7.9821e-03, -3.2192e-03, -1.8198e-02,  1.5427e-02,\n",
            "          -6.8229e-03,  2.1802e-02]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 1.17811570e-02  5.68869943e-03 -4.96119587e-03 -1.30025367e-03\n",
            "    1.16233034e-02  8.58482346e-03 -1... -1.09221851e-02 -3.99526302e-03 -1.61636889e-03\n",
            "   -9.12116561e-03  7.62507692e-03 -3.40662268e-03  1.09829167e-02]]])\n",
            "h0         = array([[[ 1.1211047 , -2.559918  ,  2.1127906 , -0.65698564,\n",
            "          0.06928255, -1.504411  , -0.4125608 , -0.321991...788629 , -0.40603027, -0.57028615,\n",
            "         -1.5136256 ,  0.51194346,  0.9412637 ,  0.77415377]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 1.1781e-02,  5.6887e-03, -4.9612e-03, -1.3003e-03,  1.1623e-02,\n",
            "           8.5848e-03, -1.2619e-03,  2.9803...2, -3.9953e-03, -1.6164e-03, -9.1212e-03,  7.6251e-03,\n",
            "          -3.4066e-03,  1.0983e-02]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32085a2b40>\n",
            "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[ 9.00791609e-04  2.64723296e-03  6.04293030e-03 ... -1.94198149e-03\n",
            "    1.41292927e-03 -3.43285780e-0...5636e-02]\n",
            "  [ 6.89685694e-04 -6.31567976e-03 -1.53638050e-02 ...  7.62507692e-03\n",
            "   -3.40662268e-03  1.09829167e-02]]])\n",
            "output_    = tensor([[[ 9.0079e-04,  2.6472e-03,  6.0429e-03,  ..., -1.9420e-03,\n",
            "           1.4129e-03, -3.4329e-03],\n",
            "         [ 1.... -6.3157e-03, -1.5364e-02,  ...,  7.6251e-03,\n",
            "          -3.4066e-03,  1.0983e-02]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.6423792 ],\n",
            "        [ 1.2542683 ],\n",
            "        [-0.02117701],\n",
            "        [ 0.818542  ],\n",
            "        [-1.4597014 ],\n",
            "   ...04015423],\n",
            "        [-0.9073024 ],\n",
            "        [-0.3310446 ],\n",
            "        [-1.1255155 ],\n",
            "        [ 0.20377481]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00...71e-02, -3.3346578e-02,\n",
            "        -1.7742002e+00, -7.9053089e-02,  1.1596502e+00,  9.2274046e-01]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 48 / 48 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 15.89281\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 1161.2395\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00,  0.000000e+00, -1.582609e+01,  2.311187e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -1.510658e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 3.070400e+00,  1.103746e+00,  2.882679e-01, -3.572629e-03,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    2.412368e+00,  1.890389e+00,  6.672473e-02, -5.515005e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -3.602868e+00, -1.408867e-01,  1.900035e+00,  1.705546e+00,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00...71e-02, -3.3346578e-02,\n",
            "        -1.7742002e+00, -7.9053089e-02,  1.1596502e+00,  9.2274046e-01]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-11-1-1-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.04539559 -0.00256606 -0.01602675  0.10837647  0.40149313\n",
            "    0.00836954  0.3176822   0.08747403  0.24301925  0.08570749\n",
            "    0.05337065  0.09124523]]])\n",
            "c0         = array([[[-1.4436438 ,  0.6679995 , -0.34105703,  1.3953048 ,\n",
            "         -1.1688222 ,  0.16726318, -0.7044657 , -0.8221313 ,\n",
            "         -1.1227698 , -1.1421828 , -0.17436767, -0.9947966 ]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 0.0454, -0.0026, -0.0160,  0.1084,  0.4015,  0.0084,  0.3177,\n",
            "           0.0875,  0.2430,  0.0857,  0.0534,  0.0912]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.03012573 -0.00144392 -0.00765558  0.04502128  0.21609868\n",
            "    0.00273166  0.13217263  0.04003279  0.13841353  0.05201499\n",
            "    0.03614344  0.03709361]]])\n",
            "h0         = array([[[ 0.5190748 , -0.1325812 , -1.3326107 ,  0.9759701 ,\n",
            "         -0.42519653,  0.00754201, -0.09041007, -2.5255497 ,\n",
            "          0.406759  , -0.9410288 ,  1.5160166 ,  1.1750592 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 0.0301, -0.0014, -0.0077,  0.0450,  0.2161,  0.0027,  0.1322,\n",
            "           0.0400,  0.1384,  0.0520,  0.0361,  0.0371]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32011f51c0>\n",
            "model_     = LSTM(11, 12, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[ 0.03012573 -0.00144392 -0.00765558  0.04502128  0.21609868\n",
            "    0.00273166  0.13217263  0.04003279  0.13841353  0.05201499\n",
            "    0.03614344  0.03709361]]])\n",
            "output_    = tensor([[[ 0.0301, -0.0014, -0.0077,  0.0450,  0.2161,  0.0027,  0.1322,\n",
            "           0.0400,  0.1384,  0.0520,  0.0361,  0.0371]]],\n",
            "       grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.38576588,  0.63493496,  0.19667035, -1.0373931 ,\n",
            "          1.3076081 , -0.98691887,  0.35214654,  0.17031492,\n",
            "          0.38632253, -0.685794  ,  0.43262026]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32017034c0>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...333e-02,  9.37269256e-03,  2.51063127e-02,\n",
            "         8.81263614e-03,  5.03712567e-03,  9.50563792e-03]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 429 / 528 (81.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 1.2540876\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 70.032745\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.384723, -0.331993, -0.394772,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.016643, -0.05037 , -0.052722,  0.      ,  0.      ,  0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-7.054440e-03,  2.494380e-04,  1.135056e-03, -1.097324e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -3.047941e-02, -4.708102e-04, -1.474642e-02, -4.673809e-03,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -2.917450e-02, -1.210649e-02, -5.505010e-03, -5.936221e-03,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32017034c0>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...333e-02,  9.37269256e-03,  2.51063127e-02,\n",
            "         8.81263614e-03,  5.03712567e-03,  9.50563792e-03]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-11-1-1-13] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.16173877 -0.03599169  0.607666    0.20459734  0.30439055\n",
            "   -0.3101442  -0.42207468 -0.00776969 -0.2937375   0.03938359\n",
            "    0.02896984 -0.0315619 ]]])\n",
            "c0         = array([[[-1.9332949 , -2.254563  ,  1.5698602 ,  2.0465996 ,\n",
            "          1.2145425 , -0.09435143,  1.2529647 ,  0.3304331 ,\n",
            "         -0.8725745 , -0.11471947, -1.4410963 ,  0.8578    ]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 0.1617, -0.0360,  0.6077,  0.2046,  0.3044, -0.3101, -0.4221,\n",
            "          -0.0078, -0.2937,  0.0394,  0.0290, -0.0316]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.06667931 -0.0146755   0.23855397  0.07720271  0.1284318\n",
            "   -0.17253353 -0.15844922 -0.00429005 -0.12807071  0.01647629\n",
            "    0.01675206 -0.01233748]]])\n",
            "h0         = array([[[-0.7856467 , -0.6373312 ,  0.4399375 , -0.28627828,\n",
            "          0.03209776,  0.06872858, -0.5322076 ,  0.6231605 ,\n",
            "         -1.9603096 , -0.50633544,  2.0299227 , -0.09070785]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 0.0667, -0.0147,  0.2386,  0.0772,  0.1284, -0.1725, -0.1584,\n",
            "          -0.0043, -0.1281,  0.0165,  0.0168, -0.0123]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32080d6c00>\n",
            "model_     = LSTM(11, 12, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[ 1.06032997e-01 -2.26526707e-01  1.22817541e-02 -3.06003898e-01\n",
            "    1.50365531e-02 -1.38061956e-01 -1... -1.72533527e-01 -1.58449218e-01 -4.29004710e-03\n",
            "   -1.28070712e-01  1.64762884e-02  1.67520568e-02 -1.23374797e-02]]])\n",
            "output_    = tensor([[[ 1.0603e-01, -2.2653e-01,  1.2282e-02, -3.0600e-01,  1.5037e-02,\n",
            "          -1.3806e-01, -1.2201e-01, -7.8258...5e-01, -4.2901e-03, -1.2807e-01,  1.6476e-02,\n",
            "           1.6752e-02, -1.2337e-02]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-4.2870623e-01, -2.3837423e+00,  1.8562835e-01, -9.8624784e-01,\n",
            "          3.9629886e-01,  8.6343563e-01,  1.5...6389634e-01,  1.4245009e+00, -8.1204766e-01,\n",
            "          4.1060328e-01,  1.2405843e+00,  2.2058849e-01]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[  0.        ,   0.        ,   0.        ,   0....359e-01, -4.74845439e-01,  1.48426324e-01,\n",
            "         1.92377403e-01,  1.17678056e-02, -6.01688981e-01]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 528 / 528 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 10.579461\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 164.54594\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[  0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                     0.      , -10.189411,  -8.925694,  -5.836707,   0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                     0.      ,   0.      ,  -1.139723,  -0.166883,   0.705329,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-2.202438e-01, -3.773945e-01, -1.543703e-03, -6.868051e-01,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.614776e-01,  8.604204e-01,  3.900502e-01, -1.349040e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    7.477685e-01,  7.150156e-01,  6.971458e-01, -5.439906e-01,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e320192ae80>, array([[  0.        ,   0.        ,   0.        ,   0....359e-01, -4.74845439e-01,  1.48426324e-01,\n",
            "         1.92377403e-01,  1.17678056e-02, -6.01688981e-01]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-11-1-2-1] ____________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.16421655 -0.1028042   0.17901503  0.00125839  0.06658919\n",
            "   -0.20574608 -0.12906782 -0.08037508 -0...3  0.01261454 -0.03043001\n",
            "   -0.07274395  0.00669085 -0.00358281  0.01178336  0.04877537\n",
            "   -0.00877995  0.01333933]]])\n",
            "c0         = array([[[ 0.7651031 ,  0.03721954, -0.540574  , -2.3488863 ,\n",
            "         -2.1766925 ,  0.8179868 ,  1.4280653 ,  0.302600...6850806, -0.46646824,  2.3030012 ,\n",
            "         -0.7498517 ,  0.29380912, -1.0509652 , -0.5177273 ]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 0.1642, -0.1028,  0.1790,  0.0013,  0.0666, -0.2057, -0.1291,\n",
            "          -0.0804, -0.4640,  0.5795, -0.0602,..., -0.0304, -0.0727,  0.0067,\n",
            "          -0.0036,  0.0118,  0.0488, -0.0088,  0.0133]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.11901573 -0.03945327  0.08541432  0.00055376  0.03058181\n",
            "   -0.06449902 -0.03197723 -0.04571311 -0...411  0.00645589 -0.0146554\n",
            "   -0.03565499  0.00348822 -0.00174338  0.00560964  0.0238831\n",
            "   -0.0042158   0.0065794 ]]])\n",
            "h0         = array([[[-0.17181908, -0.8350305 , -1.3316319 , -0.718315  ,\n",
            "         -0.7523522 , -1.5295409 , -1.2907265 ,  2.632833...51996  ,  1.2634066 ,  0.03484675,\n",
            "         -1.0312392 , -0.65355945,  0.708028  , -1.2321627 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 0.1190, -0.0395,  0.0854,  0.0006,  0.0306, -0.0645, -0.0320,\n",
            "          -0.0457, -0.3109,  0.2078, -0.0254,..., -0.0147, -0.0357,  0.0035,\n",
            "          -0.0017,  0.0056,  0.0239, -0.0042,  0.0066]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e320110e2d0>\n",
            "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[ 0.02505473  0.00137741  0.03619411  0.00645589 -0.0146554\n",
            "   -0.03565499  0.00348822 -0.00174338  0.00560964  0.0238831\n",
            "   -0.0042158   0.0065794 ]]])\n",
            "output_    = tensor([[[ 0.0251,  0.0014,  0.0362,  0.0065, -0.0147, -0.0357,  0.0035,\n",
            "          -0.0017,  0.0056,  0.0239, -0.0042,  0.0066]]],\n",
            "       grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.01866067, -1.1503735 ,  0.01720059, -0.5099862 ,\n",
            "          0.5149624 , -1.748971  , -1.3764118 , -1.6868072 ,\n",
            "         -0.39962828,  0.41764128, -2.3003025 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e3201703b00>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...675e-03, -4.19804314e-03, -2.81254835e-02,\n",
            "         2.57090870e-02, -6.94911636e-04, -1.10491021e-02]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 411 / 528 (77.8%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.3494653\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 41.441105\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00,  0.000000e+00,  3.933513e-04, -1.214518e-04,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    2.558480e-03,  0.000000e+00,  0.000000e+00,  0.000000e+00,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 1.020335e-04, -8.772625e-06, -2.491697e-04,  3.207546e-07,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -1.559552e-05,  1.140566e-04, -4.687096e-05, -6.003265e-05,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -2.764758e-04,  6.216484e-05, -4.893333e-06, -4.656734e-05,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e3201703b00>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...675e-03, -4.19804314e-03, -2.81254835e-02,\n",
            "         2.57090870e-02, -6.94911636e-04, -1.10491021e-02]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-11-1-2-13] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.2101449  -0.38110635  0.37297523  0.00193702  0.3816085\n",
            "    0.24041897 -0.14697051  0.29764748  0....62  0.04388171 -0.0072759\n",
            "    0.11917274 -0.06852646 -0.08693929  0.01261519 -0.02410053\n",
            "    0.01355221  0.01529857]]])\n",
            "c0         = array([[[-0.8546741 , -0.22737199,  0.6497712 , -0.1280131 ,\n",
            "          0.41781795,  1.6515701 ,  0.15933348,  1.147528...4891571,  0.28146532, -0.7276301 ,\n",
            "          0.3451195 ,  0.38813856,  0.59273434,  1.3941225 ]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 0.2101, -0.3811,  0.3730,  0.0019,  0.3816,  0.2404, -0.1470,\n",
            "           0.2976,  0.1838, -0.2545,  0.0312,..., -0.0073,  0.1192, -0.0685,\n",
            "          -0.0869,  0.0126, -0.0241,  0.0136,  0.0153]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.1439831  -0.1186385   0.10444035  0.00107108  0.14387268\n",
            "    0.13851108 -0.08712917  0.11684801  0...96  0.0223609  -0.00352089\n",
            "    0.0620882  -0.03583853 -0.04411396  0.00611055 -0.0121048\n",
            "    0.00656726  0.00756829]]])\n",
            "h0         = array([[[-0.22502714, -1.1518507 ,  1.8057508 , -0.4005674 ,\n",
            "          2.065633  , -1.2282927 , -1.1712991 , -0.202986...717303 , -0.4877458 ,  1.0607754 ,\n",
            "          1.9720509 , -1.7866637 , -0.576787  , -0.5352528 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 0.1440, -0.1186,  0.1044,  0.0011,  0.1439,  0.1385, -0.0871,\n",
            "           0.1168,  0.0592, -0.1360,  0.0190,..., -0.0035,  0.0621, -0.0358,\n",
            "          -0.0441,  0.0061, -0.0121,  0.0066,  0.0076]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32081769f0>\n",
            "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[-5.98885491e-03  3.14910663e-03  5.00406744e-03  1.67747159e-02\n",
            "    1.22746117e-02 -1.25034436e-04 -1...  6.20881952e-02 -3.58385295e-02 -4.41139564e-02\n",
            "    6.11055223e-03 -1.21047990e-02  6.56725653e-03  7.56829418e-03]]])\n",
            "output_    = tensor([[[-5.9889e-03,  3.1491e-03,  5.0041e-03,  1.6775e-02,  1.2275e-02,\n",
            "          -1.2503e-04, -1.3310e-02, -1.2302...9e-02, -4.4114e-02,  6.1105e-03, -1.2105e-02,\n",
            "           6.5673e-03,  7.5683e-03]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.2569068 , -0.055024  ,  0.8803194 ,  0.89713144,\n",
            "         -1.1985395 ,  0.6297326 ,  0.4444388 , -0.129964...  -0.12316269,  0.21934338,  0.9253136 ,  0.283224  ,\n",
            "         -0.7231322 , -0.4743863 ,  1.9163061 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...782e-02, -3.89022450e-03,  3.84457819e-02,\n",
            "         3.18112709e-02, -5.09962104e-02, -3.39344367e-02]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 528 / 528 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 2.5985622\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 1076.1594\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -0.674154, -0.411909, -0.07376 ,  0.      ,  0.      ,  0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.01137 ,  0.392345,  0.110325,  0.      ,  0.      ,  0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 3.357841e-02, -5.596231e-02, -1.233072e-02, -3.696039e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.130111e-01, -2.944914e-02, -1.462725e-02, -5.503571e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -7.919645e-02, -3.100363e-02,  2.241820e-01,  4.316625e-02,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.        ,  0.        ,  0.        ,  0.    ...782e-02, -3.89022450e-03,  3.84457819e-02,\n",
            "         3.18112709e-02, -5.09962104e-02, -3.39344367e-02]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-11-15-1-1] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-0.00562795 -0.25045866  0.00631349  0.20199743  0.0347029\n",
            "   -0.31499    -0.06724703  0.09278316  0....2 -0.0829571   0.30239213\n",
            "   -0.05439122 -0.00655998 -0.20893517  0.06291619 -0.31656206\n",
            "   -0.15400648 -0.23588857]]])\n",
            "c0         = array([[[-2.5739121e+00,  2.8175691e-01, -1.3566890e-01,  6.2442601e-01,\n",
            "         -1.9992374e+00,  8.7734872e-01,  1.1...6e-01, -7.3711288e-01,\n",
            "          2.0144117e-01, -4.5978305e-01,  1.9746404e+00, -7.7452451e-01]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[-0.0056, -0.2505,  0.0063,  0.2020,  0.0347, -0.3150, -0.0672,\n",
            "           0.0928,  0.0235,  0.1552, -0.2756,...,  0.3024, -0.0544, -0.0066,\n",
            "          -0.2089,  0.0629, -0.3166, -0.1540, -0.2359]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-3.07018193e-03 -1.51785523e-01  2.79703597e-03  9.95477661e-02\n",
            "    1.29707074e-02 -1.00824527e-01 -2... -2.65942607e-02 -3.36619304e-03 -1.01625957e-01\n",
            "    3.95069420e-02 -1.56647265e-01 -6.87794834e-02 -1.31999850e-01]]])\n",
            "h0         = array([[[-7.01195121e-01, -8.36934626e-01,  1.12714136e+00,\n",
            "         -3.05271208e-01, -7.06681788e-01,  5.49170971e-01..., -1.18560970e+00,  4.61356640e-02,\n",
            "          2.94582546e-01,  4.89321411e-01,  2.82626301e-01]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[-3.0702e-03, -1.5179e-01,  2.7970e-03,  9.9548e-02,  1.2971e-02,\n",
            "          -1.0082e-01, -2.5300e-02,  6.8449...2, -3.3662e-03, -1.0163e-01,  3.9507e-02, -1.5665e-01,\n",
            "          -6.8779e-02, -1.3200e-01]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e321897cc20>\n",
            "model_     = LSTM(11, 12, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[-3.07018193e-03 -1.51785523e-01  2.79703597e-03  9.95477661e-02\n",
            "    1.29707074e-02 -1.00824527e-01 -2... -2.65942607e-02 -3.36619304e-03 -1.01625957e-01\n",
            "    3.95069420e-02 -1.56647265e-01 -6.87794834e-02 -1.31999850e-01]]])\n",
            "output_    = tensor([[[-3.0702e-03, -1.5179e-01,  2.7970e-03,  9.9548e-02,  1.2971e-02,\n",
            "          -1.0082e-01, -2.5300e-02,  6.8449...2e-03, -1.0163e-01,  3.9507e-02, -1.5665e-01,\n",
            "          -6.8779e-02, -1.3200e-01]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 2.44934723e-01, -1.21458936e+00,  6.77863777e-01,\n",
            "          3.35727483e-01,  2.03088835e-01,  9.59993422e-01...         1.05416048e+00, -9.55596045e-02, -1.10406347e-01,\n",
            "          2.55326778e-01, -1.04525375e+00]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32016b49a0>, array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00...875e-02,  2.76347041e-01,  5.92636652e-02,\n",
            "        -3.39712441e-01,  5.65743983e-01, -2.85228919e-02]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 429 / 528 (81.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 9.398554\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 829.29156\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00,  0.000000e+00, -3.873421e-01, -3.948601e-01,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    4.861116e-01,  0.000000e+00,  0.000000e+00,  0.000000e+00,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-4.670289e-01,  4.254104e-01, -6.662260e-01, -7.464555e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    3.649772e-02, -9.256987e-02, -1.745326e-01, -5.850688e-01,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.692850e-01,  3.281918e-01, -5.248194e-01,  3.285327e-01,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32016b49a0>, array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00...875e-02,  2.76347041e-01,  5.92636652e-02,\n",
            "        -3.39712441e-01,  5.65743983e-01, -2.85228919e-02]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m__________________ test_lstm[cuda-False-False-12-11-15-1-13] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 0.35504907 -0.00521652 -0.05768154 -0.10526732 -0.21250147\n",
            "   -0.00884639 -0.36652473 -0.37790892  0...3 -0.20032261 -0.12467161\n",
            "    0.04790417  0.17301375 -0.07599732 -0.02787573 -0.02971128\n",
            "    0.01255818 -0.23163556]]])\n",
            "c0         = array([[[-1.20683062e+00, -1.79124928e+00,  1.00222850e+00,\n",
            "          8.21182251e-01, -5.12118518e-01,  7.67726541e-01...,  7.33301699e-01, -6.62287295e-01,\n",
            "          1.29186022e+00,  9.18141127e-01,  1.88571966e+00]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 0.3550, -0.0052, -0.0577, -0.1053, -0.2125, -0.0088, -0.3665,\n",
            "          -0.3779,  0.4638,  0.2792, -0.4806,..., -0.1247,  0.0479,  0.1730,\n",
            "          -0.0760, -0.0279, -0.0297,  0.0126, -0.2316]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 0.15548456 -0.00266051 -0.02533491 -0.06250545 -0.11172714\n",
            "   -0.00501913 -0.19422652 -0.20786047  0...2 -0.06828944 -0.05912838\n",
            "    0.02442962  0.08223837 -0.03952033 -0.01060113 -0.01852464\n",
            "    0.00570348 -0.11398599]]])\n",
            "h0         = array([[[ 0.43234736,  1.1997933 ,  0.98080164, -0.01609142,\n",
            "          1.624162  , -0.15787955,  1.7431118 , -2.893513...276499 , -0.78516454, -0.07334998,\n",
            "         -1.3807831 , -0.32598993,  0.15097256,  1.220226  ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 0.1555, -0.0027, -0.0253, -0.0625, -0.1117, -0.0050, -0.1942,\n",
            "          -0.2079,  0.2714,  0.0944, -0.2101,..., -0.0591,  0.0244,  0.0822,\n",
            "          -0.0395, -0.0106, -0.0185,  0.0057, -0.1140]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32161ff680>\n",
            "model_     = LSTM(11, 12, bias=False)\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[ 0.0506708   0.08564103  0.12489627 ... -0.04042862 -0.20489338\n",
            "   -0.00466586]\n",
            "  [ 0.02575246 -0.163...48259  0.06342419\n",
            "   -0.02564167]\n",
            "  [-0.06356201  0.19708696  0.03907632 ... -0.01852464  0.00570348\n",
            "   -0.11398599]]])\n",
            "output_    = tensor([[[ 0.0507,  0.0856,  0.1249,  ..., -0.0404, -0.2049, -0.0047],\n",
            "         [ 0.0258, -0.1636,  0.0223,  ...,  0.0...56],\n",
            "         [-0.0636,  0.1971,  0.0391,  ..., -0.0185,  0.0057, -0.1140]]],\n",
            "       grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-1.59384263e+00,  7.95496166e-01, -1.06609643e+00, ...,\n",
            "          2.44756505e-01, -1.17292845e+00, -8.8156008...79798269e+00, -5.87329030e-01, ...,\n",
            "         -5.53797424e-01,  5.76991737e-01, -3.86751086e-01]]],\n",
            "      dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...178e+00,  1.42798448e+00, -9.64631379e-01,\n",
            "         1.69786143e+00, -9.25619677e-02,  4.70399523e+00]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 528 / 528 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 58.02474\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 202.16484\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00,  0.000000e+00, -1.143297e+01,  1.010216e+01,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -1.262752e+01,  0.000000e+00,  0.000000e+00,  0.000000e+00,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 6.293366e-01, -8.653004e+00,  2.648816e+00, -3.163158e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -8.060991e+00, -6.014734e+00,  9.970508e+00,  3.042836e-01,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    5.887207e+00,  7.570674e+00,  6.473830e+00,  3.954287e+00,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32162ff420>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...178e+00,  1.42798448e+00, -9.64631379e-01,\n",
            "         1.69786143e+00, -9.25619677e-02,  4.70399523e+00]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m___________________ test_lstm[cuda-False-False-12-11-15-2-1] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[ 4.97899204e-02  4.45739888e-02  2.64929622e-01  1.79305933e-02\n",
            "    2.16475859e-01 -1.83788270e-01  1... -7.65838369e-04  2.16754600e-02 -7.33997375e-02\n",
            "   -6.73291013e-02  2.56490819e-02 -2.22774763e-02  1.68073326e-02]]])\n",
            "c0         = array([[[-0.7756831 ,  0.4879507 , -2.0050743 , -1.2938912 ,\n",
            "          0.27797014,  1.3588866 ,  0.4252549 ,  0.123398...9670264, -0.551329  ,  0.7130748 ,\n",
            "          0.41843006, -0.7325117 , -1.4167105 , -1.4657667 ]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[ 4.9790e-02,  4.4574e-02,  2.6493e-01,  1.7931e-02,  2.1648e-01,\n",
            "          -1.8379e-01,  1.1460e-02,  1.0686...4,  2.1675e-02, -7.3400e-02, -6.7329e-02,  2.5649e-02,\n",
            "          -2.2277e-02,  1.6807e-02]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[ 2.70775277e-02  2.60119494e-02  1.46963328e-01  1.22081768e-02\n",
            "    1.04370117e-01 -1.04169719e-01  5... -3.79214587e-04  1.05329202e-02 -3.67407650e-02\n",
            "   -3.44343297e-02  1.37570957e-02 -1.10148955e-02  8.22172128e-03]]])\n",
            "h0         = array([[[-2.1997871e-01,  2.0979477e-01, -4.1206697e-01,  7.9390270e-01,\n",
            "          1.6041462e+00,  5.9153205e-01, -4.9...1e-01,  2.2114946e-01,\n",
            "          1.0071075e-01, -1.2307869e+00, -2.7416080e-01, -7.7629721e-01]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[ 2.7078e-02,  2.6012e-02,  1.4696e-01,  1.2208e-02,  1.0437e-01,\n",
            "          -1.0417e-01,  5.4503e-03,  6.6453...4,  1.0533e-02, -3.6741e-02, -3.4434e-02,  1.3757e-02,\n",
            "          -1.1015e-02,  8.2217e-03]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e3218bae390>\n",
            "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[ 0.00646803 -0.00132548 -0.01932332 -0.00690827 -0.02851981\n",
            "   -0.0098289  -0.00262829  0.02547442  0...23 -0.02331466  0.00700946\n",
            "   -0.00037921  0.01053292 -0.03674076 -0.03443433  0.0137571\n",
            "   -0.0110149   0.00822172]]])\n",
            "output_    = tensor([[[ 0.0065, -0.0013, -0.0193, -0.0069, -0.0285, -0.0098, -0.0026,\n",
            "           0.0255,  0.0112,  0.0031,  0.0197,..., -0.0004,  0.0105,\n",
            "          -0.0367, -0.0344,  0.0138, -0.0110,  0.0082]]],\n",
            "       grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 0.56045353, -0.16640641, -0.64860016, -1.1532604 ,\n",
            "         -0.33945698, -0.97177136, -1.1901674 , -1.050458...   0.75940704, -1.1607738 , -1.054326  ,  0.27760512,\n",
            "         -0.28504765,  0.19725206, -0.33256018]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32016b4220>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...937e-02,  4.04060669e-02,  2.06004526e-03,\n",
            "        -3.60194072e-02, -4.02086368e-03,  1.00619979e-02]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 429 / 528 (81.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 1.6275346\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 887.62726\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00,  0.000000e+00, -5.831198e-02,  8.600432e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.543051e-01,  0.000000e+00,  0.000000e+00,  0.000000e+00,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[ 2.977993e-02,  2.489806e-02, -2.545617e-02,  1.372671e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    2.273202e-02, -3.623927e-03, -2.349531e-02,  4.753293e-02,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -6.026372e-04, -9.690054e-02, -1.370423e-02,  2.228362e-02,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32016b4220>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...937e-02,  4.04060669e-02,  2.06004526e-03,\n",
            "        -3.60194072e-02, -4.02086368e-03,  1.00619979e-02]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[31m\u001b[1m__________________ test_lstm[cuda-False-False-12-11-15-2-13] ___________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
            "hidden_size = 12, bias = False, init_hidden = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(c_.detach().numpy(), c.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        output.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "        output_.sum().backward()\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(model.lstm_cells[\u001b[94m0\u001b[39;49;00m].W_ih.grad.detach().numpy(), model_.weight_ih_l0.grad.numpy().transpose(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = False\n",
            "c          = needle.Tensor([[[-1.40688062e-01 -1.47967726e-01 -1.79024130e-01 -2.50852406e-01\n",
            "   -1.08171999e-03  6.98700845e-02 -3...  1.41299143e-01 -4.08759229e-02 -1.52309105e-01\n",
            "    7.87626952e-02 -1.68108586e-02 -2.09239945e-02  5.75327314e-03]]])\n",
            "c0         = array([[[-1.1739507 ,  0.16776769, -0.39855134,  0.07401069,\n",
            "         -1.5828049 ,  0.04162287,  2.33517   , -0.576201...293487 , -0.6400922 ,  0.2152001 ,\n",
            "          0.15897496, -0.31589383, -1.1194615 ,  0.26298866]]],\n",
            "      dtype=float32)\n",
            "c_         = tensor([[[-1.4069e-01, -1.4797e-01, -1.7902e-01, -2.5085e-01, -1.0817e-03,\n",
            "           6.9870e-02, -3.2634e-02,  6.5603...1, -4.0876e-02, -1.5231e-01,  7.8763e-02, -1.6811e-02,\n",
            "          -2.0924e-02,  5.7533e-03]]], grad_fn=<StackBackward0>)\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[-5.64900823e-02 -8.09256658e-02 -8.34929943e-02 -1.14693038e-01\n",
            "   -4.48242499e-04  4.16014120e-02 -1...  7.35375583e-02 -2.11718492e-02 -7.97596425e-02\n",
            "    3.83907482e-02 -8.90105776e-03 -1.07936189e-02  2.75020581e-03]]])\n",
            "h0         = array([[[ 2.63340831e+00,  2.27567816e+00,  4.17235196e-01,\n",
            "         -2.16966256e-01,  1.00705534e-01, -1.94403541e+00..., -3.58766317e-02, -1.26866603e+00,\n",
            "          2.58771718e-01, -3.68971378e-02,  1.23212361e+00]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[-5.6490e-02, -8.0926e-02, -8.3493e-02, -1.1469e-01, -4.4824e-04,\n",
            "           4.1601e-02, -1.7154e-02,  3.0936...2, -2.1172e-02, -7.9760e-02,  3.8391e-02, -8.9011e-03,\n",
            "          -1.0794e-02,  2.7502e-03]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.LSTM object at 0x7e32163d29c0>\n",
            "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[-1.06564527e-02 -3.02663613e-02 -4.19388572e-03 ...  1.46344153e-03\n",
            "   -1.08513441e-02 -2.07909457e-0...0871e-02]\n",
            "  [ 2.43849121e-02 -7.83900451e-03  3.66092846e-02 ... -8.90105776e-03\n",
            "   -1.07936189e-02  2.75020581e-03]]])\n",
            "output_    = tensor([[[-1.0656e-02, -3.0266e-02, -4.1939e-03,  ...,  1.4634e-03,\n",
            "          -1.0851e-02, -2.0791e-02],\n",
            "         [ 5.... -7.8390e-03,  3.6609e-02,  ..., -8.9011e-03,\n",
            "          -1.0794e-02,  2.7502e-03]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-0.6615442 , -1.9768552 ,  0.671461  , ...,  0.5404096 ,\n",
            "          0.24552427, -2.0281434 ],\n",
            "        [ 1.4809...\n",
            "        [-0.9602228 , -1.9513258 , -0.98804134, ...,  0.5886315 ,\n",
            "         -1.3769804 , -0.18807463]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:179: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7e32016b42c0>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...565e-01,  6.03039451e-02, -1.03187785e-02,\n",
            "         4.64133263e-01, -1.55352667e-01,  4.03424501e-01]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 528 / 528 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference among violations: 10.259132\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference among violations: 16057.793\u001b[0m\n",
            "\u001b[1m\u001b[31mE            ACTUAL: array([[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00,  0.000000e+00,  7.351310e+00,  5.591442e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   -1.428802e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            DESIRED: array([[-4.487490e-01, -1.398621e-01,  7.724704e-01, -2.385779e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    3.686748e-01,  1.610572e+00,  2.722259e+00, -7.262863e-01,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.169207e-01, -2.512293e-01,  1.674640e+00,  3.027901e-01,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7e32016b42c0>, array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e...565e-01,  6.03039451e-02, -1.03187785e-02,\n",
            "         4.64133263e-01, -1.55352667e-01,  4.03424501e-01]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7e32187999e0>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'strict': False, ...}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7e32187babd0>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-False-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-False-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-False-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-False-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-False-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-False-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-False-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-True-False-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-False-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-False-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-False-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-False-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-False-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-False-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-False-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cpu-False-False-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-False-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-False-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-False-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-False-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-False-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-False-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-False-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-True-False-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-False-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-False-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-False-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-False-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-False-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-False-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-False-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm_cell[cuda-False-False-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-True-False-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cpu-False-False-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-True-False-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_lstm[cuda-False-False-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31m==================== \u001b[31m\u001b[1m320 failed\u001b[0m, \u001b[33m1483 deselected\u001b[0m\u001b[31m in 38.65s\u001b[0m\u001b[31m =====================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"test_lstm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "gGn16F-dnJnr",
        "outputId": "6a2e6bc7-d015-4ec8-9952-c683d975a2b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_sequence_models.py \n",
            "Submitting lstm...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 failed\n",
            "Grader test 5 passed\n",
            "Grader test 6 passed\n",
            "Grader test 7 passed\n",
            "Grader test 8 failed\n",
            "Grader test 9 passed\n",
            "Grader test 10 passed\n",
            "Grader test 11 passed\n",
            "Grader test 12 failed\n",
            "Grader test 13 passed\n",
            "Grader test 14 passed\n",
            "Grader test 15 passed\n",
            "Grader test 16 failed\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_________________________________ submit_lstm __________________________________\u001b[0m\n",
            "\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1msubmit_lstm\u001b[0m - Failed\n",
            "\u001b[31m================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 9.53s\u001b[0m\u001b[31m ==================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"lstm\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFAqotmInJnr"
      },
      "source": [
        "## Part 6: Penn Treebank dataset [10 points]\n",
        "\n",
        "In word-level language modeling tasks, the model predicts the probability of the next word in the sequence, based on the words already observed in the sequence. You will write support for the Penn Treebank dataset, which consists of stories from the Wall Street Journal, to train and evaluate a language model on word-level prediction.\n",
        "\n",
        "In `python/needle/data/datasets/ptb_dataset.py`, start by implementing the `Dictionary` class, which creates a dictionary from a list of words, mapping each word to a unique integer.\n",
        "\n",
        "Next, we will use this `Dictionary` class to create a corpus from the train and test txt files in the Penn Treebank dataset that you downloaded at the beginning of the notebook. Implement the `tokenize` function in the `Corpus` class to do this.\n",
        "\n",
        "In order to prepare the data for training and evaluation, you will next implement the `batchify` function. Starting from sequential data, batchify arranges the dataset into columns. For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "\n",
        "```\n",
        " a g m s \n",
        " b h n t \n",
        " c i o u \n",
        " d j p v \n",
        " e k q w \n",
        " f l r x \n",
        "```\n",
        "\n",
        "These columns are treated as independent by the model, which means that the dependence of e. g. 'g' on 'f' cannot be learned, but allows more efficient batch processing.\n",
        "\n",
        "Next, implement the `get_batch` function. `get_batch` subdivides the source data into chunks of length `bptt`. If source is equal to the example output of the batchify function, with a bptt-limit of 2, we'd get the following two `Tensor`s for i = 0:\n",
        "```\n",
        " a g m s   b h n t \n",
        " b h n t   c i o u \n",
        "```\n",
        "Note that despite the name of the function, the subdivison of data is not done along the batch dimension (i.e. dimension 1), since that was handled by the batchify function. The chunks are along dimension 0, corresponding to the seq_len dimension in the LSTM or RNN. Also, as per the function docs, the second returned `Tensor` (the targets) should be reshaped to be 1-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "Z9J8txKFnJnr",
        "outputId": "5943306d-4da8-40fc-c777-9971a345242b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1777 deselected / 26 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[True] \u001b[32mPASSED\u001b[0m\u001b[32m      [  3%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[False] \u001b[32mPASSED\u001b[0m\u001b[32m     [  7%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 42%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m===================== \u001b[32m\u001b[1m26 passed\u001b[0m, \u001b[33m1777 deselected\u001b[0m\u001b[32m in 13.44s\u001b[0m\u001b[32m =====================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"ptb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "2_CcoqwgnJnr",
        "outputId": "c645f546-6ed1-4515-c10f-4fedf8326bb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 8 deselected / 2 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_cifar_ptb_data.py \n",
            "Submitting cifar10...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 passed\n",
            "Grader test 5 passed\n",
            "Grader test 6 passed\n",
            "Grader test 7 passed\n",
            "Grader test 8 passed\n",
            "Grader test 9 passed\n",
            "Grader test 10 passed\n",
            "Grader test 11 passed\n",
            "Grader test 12 passed\n",
            "Grader test 13 passed\n",
            "Grader test 14 passed\n",
            "Grader test 15 passed\n",
            "Grader test 16 passed\n",
            "Grader test 17 passed\n",
            "Grader test 18 passed\n",
            "\u001b[32m.\u001b[0m\n",
            "Submitting ptb...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 passed\n",
            "Grader test 5 passed\n",
            "Grader test 6 passed\n",
            "Grader test 7 passed\n",
            "Grader test 8 passed\n",
            "Grader test 9 passed\n",
            "Grader test 10 passed\n",
            "Grader test 11 passed\n",
            "Grader test 12 passed\n",
            "Grader test 13 passed\n",
            "Grader test 14 passed\n",
            "Grader test 15 passed\n",
            "Grader test 16 passed\n",
            "Grader test 17 passed\n",
            "Grader test 18 passed\n",
            "Grader test 19 passed\n",
            "Grader test 20 passed\n",
            "Grader test 21 passed\n",
            "Grader test 22 passed\n",
            "Grader test 23 passed\n",
            "Grader test 24 passed\n",
            "Grader test 25 passed\n",
            "Grader test 26 passed\n",
            "Grader test 27 passed\n",
            "Grader test 28 passed\n",
            "Grader test 29 passed\n",
            "Grader test 30 passed\n",
            "Grader test 31 passed\n",
            "Grader test 32 passed\n",
            "Error : {\"status\":\"error\",\"code\":502,\"message\":\"Application failed to respond\",\"request_id\":\"NCwuPUjZREWoUCRAAQeqjw\"}\n",
            "Grader test 34 passed\n",
            "Grader test 35 passed\n",
            "Grader test 36 passed\n",
            "Grader test 37 passed\n",
            "Grader test 38 passed\n",
            "Grader test 39 passed\n",
            "Grader test 40 passed\n",
            "Grader test 41 passed\n",
            "Grader test 42 passed\n",
            "Grader test 43 passed\n",
            "Grader test 44 passed\n",
            "Grader test 45 passed\n",
            "Grader test 46 passed\n",
            "Grader test 47 passed\n",
            "Grader test 48 passed\n",
            "Grader test 49 passed\n",
            "\u001b[32m.\u001b[0m\n",
            "\n",
            "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m8 deselected\u001b[0m\u001b[32m in 27.94s\u001b[0m\u001b[32m =======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"ptb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNn-9ELznJnr"
      },
      "source": [
        "## Part 7: Training a word-level language model [10 points]\n",
        "\n",
        "Finally, you will use the `RNN` and `LSTM` components you have written to construct a language model that we will train on the Penn Treebank dataset.\n",
        "\n",
        "First, in `python/needle/nn/nn_sequence.py` implement `Embedding`. Consider we have a dictionary with 1000 words. Then for a word which indexes into this dictionary, we can represent this word as a one-hot vector of size 1000, and then use a linear layer to project this to a vector of some embedding size.\n",
        "\n",
        "In `apps/models.py`, you can now implement `LanguageModel`. Your language model should consist of\n",
        "\n",
        "- An embedding layer (which maps word IDs to embeddings)\n",
        "- A sequence model (either RNN or LSTM)\n",
        "- A linear layer (which outputs probabilities of the next word)\n",
        "\n",
        "In `apps/simple_ml.py` implement `epoch_general_ptb`, `train_ptb`, and `evaluate_ptb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "ycI_16XDnJnr",
        "outputId": "5bbafa11-93b0-4e56-b531-790f724cdcaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1291 deselected / 512 selected                          \u001b[0m\n",
            "\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m==================== \u001b[32m\u001b[1m512 passed\u001b[0m, \u001b[33m1291 deselected\u001b[0m\u001b[32m in 29.63s\u001b[0m\u001b[32m =====================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"language_model_implementation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "rauG3HZMnJnr",
        "outputId": "fde6bf5a-5399-4738-ec6f-064cda01eefc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\n",
            "\n",
            "tests/hw4/test_sequence_models.py::test_language_model_training[cpu] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::test_language_model_training[cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m______________________ test_language_model_training[cpu] _______________________\u001b[0m\n",
            "\n",
            "device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_language_model_training\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        corpus = ndl.data.Corpus(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/ptb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, max_lines=\u001b[94m20\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        seq_len = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        num_examples = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        batch_size = \u001b[94m16\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        seq_model = \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        num_layers = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        hidden_size = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_epochs=\u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        train_data = ndl.data.batchify(corpus.train, batch_size=batch_size, device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        model = LanguageModel(\u001b[94m30\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(corpus.dictionary), hidden_size=hidden_size, num_layers=num_layers, seq_model=seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       train_acc, train_loss = train_ptb(model, train_data, seq_len=seq_len, n_epochs=n_epochs, device=device)\u001b[90m\u001b[39;49;00m\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 16\n",
            "corpus     = <needle.data.datasets.ptb_dataset.Corpus object at 0x788c2fcbf230>\n",
            "device     = cpu()\n",
            "hidden_size = 10\n",
            "model      = <models.LanguageModel object at 0x788c2fd22870>\n",
            "n_epochs   = 2\n",
            "num_examples = 100\n",
            "num_layers = 2\n",
            "seq_len    = 10\n",
            "seq_model  = 'rnn'\n",
            "train_data = array([[  0.,  26.,  24.,  60.,  79.,  91., 108., 120., 131., 147., 158.,\n",
            "        165., 181.,  87., 197.,  26.],\n",
            "     ...25.,  46.,  35.,  78.,  78.,  26., 101., 130.,  26., 157.,  73.,\n",
            "        180., 105.,  32., 206., 148.]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:236: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mapps/simple_ml.py\u001b[0m:419: in train_ptb\n",
            "    \u001b[0mavg_acc, avg_loss = epoch_general_ptb(data, model, seq_len=seq_len,\u001b[90m\u001b[39;49;00m\n",
            "        clip       = None\n",
            "        data       = array([[  0.,  26.,  24.,  60.,  79.,  91., 108., 120., 131., 147., 158.,\n",
            "        165., 181.,  87., 197.,  26.],\n",
            "     ...25.,  46.,  35.,  78.,  78.,  26., 101., 130.,  26., 157.,  73.,\n",
            "        180., 105.,  32., 206., 148.]], dtype=float32)\n",
            "        device     = cpu()\n",
            "        dtype      = 'float32'\n",
            "        epoch      = 0\n",
            "        loss_fn    = <class 'needle.nn.nn_basic.SoftmaxLoss'>\n",
            "        loss_fn_instance = <needle.nn.nn_basic.SoftmaxLoss object at 0x788c30397260>\n",
            "        lr         = 4.0\n",
            "        model      = <models.LanguageModel object at 0x788c2fd22870>\n",
            "        n_epochs   = 2\n",
            "        opt        = <needle.optim.SGD object at 0x788c2fcd5520>\n",
            "        optimizer  = <class 'needle.optim.SGD'>\n",
            "        seq_len    = 10\n",
            "        weight_decay = 0.0\n",
            "\u001b[1m\u001b[31mapps/simple_ml.py\u001b[0m:371: in epoch_general_ptb\n",
            "    \u001b[0mopt.step()\u001b[90m\u001b[39;49;00m\n",
            "        batch_data = needle.Tensor([[  0.  26.  24.  60.  79.  91. 108. 120. 131. 147. 158. 165. 181.  87.\n",
            "  197.  26.]\n",
            " [  1.  27.  47.  4... 42.  48. 184.  24.\n",
            "   76.  80.]\n",
            " [  9.  35.  42.  68.  61.  24. 111. 101.  61.  42. 164. 164.  87.  75.\n",
            "  154. 197.]])\n",
            "        batch_target = needle.Tensor([  1.  27.  47.  42.  80.  92. 109. 121. 132.  32. 159.  48.  32.  32.\n",
            " 198. 207.   2.  28.  26.  61.  2...  42. 164. 164.\n",
            "  87.  75. 154. 197.  10.  36.  50.  69.  84.  26. 112. 126. 137. 138.\n",
            " 119. 174.  35.  27.  26.  32.])\n",
            "        clip       = None\n",
            "        correct    = np.int64(0)\n",
            "        data       = array([[  0.,  26.,  24.,  60.,  79.,  91., 108., 120., 131., 147., 158.,\n",
            "        165., 181.,  87., 197.,  26.],\n",
            "     ...25.,  46.,  35.,  78.,  78.,  26., 101., 130.,  26., 157.,  73.,\n",
            "        180., 105.,  32., 206., 148.]], dtype=float32)\n",
            "        device     = cpu()\n",
            "        dtype      = 'float32'\n",
            "        get_batch  = <function get_batch at 0x788d21bc6980>\n",
            "        h          = needle.Tensor([[[-4.56607461e-01 -8.85777831e-01  6.46062732e-01 -7.33713448e-01\n",
            "    6.13177240e-01 -7.42687225e-01  9....78409123e-01\n",
            "    5.05340338e-01 -2.31776997e-01 -6.65940464e-01  7.56043553e-01\n",
            "    5.72099507e-01 -4.74694282e-01]]])\n",
            "        i          = 0\n",
            "        loss       = needle.Tensor([6.090632])\n",
            "        loss_fn    = <needle.nn.nn_basic.SoftmaxLoss object at 0x788c30397260>\n",
            "        model      = <models.LanguageModel object at 0x788c2fd22870>\n",
            "        nbatch     = 26\n",
            "        opt        = <needle.optim.SGD object at 0x788c2fcd5520>\n",
            "        output     = needle.Tensor([[-3.9629281e-01  5.4703140e-01 -5.8157754e-01 ... -1.7925632e-01\n",
            "   1.6539544e-04  1.9283330e+00]\n",
            " [ 3....01  9.5480520e-01]\n",
            " [ 4.0743902e-02  1.1177673e+00 -1.0004728e+00 ... -2.7178800e-01\n",
            "   9.8603296e-01  9.5902842e-01]])\n",
            "        pred       = array([353, 330,  21, 360,  52,  52, 377, 352, 320, 330, 330, 143,  10,\n",
            "       353, 248, 330, 364, 347, 311, 130, 130,... 69,  90,  21,  52,\n",
            "       180, 353, 267, 364, 364,  52, 161, 258, 377, 347, 248, 353, 143,\n",
            "       353, 364, 137, 364])\n",
            "        seq_len    = 10\n",
            "        total_correct = np.int64(0)\n",
            "        total_loss = 0.0\n",
            "        total_tokens = 160\n",
            "\u001b[1m\u001b[31mpython/needle/optim.py\u001b[0m:80: in step\n",
            "    \u001b[0mnew_data = p.detach().realize_cached_data() - \u001b[96mself\u001b[39;49;00m.lr * update\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        g          = needle.Tensor([[-2.53279246e-02  2.02078428e-02 -2.34867614e-02  2.14989502e-02\n",
            "   1.32262781e-02 -9.91850393e-04  2.9... -2.25716513e-02\n",
            "  -6.52786111e-03 -3.80765251e-03 -3.07367109e-02 -1.38791986e-02\n",
            "  -9.45260003e-03 -1.44784804e-04]])\n",
            "        g_data     = NDArray([[-2.53279246e-02  2.02078428e-02 -2.34867614e-02  2.14989502e-02\n",
            "   1.32262781e-02 -9.91850393e-04  2.9737543...02\n",
            "  -6.52786111e-03 -3.80765251e-03 -3.07367109e-02 -1.38791986e-02\n",
            "  -9.45260003e-03 -1.44784804e-04]], device=cpu())\n",
            "        new_data   = NDArray([-0.29716673  0.20466769 -0.06600116  0.38485628 -0.23425078  0.07398975\n",
            " -0.16973777 -0.32125783 -0.44175518 -0.20587912], device=cpu())\n",
            "        p          = needle.Tensor([[-0.18640713  0.16170883 -0.09447562 -0.09710888  0.25559562 -0.02303306\n",
            "  -0.25616714  0.1491436  -0.4...5963525 -0.23728809  0.28115067  0.21942562  0.11859175  0.0885192\n",
            "   0.16139694  0.13963796  0.26058596  0.01179831]])\n",
            "        self       = <needle.optim.SGD object at 0x788c2fcd5520>\n",
            "        update     = NDArray([[-2.53279246e-02  2.02078428e-02 -2.34867614e-02  2.14989502e-02\n",
            "   1.32262781e-02 -9.91850393e-04  2.9737543...02\n",
            "  -6.52786111e-03 -3.80765251e-03 -3.07367109e-02 -1.38791986e-02\n",
            "  -9.45260003e-03 -1.44784804e-04]], device=cpu())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:526: in __sub__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m + (-other)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        other      = NDArray([[-0.1013117   0.08083137 -0.09394705  0.0859958   0.05290511 -0.0039674\n",
            "   0.11895017  0.1069333   0.15185139...6105  0.00522423 -0.09028661 -0.02611144 -0.01523061\n",
            "  -0.12294684 -0.05551679 -0.0378104  -0.00057914]], device=cpu())\n",
            "        self       = NDArray([[-0.18640713  0.16170883 -0.09447562 -0.09710888  0.25559562 -0.02303306\n",
            "  -0.25616714  0.1491436  -0.4207928... 0.28115067  0.21942562  0.11859175  0.0885192\n",
            "   0.16139694  0.13963796  0.26058596  0.01179831]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:519: in __add__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.ewise_or_scalar(\u001b[90m\u001b[39;49;00m\n",
            "        other      = NDArray([[ 0.1013117  -0.08083137  0.09394705 -0.0859958  -0.05290511  0.0039674\n",
            "  -0.11895017 -0.1069333  -0.15185139...6105 -0.00522423  0.09028661  0.02611144  0.01523061\n",
            "   0.12294684  0.05551679  0.0378104   0.00057914]], device=cpu())\n",
            "        self       = NDArray([[-0.18640713  0.16170883 -0.09447562 -0.09710888  0.25559562 -0.02303306\n",
            "  -0.25616714  0.1491436  -0.4207928... 0.28115067  0.21942562  0.11859175  0.0885192\n",
            "   0.16139694  0.13963796  0.26058596  0.01179831]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:513: in ewise_or_scalar\n",
            "    \u001b[0mewise_func(\u001b[96mself\u001b[39;49;00m.compact()._handle, other.compact()._handle, out._handle)\u001b[90m\u001b[39;49;00m\n",
            "        ewise_func = <function ewise_add at 0x788d21b77560>\n",
            "        other      = NDArray([[ 0.1013117  -0.08083137  0.09394705 -0.0859958  -0.05290511  0.0039674\n",
            "  -0.11895017 -0.1069333  -0.15185139...6105 -0.00522423  0.09028661  0.02611144  0.01523061\n",
            "   0.12294684  0.05551679  0.0378104   0.00057914]], device=cpu())\n",
            "        out        = NDArray([[ 1.30661812e-14  4.32454719e-41  1.30661812e-14  4.32454719e-41\n",
            "   4.60152933e-07  0.00000000e+00  4.6015293...1.18591748e-01  8.85192007e-02  1.61396936e-01  1.39637962e-01\n",
            "   2.60585964e-01  1.17983129e-02]], device=cpu_numpy())\n",
            "        scalar_func = <function scalar_add at 0x788d21b77600>\n",
            "        self       = NDArray([[-0.18640713  0.16170883 -0.09447562 -0.09710888  0.25559562 -0.02303306\n",
            "  -0.25616714  0.1491436  -0.4207928... 0.28115067  0.21942562  0.11859175  0.0885192\n",
            "   0.16139694  0.13963796  0.26058596  0.01179831]], device=cpu_numpy())\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "a = <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x788c2f0098b0>\n",
            "b = <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x788c2eaf74f0>\n",
            "out = <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x788c2f009ac0>\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mewise_add\u001b[39;49;00m(a, b, out):\u001b[90m\u001b[39;49;00m\n",
            ">       out.array[:] = a.array + b.array\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'needle.backend_ndarray.ndarray_backend_cpu.Array' object has no attribute 'array'\u001b[0m\n",
            "\n",
            "a          = <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x788c2f0098b0>\n",
            "b          = <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x788c2eaf74f0>\n",
            "out        = <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x788c2f009ac0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray_backend_numpy.py\u001b[0m:45: AttributeError\n",
            "\u001b[31m\u001b[1m______________________ test_language_model_training[cuda] ______________________\u001b[0m\n",
            "\n",
            "device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_language_model_training\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        corpus = ndl.data.Corpus(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/ptb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, max_lines=\u001b[94m20\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        seq_len = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        num_examples = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        batch_size = \u001b[94m16\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        seq_model = \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        num_layers = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        hidden_size = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_epochs=\u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        train_data = ndl.data.batchify(corpus.train, batch_size=batch_size, device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        model = LanguageModel(\u001b[94m30\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(corpus.dictionary), hidden_size=hidden_size, num_layers=num_layers, seq_model=seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       train_acc, train_loss = train_ptb(model, train_data, seq_len=seq_len, n_epochs=n_epochs, device=device)\u001b[90m\u001b[39;49;00m\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 16\n",
            "corpus     = <needle.data.datasets.ptb_dataset.Corpus object at 0x788c2fc4ef00>\n",
            "device     = cuda()\n",
            "hidden_size = 10\n",
            "model      = <models.LanguageModel object at 0x788c2fd6d4c0>\n",
            "n_epochs   = 2\n",
            "num_examples = 100\n",
            "num_layers = 2\n",
            "seq_len    = 10\n",
            "seq_model  = 'rnn'\n",
            "train_data = array([[  0.,  26.,  24.,  60.,  79.,  91., 108., 120., 131., 147., 158.,\n",
            "        165., 181.,  87., 197.,  26.],\n",
            "     ...25.,  46.,  35.,  78.,  78.,  26., 101., 130.,  26., 157.,  73.,\n",
            "        180., 105.,  32., 206., 148.]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:236: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mapps/simple_ml.py\u001b[0m:419: in train_ptb\n",
            "    \u001b[0mavg_acc, avg_loss = epoch_general_ptb(data, model, seq_len=seq_len,\u001b[90m\u001b[39;49;00m\n",
            "        clip       = None\n",
            "        data       = array([[  0.,  26.,  24.,  60.,  79.,  91., 108., 120., 131., 147., 158.,\n",
            "        165., 181.,  87., 197.,  26.],\n",
            "     ...25.,  46.,  35.,  78.,  78.,  26., 101., 130.,  26., 157.,  73.,\n",
            "        180., 105.,  32., 206., 148.]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        epoch      = 0\n",
            "        loss_fn    = <class 'needle.nn.nn_basic.SoftmaxLoss'>\n",
            "        loss_fn_instance = <needle.nn.nn_basic.SoftmaxLoss object at 0x788c2f00b140>\n",
            "        lr         = 4.0\n",
            "        model      = <models.LanguageModel object at 0x788c2fd6d4c0>\n",
            "        n_epochs   = 2\n",
            "        opt        = <needle.optim.SGD object at 0x788c2f038fb0>\n",
            "        optimizer  = <class 'needle.optim.SGD'>\n",
            "        seq_len    = 10\n",
            "        weight_decay = 0.0\n",
            "\u001b[1m\u001b[31mapps/simple_ml.py\u001b[0m:371: in epoch_general_ptb\n",
            "    \u001b[0mopt.step()\u001b[90m\u001b[39;49;00m\n",
            "        batch_data = needle.Tensor([[  0.  26.  24.  60.  79.  91. 108. 120. 131. 147. 158. 165. 181.  87.\n",
            "  197.  26.]\n",
            " [  1.  27.  47.  4... 42.  48. 184.  24.\n",
            "   76.  80.]\n",
            " [  9.  35.  42.  68.  61.  24. 111. 101.  61.  42. 164. 164.  87.  75.\n",
            "  154. 197.]])\n",
            "        batch_target = needle.Tensor([  1.  27.  47.  42.  80.  92. 109. 121. 132.  32. 159.  48.  32.  32.\n",
            " 198. 207.   2.  28.  26.  61.  2...  42. 164. 164.\n",
            "  87.  75. 154. 197.  10.  36.  50.  69.  84.  26. 112. 126. 137. 138.\n",
            " 119. 174.  35.  27.  26.  32.])\n",
            "        clip       = None\n",
            "        correct    = np.int64(3)\n",
            "        data       = array([[  0.,  26.,  24.,  60.,  79.,  91., 108., 120., 131., 147., 158.,\n",
            "        165., 181.,  87., 197.,  26.],\n",
            "     ...25.,  46.,  35.,  78.,  78.,  26., 101., 130.,  26., 157.,  73.,\n",
            "        180., 105.,  32., 206., 148.]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        get_batch  = <function get_batch at 0x788d21bc6980>\n",
            "        h          = needle.Tensor([[[ 0.93954444  0.20421238  0.25114688  0.8068905   0.29606527\n",
            "   -0.2942163   0.66814303 -0.9311262   0...87703  0.49899358  0.46426335  0.16505556 -0.5810051\n",
            "    0.16867663  0.5350484  -0.09321939  0.31950545 -0.6196501 ]]])\n",
            "        i          = 0\n",
            "        loss       = needle.Tensor([6.0099034])\n",
            "        loss_fn    = <needle.nn.nn_basic.SoftmaxLoss object at 0x788c2f00b140>\n",
            "        model      = <models.LanguageModel object at 0x788c2fd6d4c0>\n",
            "        nbatch     = 26\n",
            "        opt        = <needle.optim.SGD object at 0x788c2f038fb0>\n",
            "        output     = needle.Tensor([[-0.5058068  -0.3128773   0.46892548 ...  0.89018583 -0.7612162\n",
            "  -0.6547351 ]\n",
            " [-0.00474732  0.1168506... 0.95127606 -0.5544533\n",
            "  -0.97292554]\n",
            " [-0.4677797   0.3908639   0.7631632  ...  0.01610792  0.2524526\n",
            "  -0.5985326 ]])\n",
            "        pred       = array([ 75, 177,  34, 272, 206,  34,  34, 165, 165,  24, 359,  32,  34,\n",
            "       271, 272, 177, 162, 162, 306, 162, 162,...162,  75, 294, 376,\n",
            "       162,   7, 162, 162, 162,   7, 299, 160, 162, 162, 165, 162,  75,\n",
            "       155, 162, 294, 272])\n",
            "        seq_len    = 10\n",
            "        total_correct = np.int64(3)\n",
            "        total_loss = 0.0\n",
            "        total_tokens = 160\n",
            "\u001b[1m\u001b[31mpython/needle/optim.py\u001b[0m:80: in step\n",
            "    \u001b[0mnew_data = p.detach().realize_cached_data() - \u001b[96mself\u001b[39;49;00m.lr * update\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        g          = needle.Tensor([[-2.60232482e-04 -1.41798519e-04  3.00793955e-03  6.36872370e-03\n",
            "  -2.37581134e-02 -2.44454835e-02  2.5... -7.16542825e-03\n",
            "  -2.07750127e-04 -1.57735590e-02  7.27740116e-04 -1.70236733e-02\n",
            "   2.18544179e-03 -1.66133754e-02]])\n",
            "        g_data     = NDArray([[-2.60232482e-04 -1.41798519e-04  3.00793955e-03  6.36872370e-03\n",
            "  -2.37581134e-02 -2.44454835e-02  2.5907801...3\n",
            "  -2.07750127e-04 -1.57735590e-02  7.27740116e-04 -1.70236733e-02\n",
            "   2.18544179e-03 -1.66133754e-02]], device=cuda())\n",
            "        new_data   = NDArray([ 0.02886724 -0.0561167  -0.0828234  -0.15901914 -0.4920621   0.01154834\n",
            "  0.23721752  0.43878528 -0.1224708  -0.09318885], device=cuda())\n",
            "        p          = needle.Tensor([[-1.07733034e-01 -4.32778932e-02 -6.08706102e-02 -2.28346765e-01\n",
            "  -1.72453582e-01  6.89588860e-02  6.7... -7.85946995e-02\n",
            "   1.62148565e-01  8.27369764e-02  1.77602157e-01  8.90957341e-02\n",
            "   3.52227986e-02  3.63892436e-01]])\n",
            "        self       = <needle.optim.SGD object at 0x788c2f038fb0>\n",
            "        update     = NDArray([[-2.60232482e-04 -1.41798519e-04  3.00793955e-03  6.36872370e-03\n",
            "  -2.37581134e-02 -2.44454835e-02  2.5907801...3\n",
            "  -2.07750127e-04 -1.57735590e-02  7.27740116e-04 -1.70236733e-02\n",
            "   2.18544179e-03 -1.66133754e-02]], device=cuda())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:526: in __sub__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m + (-other)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        other      = NDArray([[-1.04092993e-03 -5.67194074e-04  1.20317582e-02  2.54748948e-02\n",
            "  -9.50324535e-02 -9.77819338e-02  1.0363120...2\n",
            "  -8.31000507e-04 -6.30942360e-02  2.91096047e-03 -6.80946931e-02\n",
            "   8.74176715e-03 -6.64535016e-02]], device=cuda())\n",
            "        self       = NDArray([[-1.07733034e-01 -4.32778932e-02 -6.08706102e-02 -2.28346765e-01\n",
            "  -1.72453582e-01  6.89588860e-02  6.7645691...1.62148565e-01  8.27369764e-02  1.77602157e-01  8.90957341e-02\n",
            "   3.52227986e-02  3.63892436e-01]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:519: in __add__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.ewise_or_scalar(\u001b[90m\u001b[39;49;00m\n",
            "        other      = NDArray([[ 1.04092993e-03  5.67194074e-04 -1.20317582e-02 -2.54748948e-02\n",
            "   9.50324535e-02  9.77819338e-02 -1.0363120...2\n",
            "   8.31000507e-04  6.30942360e-02 -2.91096047e-03  6.80946931e-02\n",
            "  -8.74176715e-03  6.64535016e-02]], device=cuda())\n",
            "        self       = NDArray([[-1.07733034e-01 -4.32778932e-02 -6.08706102e-02 -2.28346765e-01\n",
            "  -1.72453582e-01  6.89588860e-02  6.7645691...1.62148565e-01  8.27369764e-02  1.77602157e-01  8.90957341e-02\n",
            "   3.52227986e-02  3.63892436e-01]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:513: in ewise_or_scalar\n",
            "    \u001b[0mewise_func(\u001b[96mself\u001b[39;49;00m.compact()._handle, other.compact()._handle, out._handle)\u001b[90m\u001b[39;49;00m\n",
            "        ewise_func = <function ewise_add at 0x788d21b77560>\n",
            "        other      = NDArray([[ 1.04092993e-03  5.67194074e-04 -1.20317582e-02 -2.54748948e-02\n",
            "   9.50324535e-02  9.77819338e-02 -1.0363120...2\n",
            "   8.31000507e-04  6.30942360e-02 -2.91096047e-03  6.80946931e-02\n",
            "  -8.74176715e-03  6.64535016e-02]], device=cuda())\n",
            "        out        = NDArray([[1.3066859e-14 4.3245472e-41 1.3066859e-14 4.3245472e-41 6.1527317e-06\n",
            "  0.0000000e+00 6.1527317e-06 0.000000...       nan           nan\n",
            "  1.6824262e-37           nan           nan 1.7044667e-37           nan]], device=cpu_numpy())\n",
            "        scalar_func = <function scalar_add at 0x788d21b77600>\n",
            "        self       = NDArray([[-1.07733034e-01 -4.32778932e-02 -6.08706102e-02 -2.28346765e-01\n",
            "  -1.72453582e-01  6.89588860e-02  6.7645691...1.62148565e-01  8.27369764e-02  1.77602157e-01  8.90957341e-02\n",
            "   3.52227986e-02  3.63892436e-01]], device=cpu_numpy())\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "a = <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x788c2f084e30>\n",
            "b = <needle.backend_ndarray.ndarray_backend_cuda.Array object at 0x788c2f0a26b0>\n",
            "out = <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x788c2f085100>\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mewise_add\u001b[39;49;00m(a, b, out):\u001b[90m\u001b[39;49;00m\n",
            ">       out.array[:] = a.array + b.array\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'needle.backend_ndarray.ndarray_backend_cuda.Array' object has no attribute 'array'\u001b[0m\n",
            "\n",
            "a          = <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x788c2f084e30>\n",
            "b          = <needle.backend_ndarray.ndarray_backend_cuda.Array object at 0x788c2f0a26b0>\n",
            "out        = <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x788c2f085100>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray_backend_numpy.py\u001b[0m:45: AttributeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_training[cpu]\u001b[0m - AttributeError: 'needle.backend_ndarray.ndarray_backend_cpu.Array' object h...\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_training[cuda]\u001b[0m - AttributeError: 'needle.backend_ndarray.ndarray_backend_cuda.Array' object ...\n",
            "\u001b[31m====================== \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[31m in 2.57s\u001b[0m\u001b[31m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"language_model_training\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "PWWWCYecnJnr",
        "outputId": "f77d735d-72a4-43d6-d11f-0fcc35cd5468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.42\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_sequence_models.py \n",
            "Submitting language_model...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 passed\n",
            "Grader test 5 passed\n",
            "Grader test 6 passed\n",
            "Grader test 7 passed\n",
            "Grader test 8 passed\n",
            "Grader test 9 passed\n",
            "Grader test 10 passed\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m____________________________ submit_language_model _____________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_language_model\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "        devices = [ndl.cpu(), ndl.cuda()] \u001b[94mif\u001b[39;49;00m ndl.cuda().enabled() \u001b[94melse\u001b[39;49;00m [ndl.cpu()]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# devices = [ndl.cpu(), ndl.cuda()]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m ndl.cuda().enabled():\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mYou need a GPU to run some of these tests.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m (device, seq_length, num_layers, batch_size, embedding_size, hidden_size, seq_model, output_size) \u001b[95min\u001b[39;49;00m itertools.product(\u001b[90m\u001b[39;49;00m\n",
            "            devices, TEST_SEQ_LENGTHS, TEST_NUM_LAYERS, TEST_BATCH_SIZES, TEST_EMBEDDING_SIZES, TEST_HIDDEN_SIZES, TEST_SEQ_MODEL, TEST_OUTPUT_SIZES):\u001b[90m\u001b[39;49;00m\n",
            "            x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "            h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                h = (h0, c0)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                h = h0\u001b[90m\u001b[39;49;00m\n",
            "            output, h_ = model(ndl.Tensor(x, device=device), h)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                h0_, c0_ = h_\u001b[90m\u001b[39;49;00m\n",
            "                mugrade_submit(c0_.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                h0_ = h_\u001b[90m\u001b[39;49;00m\n",
            "            mugrade_submit(h0_.numpy())\u001b[90m\u001b[39;49;00m\n",
            "            mugrade_submit(output.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        device = ndl.cpu() \u001b[90m# TODO CHANGE BACK\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# device = ndl.cpu()\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        corpus = ndl.data.Corpus(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/ptb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, max_lines=\u001b[94m20\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        seq_len = \u001b[94m8\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        num_examples = \u001b[94m88\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        batch_size = \u001b[94m12\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        seq_model = \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        num_layers = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        hidden_size = \u001b[94m12\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_epochs=\u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        train_data = ndl.data.batchify(corpus.train, batch_size=batch_size, device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        model = LanguageModel(\u001b[94m28\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(corpus.dictionary), hidden_size=hidden_size, num_layers=num_layers,\u001b[90m\u001b[39;49;00m\n",
            "            seq_model=seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       train_acc, train_loss = train_ptb(model, train_data, seq_len=seq_len, n_epochs=n_epochs, device=device)\u001b[90m\u001b[39;49;00m\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:371: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mapps/simple_ml.py\u001b[0m:419: in train_ptb\n",
            "    \u001b[0mavg_acc, avg_loss = epoch_general_ptb(data, model, seq_len=seq_len,\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mapps/simple_ml.py\u001b[0m:335: in epoch_general_ptb\n",
            "    \u001b[0moutput, h = model(batch_data, h)\u001b[90m\u001b[39;49;00m\n",
            "                ^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:74: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mapps/models.py\u001b[0m:170: in forward\n",
            "    \u001b[0mx_emb = \u001b[96mself\u001b[39;49;00m.embedding(x)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:74: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_sequence.py\u001b[0m:452: in forward\n",
            "    \u001b[0memb = one_hot_reshaped @ \u001b[96mself\u001b[39;49;00m.weight  \u001b[90m# (1, embedding_dim)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:342: in __matmul__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:454: in compute\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m a @ b\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = NDArray([[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], device=cpu())\n",
            "other = NDArray([[ 0.35215408 -0.03489595  0.31612736 ...  0.2942371   0.32408518\n",
            "  -0.13565348]\n",
            " [-1.1058018  -0.9731328  -0....2\n",
            "   1.022028  ]\n",
            " [ 0.7260691  -0.31022093 -0.67203075 ...  0.42771512  0.79273224\n",
            "  -1.847698  ]], device=cpu_numpy())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__matmul__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, other: \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Matrix multplication of two arrays.  This requires that both arrays\u001b[39;49;00m\n",
            "    \u001b[33m    be 2D (i.e., we don't handle batch matrix multiplication), and that the\u001b[39;49;00m\n",
            "    \u001b[33m    sizes match up properly for matrix multiplication.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    In the case of the CPU backend, you will implement an efficient \"tiled\"\u001b[39;49;00m\n",
            "    \u001b[33m    version of matrix multiplication for the case when all dimensions of\u001b[39;49;00m\n",
            "    \u001b[33m    the array are divisible by self.device.__tile_size__.  In this case,\u001b[39;49;00m\n",
            "    \u001b[33m    the code below will restride and compact the matrix into tiled form,\u001b[39;49;00m\n",
            "    \u001b[33m    and then pass to the relevant CPU backend.  For the CPU version we will\u001b[39;49;00m\n",
            "    \u001b[33m    just fall back to the naive CPU implementation if the array shape is not\u001b[39;49;00m\n",
            "    \u001b[33m    a multiple of the tile size\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    The GPU (and numpy) versions don't have any tiled version (or rather,\u001b[39;49;00m\n",
            "    \u001b[33m    the GPU version will just work natively by tiling any input size).\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94massert\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.ndim == \u001b[94m2\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m other.ndim == \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94massert\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.shape[\u001b[94m1\u001b[39;49;00m] == other.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        m, n, p = \u001b[96mself\u001b[39;49;00m.shape[\u001b[94m0\u001b[39;49;00m], \u001b[96mself\u001b[39;49;00m.shape[\u001b[94m1\u001b[39;49;00m], other.shape[\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# if the matrix is aligned, use tiled matrix multiplication\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.device, \u001b[33m\"\u001b[39;49;00m\u001b[33mmatmul_tiled\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[95mand\u001b[39;49;00m \u001b[96mall\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "            d % \u001b[96mself\u001b[39;49;00m.device.__tile_size__ == \u001b[94m0\u001b[39;49;00m \u001b[94mfor\u001b[39;49;00m d \u001b[95min\u001b[39;49;00m (m, n, p)\u001b[90m\u001b[39;49;00m\n",
            "        ):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtile\u001b[39;49;00m(a, tile):\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m a.as_strided(\u001b[90m\u001b[39;49;00m\n",
            "                    (a.shape[\u001b[94m0\u001b[39;49;00m] // tile, a.shape[\u001b[94m1\u001b[39;49;00m] // tile, tile, tile),\u001b[90m\u001b[39;49;00m\n",
            "                    (a.shape[\u001b[94m1\u001b[39;49;00m] * tile, tile, a.shape[\u001b[94m1\u001b[39;49;00m], \u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "            t = \u001b[96mself\u001b[39;49;00m.device.__tile_size__\u001b[90m\u001b[39;49;00m\n",
            "            a = tile(\u001b[96mself\u001b[39;49;00m.compact(), t).compact()\u001b[90m\u001b[39;49;00m\n",
            "            b = tile(other.compact(), t).compact()\u001b[90m\u001b[39;49;00m\n",
            "            out = NDArray.make((a.shape[\u001b[94m0\u001b[39;49;00m], b.shape[\u001b[94m1\u001b[39;49;00m], t, t), device=\u001b[96mself\u001b[39;49;00m.device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mself\u001b[39;49;00m.device.matmul_tiled(a._handle, b._handle, out._handle, m, n, p)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m (\u001b[90m\u001b[39;49;00m\n",
            "                out.permute((\u001b[94m0\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "                .compact()\u001b[90m\u001b[39;49;00m\n",
            "                .reshape((\u001b[96mself\u001b[39;49;00m.shape[\u001b[94m0\u001b[39;49;00m], other.shape[\u001b[94m1\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            "            )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            out = NDArray.make((m, p), device=\u001b[96mself\u001b[39;49;00m.device)\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[96mself\u001b[39;49;00m.device.matmul(\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[96mself\u001b[39;49;00m.compact()._handle, other.compact()._handle, out._handle, m, n, p\u001b[90m\u001b[39;49;00m\n",
            "            )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           TypeError: matmul(): incompatible function arguments. The following argument types are supported:\u001b[0m\n",
            "\u001b[1m\u001b[31mE               1. (arg0: needle.backend_ndarray.ndarray_backend_cpu.Array, arg1: needle.backend_ndarray.ndarray_backend_cpu.Array, arg2: needle.backend_ndarray.ndarray_backend_cpu.Array, arg3: typing.SupportsInt, arg4: typing.SupportsInt, arg5: typing.SupportsInt) -> None\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Invoked with: <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x7e84331220b0>, <needle.backend_ndarray.ndarray_backend_numpy.Array object at 0x7e843311a9c0>, <needle.backend_ndarray.ndarray_backend_cpu.Array object at 0x7e8433121f70>, 1, 381, 28\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:640: TypeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1msubmit_language_model\u001b[0m - TypeError: matmul(): incompatible function arguments. The following argumen...\n",
            "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 6.45s\u001b[0m\u001b[31m ========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"language_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myjjNnSonJnr"
      },
      "source": [
        "Now, you can train your language model on the Penn Treebank dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "QCx173VvnJnr",
        "outputId": "0c7a8948-0932-4a43-e38c-b0b414faff38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'Tensor' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1693303832.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rnn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_ptb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mevaluate_ptb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/apps/simple_ml.py\u001b[0m in \u001b[0;36mtrain_ptb\u001b[0;34m(model, data, seq_len, n_epochs, optimizer, lr, weight_decay, loss_fn, clip, device, dtype)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mloss_fn_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         avg_acc, avg_loss = epoch_general_ptb(data, model, seq_len=seq_len, \n\u001b[1;32m    420\u001b[0m                                                \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/apps/simple_ml.py\u001b[0m in \u001b[0;36mepoch_general_ptb\u001b[0;34m(data, model, seq_len, loss_fn, opt, clip, device, dtype)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# output shape: (seq_len * batch_size, output_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# batch_target shape: (seq_len * batch_size,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/nn/nn_basic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/apps/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m### BEGIN YOUR SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Embedding: (seq_len, bs) -> (seq_len, bs, embedding_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mx_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# Sequence model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/nn/nn_basic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/10714/hw4/python/needle/nn/nn_sequence.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mx_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_len * bs,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;31m# For each index, create one-hot and multiply with weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "import needle as ndl\n",
        "sys.path.append('./apps')\n",
        "from models import LanguageModel\n",
        "from simple_ml import train_ptb, evaluate_ptb\n",
        "\n",
        "device = ndl.cpu()\n",
        "corpus = ndl.data.Corpus(\"data/ptb\")\n",
        "train_data = ndl.data.batchify(corpus.train, batch_size=16, device=ndl.cpu(), dtype=\"float32\")\n",
        "model = LanguageModel(30, len(corpus.dictionary), hidden_size=10, num_layers=2, seq_model='rnn', device=ndl.cpu())\n",
        "train_ptb(model, train_data, seq_len=1, n_epochs=1, device=device)\n",
        "evaluate_ptb(model, train_data, seq_len=40, device=device)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}